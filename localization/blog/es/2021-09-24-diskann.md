---
id: 2021-09-24-diskann.md
title: >-
  DiskANN, una solución ANNS basada en disco con alta recuperación y alto QPS en
  un conjunto de datos a escala de miles de millones.
author: Zilliz
date: 2021-09-24T00:00:00.000Z
desc: >-
  Lectura en papel con los ingenieros de Zilliz para saber más sobre el
  rendimiento de DiskANN en un conjunto de datos a escala de miles de millones.
cover: assets.zilliz.com/medium_1_10cebc1e50.png
tag: Engineering
---
<custom-h1>DiskANN: Una Solución ANNS Basada en Disco con Alta Recuperación y Alto QPS en un Conjunto de Datos a Escala de Mil Millones</custom-h1><blockquote>
<p>Chengming Li, Ingeniero de I+D de Zilliz, se licenció en Informática por la SouthEast University. Su interés actual se centra en los problemas de ANNS en datos de alta dimensión, incluyendo soluciones basadas en grafos y cuantificación.</p>
</blockquote>
<p>"DiskANN: Fast Accurate Billion-point Nearest Neighbor Search on a Single Node" es un artículo publicado en NeurIPS en 2019. El documento presenta un método de vanguardia para realizar la construcción de índices y la búsqueda en el conjunto de datos a escala de mil millones utilizando una sola máquina con solo 64 GB de RAM y un SSD lo suficientemente grande. Además, satisface los tres requisitos de ANNS (Approximate Nearest Neighbor Search) en el conjunto de datos a gran escala: alta recuperación, baja latencia y alta densidad (número de nodos en una sola máquina). Este método construye un índice basado en grafos en un conjunto de datos a gran escala de miles de millones de SIFT-1B utilizando una sola máquina con 64 GB de RAM y una CPU de 16 núcleos, alcanzando 5000 QPS (consultas por segundo) con más del 95 % de recall@1, y una latencia media inferior a 3 ms.</p>
<h2 id="Authors" class="common-anchor-header">Autores<button data-href="#Authors" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p><strong>Suhas Jayaram Subramanya</strong>: Antiguo empleado del Instituto de Investigación de Microsoft India, estudiante de doctorado de la CMU. Sus principales intereses de investigación son la informática de alto rendimiento y los algoritmos de aprendizaje automático para datos a gran escala.</p>
<p><strong>Devvrit</strong>: Asistente de investigación de posgrado en la Universidad de Texas en Austin. Sus intereses de investigación son la informática teórica, el aprendizaje automático y el aprendizaje profundo.</p>
<p><strong>Rohan Kadekodi</strong>: Estudiante de doctorado en la Universidad de Texas. Su dirección de investigación es el sistema y el almacenamiento, incluyendo principalmente el almacenamiento persistente, el sistema de archivos y el almacenamiento kV.</p>
<p><strong>Ravishankar Krishaswamy</strong>: Investigador principal del instituto de investigación indio de Microsoft. Doctor por la CMU. La dirección de investigación es el algoritmo de aproximación basado en grafos y clustering.</p>
<p><strong>Harsha Vardhan Simhadri</strong>: Investigador principal del instituto de investigación indio de Microsoft. Doctor por la CMU. En el pasado estudió algoritmos paralelos y sistemas en tiempo de ejecución. Ahora su principal trabajo es desarrollar nuevos algoritmos y escribir modelos de programación.</p>
<h2 id="Motivations" class="common-anchor-header">Motivaciones<button data-href="#Motivations" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>La mayoría de los principales algoritmos de ANNS hacen concesiones entre el rendimiento de la creación de índices, el rendimiento de la búsqueda y la recuperación. Los algoritmos basados en grafos, como HNSW y NSG, son actualmente los métodos más avanzados en términos de rendimiento de búsqueda y recuperación. Dado que el método de indexación basado en grafos residentes en memoria ocupa demasiada memoria, es relativamente difícil indexar y buscar en un conjunto de datos a gran escala utilizando una sola máquina con recursos de memoria limitados.</p>
<p>Muchas aplicaciones requieren respuestas rápidas de los RNA basados en la distancia euclidiana en el conjunto de datos a escala de miles de millones. A continuación se presentan dos soluciones principales:</p>
<ol>
<li>Índice invertido + cuantización: agrupar el conjunto de datos en M particiones y comprimir el conjunto de datos utilizando esquemas de cuantización como PQ (Product Quantization). Esta solución produce una baja recuperación debido a la pérdida de precisión causada por la compresión de los datos. Aumentar el topk ayuda a mejorar la recuperación, mientras que el QPS disminuiría en consecuencia.</li>
<li>Dividir e indexar: dividir el conjunto de datos en varios fragmentos independientes y crear un índice en memoria para cada fragmento. Cuando lleguen las solicitudes de consulta, la búsqueda se realizará en los índices de cada fragmento y los resultados se devolverán tras la fusión. Esta solución provoca la sobreexpansión de la escala del conjunto de datos, por lo que se necesitan más máquinas debido a la restricción de recursos de memoria en una sola máquina, lo que conduce a un QPS bajo.</li>
</ol>
<p>Ambas soluciones mencionadas anteriormente están limitadas por la restricción de memoria de una sola máquina. Este artículo propone el diseño de un mecanismo de indexación residente en SSD para resolver este problema. El reto de la indexación residente en SSD es reducir el número de accesos aleatorios al disco y el número de peticiones de acceso al disco.</p>
<h2 id="Contributions" class="common-anchor-header">Aportaciones<button data-href="#Contributions" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Este artículo presenta un esquema ANNS residente en SSD llamado DiskANN, que puede soportar de forma efectiva la búsqueda en conjuntos de datos a gran escala. Este esquema se basa en un algoritmo basado en grafos que se presenta en este trabajo: Vamana. Entre las aportaciones de este trabajo se incluyen:</p>
<ol>
<li>DiskANN puede indexar y buscar en un conjunto de datos a escala de miles de millones de dimensiones en una sola máquina con 64 GB de RAM, proporcionando más de un 95% de recall@1 con latencias inferiores a 5 milisegundos.</li>
<li>Se propuso un nuevo algoritmo basado en grafos llamado Vamana con un radio de búsqueda menor que los de NSG y HNSW para minimizar el número de accesos al disco.</li>
<li>Vamana puede trabajar en memoria y su rendimiento no es inferior al de NSG y HNSW.</li>
<li>Los índices Vamana más pequeños construidos sobre particiones solapadas del gran conjunto de datos pueden fusionarse en un solo grafo sin perder conectividad.</li>
<li>Vamana puede combinarse con esquemas de cuantificación como PQ. La estructura del grafo y los datos originales se almacenan en el disco, mientras que los datos comprimidos se guardan en la memoria.</li>
</ol>
<h2 id="Vamana" class="common-anchor-header">Vamana<button data-href="#Vamana" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Este algoritmo es similar a la idea de NSG[2][4] (para los que no entiendan NSG, pueden consultar la Referencia [2], y si no quieren leer papers, pueden consultar la Referencia [4]). Su principal diferencia radica en la estrategia de recorte. Para ser precisos, se ha añadido un interruptor alfa a la estrategia de recorte de la NSG. La idea principal de la estrategia de recorte de la NSG es que la elección de los vecinos del punto objetivo sea lo más diversa posible. Si el nuevo vecino está más cerca de un vecino del punto objetivo que del punto objetivo, no necesitamos añadir este punto al conjunto de puntos vecinos. En otras palabras, para cada vecino del punto objetivo, no puede haber otros puntos vecinos dentro del radio circundante dist (punto objetivo, punto vecino). Esta estrategia de recorte controla eficazmente el grado de salida del gráfico y es relativamente radical. Reduce la huella de memoria del índice, mejora la velocidad de búsqueda, pero también reduce la precisión de la búsqueda. La estrategia de recorte de Vamana consiste en controlar libremente la escala de recorte mediante el parámetro alfa. El principio de funcionamiento consiste en multiplicar la dist (punto vecino, punto candidato) en la condición de recorte por un parámetro alfa (no inferior a 1). Sólo cuando la dist (punto objetivo, cierto punto candidato) es mayor que la distancia de referencia ampliada se adopta la estrategia de recorte, aumentando la tolerancia de exclusión mutua entre vecinos del punto objetivo.</p>
<p>El proceso de indexación de Vamana es relativamente sencillo:</p>
<ol>
<li>Inicializar un grafo aleatorio;</li>
<li>Calcular el punto de partida, que es similar al punto de navegación de NSG. En primer lugar, encontrar el centroide global y, a continuación, encontrar el punto más cercano al centroide global como punto de navegación. La diferencia entre Vamana y NSG es que la entrada de NSG ya es un grafo de vecinos más cercanos, por lo que los usuarios pueden simplemente hacer una búsqueda aproximada de vecinos más cercanos en el punto centroide directamente en el grafo de vecinos inicial. Sin embargo, Vamana inicializa un grafo de vecinos más cercanos aleatorio, por lo que los usuarios no pueden realizar una búsqueda aproximada directamente en el grafo aleatorio. Necesitan realizar una comparación global para obtener un punto de navegación como punto de partida de las iteraciones posteriores. El objetivo de este punto es minimizar el radio medio de búsqueda;</li>
<li>Realizar la Búsqueda Aproximada del Vecino más Cercano en cada punto basándose en el grafo aleatorio de vecinos inicializado y en el punto de inicio de la búsqueda determinado en el paso 2, hacer que todos los puntos de la ruta de búsqueda sean los conjuntos de vecinos candidatos y ejecutar la estrategia de recorte de aristas utilizando alfa = 1. Al igual que en NSG, la selección del conjunto de puntos en la ruta de búsqueda a partir del punto de navegación como el conjunto de vecinos candidatos aumentará algunos bordes largos y reducirá eficazmente el radio de búsqueda.</li>
<li>Ajuste alfa &gt; 1 (el documento recomienda 1,2) y repita el paso 3. Considerando que el paso 3 se basa en un grafo de vecino más cercano aleatorio, el grafo es de baja calidad después de la primera iteración. Por lo tanto, se necesita otra iteración para mejorar la calidad del gráfico, que es muy importante para la tasa de recuperación.</li>
</ol>
<p>En este artículo se comparan tres índices de grafos: Vamana, NSG y HNSW. En términos de rendimiento de indexación y consulta, Vamana y NSG están relativamente cerca, y ambos superan ligeramente a HNSW. Los datos figuran en la sección "Experimentos".</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/2_906f6a4def.png" alt="2.png" class="doc-image" id="2.png" />
   </span> <span class="img-wrapper"> <span>2.png</span> </span></p>
<p>Para visualizar el proceso de construcción del índice Vamana, el artículo presenta un gráfico en el que se utilizan 200 puntos bidimensionales para simular dos rondas de iteración. En la primera fila se utiliza alfa = 1 para recortar los bordes. Se puede observar que la estrategia de recorte es relativamente radical, y se recorta un gran número de aristas. Tras aumentar el valor de alfa y relajar las condiciones de recorte, obviamente se vuelven a añadir muchas aristas. En el gráfico final, se añaden bastantes aristas largas. Puede reducir eficazmente el radio de búsqueda.</p>
<h2 id="DiskANN" class="common-anchor-header">DiskANN<button data-href="#DiskANN" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Un ordenador personal con sólo 64 GB de memoria no podría albergar ni mil millones de datos en bruto, por no hablar del índice construido a partir de ellos. Hay dos retos por delante: 1. ¿Cómo indexar un conjunto de datos tan grande con recursos de memoria limitados? 2. ¿Cómo calcular la distancia en la búsqueda si los datos originales no pueden cargarse en memoria?</p>
<p>El documento propone las siguientes soluciones:</p>
<ol>
<li>Para el primer reto: en primer lugar, dividir los datos en k clusters mediante k-means y, a continuación, asignar cada punto a los i clusters más cercanos. Generalmente, 2 es suficiente para el número i. Construir un índice Vamana basado en memoria para cada cluster, y finalmente fusionar k índices Vamana en uno.</li>
<li>Para el segundo reto: construir índices sobre los vectores originales y consultar los vectores comprimidos. Construir índices sobre el vector original garantiza la calidad del gráfico, mientras que el vector comprimido puede cargarse en la memoria para realizar búsquedas de grano grueso. Aunque la búsqueda con los vectores comprimidos puede provocar una pérdida de precisión, la dirección general será correcta siempre que la calidad del grafo sea lo suficientemente alta. El resultado final de la distancia se calculará utilizando el vector original.</li>
</ol>
<p>La disposición de los índices de DiskANN es similar a la de los índices de grafos generales. El conjunto de vecinos de cada punto y los datos del vector original se almacenan juntos. De este modo se aprovecha mejor la localidad de los datos.</p>
<p>Como se mencionó anteriormente, si los datos del índice se almacenan en el SSD, el número de accesos al disco y las solicitudes de lectura y escritura del disco deben reducirse tanto como sea posible para garantizar un bajo retardo en la búsqueda. Por lo tanto, DiskANN propone dos estrategias de optimización:</p>
<ol>
<li>Cache hotspot: almacenar en caché todos los puntos dentro de los saltos C desde el punto inicial en memoria. El valor de C se fija mejor entre 3 y 4.</li>
<li>Búsqueda por haces: En pocas palabras, se trata de precargar la información de los vecinos. Cuando se busca un punto p, el punto vecino de p debe cargarse desde el disco si no está en memoria. Dado que una pequeña operación de acceso aleatorio SSD tarda aproximadamente el mismo tiempo que una operación de acceso a un único sector SSD, se puede cargar a la vez la información vecina de W puntos no accedidos. W no puede ser demasiado grande ni demasiado pequeño. Una W grande desperdiciará recursos informáticos y ancho de banda SSD, mientras que una pequeña aumentará el retraso de la búsqueda.</li>
</ol>
<h2 id="Experiment" class="common-anchor-header">Experimento<button data-href="#Experiment" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>El experimento consta de tres grupos:</p>
<h4 id="Comparison-among-memory-based-indexes-Vamana-VS-NSG-VS-HNSW" class="common-anchor-header">Comparación entre índices basados en memoria: Vamana VS. NSG VS. HNSW</h4><p>Conjuntos de datos: SIFT1M (128 dimensiones), GIST1M (960 dimensiones), DEEP1M (96 dimensiones) y un conjunto de datos de 1M extraído aleatoriamente de DEEP1B.</p>
<p>Parámetros del índice (todos los conjuntos de datos utilizan el mismo conjunto de parámetros):</p>
<p>HNSW：M = 128, efc = 512.</p>
<p>Vamana: R = 70, L = 75, alfa = 1,2.</p>
<p>NSG: R = 60, L = 70, C= 500.</p>
<p>En el documento no se facilitan los parámetros de búsqueda, que pueden coincidir con los de indexación. Para la selección de parámetros, los parámetros de NSG mencionados en el artículo se basan en los parámetros listados en el repositorio GitHub de NSG para seleccionar el grupo con mejor rendimiento. Vamana y NSG están relativamente cerca, por lo que los parámetros también se establecen cerca. Sin embargo, no se indica la razón de la selección de los parámetros de HNSW. Creemos que el parámetro M de HNSW es relativamente grande. La comparación entre índices basados en grafos podría resultar menos convincente si sus grados de salida no se fijan al mismo nivel.</p>
<p>Con los parámetros de indexación anteriores, el tiempo de indexación de Vamana, HNSW y NSG es de 129s, 219s y 480s respectivamente. El tiempo de indexación de NSG incluye el tiempo de construcción del grafo vecino inicial con EFANN [3].</p>
<p>Curva Recall-QPS:</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/3_dcdb9452ca.png" alt="3.png" class="doc-image" id="3.png" />
   </span> <span class="img-wrapper"> <span>3.png</span> </span></p>
<p>Se puede observar en la Figura 3 que Vamana tiene un rendimiento excelente en los tres conjuntos de datos, similar al de NSG y ligeramente mejor que HNSW.</p>
<p>Comparación del radio de búsqueda:</p>
<p>En la figura 2.c, podemos ver que Vamana tiene el radio de búsqueda medio más corto con el mismo índice de recuperación que NSG y HNSW.</p>
<h4 id="Comparison-between-a-one-time-built-index-and-a-large-merged-index" class="common-anchor-header">Comparación entre un índice construido una sola vez y un gran índice fusionado</h4><p>Conjunto de datos: SIFT1B</p>
<p>Parámetros del índice construido una sola vez: L = 50, R = 128, alfa = 1,2. Tras 2 días de funcionamiento en una máquina DDR3 de 1800 G, el pico de memoria es de unos 1100 G, y el grado medio de salida es de 113,9.</p>
<p>Procedimiento de indexación basado en la fusión:</p>
<ol>
<li>Entrenar 40 clusters en el conjunto de datos utilizando kmeans;</li>
<li>Cada punto se distribuye en los 2 clusters más cercanos;</li>
<li>Construir un índice Vamana con L = 50, R = 64 y alfa = 1,2 para cada clúster;</li>
<li>Fusionar los índices de cada clúster.</li>
</ol>
<p>Este índice generó un índice de 384 GB con una media de fuera de grado de 92,1. Este índice se ejecutó durante 5 días en una máquina DDR4 de 64 GB.</p>
<p>Los resultados de la comparación son los siguientes (Figura 2a): 
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/4_ea421b98c3.png" alt="4.png" class="doc-image" id="4.png" />
   </span> <span class="img-wrapper"> <span>4.png</span> </span></p>
<p>En conclusión:</p>
<ol>
<li>El índice construido una sola vez es significativamente mejor que el índice basado en la fusión;</li>
<li>El índice basado en la fusión también es excelente;</li>
<li>El esquema de indexación basado en la fusión también es aplicable al conjunto de datos DEEP1B (Figura 2b).</li>
</ol>
<h4 id="Disk-based-index-DiskANN-VS-FAISS-VS-IVF-OADC+G+P" class="common-anchor-header">Índice basado en disco: DiskANN VS. FAISS VS. IVF-OADC+G+P</h4><p>IVFOADC+G+P es un algoritmo propuesto en la Referencia [5].</p>
<p>Este documento sólo compara DiskANN con IVFOADC+G+P, ya que la referencia [5] ha demostrado que IVFOADC+G+P es mejor que FAISS. Además, FAISS requiere recursos de GPU, que no son compatibles con todas las plataformas.</p>
<p>IVF-OADC+G+P parece ser una combinación de HNSW e IVF-PQ. Determina los clusters utilizando HNSW y realiza la búsqueda añadiendo algunas estrategias de poda al cluster objetivo.</p>
<p>El resultado se muestra en la figura 2a. Los 16 y 32 de la figura son el tamaño del libro de códigos. El conjunto de datos es SIFT1B, cuantificado por OPQ.</p>
<h4 id="Code-implementation-details" class="common-anchor-header">Detalles de la implementación del código</h4><p>El código fuente de DiskANN es de código abierto en https://github.com/microsoft/DiskANN.</p>
<p>En enero de 2021, el código fuente de la solución de disco fue de código abierto.</p>
<p>A continuación se presenta principalmente el proceso de indexación y el proceso de búsqueda.</p>
<p><strong>Construcción del índice</strong></p>
<p>Existen 8 parámetros para crear un índice:</p>
<p>data_type: las opciones incluyen float/int8/uint8.</p>
<p>archivo_datos.bin: El archivo binario de datos original. Los dos primeros enteros del archivo representan respectivamente el número total n del vector del conjunto de datos y la dimensión dim del vector. Los últimos n bytes <em>dim</em> sizeof(data_type) son datos vectoriales continuos.</p>
<p>index_prefix_path: El prefijo de la ruta del archivo de salida. Una vez construido el índice, se generarán varios archivos relacionados con el índice. Este parámetro es el prefijo común del directorio donde se almacenan.</p>
<p>R: El grado máximo de salida del índice global.</p>
<p>L: El parámetro L del índice Vamana, el límite superior del tamaño del conjunto de candidatos.</p>
<p>B: El umbral de memoria en la consulta. Controla el tamaño del libro de códigos PQ, en GB.</p>
<p>M: El umbral de memoria cuando se construye un índice. Determina el tamaño del fragmento, en GB.</p>
<p>T: El número de hilos.</p>
<p>Proceso de indexación (función de entrada: aux_utils.cpp::build_disk_index):</p>
<ol>
<li>Genera varios nombres de ficheros de salida según index_prefix_path.</li>
<li>Comprobación de parámetros.</li>
<li>Leer la meta de data_file.bin para obtener n y dim. Determinar el subespacio de libro de códigos número m de PQ según B y n.</li>
<li>generar_pq_pivotes: Muestrea el punto central del conjunto de entrenamiento PQ usando la tasa de muestreo de p = 1500000/n uniformemente para entrenar PQ globalmente.</li>
<li>generate_pq_data_from_pivots: Genera un libro de códigos PQ global y guarda el punto central y el libro de códigos por separado.</li>
<li>build_merged_vamana_index: trocea el conjunto de datos original, construye índices Vamana en segmentos, y finalmente fusiona los índices en uno.</li>
</ol>
<ul>
<li>partition_with_ram_budget: Determinar el número de fragmentos k en función del parámetro M. Muestrear el conjunto de datos mediante kmeans, distribuyendo cada punto en dos clusters más cercanos. Fragmente el conjunto de datos, y cada fragmento produce dos archivos: un archivo de datos y un archivo de ID. El archivo ID y el archivo de datos se corresponden entre sí, y cada ID del archivo ID corresponde a un vector del archivo de datos. Los ID se obtienen numerando cada vector de los datos originales de 0 a n-1. El ID es relativamente importante y está relacionado con la fusión.<ul>
<li>Muestrear globalmente de forma uniforme el conjunto de entrenamiento con una tasa de muestreo de 1500000 / n;</li>
<li>Inicializar num_parts = 3. Iterar desde 3:<ul>
<li>Hacer num_parts-means++ en el conjunto de entrenamiento en el paso i;</li>
<li>Utilice una tasa de muestreo de 0,01 para muestrear un conjunto de prueba de manera uniforme a nivel mundial, y dividir el conjunto de prueba en los 2 clusters más cercanos;</li>
<li>Contar el número de puntos en cada cluster y dividirlo por la tasa de muestreo para estimar el número de puntos en cada cluster;</li>
<li>Estimar la memoria requerida por el cluster más grande en el paso 3 de acuerdo con el tamaño del índice Vamana, si no excede el parámetro M, ir al paso iii, de lo contrario num_parts ++ volver al paso 2;</li>
</ul></li>
<li>Dividir el conjunto de datos original en archivos de grupo num_parts, cada grupo de archivos incluye archivos de datos fragmentados y archivos ID correspondientes a los datos fragmentados.</li>
</ul></li>
<li>Cree índices Vamana por separado para todos los fragmentos del paso a y guárdelos en el disco;</li>
<li>merge_shards: fusionar num_parts shard Vamana en un índice global:<ul>
<li>Leer el archivo ID de num_parts fragmentos en idmap. Este idmap equivale a establecer un mapeo hacia adelante de fragmento-&gt;id;</li>
<li>Establecer un mapeo inverso de id-&gt;fragmentos según idmap, y saber en qué dos fragmentos está cada vector;</li>
<li>Utilizar un lector con 1GB de caché para abrir los índices de num_parts slice Vamana, y utilizar un escritor con 1GB de caché para abrir el archivo de salida, listo para fusionar;</li>
<li>Colocar num_parts puntos de navegación de índice Vamana en el archivo de punto central, que se utilizará en la búsqueda;</li>
<li>Empezar a fusionar según ID de pequeño a grande, leer el conjunto de puntos vecinos de cada vector original en cada fragmento por turnos según el mapeado inverso, deduplicar, barajar, truncar y escribir en el fichero de salida. Debido a que el troceado se ordenó originalmente de forma global, y ahora la fusión también está ordenada, por lo que el ID en el índice final volcado y el ID de los datos originales tienen una correspondencia uno a uno.</li>
<li>Elimine los archivos temporales, incluidos los archivos de fragmentos, los índices de fragmentos y los archivos de ID de fragmentos.</li>
</ul></li>
</ul>
<ol start="7">
<li><p>crear_disposición_disco: El índice global generado en el paso 6 sólo tiene una tabla de adyacencia compacta. Este paso sirve para alinear el índice. La tabla de adyacencia y los datos originales se almacenan juntos. Al buscar, cargue la tabla de adyacencia y lea el vector original juntos para calcular la distancia con precisión. También existe el concepto de SECTOR, cuyo tamaño por defecto es de 4096. Cada SECTOR sólo contiene 4096 / node_size piezas de información vectorial. node_size = tamaño de vector único + tamaño de tabla de adyacencia de nodo único.</p></li>
<li><p>Por último, hacer un muestreo uniforme global de 150000 / n, guardarlo, y utilizarlo para el calentamiento en la búsqueda.</p></li>
</ol>
<p><strong>Búsqueda</strong></p>
<p>Hay 10 parámetros de búsqueda:</p>
<ul>
<li>tipo_índice: Las opciones incluyen Float/int8/uint8, similar al primer parámetro data_type cuando se construye un índice.</li>
<li>index_prefix_path: Consulte el parámetro index_prefix_path.</li>
<li>num_nodes_to_cache: Número de puntos calientes de la caché.</li>
<li>num_threads: Número de hilos de búsqueda.</li>
<li>beamwidth: Límite superior del número de puntos de precarga. El sistema determina si está a 0.</li>
<li>archivo_consulta.bin: Archivo del conjunto de consultas.</li>
<li>truthset.bin: Fichero del conjunto de resultados, "null" significa que no se proporciona el conjunto de resultados, el programa lo calcula por sí mismo;</li>
<li>K: topk;</li>
<li>result_output_prefix: Ruta para guardar los resultados de la búsqueda;</li>
<li>L*: Lista de parámetros de búsqueda. Se pueden añadir varios valores. Para cada L, se dará información estadística al buscar con diferentes L.</li>
</ul>
<p>Proceso de búsqueda:</p>
<ol>
<li>Cargar los datos relacionados: cargar el conjunto de consultas, los datos del punto central PQ, los datos del libro de códigos, el punto de inicio de la búsqueda y otros datos, y leer el índice meta.</li>
<li>Utilizar el conjunto de datos muestreados durante la indexación para hacer cached_beam_search, contar los tiempos de acceso de cada punto y cargar num_nodes_to_cache los puntos con mayor frecuencia de acceso a la caché.</li>
<li>Hay una operación WARMUP por defecto. Al igual que en el paso 2, este conjunto de datos de muestra también se utiliza para realizar una búsqueda_beam_en_cache.</li>
<li>Según el número de parámetros L indicados, cada L se ejecutará con cached_beam_search de nuevo con el conjunto de consultas, y se obtendrán estadísticas como la tasa de recuperación y el QPS. El proceso de calentamiento y los datos estadísticos de los puntos calientes no se contabilizan en el tiempo de consulta.</li>
</ol>
<p>Acerca de cached_beam_search:</p>
<ol>
<li>Busca el candidato más cercano al punto de consulta desde el punto de partida del candidato. Aquí se utiliza la distancia PQ, y el punto de partida se añade a la cola de búsqueda.</li>
<li>Iniciar la búsqueda:</li>
</ol>
<ul>
<li>A partir de la cola de búsqueda, no hay más de beam_width + 2 puntos sin visitar. Si estos puntos están en la caché, añádalos a la cola de aciertos de la caché. Si no están en la caché, añádalos a la cola de errores. Asegúrese de que el tamaño de la cola de errores no supera el ancho del haz.</li>
<li>Envía peticiones asíncronas de acceso al disco a los puntos de la cola de errores.</li>
<li>Para los puntos alcanzados por la caché, utilice los datos originales y los datos de la consulta para calcular la distancia exacta, añádalos a la cola de resultados y, a continuación, utilice PQ para calcular la distancia a los puntos vecinos que no se han visitado antes de añadirlos a la cola de búsqueda. La longitud de la cola de búsqueda está limitada por parámetros.</li>
<li>Procesa los puntos perdidos en caché en el paso a, de forma similar al paso c.</li>
<li>Cuando la cola de búsqueda está vacía, la búsqueda finaliza y se devuelve la cola de resultados topk.</li>
</ul>
<h4 id="Summarize" class="common-anchor-header">Resumir</h4><p>Aunque se trata de un trabajo relativamente largo, en general es excelente. Las ideas del trabajo y del código son claras: dividir un número de cubos superpuestos mediante k-means, y luego dividir los cubos para construir un índice de mapa, y finalmente fusionar los índices, que es una idea relativamente nueva. En cuanto al índice de grafos basado en memoria Vamana, se trata esencialmente de una versión de NSG inicializada aleatoriamente que puede controlar la granularidad del recorte. Al realizar consultas, aprovecha al máximo la caché + pipeline, cubre parte del tiempo de io y mejora el QPS. Sin embargo, según el artículo, incluso si las condiciones de la máquina no son extraordinarias, el tiempo de entrenamiento es de hasta 5 días, y la usabilidad es relativamente baja. En el futuro será necesario optimizar el entrenamiento. Desde el punto de vista del código, la calidad es relativamente alta y puede utilizarse directamente en el entorno de producción.</p>
<h4 id="References" class="common-anchor-header">Referencias</h4><ol>
<li><a href="https://www.microsoft.com/en-us/research/publication/diskann-fast-accurate-billion-point-nearest-neighbor-search-on-a-single-node/">Suhas Jayaram Subramanya, Fnu Devvrit, Harsha Vardhan Simhadri, Ravishankar Krishnawamy, Rohan Kadekodi. DiskANN: Búsqueda rápida y precisa de miles de millones de puntos de vecinos más cercanos en un solo nodo. NeurIPS 2019.</a></li>
<li>[Cong Fu, Chao Xiang, Changxu Wang y Deng Cai. Búsqueda rápida aproximada de vecino más cercano con los gráficos de dispersión de navegación. PVLDB, 12(5):461 - 474, 2019. doi: 10.14778/3303753.3303754]. (http://www.vldb.org/pvldb/vol12/p461-fu.pdf)</li>
<li>Cong Fu y Deng Cai. <a href="https://github.com/ZJULearning/efanna">GitHub - ZJULearning/efanna: biblioteca rápida para la búsqueda de RNA y la construcción de gráficos KNN.</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/50143204">Motor de búsqueda para AI：高维数据检索工业级解决方案</a></li>
</ol>
<p>5.<a href="https://arxiv.org/abs/1802.02422"> Dmitry Baranchuk, Artem Babenko y Yury Malkov. Revisiting the inverted indices for billion-scale approximate nearest neighbors.</a></p>
