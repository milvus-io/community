---
id: >-
  langchain-and-milvus-build-production-ready-agents-with-real-long-term-memory.md
title: >-
  LangChain 1.0 y Milvus: c√≥mo crear agentes listos para la producci√≥n con
  memoria a largo plazo real
author: Min Yin
date: 2025-12-19T00:00:00.000Z
cover: assets.zilliz.com/langchain1_0_cover_8c4bc608af.png
tag: Tutorials
recommend: false
publishToMedium: true
tags: 'Milvus, vector database'
meta_keywords: 'Milvus, LangChain 1.0, AI Agent, vector database, LangGraph'
meta_title: >
  LangChain 1.0 and Milvus: Build Production-Ready AI Agents with Long-Term
  Memory
desc: >-
  Descubra c√≥mo LangChain 1.0 simplifica la arquitectura de agentes y c√≥mo
  Milvus a√±ade memoria a largo plazo para aplicaciones de IA escalables y listas
  para la producci√≥n.
origin: >-
  https://milvus.io/blog/langchain-and-milvus-build-production-ready-agents-with-real-long-term-memory.md
---
<p>LangChain es un popular marco de c√≥digo abierto para el desarrollo de aplicaciones basadas en grandes modelos ling√º√≠sticos (LLM). Proporciona un conjunto de herramientas modulares para crear agentes que razonen y utilicen herramientas, conectar modelos a datos externos y gestionar flujos de interacci√≥n.</p>
<p>Con el lanzamiento de <strong>LangChain 1.0</strong>, el marco da un paso hacia una arquitectura m√°s f√°cil de producir. La nueva versi√≥n sustituye el dise√±o anterior basado en cadenas por un bucle ReAct estandarizado (Razonar ‚Üí Llamar a la herramienta ‚Üí Observar ‚Üí Decidir) e introduce middleware para gestionar la ejecuci√≥n, el control y la seguridad.</p>
<p>Sin embargo, el razonamiento por s√≠ solo no es suficiente. Los agentes tambi√©n necesitan la capacidad de almacenar, recuperar y reutilizar informaci√≥n. Ah√≠ es donde <a href="https://milvus.io/"><strong>Milvus</strong></a>, una base de datos vectorial de c√≥digo abierto, puede desempe√±ar un papel esencial. Milvus proporciona una capa de memoria escalable y de alto rendimiento que permite a los agentes almacenar, buscar y recuperar informaci√≥n de forma eficiente a trav√©s de la similitud sem√°ntica.</p>
<p>En este post, exploraremos c√≥mo LangChain 1.0 actualiza la arquitectura de agentes y c√≥mo la integraci√≥n de Milvus ayuda a los agentes a ir m√°s all√° del razonamiento, permitiendo una memoria persistente e inteligente para casos de uso del mundo real.</p>
<h2 id="Why-the-Chain-based-Design-Falls-Short" class="common-anchor-header">Por qu√© el dise√±o basado en cadenas se queda corto<button data-href="#Why-the-Chain-based-Design-Falls-Short" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>En sus primeros d√≠as (versi√≥n 0.x), la arquitectura de LangChain se centraba en Cadenas. Cada Cadena defin√≠a una secuencia fija y ven√≠a con plantillas pre-construidas que hac√≠an la orquestaci√≥n LLM simple y r√°pida. Este dise√±o era genial para construir prototipos r√°pidamente. Pero a medida que el ecosistema LLM evolucionaba y los casos de uso en el mundo real se hac√≠an m√°s complejos, empezaron a aparecer grietas en esta arquitectura.</p>
<p><strong>1. 1. Falta de flexibilidad</strong></p>
<p>Las primeras versiones de LangChain proporcionaban pipelines modulares como SimpleSequentialChain o LLMChain, cada uno de los cuales segu√≠a un flujo fijo y lineal: creaci√≥n de la solicitud ‚Üí llamada al modelo ‚Üí procesamiento de la salida. Este dise√±o funcionaba bien para tareas sencillas y predecibles y facilitaba la creaci√≥n r√°pida de prototipos.</p>
<p>Sin embargo, a medida que las aplicaciones se volv√≠an m√°s din√°micas, estas plantillas r√≠gidas empezaron a resultar restrictivas. Cuando la l√≥gica de negocio ya no encaja perfectamente en una secuencia predefinida, te quedas con dos opciones insatisfactorias: forzar tu l√≥gica para que se ajuste al framework o eludirlo por completo llamando directamente a la API de LLM.</p>
<p><strong>2. Falta de control de producci√≥n</strong></p>
<p>Lo que funcionaba bien en las demos a menudo no funcionaba en producci√≥n. Las cadenas no inclu√≠an las salvaguardas necesarias para aplicaciones a gran escala, persistentes o sensibles. Algunos de los problemas m√°s comunes son</p>
<ul>
<li><p><strong>Desbordamiento de contexto:</strong> Las conversaciones largas pod√≠an superar los l√≠mites de tokens, provocando bloqueos o truncamientos silenciosos.</p></li>
<li><p><strong>Fugas de datos sensibles:</strong> La informaci√≥n personal identificable (como correos electr√≥nicos o identificaciones) podr√≠a enviarse inadvertidamente a modelos de terceros.</p></li>
<li><p><strong>Operaciones no supervisadas:</strong> Los agentes podr√≠an borrar datos o enviar correos electr√≥nicos sin la aprobaci√≥n humana.</p></li>
</ul>
<p><strong>3. Falta de compatibilidad entre modelos</strong></p>
<p>Cada proveedor de LLM -OpenAI, Anthropic y muchos modelos chinos- implementa sus propios protocolos de razonamiento y llamada a herramientas. Cada vez que se cambiaba de proveedor, hab√≠a que reescribir la capa de integraci√≥n: plantillas de solicitud, adaptadores y analizadores de respuestas. Este trabajo repetitivo ralentizaba el desarrollo y dificultaba la experimentaci√≥n.</p>
<h2 id="LangChain-10-All-in-ReAct-Agent" class="common-anchor-header">LangChain 1.0: Agente ReAct todo en uno<button data-href="#LangChain-10-All-in-ReAct-Agent" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Cuando el equipo de LangChain analiz√≥ cientos de implementaciones de agentes en producci√≥n, hubo una idea que salt√≥ a la vista: casi todos los agentes de √©xito converg√≠an de forma natural en el <strong>patr√≥n ReAct ("Razonamiento + Actuaci√≥n")</strong>.</p>
<p>Tanto si se trata de un sistema multiagente como de un √∫nico agente que realiza un razonamiento profundo, surge el mismo bucle de control: alternar breves pasos de razonamiento con llamadas a herramientas espec√≠ficas y, a continuaci√≥n, alimentar las decisiones posteriores con las observaciones resultantes hasta que el agente pueda ofrecer una respuesta final.</p>
<p>Para basarse en esta estructura probada, LangChain 1.0 sit√∫a el bucle ReAct en el n√∫cleo de su arquitectura, convirti√©ndolo en la estructura por defecto para construir agentes fiables, interpretables y listos para la producci√≥n.</p>
<p>Para soportar desde agentes sencillos hasta orquestaciones complejas, LangChain 1.0 adopta un dise√±o en capas que combina la facilidad de uso con un control preciso:</p>
<ul>
<li><p><strong>Escenarios est√°ndar:</strong> Comience con la funci√≥n create_agent() - un bucle ReAct limpio y estandarizado que maneja el razonamiento y las llamadas a herramientas fuera de la caja.</p></li>
<li><p><strong>Escenarios ampliados:</strong> A√±ada middleware para obtener un control m√°s preciso. El middleware le permite inspeccionar o modificar lo que ocurre dentro del agente, por ejemplo, a√±adiendo detecci√≥n PII, puntos de control de aprobaci√≥n humana, reintentos autom√°ticos o ganchos de supervisi√≥n.</p></li>
<li><p><strong>Escenarios complejos:</strong> Para flujos de trabajo con estados u orquestaci√≥n multiagente, utilice LangGraph, un motor de ejecuci√≥n basado en gr√°ficos que proporciona un control preciso sobre el flujo l√≥gico, las dependencias y los estados de ejecuci√≥n.</p></li>
</ul>
<p>Ahora vamos a desglosar los tres componentes clave que hacen que el desarrollo de agentes sea m√°s sencillo, seguro y coherente en todos los modelos.</p>
<h3 id="1-The-createagent-A-Simpler-Way-to-Build-Agents" class="common-anchor-header">1. La funci√≥n create_agent(): Una forma m√°s sencilla de crear agentes</h3><p>Un avance clave en LangChain 1.0 es c√≥mo reduce la complejidad de construir agentes a una √∫nica funci√≥n - create_agent(). Ya no es necesario manejar manualmente la gesti√≥n de estados, la gesti√≥n de errores o la transmisi√≥n de salidas. Estas caracter√≠sticas de nivel de producci√≥n son ahora gestionadas autom√°ticamente por el tiempo de ejecuci√≥n LangGraph subyacente.</p>
<p>Con s√≥lo tres par√°metros, puedes lanzar un agente completamente funcional:</p>
<ul>
<li><p><strong>model</strong> - un identificador de modelo (cadena) o un objeto modelo instanciado.</p></li>
<li><p><strong>tools</strong> - una lista de funciones que dan al agente sus habilidades.</p></li>
<li><p><strong>system_prompt</strong> - la instrucci√≥n que define el rol, tono y comportamiento del agente.</p></li>
</ul>
<p>Bajo el cap√≥, create_agent() se ejecuta en el bucle de agente est√°ndar - llamando a un modelo, dej√°ndole elegir las herramientas a ejecutar, y completando una vez que no se necesitan m√°s herramientas:</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/langchain_chain_1_1192c31ce3.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Tambi√©n hereda las capacidades incorporadas de LangGraph para la persistencia del estado, la recuperaci√≥n de interrupciones y el streaming. Las tareas que antes requer√≠an cientos de l√≠neas de c√≥digo de orquestaci√≥n ahora se gestionan a trav√©s de una √∫nica API declarativa.</p>
<pre><code translate="no"><span class="hljs-keyword">from</span> langchain.<span class="hljs-property">agents</span> <span class="hljs-keyword">import</span> create_agent
agent = <span class="hljs-title function_">create_agent</span>(
    model=<span class="hljs-string">&quot;openai:gpt-4o&quot;</span>,
    tools=[get_weather, query_database],
    system_prompt=<span class="hljs-string">&quot;You are a customer service assistant who helps users check the weather and order information.&quot;</span>
)
result = agent.<span class="hljs-title function_">invoke</span>({
    <span class="hljs-string">&quot;messages&quot;</span>: [{<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;What‚Äôs the weather like in Shanghai today?&quot;</span>}]
})
<button class="copy-code-btn"></button></code></pre>
<h3 id="2-The-Middleware-A-Composable-Layer-for-Production-Ready-Control" class="common-anchor-header">2. El middleware: Una capa componible para un control listo para la producci√≥n</h3><p>El middleware es el puente clave que lleva a LangChain del prototipo a la producci√≥n. Expone ganchos en puntos estrat√©gicos del bucle de ejecuci√≥n del agente, lo que permite a√±adir l√≥gica personalizada sin reescribir el proceso central de ReAct.</p>
<p>El bucle principal de un agente sigue un proceso de decisi√≥n de tres pasos - Modelo ‚Üí Herramienta ‚Üí Terminaci√≥n:</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/langchain_1_0_chain_902054bde2.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>LangChain 1.0 proporciona algunos <a href="https://docs.langchain.com/oss/python/langchain/middleware#built-in-middleware">middlewares preconstruidos</a> para patrones comunes. He aqu√≠ cuatro ejemplos.</p>
<ul>
<li><strong>Detecci√≥n de PII: Cualquier aplicaci√≥n que maneje datos sensibles del usuario.</strong></li>
</ul>
<pre><code translate="no"><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> create_agent
<span class="hljs-keyword">from</span> langchain.agents.middleware <span class="hljs-keyword">import</span> PIIMiddleware


agent = create_agent(
    model=<span class="hljs-string">&quot;gpt-4o&quot;</span>,
    tools=[],  <span class="hljs-comment"># Add tools as needed</span>
    middleware=[
        <span class="hljs-comment"># Redact emails in user input</span>
        PIIMiddleware(<span class="hljs-string">&quot;email&quot;</span>, strategy=<span class="hljs-string">&quot;redact&quot;</span>, apply_to_input=<span class="hljs-literal">True</span>),
        <span class="hljs-comment"># Mask credit cards (show last 4 digits)</span>
        PIIMiddleware(<span class="hljs-string">&quot;credit_card&quot;</span>, strategy=<span class="hljs-string">&quot;mask&quot;</span>, apply_to_input=<span class="hljs-literal">True</span>),
        <span class="hljs-comment"># Custom PII type with regex</span>
        PIIMiddleware(
            <span class="hljs-string">&quot;api_key&quot;</span>,
            detector=<span class="hljs-string">r&quot;sk-[a-zA-Z0-9]{32}&quot;</span>,
            strategy=<span class="hljs-string">&quot;block&quot;</span>,  <span class="hljs-comment"># Raise error if detected</span>
        ),
    ],
)
<button class="copy-code-btn"></button></code></pre>
<ul>
<li><strong>Resumir: Resume autom√°ticamente el historial de conversaciones cuando se acerca al l√≠mite de tokens.</strong></li>
</ul>
<pre><code translate="no"><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> create_agent
<span class="hljs-keyword">from</span> langchain.agents.middleware <span class="hljs-keyword">import</span> SummarizationMiddleware


agent = create_agent(
    model=<span class="hljs-string">&quot;gpt-4o&quot;</span>,
    tools=[weather_tool, calculator_tool],
    middleware=[
        SummarizationMiddleware(
            model=<span class="hljs-string">&quot;gpt-4o-mini&quot;</span>,  <span class="hljs-comment">#Summarize using a cheaper model  </span>
            max_tokens_before_summary=<span class="hljs-number">4000</span>,  <span class="hljs-comment"># Trigger summarization at 4000 tokens</span>
            messages_to_keep=<span class="hljs-number">20</span>,  <span class="hljs-comment"># Keep last 20 messages after summary</span>
        ),
    ],
)
<button class="copy-code-btn"></button></code></pre>
<ul>
<li><strong>Reintento de herramientas: Reintento autom√°tico de llamadas a herramientas fallidas con un backoff exponencial configurable.</strong></li>
</ul>
<pre><code translate="no"><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> create_agent
<span class="hljs-keyword">from</span> langchain.agents.middleware <span class="hljs-keyword">import</span> ToolRetryMiddleware
agent = create_agent(
    model=<span class="hljs-string">&quot;gpt-4o&quot;</span>,
    tools=[search_tool, database_tool],
    middleware=[
        ToolRetryMiddleware(
            max_retries=<span class="hljs-number">3</span>,  <span class="hljs-comment"># Retry up to 3 times</span>
            backoff_factor=<span class="hljs-number">2.0</span>,  <span class="hljs-comment"># Exponential backoff multiplier</span>
            initial_delay=<span class="hljs-number">1.0</span>,  <span class="hljs-comment"># Start with 1 second delay</span>
            max_delay=<span class="hljs-number">60.0</span>,  <span class="hljs-comment"># Cap delays at 60 seconds</span>
            jitter=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># Add random jitter to avoid thundering herd (¬±25%)</span>

        ),
    ],
)
<button class="copy-code-btn"></button></code></pre>
<ul>
<li><strong>Middleware personalizado</strong></li>
</ul>
<p>Adem√°s de las opciones de middleware oficiales y predefinidas, tambi√©n puedes crear middleware personalizado mediante decoradores o clases.</p>
<p>Por ejemplo, el siguiente fragmento muestra c√≥mo registrar las llamadas al modelo antes de la ejecuci√≥n:</p>
<pre><code translate="no"><span class="hljs-keyword">from</span> langchain.agents.middleware <span class="hljs-keyword">import</span> before_model
<span class="hljs-keyword">from</span> langchain.agents.middleware <span class="hljs-keyword">import</span> AgentState
<span class="hljs-keyword">from</span> langgraph.runtime <span class="hljs-keyword">import</span> Runtime
<span class="hljs-meta">@before_model</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">log_before_model</span>(<span class="hljs-params">state: AgentState, runtime: Runtime</span>) -&gt; <span class="hljs-built_in">dict</span> | <span class="hljs-literal">None</span>:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;About to call model with <span class="hljs-subst">{<span class="hljs-built_in">len</span>(state[<span class="hljs-string">&#x27;messages&#x27;</span>])}</span> messages&quot;</span>)
    <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>  <span class="hljs-comment"># Returning None means the normal flow continues</span>
agent = create_agent(
    model=<span class="hljs-string">&quot;openai:gpt-4o&quot;</span>,
    tools=[...],
    middleware=[log_before_model],
)
<button class="copy-code-btn"></button></code></pre>
<h3 id="3-Structured-Output-A-Standardized-Way-to-Handle-Data" class="common-anchor-header">3. Salida estructurada: Una forma estandarizada de manejar datos</h3><p>En el desarrollo tradicional de agentes, la salida estructurada siempre ha sido dif√≠cil de gestionar. Por ejemplo, OpenAI ofrece una API nativa de salida estructurada, mientras que otros s√≥lo soportan respuestas estructuradas indirectamente a trav√©s de llamadas a herramientas. Esto a menudo significaba escribir adaptadores personalizados para cada proveedor, a√±adiendo trabajo extra y haciendo el mantenimiento m√°s doloroso de lo que deber√≠a ser.</p>
<p>En LangChain 1.0, la salida estructurada se gestiona directamente a trav√©s del par√°metro response_format de create_agent().  S√≥lo es necesario definir el esquema de datos una vez. LangChain elige autom√°ticamente la mejor estrategia de aplicaci√≥n en funci√≥n del modelo que est√© utilizando, sin necesidad de configuraci√≥n adicional ni de c√≥digo espec√≠fico del proveedor.</p>
<pre><code translate="no"><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> create_agent
<span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel, Field
<span class="hljs-keyword">class</span> <span class="hljs-title class_">WeatherReport</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):
    location: <span class="hljs-built_in">str</span> = Field(description=<span class="hljs-string">&quot;City name&quot;</span>)
    temperature: <span class="hljs-built_in">float</span> = Field(description=<span class="hljs-string">&quot;Temperature (¬∞C)&quot;</span>)
    condition: <span class="hljs-built_in">str</span> = Field(description=<span class="hljs-string">&quot;Weather condition&quot;</span>)
agent = create_agent(
    model=<span class="hljs-string">&quot;openai:gpt-4o&quot;</span>,
    tools=[get_weather],
    response_format=WeatherReport  <span class="hljs-comment"># Use the Pydantic model as the response schema</span>
)
result = agent.invoke({<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;What‚Äôs the weather like in Shanghai today??&quot;</span>})
weather_data = result[<span class="hljs-string">&#x27;structured_response&#x27;</span>]  <span class="hljs-comment"># Retrieve the structured response</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">{weather_data.location}</span>: <span class="hljs-subst">{weather_data.temperature}</span>¬∞C, <span class="hljs-subst">{weather_data.condition}</span>&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<p>LangChain admite dos estrategias para la salida estructurada:</p>
<p><strong>1. Estrategia del proveedor:</strong> Algunos proveedores de modelos soportan de forma nativa la salida estructurada a trav√©s de sus API (por ejemplo, OpenAI y Grok). Cuando este soporte est√° disponible, LangChain utiliza directamente la aplicaci√≥n de esquemas incorporada en el proveedor. Este enfoque ofrece el m√°ximo nivel de fiabilidad y coherencia, ya que el propio modelo garantiza el formato de salida.</p>
<p><strong>2. Estrategia de llamada a la herramienta:</strong> Para los modelos que no soportan la salida estructurada nativa, LangChain utiliza la llamada a herramientas para lograr el mismo resultado.</p>
<p>No tiene que preocuparse de qu√© estrategia se est√° utilizando: el marco de trabajo detecta las capacidades del modelo y se adapta autom√°ticamente. Esta abstracci√≥n le permite cambiar libremente entre diferentes proveedores de modelos sin cambiar su l√≥gica empresarial.</p>
<h2 id="How-Milvus-Enhances-Agent-Memory" class="common-anchor-header">C√≥mo Milvus mejora la memoria del agente<button data-href="#How-Milvus-Enhances-Agent-Memory" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Para los agentes de producci√≥n, el verdadero cuello de botella del rendimiento no suele ser el motor de razonamiento, sino el sistema de memoria. En LangChain 1.0, las bases de datos vectoriales act√∫an como memoria externa del agente, proporcionando memoria a largo plazo a trav√©s de la recuperaci√≥n sem√°ntica.</p>
<p><a href="https://milvus.io/">Milvus</a> es una de las bases de datos vectoriales de c√≥digo abierto m√°s maduras disponibles en la actualidad, creada espec√≠ficamente para la b√∫squeda vectorial a gran escala en aplicaciones de IA. Se integra de forma nativa con LangChain, por lo que no es necesario gestionar manualmente la vectorizaci√≥n, la gesti√≥n de √≠ndices o la b√∫squeda de similitudes. El paquete langchain_milvus envuelve Milvus como una interfaz VectorStore est√°ndar, lo que le permite conectarlo a sus agentes con s√≥lo unas pocas l√≠neas de c√≥digo.</p>
<p>De este modo, Milvus aborda tres retos clave en la construcci√≥n de sistemas de memoria de agentes escalables y fiables:</p>
<h4 id="1-Fast-Retrieval-from-Massive-Knowledge-Bases" class="common-anchor-header"><strong>1. Recuperaci√≥n r√°pida de bases de conocimiento masivas</strong></h4><p>Cuando un agente necesita procesar miles de documentos, conversaciones pasadas o manuales de productos, la simple b√∫squeda por palabras clave no es suficiente. Milvus utiliza la b√∫squeda por similitud vectorial para encontrar informaci√≥n sem√°nticamente relevante en milisegundos, incluso si la consulta utiliza una redacci√≥n diferente. Esto permite a su agente recuperar conocimientos bas√°ndose en el significado, no s√≥lo en coincidencias exactas de texto.</p>
<pre><code translate="no"><span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> create_agent
<span class="hljs-keyword">from</span> langchain_milvus <span class="hljs-keyword">import</span> Milvus
<span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> OpenAIEmbeddings
<span class="hljs-comment"># Initialize the vector database as a knowledge base</span>
vectorstore = Milvus(
    embedding=OpenAIEmbeddings(),  
    collection_name=<span class="hljs-string">&quot;company_knowledge&quot;</span>,
    connection_args={<span class="hljs-string">&quot;uri&quot;</span>: <span class="hljs-string">&quot;http://localhost:19530&quot;</span>}  <span class="hljs-comment">#</span>
)
<span class="hljs-comment"># Convert the retriever into a Tool for the Agent</span>
agent = create_agent(
    model=<span class="hljs-string">&quot;openai:gpt-4o&quot;</span>,
    tools=[vectorstore.as_retriever().as_tool(
        name=<span class="hljs-string">&quot;knowledge_search&quot;</span>,
        description=<span class="hljs-string">&quot;Search the company knowledge base to answer professional questions&quot;</span>
    )],
    system_prompt=<span class="hljs-string">&quot;You can retrieve information from the knowledge base to answer questions.&quot;</span>
)
<button class="copy-code-btn"></button></code></pre>
<h4 id="2-Persistent-Long-Term-Memory" class="common-anchor-header"><strong>2. Memoria persistente a largo plazo</strong></h4><p>El SummarizationMiddleware de LangChain puede condensar el historial de la conversaci√≥n cuando se hace demasiado largo, pero ¬øqu√© ocurre con todos los detalles que se resumen? Milvus los conserva. Cada conversaci√≥n, llamada a herramientas y paso de razonamiento puede vectorizarse y almacenarse para su consulta a largo plazo. Cuando es necesario, el agente puede recuperar r√°pidamente los recuerdos relevantes mediante la b√∫squeda sem√°ntica, lo que permite una verdadera continuidad entre sesiones.</p>
<pre><code translate="no"><span class="hljs-keyword">from</span> langchain_milvus <span class="hljs-keyword">import</span> Milvus
<span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> create_agent
<span class="hljs-keyword">from</span> langchain.agents.middleware <span class="hljs-keyword">import</span> SummarizationMiddleware
<span class="hljs-keyword">from</span> langgraph.checkpoint.memory <span class="hljs-keyword">import</span> InMemorySaver
<span class="hljs-comment"># Long-term memory storage(Milvus)</span>
long_term_memory = Milvus.from_documents(
    documents=[],  <span class="hljs-comment"># Initially empty; dynamically updated at runtime</span>
    embedding=OpenAIEmbeddings(),
    connection_args={<span class="hljs-string">&quot;uri&quot;</span>: <span class="hljs-string">&quot;./agent_memory.db&quot;</span>}
)
<span class="hljs-comment"># Short-term memory management(LangGraph Checkpointer + Summarization)</span>
agent = create_agent(
    model=<span class="hljs-string">&quot;openai:gpt-4o&quot;</span>,
    tools=[long_term_memory.as_retriever().as_tool(
        name=<span class="hljs-string">&quot;recall_memory&quot;</span>,
        description=<span class="hljs-string">&quot;Retrieve the agent‚Äôs historical memories and past experiences&quot;</span>
    )],
    checkpointer=InMemorySaver(),  <span class="hljs-comment"># Short-term memory</span>
    middleware=[
        SummarizationMiddleware(
            model=<span class="hljs-string">&quot;openai:gpt-4o-mini&quot;</span>,
            max_tokens_before_summary=<span class="hljs-number">4000</span>  <span class="hljs-comment"># When the threshold is exceeded, summarize and store it in Milvus</span>
        )
    ]
)
<button class="copy-code-btn"></button></code></pre>
<h4 id="3-Unified-Management-of-Multimodal-Content" class="common-anchor-header"><strong>3. Gesti√≥n unificada de contenidos multimodales</strong></h4><p>Los agentes modernos manejan m√°s que texto: interact√∫an con im√°genes, audio y v√≠deo. Milvus admite el almacenamiento multivectorial y el esquema din√°mico, lo que le permite gestionar incrustaciones de m√∫ltiples modalidades en un √∫nico sistema. Esto proporciona una base de memoria unificada para agentes multimodales, permitiendo una recuperaci√≥n consistente a trav√©s de diferentes tipos de datos.</p>
<pre><code translate="no"><span class="hljs-comment"># Filter retrievals by source (e.g., search only medical reports)</span>
vectorstore.similarity_search(
    query=<span class="hljs-string">&quot;What is the patient&#x27;s blood pressure reading?&quot;</span>,
    k=<span class="hljs-number">3</span>,
    expr=<span class="hljs-string">&quot;source == &#x27;medical_reports&#x27; AND modality == &#x27;text&#x27;&quot;</span>  <span class="hljs-comment"># Milvus scalar filtering</span>
)
<button class="copy-code-btn"></button></code></pre>
<h2 id="LangChain-vs-LangGraph-How-to-Choose-the-One-That-Fits-for-Your-Agents" class="common-anchor-header">LangChain frente a LangGraph: C√≥mo elegir el m√°s adecuado para sus agentes<button data-href="#LangChain-vs-LangGraph-How-to-Choose-the-One-That-Fits-for-Your-Agents" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Actualizarse a LangChain 1.0 es un paso esencial hacia la creaci√≥n de agentes de producci√≥n, pero eso no significa que sea siempre la √∫nica o la mejor opci√≥n para cada caso de uso. Elegir el marco de trabajo adecuado determina la rapidez con la que se pueden combinar estas capacidades en un sistema funcional y f√°cil de mantener.</p>
<p>En realidad, LangChain 1.0 y LangGraph 1.0 pueden considerarse parte de la misma pila de capas, dise√±adas para trabajar juntas en lugar de sustituirse mutuamente: LangChain te ayuda a construir agentes est√°ndar r√°pidamente, mientras que LangGraph te da un control detallado para flujos de trabajo complejos. En otras palabras, LangChain le ayuda a moverse r√°pido, mientras que LangGraph le ayuda a profundizar.</p>
<p>A continuaci√≥n se muestra una r√°pida comparaci√≥n de c√≥mo se diferencian en el posicionamiento t√©cnico:</p>
<table>
<thead>
<tr><th><strong>Dimensi√≥n</strong></th><th><strong>LangChain 1.0</strong></th><th><strong>LangChain 1.0</strong></th></tr>
</thead>
<tbody>
<tr><td><strong>Nivel de abstracci√≥n</strong></td><td>Abstracci√≥n de alto nivel, dise√±ada para escenarios de agentes est√°ndar</td><td>Marco de orquestaci√≥n de bajo nivel, dise√±ado para flujos de trabajo complejos</td></tr>
<tr><td><strong>Capacidad b√°sica</strong></td><td>Bucle ReAct est√°ndar (Raz√≥n ‚Üí Llamada a herramienta ‚Üí Observaci√≥n ‚Üí Respuesta)</td><td>M√°quinas de estado personalizadas y l√≥gica de bifurcaci√≥n compleja (StateGraph + enrutamiento condicional)</td></tr>
<tr><td><strong>Mecanismo de extensi√≥n</strong></td><td>Middleware para capacidades de nivel de producci√≥n</td><td>Gesti√≥n manual de nodos, aristas y transiciones de estado</td></tr>
<tr><td><strong>Implementaci√≥n subyacente</strong></td><td>Gesti√≥n manual de nodos, aristas y transiciones de estado</td><td>Tiempo de ejecuci√≥n nativo con persistencia y recuperaci√≥n integradas</td></tr>
<tr><td><strong>Casos de uso t√≠picos</strong></td><td>80% de los escenarios de agentes est√°ndar</td><td>Colaboraci√≥n multiagente y orquestaci√≥n de flujos de trabajo de larga duraci√≥n</td></tr>
<tr><td><strong>Curva de aprendizaje</strong></td><td>Construir un agente en ~10 l√≠neas de c√≥digo</td><td>Requiere conocimientos de gr√°ficos de estado y orquestaci√≥n de nodos</td></tr>
</tbody>
</table>
<p>Si es la primera vez que construye agentes o quiere poner en marcha un proyecto r√°pidamente, empiece con LangChain. Si ya sabes que tu caso de uso requiere una orquestaci√≥n compleja, colaboraci√≥n multi-agente, o flujos de trabajo de larga duraci√≥n, ve directamente a LangGraph.</p>
<p>Ambos frameworks pueden coexistir en el mismo proyecto: puedes empezar de forma sencilla con LangChain e incorporar LangGraph cuando tu sistema necesite m√°s control y flexibilidad. La clave est√° en elegir la herramienta adecuada para cada parte de tu flujo de trabajo.</p>
<h2 id="Conclusion" class="common-anchor-header">Conclusi√≥n<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Hace tres a√±os, LangChain comenz√≥ como una envoltura ligera para llamar a LLMs. Hoy en d√≠a, se ha convertido en un completo marco de producci√≥n.</p>
<p>En el n√∫cleo, las capas de middleware proporcionan seguridad, conformidad y observabilidad. LangGraph a√±ade ejecuci√≥n persistente, flujo de control y gesti√≥n de estados. Y en la capa de memoria, <a href="https://milvus.io/">Milvus</a> llena un vac√≠o cr√≠tico: proporciona una memoria a largo plazo escalable y fiable que permite a los agentes recuperar el contexto, razonar sobre el historial y mejorar con el tiempo.</p>
<p>Juntos, LangChain, LangGraph y Milvus forman una pr√°ctica cadena de herramientas para la era moderna de los agentes, que une la creaci√≥n r√°pida de prototipos con el despliegue a escala empresarial, sin sacrificar la fiabilidad ni el rendimiento.</p>
<p>üöÄ ¬øListo para dotar a su agente de una memoria fiable a largo plazo? Explore <a href="https://milvus.io">Milvus</a> y vea c√≥mo potencia la memoria inteligente a largo plazo para los agentes LangChain en producci√≥n.</p>
<p>Tienes preguntas o quieres una inmersi√≥n profunda en cualquier caracter√≠stica? √önase a nuestro <a href="https://discord.com/invite/8uyFbECzPX">canal Discord</a> o presente incidencias en <a href="https://github.com/milvus-io/milvus">GitHub</a>. Tambi√©n puede reservar una sesi√≥n individual de 20 minutos para obtener informaci√≥n, orientaci√≥n y respuestas a sus preguntas a trav√©s de <a href="https://milvus.io/blog/join-milvus-office-hours-to-get-support-from-vectordb-experts.md">Milvus Office Hours</a>.</p>
