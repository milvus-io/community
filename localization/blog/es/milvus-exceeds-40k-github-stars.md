---
id: milvus-exceeds-40k-github-stars.md
title: >-
  7 a√±os, 2 grandes reconstrucciones, m√°s de 40.000 estrellas GitHub: El ascenso
  de Milvus como principal base de datos vectorial de c√≥digo abierto
author: Fendy Feng
date: 2025-12-02T00:00:00.000Z
cover: assets.zilliz.com/star_history_3dfceda40f.png
tag: announcements
recommend: true
publishToMedium: true
tags: 'Milvus, vector database'
meta_keywords: 'Milvus, vector database'
meta_title: >
  7 Years, 2 Major Rebuilds, 40K+ GitHub Stars: The Rise of Milvus as the
  Leading Open-Source Vector Database
desc: >-
  Celebraci√≥n de los 7 a√±os de viaje de Milvus para convertirse en la principal
  base de datos vectorial de c√≥digo abierto del mundo
origin: 'https://milvus.io/blog/milvus-exceeds-40k-github-stars.md'
---
<p>En junio de 2025, Milvus alcanz√≥ las 35.000 estrellas de GitHub. Tan solo unos meses despu√©s, hemos <a href="https://github.com/milvus-io/milvus">superado las 40.000, prueba</a>no solo del impulso, sino tambi√©n de una comunidad global que sigue impulsando el futuro de la b√∫squeda vectorial y multimodal.</p>
<p>Estamos profundamente agradecidos. A todos los que han puesto una estrella, han hecho un fork, han presentado problemas, han discutido sobre una API, han compartido un benchmark o han construido algo incre√≠ble con Milvus: <strong>Gracias, y ustedes son la raz√≥n por la que este proyecto se mueve tan r√°pido como lo hace</strong>. Cada estrella representa algo m√°s que un bot√≥n pulsado: refleja a alguien que elige Milvus para impulsar su trabajo, alguien que cree en lo que estamos construyendo, alguien que comparte nuestra visi√≥n de una infraestructura de IA abierta, accesible y de alto rendimiento.</p>
<p>As√≠ que, mientras celebramos, tambi√©n miramos hacia el futuro: hacia las funciones que nos piden, hacia las arquitecturas que la IA exige ahora y hacia un mundo en el que la comprensi√≥n multimodal y sem√°ntica sea la norma en todas las aplicaciones.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/star_history_3dfceda40f.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h2 id="The-Journey-From-Zero-to-40000+-Stars" class="common-anchor-header">El viaje: De cero a m√°s de 40.000 estrellas<button data-href="#The-Journey-From-Zero-to-40000+-Stars" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Cuando empezamos a construir Milvus en 2017, el t√©rmino <em>base de datos vectorial</em> ni siquiera exist√≠a. Solo √©ramos un peque√±o equipo de ingenieros convencidos de que las aplicaciones de IA pronto necesitar√≠an un nuevo tipo de infraestructura de datos: una construida no para filas y columnas, sino para datos multidimensionales, no estructurados y multimodales. Las bases de datos tradicionales no estaban hechas para ese mundo, y sab√≠amos que alguien ten√≠a que reimaginar c√≥mo podr√≠a ser el almacenamiento y la recuperaci√≥n.</p>
<p>Los primeros d√≠as no fueron nada glamurosos. Construir una infraestructura de nivel empresarial es un trabajo lento y obstinado: semanas dedicadas a perfilar rutas de c√≥digo, reescribir componentes y cuestionar decisiones de dise√±o a las 2 de la madrugada. Pero nos aferramos a una misi√≥n sencilla: <strong>hacer que la b√∫squeda vectorial fuera accesible, escalable y fiable para todos los desarrolladores que crean aplicaciones de IA</strong>. Esa misi√≥n nos llev√≥ a trav√©s de los primeros avances y a trav√©s de los inevitables contratiempos.</p>
<p>Y en el camino, algunos puntos de inflexi√≥n lo cambiaron todo:</p>
<ul>
<li><p><strong>2019:</strong> Pusimos Milvus 0.10 en c√≥digo abierto. Signific√≥ exponer todos nuestros bordes √°speros: los hacks, los TODOs, las piezas de las que a√∫n no est√°bamos orgullosos. Pero la comunidad apareci√≥. Los desarrolladores presentaron problemas que nunca habr√≠amos encontrado, propusieron caracter√≠sticas que no hab√≠amos imaginado y desafiaron suposiciones que, en √∫ltima instancia, hicieron que Milvus fuera m√°s fuerte.</p></li>
<li><p><strong>2020-2021:</strong> Nos unimos a la <a href="https://lfaidata.foundation/projects/milvus/">Fundaci√≥n LF</a> AI <a href="https://lfaidata.foundation/projects/milvus/">&amp; Data</a>, lanzamos Milvus 1.0, nos graduamos de LF AI &amp; Data y ganamos el desaf√≠o de b√∫squeda vectorial a escala de mil millones de <a href="https://big-ann-benchmarks.com/neurips21.html">BigANN</a>, una prueba temprana de que nuestra arquitectura pod√≠a manejar la escala del mundo real.</p></li>
<li><p><strong>2022:</strong> Los usuarios empresariales necesitaban un escalado nativo de Kubernetes, elasticidad y una separaci√≥n real entre almacenamiento y computaci√≥n. Nos enfrentamos a una dif√≠cil decisi√≥n: parchear el sistema antiguo o reconstruirlo todo. Elegimos el camino m√°s dif√≠cil. <strong>Milvus 2.0 fue una reinvenci√≥n desde cero</strong>, introduciendo una arquitectura nativa de la nube totalmente desacoplada que transform√≥ Milvus en una plataforma de nivel de producci√≥n para cargas de trabajo de IA de misi√≥n cr√≠tica.</p></li>
<li><p><strong>2024-2025:</strong> <a href="https://zilliz.com/">Zilliz</a> (el equipo detr√°s de Milvus) fue nombrado <a href="https://zilliz.com/resources/analyst-report/zilliz-forrester-wave-vector-database-report">l√≠der por Forrester</a>, super√≥ las 30.000 estrellas y ahora est√° por encima de las 40.000. Se convirti√≥ en la <a href="https://zilliz.com/resources/analyst-report/zilliz-forrester-wave-vector-database-report">columna</a> vertebral de las empresas multiservicio. Se convirti√≥ en la columna vertebral de la b√∫squeda multimodal, los sistemas RAG, los flujos de trabajo ag√©nticos y la recuperaci√≥n a escala de miles de millones en todos los sectores (educaci√≥n, finanzas, producci√≥n creativa, investigaci√≥n cient√≠fica, etc.).</p></li>
</ul>
<p>Este hito no se consigui√≥ a base de bombo y platillo, sino gracias a que los desarrolladores eligieron Milvus para cargas de trabajo de producci√≥n reales y nos empujaron a mejorar en cada paso del camino.</p>
<h2 id="2025-Two-Major-Releases-Massive-Performance-Gains" class="common-anchor-header">2025: Dos grandes lanzamientos, enormes mejoras de rendimiento<button data-href="#2025-Two-Major-Releases-Massive-Performance-Gains" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>2025 fue el a√±o en que Milvus entr√≥ en una nueva liga. Aunque la b√∫squeda vectorial destaca en la comprensi√≥n sem√°ntica, la realidad en la producci√≥n es simple: <strong>los desarrolladores siguen necesitando una concordancia precisa de palabras clave</strong> para ID de productos, n√∫meros de serie, frases exactas, t√©rminos legales y mucho m√°s. Sin la b√∫squeda nativa de texto completo, los equipos se ve√≠an obligados a mantener cl√∫steres de Elasticsearch/OpenSearch o a unir sus propias soluciones personalizadas, lo que duplicaba la sobrecarga operativa y la fragmentaci√≥n.</p>
<p><a href="https://milvus.io/blog/introduce-milvus-2-5-full-text-search-powerful-metadata-filtering-and-more.md"><strong>Milvus 2.5</strong></a> <strong>cambi√≥ eso</strong>. Introdujo <strong>la b√∫squeda h√≠brida verdaderamente nativa</strong>, combinando la recuperaci√≥n de texto completo y la b√∫squeda vectorial en un √∫nico motor. Por primera vez, los desarrolladores pod√≠an ejecutar conjuntamente consultas l√©xicas, consultas sem√°nticas y filtros de metadatos sin tener que hacer malabarismos con sistemas adicionales ni sincronizar canalizaciones. Tambi√©n mejoramos el filtrado de metadatos, el an√°lisis sint√°ctico de expresiones y la eficiencia de ejecuci√≥n para que las consultas h√≠bridas resultaran naturales y r√°pidas bajo cargas de producci√≥n reales.</p>
<p><a href="https://milvus.io/blog/introduce-milvus-2-6-built-for-scale-designed-to-reduce-costs.md"><strong>Milvus 2.6</strong></a> <strong>impuls√≥ a√∫n m√°s este impulso</strong>, centr√°ndose en los dos retos que escuchamos con m√°s frecuencia de los usuarios que trabajan a escala: <strong><em>el coste</em> y el <em>rendimiento</em>.</strong> Esta versi√≥n aport√≥ profundas mejoras arquitect√≥nicas: rutas de consulta m√°s predecibles, indexaci√≥n m√°s r√°pida, un uso de memoria dr√°sticamente menor y un almacenamiento significativamente m√°s eficiente. Muchos equipos informaron de mejoras inmediatas sin cambiar ni una sola l√≠nea del c√≥digo de la aplicaci√≥n.</p>
<p>Estos son algunos de los aspectos m√°s destacados de Milvus 2.6:</p>
<ul>
<li><p><a href="https://milvus.io/docs/tiered-storage-overview.md"><strong>Almacenamiento por niveles</strong></a> que permite a los equipos equilibrar el coste y el rendimiento de forma m√°s inteligente, reduciendo los costes de almacenamiento hasta en un 50%.</p></li>
<li><p><strong>Enorme ahorro de memoria</strong> gracias a <a href="https://milvus.io/blog/bring-vector-compression-to-the-extreme-how-milvus-serves-3%C3%97-more-queries-with-rabitq.md">la cuantizaci√≥n RaBitQ de 1 bit</a>, que reduce el uso de memoria hasta en un 72% sin dejar de ofrecer consultas m√°s r√°pidas.</p></li>
<li><p><a href="https://milvus.io/docs/full-text-search.md"><strong>Un motor de texto completo redise√±ado</strong></a> con una implementaci√≥n de BM25 significativamente m√°s r√°pida: hasta 4 veces m√°s r√°pido que Elasticsearch en nuestras pruebas comparativas.</p></li>
<li><p><strong>Un nuevo √≠ndice de rutas</strong> para <a href="https://milvus.io/blog/json-shredding-in-milvus-faster-json-filtering-with-flexibility.md">metadatos estructurados en JSON</a>, que permite un filtrado hasta 100 veces m√°s r√°pido de documentos complejos.</p></li>
<li><p><a href="https://milvus.io/docs/aisaq.md"><strong>AiSAQ</strong>:</a> compresi√≥n a escala de miles de millones con una reducci√≥n de almacenamiento de 3200√ó y una gran capacidad de recuperaci√≥n.</p></li>
<li><p><a href="https://milvus.io/docs/geometry-operators.md"><strong>B√∫squeda</strong></a><strong>sem√°ntica y</strong> <a href="https://milvus.io/docs/geometry-operators.md"><strong>geoespacial</strong></a> <strong>con R-Tree:</strong> Combinaci√≥n de <em>d√≥nde est√°n las cosas</em> con <em>lo que significan</em> para obtener resultados m√°s relevantes.</p></li>
<li><p><a href="https://zilliz.com/blog/Milvus-introduces-GPU-index-CAGRA"><strong>CAGRA+ Vamana</strong></a><strong>:</strong> Reduce los costes de implantaci√≥n con un modo CAGRA h√≠brido que se basa en la GPU pero realiza las consultas en la CPU.</p></li>
<li><p><strong>Un</strong><strong>flujo de trabajo</strong><strong>de "</strong><a href="https://milvus.io/blog/data-in-and-data-out-in-milvus-2-6.md"><strong>entrada de datos, salida de datos"</strong></a> que simplifica la ingesta y recuperaci√≥n de incrustaciones, especialmente para canalizaciones multimodales.</p></li>
<li><p><strong>Soporte de hasta 100.000 colecciones</strong> en un √∫nico cl√∫ster, lo que supone un gran paso hacia la multitenencia real a escala.</p></li>
</ul>
<p>Para m√°s informaci√≥n sobre Milvus 2.6, consulte <a href="https://milvus.io/docs/release_notes.md">las notas de la versi√≥n completa</a>.</p>
<h2 id="Beyond-Milvus-Open-Source-Tools-for-AI-Developers" class="common-anchor-header">M√°s all√° de Milvus: herramientas de c√≥digo abierto para desarrolladores de IA<button data-href="#Beyond-Milvus-Open-Source-Tools-for-AI-Developers" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>En 2025, no s√≥lo mejoramos Milvus, sino que creamos herramientas que fortalecen todo el ecosistema de desarrolladores de IA. Nuestro objetivo no era perseguir tendencias, sino ofrecer a los desarrolladores el tipo de herramientas abiertas, potentes y transparentes que siempre hemos deseado que existieran.</p>
<h3 id="DeepSearcher-Research-Without-Cloud-Lock-In" class="common-anchor-header">DeepSearcher: Investigaci√≥n sin bloqueo en la nube</h3><p>Deep Researcher de OpenAI demostr√≥ lo que pueden hacer los agentes de razonamiento profundo. Pero es cerrado, caro y est√° bloqueado detr√°s de APIs en la nube. <a href="https://github.com/zilliztech/deep-searcher"><strong>DeepSearcher</strong></a> <strong>es nuestra respuesta.</strong> Es un motor de investigaci√≥n profunda local y de c√≥digo abierto dise√±ado para cualquiera que desee investigaciones estructuradas sin sacrificar el control o la privacidad.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/deepsearcher_5cf6a4f0dc.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>DeepSearcher se ejecuta completamente en su m√°quina, recopilando informaci√≥n a trav√©s de fuentes, sintetizando ideas y proporcionando citas, pasos de razonamiento y trazabilidad, caracter√≠sticas esenciales para la investigaci√≥n real, no s√≥lo res√∫menes superficiales. Sin cajas negras. Sin dependencia de un proveedor. S√≥lo an√°lisis transparentes y reproducibles en los que puedan confiar desarrolladores e investigadores.</p>
<h3 id="Claude-Context-Coding-Assistants-That-Actually-Understand-Your-Code" class="common-anchor-header">Claude Context: Asistentes de codificaci√≥n que realmente entienden su c√≥digo</h3><p>La mayor√≠a de las herramientas de codificaci√≥n de inteligencia artificial se comportan todav√≠a como extravagantes grep pipelines: r√°pidas, superficiales, quemadoras de tokens y ajenas a la estructura real del proyecto. <a href="https://github.com/zilliztech/claude-context"><strong>Claude Context</strong></a> ****cambia eso. Construido como un plugin MCP, por fin ofrece a los asistentes de codificaci√≥n lo que les faltaba: una aut√©ntica comprensi√≥n sem√°ntica de tu c√≥digo base.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/claude_context_7f608a153d.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Claude Context construye un √≠ndice sem√°ntico vectorial en todo el proyecto, lo que permite a los agentes encontrar los m√≥dulos adecuados, seguir las relaciones entre los archivos, comprender la intenci√≥n a nivel de arquitectura y responder a las preguntas con relevancia en lugar de conjeturas. Reduce el desperdicio de fichas, aumenta la precisi√≥n y, lo que es m√°s importante, permite que los asistentes de codificaci√≥n se comporten como si realmente entendieran su software en lugar de fingir que lo hacen.</p>
<p>Ambas herramientas son de c√≥digo abierto. Porque la infraestructura de IA deber√≠a pertenecer a todo el mundo y porque el futuro de la IA no deber√≠a estar encerrado tras muros propietarios.</p>
<h2 id="Trusted-by-10000+-Teams-in-Production" class="common-anchor-header">Con la confianza de m√°s de 10.000 equipos en producci√≥n<button data-href="#Trusted-by-10000+-Teams-in-Production" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>En la actualidad, m√°s de 10.000 equipos empresariales utilizan Milvus en producci√≥n, desde empresas emergentes de r√°pido crecimiento hasta algunas de las compa√±√≠as tecnol√≥gicas m√°s consolidadas del mundo y de la lista Fortune 500. Los equipos de NVIDIA, Sales &amp; Co. Los equipos de NVIDIA, Salesforce, eBay, Airbnb, IBM, AT&amp;T, LINE, Shopee, Roblox, Bosch y Microsoft conf√≠an en Milvus para impulsar sistemas de IA que funcionan cada minuto del d√≠a. Sus cargas de trabajo abarcan la b√∫squeda, las recomendaciones, las canalizaciones ag√©nticas, la recuperaci√≥n multimodal y otras aplicaciones que llevan al l√≠mite la infraestructura de vectores.</p>
<p><a href="https://assets.zilliz.com/logos_eb0d3ad4af.png"></a></p>
<p>Pero lo m√°s importante no es s√≥lo <em>qui√©n</em> utiliza Milvus, sino <em>lo que est√°n construyendo con √©l</em>. En todos los sectores, Milvus est√° detr√°s de sistemas que determinan la forma en que las empresas operan, innovan y compiten:</p>
<ul>
<li><p><strong>Copilotos de IA y asistentes de empresa</strong> que mejoran la atenci√≥n al cliente, los flujos de trabajo de ventas y la toma de decisiones interna con acceso instant√°neo a miles de millones de incrustaciones.</p></li>
<li><p><strong>B√∫squeda sem√°ntica y visual en comercio electr√≥nico, medios de comunicaci√≥n y publicidad</strong>, que impulsa una mayor conversi√≥n, un mejor descubrimiento y una producci√≥n creativa m√°s r√°pida.</p></li>
<li><p><strong>Plataformas de inteligencia jur√≠dica, financiera y cient√≠fica</strong> en las que la precisi√≥n, la auditabilidad y el cumplimiento se traducen en beneficios operativos reales.</p></li>
<li><p><strong>Motores de detecci√≥n de fraudes y riesgos</strong> en la banca y la tecnolog√≠a financiera que dependen de una r√°pida correspondencia sem√°ntica para evitar p√©rdidas en tiempo real.</p></li>
<li><p><strong>Sistemas RAG y ag√©nticos a gran escala</strong> que proporcionan a los equipos un comportamiento de IA profundamente contextual y consciente del dominio.</p></li>
<li><p><strong>Capas de conocimiento empresarial</strong> que unifican texto, c√≥digo, im√°genes y metadatos en un tejido sem√°ntico coherente.</p></li>
</ul>
<p>Y no se trata de pruebas de laboratorio, sino de algunas de las implantaciones de producci√≥n m√°s exigentes del mundo. Milvus lo consigue de forma rutinaria:</p>
<ul>
<li><p>Recuperaci√≥n en menos de 50 ms de miles de millones de vectores</p></li>
<li><p>Miles de millones de documentos y eventos gestionados en un √∫nico sistema</p></li>
<li><p>Flujos de trabajo entre 5 y 10 veces m√°s r√°pidos que las soluciones alternativas</p></li>
<li><p>Arquitecturas multiusuario que soportan cientos de miles de colecciones</p></li>
</ul>
<p>Los equipos eligen Milvus por una sencilla raz√≥n: <strong>ofrece lo que importa: velocidad, fiabilidad, rentabilidad y la capacidad de escalar a miles de millones sin tener que desmontar su arquitectura cada pocos meses.</strong> La confianza que estos equipos depositan en nosotros es la raz√≥n por la que seguimos reforzando Milvus para la d√©cada de IA que tenemos por delante.</p>
<p><a href="https://zilliz.com/share-your-story">
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/share_your_story_3c44c533ed.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</a></p>
<h2 id="When-You-Need-Milvus-Without-the-Ops-Zilliz-Cloud" class="common-anchor-header">Cuando necesite Milvus sin las operaciones: Zilliz Cloud<button data-href="#When-You-Need-Milvus-Without-the-Ops-Zilliz-Cloud" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Milvus es gratuito, potente y de eficacia probada. Pero tambi√©n es un sistema distribuido y el buen funcionamiento de los sistemas distribuidos es un verdadero trabajo de ingenier√≠a. El ajuste de √≠ndices, la gesti√≥n de la memoria, la estabilidad de los cl√∫steres, el escalado, la observabilidad... estas tareas requieren un tiempo y una experiencia de los que muchos equipos simplemente no disponen. Los desarrolladores quer√≠an la potencia de Milvus, pero sin el peso operativo que inevitablemente conlleva su gesti√≥n a escala.</p>
<p>Esta realidad nos llev√≥ a una sencilla conclusi√≥n: si Milvus iba a convertirse en la infraestructura central de las aplicaciones de IA, necesit√°bamos que su funcionamiento no supusiera ning√∫n esfuerzo. Por eso creamos <a href="https://zilliz.com/cloud"><strong>Zilliz Cloud</strong></a>, el servicio Milvus totalmente gestionado, creado y mantenido por el mismo equipo que est√° detr√°s del proyecto de c√≥digo abierto.</p>
<p>Zilliz Cloud ofrece a los desarrolladores el Milvus que ya conocen y en el que conf√≠an, pero sin necesidad de aprovisionar cl√∫steres, solucionar problemas de rendimiento, planificar actualizaciones o preocuparse por el almacenamiento y el ajuste inform√°tico. Y como incluye optimizaciones imposibles de ejecutar en entornos autogestionados, es a√∫n m√°s r√°pido y fiable. <a href="https://zilliz.com/blog/cardinal-most-performant-vector-search-engine">Cardinal</a>, nuestro motor vectorial autooptimizado de calidad comercial, ofrece un rendimiento 10 veces superior <strong>al Milvus de c√≥digo abierto</strong>.</p>
<p><strong>Lo que diferencia a Zilliz Cloud</strong></p>
<ul>
<li><strong>Rendimiento autooptimizado:</strong> AutoIndex ajusta autom√°ticamente HNSW, IVF y DiskANN, ofreciendo una recuperaci√≥n superior al 96% sin necesidad de configuraci√≥n manual.</li>
</ul>
<ul>
<li><p><strong>El√°stico y rentable:</strong> Los precios de pago por uso, el escalado autom√°tico sin servidor y la gesti√≥n inteligente de recursos suelen reducir los costes en un 50% o m√°s en comparaci√≥n con las implantaciones autogestionadas.</p></li>
<li><p><strong>Fiabilidad de nivel empresarial:</strong> 99,95% de tiempo de actividad SLA, redundancia multi-AZ, SOC 2 Tipo II, ISO 27001 y cumplimiento GDPR. Compatibilidad total con RBAC, BYOC, registros de auditor√≠a y cifrado.</p></li>
<li><p><strong>Despliegue independiente de la nube:</strong> Ejecute en AWS, Azure, GCP, Alibaba Cloud o Tencent Cloud, sin dependencia del proveedor, rendimiento constante en todas partes.</p></li>
<li><p><strong>Consultas en lenguaje natural:</strong> La compatibilidad integrada con el servidor MCP le permite consultar los datos de forma conversacional en lugar de elaborar manualmente llamadas a la API.</p></li>
<li><p><strong>Migraci√≥n sin esfuerzo</strong>: Migre desde Milvus, Pinecone, Qdrant, Weaviate, Elasticsearch o PostgreSQL utilizando herramientas de migraci√≥n integradas, sin necesidad de reescribir esquemas ni tiempos de inactividad.</p></li>
<li><p><strong>100% compatible con Milvus de c√≥digo abierto.</strong> Sin bifurcaciones propietarias. Sin dependencia. S√≥lo Milvus, m√°s f√°cil.</p></li>
</ul>
<p><strong>Milvus seguir√° siendo siempre de c√≥digo abierto y de uso gratuito.</strong> Pero ejecutarlo y hacerlo funcionar de forma fiable a escala empresarial requiere una experiencia y unos recursos considerables. <strong>Zilliz Cloud es nuestra respuesta a ese vac√≠o</strong>. Desplegado en 29 regiones y cinco nubes principales, Zilliz Cloud proporciona rendimiento, seguridad y rentabilidad de nivel empresarial, al tiempo que le mantiene completamente alineado con el Milvus que ya conoce.</p>
<p><a href="https://cloud.zilliz.com/signup"><strong>Iniciar prueba gratuita ‚Üí</strong></a></p>
<h2 id="Whats-Next-Milvus-Lake" class="common-anchor-header">Lo que viene a continuaci√≥n: Milvus Lake<button data-href="#Whats-Next-Milvus-Lake" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Como el equipo que introdujo la base de datos vectorial, hemos tenido un asiento en primera fila para ver c√≥mo est√°n cambiando los datos empresariales. Lo que antes cab√≠a perfectamente en terabytes de tablas estructuradas se est√° convirtiendo r√°pidamente en petabytes -y pronto billones- de objetos multimodales. Texto, im√°genes, audio, v√≠deo, flujos de series temporales, registros de multisensores... estos son los conjuntos de datos en los que se basan los modernos sistemas de IA.</p>
<p>Las bases de datos vectoriales est√°n dise√±adas espec√≠ficamente para datos no estructurados y multimodales, pero no siempre son la opci√≥n m√°s econ√≥mica o la m√°s adecuada desde el punto de vista arquitect√≥nico, especialmente cuando la gran mayor√≠a de los datos son fr√≠os. Los corpus de entrenamiento para modelos de gran tama√±o, los registros de percepci√≥n de conducci√≥n aut√≥noma y los conjuntos de datos de rob√≥tica no suelen requerir latencia de milisegundos ni alta concurrencia. La ejecuci√≥n de este volumen de datos a trav√©s de una base de datos vectorial en tiempo real resulta cara, pesada desde el punto de vista operativo y demasiado compleja para los procesos que no requieren ese nivel de rendimiento.</p>
<p>Esta realidad nos llev√≥ a nuestra siguiente gran iniciativa: <strong>Milvus Lake, un</strong>lago multimodal basado en la sem√°ntica y en el √≠ndice dise√±ado para datos a escala de IA. Milvus Lake unifica las se√±ales sem√°nticas en todas las modalidades -vectores, metadatos, etiquetas, descripciones generadas por LLM y campos estructurados- y las organiza en <strong>tablas sem√°nticas</strong> ancladas en torno a entidades empresariales reales. Los datos que antes viv√≠an como archivos en bruto y dispersos en almacenes de objetos, almacenes de lagos y canalizaciones de modelos se convierten en una capa sem√°ntica unificada y consultable. Los corpus multimodales masivos se convierten en activos manejables, recuperables y reutilizables con un significado coherente en toda la empresa.</p>
<p>Bajo el cap√≥, Milvus Lake se basa en una arquitectura limpia <strong>de manifiesto + datos + √≠ndice</strong> que trata la indexaci√≥n como algo fundamental y no como una ocurrencia tard√≠a. Esto desbloquea un flujo de trabajo de "recuperar primero, procesar despu√©s" optimizado para datos fr√≠os a escala de billones, que ofrece una latencia predecible, unos costes de almacenamiento dr√°sticamente inferiores y una estabilidad operativa mucho mayor. Un enfoque de almacenamiento por niveles -NVMe/SSD para rutas activas y almacenamiento de objetos para archivos profundos- combinado con una compresi√≥n eficiente e √≠ndices de carga lenta preserva la fidelidad sem√°ntica a la vez que mantiene la sobrecarga de la infraestructura bajo control.</p>
<p>Milvus Lake tambi√©n se integra perfectamente en el ecosistema de datos moderno, con Paimon, Iceberg, Hudi, Spark, Ray y otros motores y formatos de big data. Los equipos pueden ejecutar el procesamiento por lotes, las canalizaciones en tiempo casi real, la recuperaci√≥n sem√°ntica, la ingenier√≠a de caracter√≠sticas y la preparaci√≥n de datos de formaci√≥n en un solo lugar, sin necesidad de volver a configurar sus flujos de trabajo existentes. Tanto si est√° construyendo corpus de modelos b√°sicos, gestionando bibliotecas de simulaci√≥n de conducci√≥n aut√≥noma, entrenando agentes rob√≥ticos o alimentando sistemas de recuperaci√≥n a gran escala, Milvus Lake proporciona un lago sem√°ntico extensible y rentable para la era de la IA.</p>
<p><strong>Milvus Lake est√° en desarrollo activo.</strong> Le interesa el acceso anticipado o quiere saber m√°s?<a href="https://zilliz.com/contact"> </a></p>
<p><a href="https://zilliz.com/contact-sales"><strong>Ponte en contacto con nosotros ‚Üí</strong></a></p>
<h2 id="Built-by-the-Community-For-the-Community" class="common-anchor-header">Construido por la comunidad, para la comunidad<button data-href="#Built-by-the-Community-For-the-Community" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Lo que hace especial a Milvus no es solo la tecnolog√≠a, sino la gente que hay detr√°s. Nuestra base de colaboradores se extiende por todo el mundo, reuniendo a especialistas en computaci√≥n de alto rendimiento, sistemas distribuidos e infraestructura de IA. Ingenieros e investigadores de ARM, NVIDIA, AMD, Intel, Meta, IBM, Salesforce, Alibaba, Microsoft y muchos m√°s han contribuido con su experiencia a dar forma a Milvus para convertirlo en lo que es hoy.</p>
<p>Cada pull request, cada informe de error, cada pregunta respondida en nuestros foros, cada tutorial creado... estas contribuciones hacen que Milvus sea mejor para todos.</p>
<p>Este hito os pertenece a todos:</p>
<ul>
<li><p><strong>A nuestros colaboradores</strong>: Gracias por su c√≥digo, sus ideas y su tiempo. Hac√©is que Milvus sea mejor cada d√≠a.</p></li>
<li><p><strong>A nuestros usuarios</strong>: Gracias por confiar en Milvus con sus cargas de trabajo de producci√≥n y por compartir sus experiencias, tanto buenas como dif√≠ciles. Sus comentarios impulsan nuestra hoja de ruta.</p></li>
<li><p><strong>A los seguidores de nuestra comunidad</strong>: Gracias por responder preguntas, escribir tutoriales, crear contenido y ayudar a los reci√©n llegados a empezar. Gracias a vosotros, nuestra comunidad es acogedora e integradora.</p></li>
<li><p><strong>A nuestros socios e integradores</strong>: Gracias por construir con nosotros y hacer de Milvus un ciudadano de primera clase en el ecosistema de desarrollo de IA.</p></li>
<li><p><strong>Al equipo de Zilliz</strong>: Gracias por vuestro inquebrantable compromiso tanto con el proyecto de c√≥digo abierto como con el √©xito de nuestros usuarios.</p></li>
</ul>
<p>Milvus ha crecido porque miles de personas decidieron construir algo juntos, de forma abierta, generosa y con la creencia de que la infraestructura b√°sica de la IA deber√≠a ser accesible para todos.</p>
<h2 id="Join-Us-on-This-Journey" class="common-anchor-header">√önase a nosotros en este viaje<button data-href="#Join-Us-on-This-Journey" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Ya sea que est√© construyendo su primera aplicaci√≥n de b√∫squeda de vectores o escalando a miles de millones de vectores, nos encantar√≠a tenerlo como parte de la comunidad Milvus.</p>
<p><strong>Comience</strong>:</p>
<ul>
<li><p><strong>‚≠ê In√≠cianos en GitHub</strong>:<a href="https://github.com/milvus-io/milvus"> github.com/milvus-io/milvus</a></p></li>
<li><p>‚òÅÔ∏è <strong>Prueba Zilliz Cloud gratis</strong>:<a href="https://zilliz.com/"> zilliz.com/cloud</a></p></li>
<li><p>üí¨ <strong>√önete a nuestro</strong> <a href="https://discord.com/invite/8uyFbECzPX"><strong>Discord</strong></a> para conectar con desarrolladores de todo el mundo</p></li>
<li><p>üìö <strong>Explora nuestra documentaci√≥n</strong>: <a href="https://milvus.io/docs">Documentaci√≥n de Milvus</a></p></li>
<li><p>üí¨ <strong>Reserva una</strong> <a href="https://milvus.io/blog/join-milvus-office-hours-to-get-support-from-vectordb-experts.md"><strong>sesi√≥n individual de 20 minutos</strong></a> para obtener ideas, orientaci√≥n y respuestas a tus preguntas.</p></li>
</ul>
<p>El camino que tenemos por delante es apasionante. A medida que la IA reconfigura las industrias y abre nuevas posibilidades, las bases de datos vectoriales se situar√°n en el centro de esta transformaci√≥n. Juntos, estamos construyendo la base sem√°ntica en la que se apoyan las aplicaciones modernas de IA, y no hemos hecho m√°s que empezar.</p>
<p>Brindemos por las pr√≥ximas 40.000 estrellas y por construir <strong>juntos</strong> el futuro de la infraestructura de la IA. üéâ</p>
