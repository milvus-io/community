---
id: vdbbench-1-0-benchmarking-with-your-real-world-production-workloads.md
title: >-
  Anuncio de VDBBench 1.0: Evaluaci√≥n comparativa de bases de datos vectoriales
  de c√≥digo abierto con cargas de trabajo reales
author: Tian Min
date: 2025-07-04T00:00:00.000Z
desc: >-
  Descubra VDBBench 1.0, una herramienta de c√≥digo abierto para la evaluaci√≥n
  comparativa de bases de datos vectoriales con datos del mundo real, ingesti√≥n
  de streaming y cargas de trabajo concurrentes.
cover: assets.zilliz.com/milvus_vdb_e0e8146c90.jpeg
tag: Announcements
recommend: false
publishToMedium: true
tags: 'vector database, Milvus, vectordb benchmarking, vector search'
meta_keywords: 'VDBBench, vector database, Milvus, Zilliz Cloud, benchmarking'
meta_title: |
  VDBBench 1.0: Real-World Benchmarking for Vector Databases
origin: >-
  https://zilliz.com/blog/vdbbench-1-0-benchmarking-with-your-real-world-production-workloads
---
<p>La mayor√≠a de las pruebas de referencia de bases de datos vectoriales se realizan con datos est√°ticos e √≠ndices preconstruidos. Pero los sistemas de producci√≥n no funcionan as√≠: los datos fluyen continuamente mientras los usuarios ejecutan consultas, los filtros fragmentan los √≠ndices y las caracter√≠sticas de rendimiento cambian dr√°sticamente bajo cargas concurrentes de lectura/escritura.</p>
<p>Hoy lanzamos <a href="https://github.com/zilliztech/VectorDBBench/releases/tag/v1.0.0"><strong>VDBBench 1.0</strong></a>, un benchmark de c√≥digo abierto dise√±ado desde cero para probar bases de datos vectoriales en condiciones de producci√≥n realistas: ingesti√≥n de datos en flujo, filtrado de metadatos con selectividad variable y cargas de trabajo concurrentes que revelan los cuellos de botella reales del sistema.</p>
<p><a href="https://github.com/zilliztech/VectorDBBench/releases/tag/v1.0.0"><strong>Descargar VDBBench 1.0</strong></a> ‚Üí<a href="https://zilliz.com/vdbbench-leaderboard?dataset=vectorSearch"> <strong>‚Üí Ver clasificaci√≥n ‚Üí</strong></a></p>
<h2 id="Why-Current-Benchmarks-Are-Misleading" class="common-anchor-header">Por qu√© los puntos de referencia actuales son enga√±osos<button data-href="#Why-Current-Benchmarks-Are-Misleading" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Seamos honestos: hay un fen√≥meno extra√±o en nuestra industria. Todo el mundo habla de "no jugar a los benchmarks", y sin embargo muchos participan exactamente en ese comportamiento. Desde que estall√≥ el mercado de las bases de datos vectoriales en 2023, hemos visto numerosos ejemplos de sistemas que "funcionan de maravilla" pero "fracasan estrepitosamente" en producci√≥n, lo que hace perder tiempo a los ingenieros y da√±a la credibilidad del proyecto.</p>
<p>Hemos sido testigos directos de esta desconexi√≥n. Por ejemplo, Elasticsearch presume de velocidades de consulta de milisegundos, pero entre bastidores puede tardar m√°s de 20 horas s√≥lo en optimizar su √≠ndice. ¬øQu√© sistema de producci√≥n puede tolerar semejante tiempo de inactividad?</p>
<p>El problema se deriva de tres defectos fundamentales:</p>
<ul>
<li><p><strong>Conjuntos de datos obsoletos:</strong> Muchas pruebas de rendimiento siguen bas√°ndose en conjuntos de datos antiguos como SIFT (128 dimensiones), mientras que las incrustaciones modernas tienen entre 768 y 3.072 dimensiones. Las caracter√≠sticas de rendimiento de los sistemas que funcionan con vectores de 128D frente a los de 1024D+ son fundamentalmente diferentes: los patrones de acceso a la memoria, la eficiencia de los √≠ndices y la complejidad computacional cambian dr√°sticamente.</p></li>
<li><p><strong>M√©tricas de vanidad:</strong> Los puntos de referencia se centran en la latencia media o el QPS m√°ximo, lo que crea una imagen distorsionada. Un sistema con una latencia media de 10 ms pero una latencia P99 de 2 segundos crea una experiencia de usuario terrible. El rendimiento m√°ximo medido en 30 segundos no dice nada sobre el rendimiento sostenido.</p></li>
<li><p><strong>Escenarios excesivamente simplificados:</strong> La mayor√≠a de las pruebas comparativas analizan flujos de trabajo b√°sicos de "escritura de datos, creaci√≥n de √≠ndices, consultas", b√°sicamente pruebas de nivel "Hola mundo". La producci√≥n real implica la ingesti√≥n continua de datos mientras se sirven consultas, el filtrado complejo de metadatos que fragmenta los √≠ndices y las operaciones concurrentes de lectura/escritura que compiten por los recursos.</p></li>
</ul>
<h2 id="What‚Äôs-New-in-VDBBench-10" class="common-anchor-header">¬øQu√© hay de nuevo en VDBBench 1.0?<button data-href="#What‚Äôs-New-in-VDBBench-10" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>VDBBench no se limita a iterar sobre filosof√≠as de benchmarking obsoletas, sino que reconstruye el concepto a partir de los primeros principios con una creencia rectora: un benchmark s√≥lo es valioso si predice el comportamiento real de la producci√≥n.</p>
<p>Hemos dise√±ado VDBBench para reproducir fielmente las condiciones del mundo real en tres dimensiones cr√≠ticas: <strong>autenticidad de los datos, patrones de carga de trabajo y metodolog√≠as de medici√≥n del rendimiento.</strong></p>
<p>Echemos un vistazo m√°s de cerca a qu√© nuevas caracter√≠sticas se ponen sobre la mesa.</p>
<h3 id="üöÄ-Redesigned-Dashboard-with-Production-Relevant-Visualizations" class="common-anchor-header"><strong>üöÄ Panel de control redise√±ado con visualizaciones relevantes para la producci√≥n</strong></h3><p>La mayor√≠a de los puntos de referencia se centran √∫nicamente en la salida de datos en bruto, pero lo que importa es c√≥mo los ingenieros interpretan y act√∫an sobre esos resultados. Hemos redise√±ado la interfaz de usuario para dar prioridad a la claridad y la interactividad, lo que le permite detectar las diferencias de rendimiento entre los sistemas y tomar decisiones r√°pidas sobre la infraestructura.</p>
<p>El nuevo panel no s√≥lo visualiza las cifras de rendimiento, sino tambi√©n las relaciones entre ellas: c√≥mo se degrada el QPS con distintos niveles de selectividad de filtros, c√≥mo fluct√∫a la recuperaci√≥n durante la ingesti√≥n de secuencias y c√≥mo las distribuciones de latencia revelan las caracter√≠sticas de estabilidad del sistema.  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/vdb_1_df593dea0b.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Hemos vuelto a probar las principales plataformas de bases de datos vectoriales, como <strong>Milvus, Zilliz Cloud, Elastic Cloud, Qdrant Cloud, Pinecone y OpenSearch</strong>, con sus √∫ltimas configuraciones y ajustes recomendados, para garantizar que todos los datos de referencia reflejen las capacidades actuales. Todos los resultados de las pruebas est√°n disponibles en<a href="https://zilliz.com/vdbbench-leaderboard?dataset=vectorSearch"> VDBBench Leaderboard</a>.</p>
<h3 id="üè∑Ô∏è-Tag-Filtering-The-Hidden-Performance-Killer" class="common-anchor-header">üè∑Ô∏è Filtrado de etiquetas: El asesino oculto del rendimiento</h3><p>Las consultas en el mundo real rara vez se producen de forma aislada. Las aplicaciones combinan la similitud vectorial con el filtrado de metadatos ("encontrar zapatos que se parezcan a esta foto pero que cuesten menos de 100 d√≥lares"). Esta b√∫squeda vectorial filtrada crea desaf√≠os √∫nicos que la mayor√≠a de las pruebas de referencia ignoran por completo.</p>
<p>Las b√∫squedas filtradas introducen complejidad en dos √°reas cr√≠ticas:</p>
<ul>
<li><p><strong>Complejidad del filtro</strong>: Un mayor n√∫mero de campos escalares y condiciones l√≥gicas complejas aumentan la demanda computacional y pueden provocar una recuperaci√≥n insuficiente y la fragmentaci√≥n del √≠ndice gr√°fico.</p></li>
<li><p><strong>Selectividad del filtro</strong>: Este es el "asesino oculto del rendimiento" que hemos comprobado repetidamente en producci√≥n. Cuando las condiciones de filtrado se vuelven muy selectivas (filtrando m√°s del 99% de los datos), la velocidad de las consultas puede fluctuar en varios √≥rdenes de magnitud, y la recuperaci√≥n puede volverse inestable a medida que las estructuras de √≠ndices se enfrentan a conjuntos de resultados dispersos.</p></li>
</ul>
<p>VDBBench prueba sistem√°ticamente varios niveles de selectividad de filtrado (del 50% al 99,9%), proporcionando un perfil de rendimiento completo bajo este patr√≥n de producci√≥n cr√≠tico. Los resultados revelan a menudo dr√°sticos desniveles de rendimiento que nunca aparecer√≠an en las pruebas de rendimiento tradicionales.</p>
<p><strong>Por ejemplo</strong>: En las pruebas de Cohere 1M, Milvus mantuvo un alto nivel de recuperaci√≥n en todos los niveles de selectividad de filtrado, mientras que OpenSearch mostr√≥ un rendimiento inestable con una recuperaci√≥n que fluctuaba significativamente bajo diferentes condiciones de filtrado, cayendo por debajo de 0,8 de recuperaci√≥n en muchos casos, lo que es inaceptable para la mayor√≠a de los entornos de producci√≥n.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/vdb_2_0ef89463e5.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Figura: QPS y recuperaci√≥n de Milvus y OpenSearch en diferentes niveles de selectividad de filtro (prueba Cohere 1M).</em></p>
<h3 id="üåä-Streaming-ReadWrite-Beyond-Static-Index-Testing" class="common-anchor-header">üåä Lectura/escritura en flujo: M√°s all√° de las pruebas de √≠ndices est√°ticos</h3><p>Los sistemas de producci√≥n rara vez disfrutan del lujo de datos est√°ticos. La nueva informaci√≥n fluye continuamente mientras se ejecutan las b√∫squedas, un escenario en el que muchas bases de datos, por lo dem√°s impresionantes, colapsan bajo la doble presi√≥n de mantener el rendimiento de la b√∫squeda mientras se gestionan las escrituras continuas.</p>
<p>Los escenarios de streaming de VDBBench simulan operaciones paralelas reales, lo que ayuda a los desarrolladores a comprender la estabilidad del sistema en entornos de alta concurrencia, en particular c√≥mo afecta la escritura de datos al rendimiento de las consultas y c√≥mo evoluciona el rendimiento a medida que aumenta el volumen de datos.</p>
<p>Para garantizar comparaciones justas entre diferentes sistemas, VDBBench utiliza un enfoque estructurado:</p>
<ul>
<li><p>Configurar tasas de escritura controladas que reflejen las cargas de trabajo de producci√≥n objetivo (por ejemplo, 500 filas/seg distribuidas en 5 procesos paralelos).</p></li>
<li><p>Desencadenar las operaciones de b√∫squeda despu√©s de cada 10% de ingesti√≥n de datos, alternando entre los modos serie y concurrente.</p></li>
<li><p>Registro de m√©tricas exhaustivas: distribuciones de latencia (incluido P99), QPS sostenidos y precisi√≥n de recuperaci√≥n.</p></li>
<li><p>Seguimiento de la evoluci√≥n del rendimiento a lo largo del tiempo, a medida que aumentan el volumen de datos y la carga del sistema.</p></li>
</ul>
<p>Esta prueba de carga incremental y controlada revela hasta qu√© punto los sistemas mantienen la estabilidad y la precisi√≥n durante la ingesta continua, algo que los puntos de referencia tradicionales rara vez captan.</p>
<p><strong>Ejemplo</strong>: En las pruebas de streaming Cohere 10M, Pinecone mantuvo un QPS y una recuperaci√≥n superiores durante todo el ciclo de escritura en comparaci√≥n con Elasticsearch. En particular, el rendimiento de Pinecone mejor√≥ significativamente tras la finalizaci√≥n de la ingesta, lo que demuestra una gran estabilidad bajo carga sostenida, mientras que Elasticsearch mostr√≥ un comportamiento m√°s err√°tico durante las fases de ingesta activa.  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/vdb3_9d2a5298b0.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Figura: QPS y Recall de Pinecone frente a Elasticsearch en la prueba de streaming Cohere 10M (tasa de ingesti√≥n de 500 filas/s).</p>
<p>VDBBench va incluso m√°s all√° al admitir un paso de optimizaci√≥n opcional, lo que permite a los usuarios comparar el rendimiento de la b√∫squeda de flujo antes y despu√©s de la optimizaci√≥n del √≠ndice. Tambi√©n realiza un seguimiento e informa del tiempo real empleado en cada etapa, ofreciendo una visi√≥n m√°s profunda de la eficiencia y el comportamiento del sistema en condiciones similares a las de producci√≥n.  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/vdb4_0caee3b201.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Figura: QPS y recuperaci√≥n de Pinecone frente a Elasticsearch en la prueba de flujo Cohere 10M despu√©s de la optimizaci√≥n (tasa de ingesti√≥n de 500 filas/s)</em></p>
<p>Como se muestra en nuestras pruebas, Elasticsearch super√≥ a Pinecone en QPS despu√©s de la optimizaci√≥n del √≠ndice. Pero cuando el eje x refleja el tiempo transcurrido real, est√° claro que Elasticsearch tard√≥ mucho m√°s tiempo en alcanzar ese rendimiento. En producci√≥n, ese retraso es importante. Esta comparaci√≥n revela un equilibrio clave: rendimiento m√°ximo frente a tiempo de servicio.</p>
<h3 id="üî¨-Modern-Datasets-That-Reflect-Current-AI-Workloads" class="common-anchor-header">Conjuntos de datos modernos que reflejan las cargas de trabajo de IA actuales</h3><p>Hemos revisado por completo los conjuntos de datos utilizados para la evaluaci√≥n comparativa de las bases de datos vectoriales. En lugar de conjuntos de pruebas heredados como SIFT y GloVe, VDBBench utiliza vectores generados a partir de modelos de incrustaci√≥n de √∫ltima generaci√≥n como OpenAI y Cohere que potencian las aplicaciones de IA actuales.</p>
<p>Para garantizar la relevancia, especialmente en casos de uso como la Generaci√≥n de Recuperaci√≥n Aumentada (RAG), hemos seleccionado corpus que reflejan escenarios empresariales y de dominios espec√≠ficos del mundo real:</p>
<table>
<thead>
<tr><th></th><th></th><th></th><th></th><th></th></tr>
</thead>
<tbody>
<tr><td><strong>Corpus</strong></td><td><strong>Modelo de incrustaci√≥n</strong></td><td><strong>Dimensiones</strong></td><td><strong>Tama√±o</strong></td><td><strong>Caso de uso</strong></td></tr>
<tr><td>Wikipedia</td><td>Cohere V2</td><td>768</td><td>1M / 10M</td><td>Base general de conocimientos</td></tr>
<tr><td>BioASQ</td><td>Cohere V3</td><td>1024</td><td>1M / 10M</td><td>Dominio espec√≠fico (biom√©dico)</td></tr>
<tr><td>C4</td><td>OpenAI</td><td>1536</td><td>500K / 5M</td><td>Procesamiento de texto a escala web</td></tr>
<tr><td>MSMarco V2</td><td>udever-bloom-1b1</td><td>1536</td><td>1M / 10M / 138M</td><td>B√∫squeda a gran escala</td></tr>
</tbody>
</table>
<p>Estos conjuntos de datos simulan mejor los datos vectoriales actuales de gran volumen y alta dimensi√≥n, lo que permite realizar pruebas realistas de la eficacia del almacenamiento, el rendimiento de las consultas y la precisi√≥n de la recuperaci√≥n en condiciones que coinciden con las cargas de trabajo de la IA moderna.</p>
<h3 id="‚öôÔ∏è-Custom-Dataset-Support-for-Industry-Specific-Testing" class="common-anchor-header">‚öôÔ∏è Soporte de conjuntos de datos personalizados para pruebas espec√≠ficas del sector</h3><p>Cada negocio es √∫nico. El sector financiero puede necesitar pruebas centradas en la incrustaci√≥n de transacciones, mientras que las plataformas sociales se preocupan m√°s por los vectores de comportamiento de los usuarios. VDBBench le permite realizar pruebas comparativas con sus propios datos generados a partir de sus modelos de incrustaci√≥n espec√≠ficos para sus cargas de trabajo concretas.</p>
<p>Puede personalizar</p>
<ul>
<li><p>Dimensiones vectoriales y tipos de datos</p></li>
<li><p>Esquema de metadatos y patrones de filtrado</p></li>
<li><p>Volumen de datos y patrones de ingesti√≥n</p></li>
<li><p>Distribuciones de consultas que coincidan con su tr√°fico de producci√≥n</p></li>
</ul>
<p>Despu√©s de todo, ning√∫n conjunto de datos cuenta una historia mejor que sus propios datos de producci√≥n.</p>
<h2 id="How-VDBBench-Measures-What-Actually-Matters-in-Production" class="common-anchor-header">C√≥mo mide VDBBench lo que realmente importa en la producci√≥n<button data-href="#How-VDBBench-Measures-What-Actually-Matters-in-Production" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Production-Focused-Metric-Design" class="common-anchor-header">Dise√±o de m√©tricas centrado en la producci√≥n</h3><p>VDBBench da prioridad a las m√©tricas que reflejan el rendimiento en el mundo real, no s√≥lo los resultados de laboratorio. Hemos redise√±ado la evaluaci√≥n comparativa en torno a lo que realmente importa en entornos de producci√≥n: <strong>fiabilidad bajo carga, caracter√≠sticas de latencia de cola, rendimiento sostenido y conservaci√≥n de la precisi√≥n.</strong></p>
<ul>
<li><p><strong>Latencia P95/P99 para una experiencia de usuario real</strong>: La latencia media oculta los valores at√≠picos que frustran a los usuarios reales y pueden indicar inestabilidad subyacente del sistema. VDBBench se centra en la latencia de cola como P95/P99, revelando qu√© rendimiento alcanzar√°n realmente el 95% o el 99% de sus consultas. Esto es crucial para la planificaci√≥n de los acuerdos de nivel de servicio (SLA) y para comprender la experiencia del usuario en el peor de los casos.</p></li>
<li><p><strong>Rendimiento sostenible bajo carga</strong>: Un sistema que funciona bien durante 5 segundos no es suficiente en producci√≥n. VDBBench aumenta gradualmente la concurrencia para encontrar las consultas por segundo m√°ximas sostenibles de su base de datos (<code translate="no">max_qps</code>), no el n√∫mero m√°ximo en condiciones ideales y breves. Esta metodolog√≠a revela la capacidad del sistema a lo largo del tiempo y ayuda a planificar la capacidad de forma realista.</p></li>
<li><p><strong>Recuperaci√≥n equilibrada con rendimiento</strong>: La velocidad sin precisi√≥n no tiene sentido. Cada n√∫mero de rendimiento en VDBBench est√° emparejado con mediciones de recuperaci√≥n, para que sepa exactamente cu√°nta relevancia est√° cambiando por rendimiento. Esto permite realizar comparaciones justas entre sistemas con compensaciones internas muy diferentes.</p></li>
</ul>
<h3 id="Test-Methodology-That-Reflects-Reality" class="common-anchor-header">Metodolog√≠a de pruebas que refleja la realidad</h3><p>Una innovaci√≥n clave en el dise√±o de VDBBench es la separaci√≥n de las pruebas en serie y concurrentes, que ayuda a captar c√≥mo se comportan los sistemas bajo diferentes tipos de carga y revela las caracter√≠sticas de rendimiento que importan para diferentes casos de uso.</p>
<p><strong>Separaci√≥n de la medici√≥n de latencia:</strong></p>
<ul>
<li><p><code translate="no">serial_latency_p99</code> Mide el rendimiento del sistema bajo una carga m√≠nima, en la que s√≥lo se procesa una petici√≥n a la vez. Esto representa el mejor escenario posible para la latencia y ayuda a identificar las capacidades b√°sicas del sistema.</p></li>
<li><p><code translate="no">conc_latency_p99</code> Captura el comportamiento del sistema en condiciones realistas de alta concurrencia, en las que varias solicitudes llegan simult√°neamente y compiten por los recursos del sistema.</p></li>
</ul>
<p><strong>Estructura de la prueba comparativa en dos fases</strong>:</p>
<ol>
<li><p><strong>Prueba en serie</strong>: Ejecuci√≥n en un √∫nico proceso de 1.000 consultas que establece el rendimiento y la precisi√≥n de referencia, informando tanto de <code translate="no">serial_latency_p99</code> como de la recuperaci√≥n. Esta fase ayuda a identificar el l√≠mite te√≥rico de rendimiento.</p></li>
<li><p>Prueba<strong>de concurrencia</strong>: Simula el entorno de producci√≥n bajo carga sostenida con varias innovaciones clave:</p>
<ul>
<li><p><strong>Simulaci√≥n realista del cliente</strong>: Cada proceso de prueba funciona de forma independiente con su propia conexi√≥n y conjunto de consultas, evitando interferencias de estado compartido que podr√≠an distorsionar los resultados.</p></li>
<li><p><strong>Inicio sincronizado</strong>: Todos los procesos se inician simult√°neamente, lo que garantiza que el QPS medido refleje con precisi√≥n los niveles de concurrencia reclamados.</p></li>
<li><p><strong>Conjuntos de consultas independientes</strong>: Evita √≠ndices de aciertos de cach√© poco realistas que no reflejan la diversidad de consultas en producci√≥n.</p></li>
</ul></li>
</ol>
<p>Estos m√©todos cuidadosamente estructurados garantizan que los valores de <code translate="no">max_qps</code> y <code translate="no">conc_latency_p99</code> notificados por VDBBench sean precisos y relevantes para la producci√≥n, proporcionando informaci√≥n significativa para la planificaci√≥n de la capacidad de producci√≥n y el dise√±o del sistema.</p>
<h2 id="Getting-Started-with-VDBBench-10" class="common-anchor-header">Introducci√≥n a VDBBench 1.0<button data-href="#Getting-Started-with-VDBBench-10" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p><strong>VDBBench 1.0</strong> representa un cambio fundamental hacia la evaluaci√≥n comparativa relevante para la producci√≥n. Al cubrir la escritura continua de datos, el filtrado de metadatos con selectividad variable y las cargas de streaming bajo patrones de acceso concurrentes, proporciona la mayor aproximaci√≥n a los entornos de producci√≥n reales disponibles en la actualidad.</p>
<p>La diferencia entre los resultados de las pruebas comparativas y el rendimiento en el mundo real no deber√≠a ser un juego de adivinanzas. Si est√° planeando desplegar una base de datos vectorial en producci√≥n, merece la pena conocer su rendimiento m√°s all√° de las pruebas de laboratorio idealizadas. VDBBench es una herramienta de c√≥digo abierto, transparente y dise√±ada para realizar comparaciones significativas.</p>
<p>No se deje llevar por cifras impresionantes que no se traducen en valor de producci√≥n. <strong>Utilice VDBBench 1.0 para probar escenarios importantes para su negocio, con sus datos y en condiciones que reflejen su carga de trabajo real.</strong> La era de los puntos de referencia enga√±osos en la evaluaci√≥n de bases de datos vectoriales ha llegado a su fin: es hora de tomar decisiones basadas en datos relevantes para la producci√≥n.</p>
<p><strong>Pruebe VDBBench con sus propias cargas de trabajo:</strong><a href="https://github.com/zilliztech/VectorDBBench"> https://github.com/zilliztech/VectorDBBench</a></p>
<p><strong>Vea los resultados de las pruebas de las principales bases de datos vectoriales:</strong><a href="https://zilliz.com/vdbbench-leaderboard?dataset=vectorSearch"> Tabla de clasificaci√≥n de VDBBench</a></p>
<p>¬øTienes preguntas o quieres compartir tus resultados? √önase a la conversaci√≥n en<a href="https://github.com/zilliztech/VectorDBBench"> GitHub</a> o conecte con nuestra comunidad en<a href="https://discord.com/invite/FG6hMJStWu"> Discord</a>.</p>
