{"codeList":["from langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.llms import OpenAI\nfrom langchain.memory import VectorStoreRetrieverMemory\nfrom langchain.chains import ConversationChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain.vectorstores import Milvus\nembeddings = OpenAIEmbeddings()\n\n\nimport os\nfrom dotenv import load_dotenv\nimport openai\nload_dotenv()\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\n\nfrom milvus import default_server\ndefault_server.start()\n","vectordb = Milvus.from_documents(\n   {},\n   embeddings,\n   connection_args={\"host\": \"127.0.0.1\", \"port\": default_server.listen_port})\nretriever = Milvus.as_retriever(vectordb, search_kwargs=dict(k=1))\nmemory = VectorStoreRetrieverMemory(retriever=retriever)\nabout_me = [\n   {\"input\": \"My favorite snack is chocolate\",\n    \"output\": \"Nice\"},\n   {\"input\": \"My favorite sport is swimming\",\n    \"output\": \"Cool\"},\n   {\"input\": \"My favorite beer is Guinness\",\n    \"output\": \"Great\"},\n   {\"input\": \"My favorite dessert is cheesecake\",\n    \"output\": \"Good to know\"},\n   {\"input\": \"My favorite musician is Taylor Swift\",\n    \"output\": \"Same\"}\n]\nfor example in about_me:\n   memory.save_context({\"input\": example[\"input\"]}, {\"output\": example[\"output\"]})\n","llm = OpenAI(temperature=0) # Can be any valid LLM\n_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\n\nRelevant pieces of previous conversation:\n{history}\n\n\n(You do not need to use these pieces of information if not relevant)\n\n\nCurrent conversation:\nHuman: {input}\nAI:\"\"\"\nPROMPT = PromptTemplate(\n   input_variables=[\"history\", \"input\"], template=_DEFAULT_TEMPLATE\n)\nconversation_with_summary = ConversationChain(\n   llm=llm,\n   prompt=PROMPT,\n   memory=memory,\n   verbose=True\n)\nconversation_with_summary.predict(input=\"Hi, my name is Gary, what's up?\")\n","conversation_with_summary.predict(input=\"who is my favorite musician?\")\n","conversation_with_summary.predict(input=\"Whats my favorite dessert?\")\n","conversation_with_summary.predict(input=\"What's my name?\")\n"],"headingContent":"","anchorList":[{"label":"Memoria Conversacional con LangChain","href":"Conversational-Memory-with-LangChain","type":2,"isActive":false},{"label":"Configuración del contexto de conversación","href":"Setting-Up-Conversation-Context","type":2,"isActive":false},{"label":"Activación de la memoria conversacional con LangChain","href":"Prompting-the-Conversational-Memory-with-LangChain","type":2,"isActive":false},{"label":"Resumen de la Memoria Conversacional LangChain","href":"LangChain-Conversational-Memory-Summary","type":2,"isActive":false}]}