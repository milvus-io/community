{"codeList":["pip install pymilvus openai numpy\n","# Using Docker (recommended)\ndocker run -d --name milvus -p 19530:19530 milvusdb/milvus:latest\n\n# Or download and run the standalone version from milvus.io\n","import json\nimport numpy as np\nfrom typing import List, Dict\nfrom pymilvus import MilvusClient, DataType\nfrom openai import OpenAI\nimport time\nimport os\nimport re\n","def __init__(self, openai_api_key: str):\n    print(\"🔧 Initializing vector database components...\")\n    \n    # OpenAI client for generating text vectors\n    self.openai_client = OpenAI(api_key=openai_api_key)\n    self.vector_dimension = 1536  # Vector dimension for OpenAI text-embedding-3-small\n    \n    # Milvus client\n    self.milvus_client = None\n    \n    print(\"✅ Vector database component initialization complete\")\n","def generate_vector(self, text: str) -> List[float]:\n    \"\"\"Convert text to vector\"\"\"\n    response = self.openai_client.embeddings.create(\n        input=[text],\n        model=\"text-embedding-3-small\"\n    )\n    return response.data[0].embedding\n","def connect_database(self) -> dict:\n    \"\"\"Connect to Milvus vector database\"\"\"\n    try:\n        self.milvus_client = MilvusClient(\n            uri=\"http://localhost:19530\"\n        )\n        return {\"success\": True, \"message\": \"Successfully connected to Milvus vector database\"}\n    except Exception as e:\n        return {\"success\": False, \"message\": f\"Connection failed: {str(e)}\"}\n","def create_collection(self, collection_name: str, description: str = \"\") -> dict:\n    \"\"\"Create document collection\"\"\"\n    try:\n        # Check if database is connected\n        if self.milvus_client is None:\n            return {\"success\": False, \"message\": \"Please connect to database first\"}\n        \n        # Check if collection already exists\n        if self.milvus_client.has_collection(collection_name):\n            return {\"success\": False, \"message\": f\"Collection {collection_name} already exists\"}\n        \n        # Define collection structure\n        schema = self.milvus_client.create_schema(\n            auto_id=True,\n            enable_dynamic_field=False,\n            description=description\n        )\n        \n        # Add fields\n        schema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True)\n        schema.add_field(field_name=\"text\", datatype=DataType.VARCHAR, max_length=2000)\n        schema.add_field(field_name=\"vector\", datatype=DataType.FLOAT_VECTOR, dim=self.vector_dimension)\n        \n        # Create index parameters\n        index_params = self.milvus_client.prepare_index_params()\n        index_params.add_index(\n            field_name=\"vector\",\n            index_type=\"IVF_FLAT\",\n            metric_type=\"COSINE\",\n            params={\"nlist\": 128}\n        )\n        \n        # Create collection\n        self.milvus_client.create_collection(\n            collection_name=collection_name,\n            schema=schema,\n            index_params=index_params\n        )\n        \n        return {\"success\": True, \"message\": f\"Successfully created collection {collection_name}\"}\n    except Exception as e:\n        return {\"success\": False, \"message\": f\"Failed to create collection: {str(e)}\"}\n","def add_documents(self, collection_name: str, documents: List[str]) -> dict:\n    \"\"\"Add documents to collection\"\"\"\n    try:\n        # Check if database is connected\n        if self.milvus_client is None:\n            return {\"success\": False, \"message\": \"Please connect to database first\"}\n        \n        # Generate vectors for each document\n        print(f\"📝 Generating vectors for {len(documents)} documents...\")\n        vectors = []\n        for doc in documents:\n            vector = self.generate_vector(doc)\n            vectors.append(vector)\n        \n        # Prepare insertion data\n        data = []\n        for i, (doc, vector) in enumerate(zip(documents, vectors)):\n            data.append({\n                \"text\": doc,\n                \"vector\": vector\n            })\n        \n        # Insert data\n        result = self.milvus_client.insert(\n            collection_name=collection_name,\n            data=data\n        )\n        \n        return {\n            \"success\": True,\n            \"message\": f\"Successfully added {len(documents)} documents to collection {collection_name}\",\n            \"inserted_count\": len(result[\"insert_count\"]) if \"insert_count\" in result else len(documents)\n        }\n    except Exception as e:\n        return {\"success\": False, \"message\": f\"Failed to add documents: {str(e)}\"}\n","def search_documents(self, collection_name: str, query: str, limit: int = 5) -> dict:\n    \"\"\"Search similar documents\"\"\"\n    try:\n        # Check if database is connected\n        if self.milvus_client is None:\n            return {\"success\": False, \"message\": \"Please connect to database first\"}\n        \n        # Convert query text to vector\n        query_vector = self.generate_vector(query)\n        \n        # Search parameters\n        search_params = {\n            \"metric_type\": \"COSINE\",\n            \"params\": {\"nprobe\": 10}\n        }\n        \n        # Execute search\n        results = self.milvus_client.search(\n            collection_name=collection_name,\n            data=[query_vector],\n            anns_field=\"vector\",\n            search_params=search_params,\n            limit=limit,\n            output_fields=[\"text\"]\n        )\n        \n        # Organize search results\n        found_docs = []\n        for result in results[0]:  # Take results from first query\n            found_docs.append({\n                \"text\": result[\"entity\"][\"text\"],\n                \"similarity\": f\"{(1 - result['distance']) * 100:.1f}%\"\n            })\n        \n        return {\n            \"success\": True,\n            \"message\": f\"Found {len(found_docs)} relevant documents\",\n            \"query\": query,\n            \"results\": found_docs\n        }\n    except Exception as e:\n        return {\"success\": False, \"message\": f\"Search failed: {str(e)}\"}\n","def list_all_collections(self) -> dict:\n    \"\"\"Query all collections in database\"\"\"\n    try:\n        # Check if database is connected\n        if self.milvus_client is None:\n            return {\"success\": False, \"message\": \"Please connect to database first\"}\n        \n        # Get all collection names\n        collections = self.milvus_client.list_collections()\n        \n        if not collections:\n            return {\n                \"success\": True,\n                \"message\": \"No collections in database\",\n                \"collections\": []\n            }\n        \n        # Get detailed information for each collection\n        collection_details = []\n        for collection_name in collections:\n            try:\n                # Get collection statistics\n                stats = self.milvus_client.get_collection_stats(collection_name)\n                doc_count = stats.get(\"row_count\", 0)\n                \n                # Get collection description\n                desc_result = self.milvus_client.describe_collection(collection_name)\n                description = desc_result.get(\"description\", \"No description\")\n                \n                collection_details.append({\n                    \"name\": collection_name,\n                    \"document_count\": doc_count,\n                    \"description\": description\n                })\n            except Exception as e:\n                collection_details.append({\n                    \"name\": collection_name,\n                    \"document_count\": \"Failed to retrieve\",\n                    \"description\": f\"Error: {str(e)}\"\n                })\n        \n        return {\n            \"success\": True,\n            \"message\": f\"Database contains {len(collections)} collections total\",\n            \"total_collections\": len(collections),\n            \"collections\": collection_details\n        }\n    except Exception as e:\n        return {\"success\": False, \"message\": f\"Failed to query collections: {str(e)}\"}\n","def split_text_into_chunks(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:\n    \"\"\"Split long text into chunks\"\"\"\n    # Clean text\n    text = text.strip()\n    \n    # Split by paragraphs\n    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n    \n    chunks = []\n    current_chunk = \"\"\n    \n    for paragraph in paragraphs:\n        # If current paragraph is too long, needs further splitting\n        if len(paragraph) > chunk_size:\n            # Save current chunk first\n            if current_chunk:\n                chunks.append(current_chunk.strip())\n                current_chunk = \"\"\n            \n            # Split long paragraph by sentences\n            sentences = re.split(r'[。！？.!?]', paragraph)\n            temp_chunk = \"\"\n            \n            for sentence in sentences:\n                sentence = sentence.strip()\n                if not sentence:\n                    continue\n                \n                if len(temp_chunk + sentence) <= chunk_size:\n                    temp_chunk += sentence + \"。\"\n                else:\n                    if temp_chunk:\n                        chunks.append(temp_chunk.strip())\n                    temp_chunk = sentence + \"。\"\n            \n            if temp_chunk:\n                chunks.append(temp_chunk.strip())\n        \n        # If adding this paragraph won't exceed limit\n        elif len(current_chunk + paragraph) <= chunk_size:\n            current_chunk += paragraph + \"\\n\\n\"\n        \n        # If it would exceed limit, save current chunk first, then start new one\n        else:\n            if current_chunk:\n                chunks.append(current_chunk.strip())\n            current_chunk = paragraph + \"\\n\\n\"\n    \n    # Save last chunk\n    if current_chunk:\n        chunks.append(current_chunk.strip())\n    \n    # Add overlapping content to improve context coherence\n    if overlap > 0 and len(chunks) > 1:\n        overlapped_chunks = []\n        for i, chunk in enumerate(chunks):\n            if i == 0:\n                overlapped_chunks.append(chunk)\n            else:\n                # Take part of previous chunk as overlap\n                prev_chunk = chunks[i-1]\n                overlap_text = prev_chunk[-overlap:] if len(prev_chunk) > overlap else prev_chunk\n                overlapped_chunk = overlap_text + \"\\n\" + chunk\n                overlapped_chunks.append(overlapped_chunk)\n        chunks = overlapped_chunks\n    \n    return chunks\n","def read_and_chunk_file(self, file_path: str, chunk_size: int = 500, overlap: int = 50) -> dict:\n    \"\"\"Read local file and chunk into pieces\"\"\"\n    try:\n        # Check if file exists\n        if not os.path.exists(file_path):\n            return {\"success\": False, \"message\": f\"File does not exist: {file_path}\"}\n        \n        # Get file information\n        file_size = os.path.getsize(file_path)\n        file_name = os.path.basename(file_path)\n        \n        # Choose reading method based on file extension\n        file_ext = os.path.splitext(file_path)[1].lower()\n        \n        if file_ext in ['.txt', '.md', '.py', '.js', '.html', '.css', '.json']:\n            # Text file, try multiple encodings\n            encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1']\n            content = None\n            used_encoding = None\n            \n            for encoding in encodings:\n                try:\n                    with open(file_path, 'r', encoding=encoding) as f:\n                        content = f.read()\n                    used_encoding = encoding\n                    break\n                except UnicodeDecodeError:\n                    continue\n            \n            if content is None:\n                return {\"success\": False, \"message\": \"Cannot read file, encoding format not supported\"}\n            \n            # Split text\n            chunks = self.split_text_into_chunks(content, chunk_size, overlap)\n            \n            # Add metadata to each chunk\n            chunk_data = []\n            for i, chunk in enumerate(chunks):\n                chunk_data.append({\n                    \"text\": chunk,\n                    \"source_file\": file_name,\n                    \"chunk_index\": i,\n                    \"total_chunks\": len(chunks)\n                })\n            \n            return {\n                \"success\": True,\n                \"message\": f\"Successfully read and chunked file {file_name}\",\n                \"total_chunks\": len(chunks),\n                \"chunks\": chunk_data\n            }\n        \n    except Exception as e:\n        return {\"success\": False, \"message\": f\"Failed to read file: {str(e)}\"}\n","def upload_file_to_collection(self, file_path: str, collection_name: str, chunk_size: int = 500, overlap: int = 50) -> dict:\n    \"\"\"Upload file to specified collection\"\"\"\n    try:\n        # Check if database is connected\n        if self.milvus_client is None:\n            return {\"success\": False, \"message\": \"Please connect to database first\"}\n        \n        # First read and chunk file\n        result = self.read_and_chunk_file(file_path, chunk_size, overlap)\n        if not result[\"success\"]:\n            return result\n        \n        chunk_data = result[\"chunks\"]\n        print(f\"📝 Generating vectors for {len(chunk_data)} text chunks...\")\n        \n        # Generate vectors for each chunk\n        vectors = []\n        texts = []\n        for chunk_info in chunk_data:\n            vector = self.generate_vector(chunk_info[\"text\"])\n            vectors.append(vector)\n            \n            # Create text with metadata\n            enriched_text = f\"[File: {chunk_info['source_file']} | Chunk: {chunk_info['chunk_index']+1}/{chunk_info['total_chunks']}]\\n{chunk_info['text']}\"\n            texts.append(enriched_text)\n        \n        # Prepare insertion data\n        data = []\n        for i, (text, vector) in enumerate(zip(texts, vectors)):\n            data.append({\n                \"text\": text,\n                \"vector\": vector\n            })\n        \n        # Insert data into collection\n        insert_result = self.milvus_client.insert(\n            collection_name=collection_name,\n            data=data\n        )\n        \n        return {\n            \"success\": True,\n            \"message\": f\"Successfully uploaded file {result['file_name']} to collection {collection_name}\",\n            \"file_name\": result[\"file_name\"],\n            \"file_size\": result[\"file_size\"],\n            \"total_chunks\": result[\"total_chunks\"],\n            \"average_chunk_size\": result[\"average_chunk_size\"],\n            \"inserted_count\": len(data),\n            \"collection_name\": collection_name\n        }\n        \n    except Exception as e:\n        return {\"success\": False, \"message\": f\"Failed to upload file: {str(e)}\"}\n","def __init__(self, kimi_api_key: str, openai_api_key: str):\n    \"\"\"Initialize intelligent assistant\"\"\"\n    print(\"🚀 Starting intelligent assistant...\")\n    \n    # Kimi client\n    self.kimi_client = OpenAI(\n        api_key=kimi_api_key,\n        base_url=\"https://api.moonshot.cn/v1\"\n    )\n    \n    # Vector database\n    self.vector_db = VectorDatabase(openai_api_key)\n    \n    # Define available tools\n    self.available_tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"connect_database\",\n                \"description\": \"Connect to vector database\",\n                \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n            }\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"create_collection\",\n                \"description\": \"Create new document collection\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"collection_name\": {\"type\": \"string\", \"description\": \"Collection name\"},\n                        \"description\": {\"type\": \"string\", \"description\": \"Collection description\"}\n                    },\n                    \"required\": [\"collection_name\"]\n                }\n            }\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"add_documents\",\n                \"description\": \"Add documents to collection\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"collection_name\": {\"type\": \"string\", \"description\": \"Collection name\"},\n                        \"documents\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"Document list\"}\n                    },\n                    \"required\": [\"collection_name\", \"documents\"]\n                }\n            }\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"search_documents\",\n                \"description\": \"Search similar documents\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"collection_name\": {\"type\": \"string\", \"description\": \"Collection name\"},\n                        \"query\": {\"type\": \"string\", \"description\": \"Search content\"},\n                        \"limit\": {\"type\": \"integer\", \"description\": \"Number of results\", \"default\": 5}\n                    },\n                    \"required\": [\"collection_name\", \"query\"]\n                }\n            }\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"list_all_collections\",\n                \"description\": \"Query information about all collections in database\",\n                \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n            }\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"read_and_chunk_file\",\n                \"description\": \"Read local file and chunk into text blocks\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"file_path\": {\"type\": \"string\", \"description\": \"File path\"},\n                        \"chunk_size\": {\"type\": \"integer\", \"description\": \"Size of each text chunk\", \"default\": 500},\n                        \"overlap\": {\"type\": \"integer\", \"description\": \"Overlapping characters between text chunks\", \"default\": 50}\n                    },\n                    \"required\": [\"file_path\"]\n                }\n            }\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"upload_file_to_collection\",\n                \"description\": \"Upload local file to specified collection, automatically chunk and vectorize\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"file_path\": {\"type\": \"string\", \"description\": \"File path\"},\n                        \"collection_name\": {\"type\": \"string\", \"description\": \"Target collection name\"},\n                        \"chunk_size\": {\"type\": \"integer\", \"description\": \"Size of each text chunk\", \"default\": 500},\n                        \"overlap\": {\"type\": \"integer\", \"description\": \"Overlapping characters between text chunks\", \"default\": 50}\n                    },\n                    \"required\": [\"file_path\", \"collection_name\"]\n                }\n            }\n        }\n    ]\n    \n    print(\"✅ Intelligent assistant startup complete\")\n","def _execute_tool(self, tool_name: str, args: dict) -> dict:\n    \"\"\"Execute specific tool\"\"\"\n    if tool_name == \"connect_database\":\n        return self.vector_db.connect_database()\n    elif tool_name == \"create_collection\":\n        return self.vector_db.create_collection(**args)\n    elif tool_name == \"add_documents\":\n        return self.vector_db.add_documents(**args)\n    elif tool_name == \"search_documents\":\n        return self.vector_db.search_documents(**args)\n    elif tool_name == \"list_all_collections\":\n        return self.vector_db.list_all_collections()\n    elif tool_name == \"read_and_chunk_file\":\n        return self.vector_db.read_and_chunk_file(**args)\n    elif tool_name == \"upload_file_to_collection\":\n        return self.vector_db.upload_file_to_collection(**args)\n    else:\n        return {\"success\": False, \"message\": f\"Unknown tool: {tool_name}\"}\n","def execute_command(self, user_command: str) -> str:\n    \"\"\"Execute user command\"\"\"\n    print(f\"\\n📝 User command: {user_command}\")\n    print(\"=\" * 60)\n    \n    # Prepare conversation messages\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"\"\"You are an intelligent assistant that can help users manage vector databases and answer questions.\n\nIntelligent Decision Principles:\n1. Prioritize answer speed and quality, choose optimal response methods\n2. For general knowledge questions, directly use your knowledge for quick responses\n3. Only use database search in the following situations:\n   - User explicitly requests searching database content\n   - Questions involve user-uploaded specific documents or professional materials\n   - Need to find specific, specialized information\n4. You can handle file uploads, database management and other tasks\n5. Always aim to provide the fastest, most accurate answers\n\nImportant Reminders:\n- Before executing any database operations, please first call connect_database to connect to the database\n- If encountering API limit errors, the system will automatically retry, please be patient\n\nRemember: Don't use tools just to use tools, but solve user problems in the optimal way.\"\"\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": user_command\n        }\n    ]\n    \n    # Start conversation and tool calling loop\n    while True:\n        try:\n            # Call Kimi model - Add retry mechanism to handle API limits\n            max_retries = 5\n            retry_delay = 20  # seconds\n            \n            for attempt in range(max_retries):\n                try:\n                    response = self.kimi_client.chat.completions.create(\n                        model=\"kimi-k2-0711-preview\", #moonshot-v1-8k\n                        messages=messages,\n                        temperature=0.3,\n                        tools=self.available_tools,\n                        tool_choice=\"auto\"\n                    )\n                    break  # Success, break out of retry loop\n                except Exception as e:\n                    if \"rate_limit\" in str(e).lower() or \"429\" in str(e) and attempt < max_retries - 1:\n                        print(f\"⏳ Kimi API limit, waiting {retry_delay} seconds before retry... (attempt {attempt + 1}/{max_retries})\")\n                        time.sleep(retry_delay)\n                        retry_delay *= 1.5  # Moderately increase delay\n                        continue\n                    else:\n                        raise e\n            else:\n                raise Exception(\"Failed to call Kimi API: exceeded maximum retry attempts\")\n            \n            choice = response.choices[0]\n            \n            # If need to call tools\n            if choice.finish_reason == \"tool_calls\":\n                messages.append(choice.message)\n                \n                # Execute each tool call\n                for tool_call in choice.message.tool_calls:\n                    tool_name = tool_call.function.name\n                    tool_args = json.loads(tool_call.function.arguments)\n                    \n                    print(f\"🔧 Calling tool: {tool_name}\")\n                    print(f\"📋 Parameters: {tool_args}\")\n                    \n                    # Execute tool\n                    result = self._execute_tool(tool_name, tool_args)\n                    print(f\"✅ Result: {result}\")\n                    print(\"-\" * 40)\n                    \n                    # Add tool result to conversation\n                    messages.append({\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call.id,\n                        \"name\": tool_name,\n                        \"content\": json.dumps(result)\n                    })\n            \n            # If task completed\n            else:\n                final_response = choice.message.content\n                print(f\"🎯 Task completed: {final_response}\")\n                return final_response\n        \n        except Exception as e:\n            error_msg = f\"Execution error: {str(e)}\"\n            print(f\"❌ {error_msg}\")\n            return error_msg\n","python\ndef main():\n    \"\"\"Main program\"\"\"\n    print(\"🌟 Kimi K2 Intelligent Vector Database Assistant\")\n    print(\"=\" * 60)\n    \n    # API key configuration\n    KIMI_API_KEY = \"sk-xxxxxxxxxxxxxxxx\"\n    OPENAI_API_KEY = \"sk-proj-xxxxxxxxxxxxxxxx\"\n    \n    # Create intelligent assistant\n    assistant = SmartAssistant(KIMI_API_KEY, OPENAI_API_KEY)\n    \n    # Interactive mode\n    print(\"\\n🎮 Interactive mode (enter 'quit' to exit)\")\n    while True:\n        try:\n            user_input = input(\"\\nPlease enter command: \").strip()\n            if user_input.lower() in ['quit', 'exit']:\n                print(\"👋 Goodbye!\")\n                break\n            \n            if user_input:\n                assistant.execute_command(user_input)\n                print(\"\\n\" + \"=\" * 60)\n        \n        except KeyboardInterrupt:\n            print(\"\\n👋 Goodbye!\")\n            break\n\nif __name__ == \"__main__\":\n    main()\n","User Input: Upload ./The Adventures of Sherlock Holmes.txt to the database\n","User Input: List five advantages of the Milvus vector database\n","How many stories are included in the book \"Sherlock Holmes\" that I uploaded? Summarize each story in one sentence.\n","list all the collections\n"],"headingContent":"","anchorList":[{"label":"O que vamos construir","href":"What-We’ll-Build","type":2,"isActive":false},{"label":"Pré-requisitos e configuração","href":"Prerequisites-and-Setup","type":2,"isActive":false},{"label":"Importar bibliotecas e configuração básica","href":"Import-Libraries-and-Basic-Configuration","type":2,"isActive":false},{"label":"Processamento de dados: Classe VectorDatabase","href":"Data-Processing-VectorDatabase-Class","type":2,"isActive":false},{"label":"Tomada de decisões inteligente: Classe SmartAssistant","href":"Intelligent-Decision-Making-SmartAssistant-Class","type":2,"isActive":false},{"label":"Programa principal e demonstração de utilização","href":"Main-Program-and-Usage-Demonstration","type":2,"isActive":false},{"label":"Exemplos de utilização","href":"Usage-Examples","type":2,"isActive":false},{"label":"O início dos agentes de IA de produção","href":"The-Dawn-of-Production-AI-Agents","type":2,"isActive":false}]}