---
id: matryoshka-embeddings-detail-at-multiple-scales
title: 'Embeddings Matryoshka: Detalhe em várias escalas'
author: 'Stefan Webb, David Wang'
date: 2024-10-30T00:00:00.000Z
desc: >-
  Embeddings com dimensões reduzidas sem sacrificar a integridade semântica,
  ideais para uma pesquisa e armazenamento mais eficientes.
metaTitle: What are Matryoshka Embeddings?
cover: assets.zilliz.com/Introduction_to_Matryoshka_Embedding_e5a5bc2056.png
tag: Engineering
tags: Matryoshka Embeddings
recommend: true
canonicalUrl: 'https://milvus.io/blog/matryoshka-embeddings-detail-at-multiple-scales'
---
<h2 id="What-are-Matryoshka-Embeddings" class="common-anchor-header">O que são Matryoshka Embeddings?<button data-href="#What-are-Matryoshka-Embeddings" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Ao criar sistemas <a href="https://zilliz.com/learn/vector-similarity-search">de pesquisa vetorial</a> eficientes, um dos principais desafios é gerir os custos de armazenamento, mantendo uma latência e uma recuperação aceitáveis. <a href="https://zilliz.com/blog/choosing-the-right-embedding-model-for-your-data">Os modelos</a> modernos <a href="https://zilliz.com/blog/choosing-the-right-embedding-model-for-your-data">de incorporação</a> produzem vectores com centenas ou milhares de dimensões, criando um armazenamento significativo e uma sobrecarga computacional para o vetor bruto e o índice.</p>
<p>Tradicionalmente, os requisitos de armazenamento são reduzidos através da aplicação de um método de quantização ou de redução da dimensionalidade imediatamente antes da construção do índice. Por exemplo, podemos poupar armazenamento reduzindo a precisão utilizando a <a href="https://zilliz.com/learn/scalar-quantization-and-product-quantization">Quantização de Produtos</a> (PQ) ou o número de dimensões utilizando a Análise de Componentes Principais (PCA). Estes métodos analisam todo o conjunto de vectores para encontrar um conjunto mais compacto que mantenha as relações semânticas entre os vectores.</p>
<p>Embora eficazes, estas abordagens padrão reduzem a precisão ou a dimensionalidade apenas uma vez e numa única escala. Mas e se pudéssemos manter várias camadas de detalhe em simultâneo, como uma pirâmide de representações cada vez mais precisas?</p>
<p>Eis <a href="https://arxiv.org/abs/2205.13147"><strong>os embeddings Matryoshka</strong></a>. Com o nome das bonecas russas (ver ilustração), estas construções inteligentes incorporam várias escalas de representação num único vetor. Ao contrário dos métodos tradicionais de pós-processamento, os encaixes Matryoshka aprendem esta estrutura multi-escala durante o processo de formação inicial. O resultado é notável: <strong>não só a incorporação completa capta a semântica da entrada, como cada prefixo de subconjunto aninhado (primeira metade, primeiro quarto, etc.) fornece uma representação coerente, embora menos pormenorizada.</strong></p>
<p>
 <span class="img-wrapper">
   <img translate="no" src="https://assets.zilliz.com/Visualization_of_Matryoshka_embeddings_with_multiple_layers_of_detail_274f2c7aba.png" alt="Figure: Visualization of Matryoshka embeddings with multiple layers of detail" class="doc-image" id="figure:-visualization-of-matryoshka-embeddings-with-multiple-layers-of-detail" />
   <span>Figura: Visualização das incorporações Matryoshka com várias camadas de pormenor</span> </span></p>
<p><em>Figura: Visualização de embeddings Matryoshka com várias camadas de pormenor</em></p>
<p>Esta abordagem contrasta fortemente com as <a href="https://zilliz.com/glossary/vector-embeddings">incrustações</a> convencionais, em que a utilização de subconjuntos arbitrários das dimensões do vetor destrói normalmente o significado semântico. Com as incorporações Matryoshka, pode escolher a granularidade que melhor equilibra a precisão e o custo computacional da sua tarefa específica.</p>
<p>Precisa de uma pesquisa rápida e aproximada? Utilize a "boneca" mais pequena. Precisa de máxima precisão? Utilize a incorporação completa. Esta flexibilidade torna-os particularmente valiosos para sistemas que se adaptam a diferentes requisitos de desempenho ou restrições de recursos.</p>
<h2 id="Inference" class="common-anchor-header">Inferência<button data-href="#Inference" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Uma aplicação valiosa das incorporações Matryoshka é a aceleração das pesquisas de semelhança sem sacrificar a recuperação. Ao aproveitar subconjuntos mais pequenos de embeddings de consultas e bases de dados - como o primeiro 1/32 das suas dimensões - podemos construir um índice sobre este espaço reduzido que ainda preserva muita da informação de semelhança. Os resultados iniciais deste espaço de incorporação mais pequeno podem ser utilizados diretamente. No entanto, existe também uma técnica para aumentar a recuperação e ter em conta qualquer redução menor do corte dimensional, tornando esta abordagem eficiente e eficaz para tarefas de pesquisa de semelhanças.</p>
<p>
 <span class="img-wrapper">
   <img translate="no" src="https://assets.zilliz.com/How_the_funnel_search_works_with_Matryoshka_embeddings_8fa05a2fe7.png" alt="Figure: How the funnel search works with Matryoshka embeddings" class="doc-image" id="figure:-how-the-funnel-search-works-with-matryoshka-embeddings" />
   <span>Figura: Como a pesquisa de funil funciona com as incorporações Matryoshka</span> </span></p>
<p><em>Figura: Como funciona a pesquisa em funil com os embeddings Matryoshka</em></p>
<p>Para acelerar eficazmente a pesquisa por semelhança, mantendo a precisão, podemos utilizar uma abordagem de "pesquisa em funil". Primeiro, efectuamos uma pesquisa de semelhanças inicial utilizando apenas o primeiro 1/32 das dimensões de incorporação, gerando um vasto conjunto de itens candidatos. De seguida, classificamos estes candidatos com base na sua semelhança com a consulta, utilizando os primeiros 1/16 das dimensões, eliminando uma parte da lista. Este processo continua de forma iterativa, reavaliando e podando com subconjuntos cada vez maiores das dimensões de incorporação - 1/8, 1/4, e assim por diante. É importante notar que só efectuamos uma pesquisa de semelhança inicial neste espaço de dimensão inferior e que uma única passagem do modelo de incorporação calcula a incorporação da consulta. Este processo de afunilamento reduz os candidatos em cada passo e é mais rápido e mais eficiente do que a pesquisa direta no espaço de dimensão total. A obtenção de muitas correspondências a partir do espaço 1/32-dimensional e o seu refinamento através da pesquisa de funil pode acelerar significativamente a pesquisa de semelhanças, preservando uma forte capacidade de recuperação.</p>
<h2 id="Training" class="common-anchor-header">Formação<button data-href="#Training" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Vejamos alguns pormenores técnicos. O método é muito simples de aplicar. Considere o contexto de afinação de um <a href="https://zilliz.com/learn/what-is-bert">modelo BERT</a> para a incorporação de frases. Para converter um modelo BERT, que foi pré-treinado com base na perda de tokens mascarados, num modelo de incorporação de frases, formamos a incorporação de frases como a média da camada final, ou seja, a média das incorporações contextualizadas por token.</p>
<p>Uma opção de objetivo de formação é a <a href="https://sbert.net/docs/package_reference/sentence_transformer/losses.html#cosentloss">perda Cosine Sentence (CoSENT)</a>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo separator="true">;</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L(u, v; s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span></span></span></span> L <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span></span> v <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span></span> s <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mclose">)</span></span></span></span>. Introduz um par de frases incorporadas, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo separator="true">,</mo><mi>vu</mi></mrow><annotation encoding="application/x-tex">,v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span></span></span></span> u <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span></span> v, e a sua pontuação de semelhança pretendida, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">ss</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span></span></span></span> s (ver a ligação acima para a fórmula). Agora, para aprender os encaixes Matryoshka, fazemos uma pequena modificação no objetivo de treino:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>LM</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mo stretchy="false">v)</mo><mi>=w0L</mi><mo stretchy="false">(</mo><msub><mrow><mn>u1</mn><mo>:</mo><mi>d</mi></mrow></msub><mo separator="true">,</mo><msub><mrow><mn>v1</mn><mo>:</mo><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mi>+w1L</mi><mo stretchy="false">(</mo><msub><mrow><mn>u1</mn><mo>:</mo><mn>d/2</mn></mrow></msub><mo separator="true">,</mo><msub><mrow><mn>v1</mn><mo>:</mo><mn>d/2</mn></mrow></msub><mo stretchy="false">)</mo><mi>+w2L</mi><mo stretchy="false">(</mo><msub><mrow><mn>u1</mn><mo>:</mo><mn>d/4</mn></mrow></msub><mo separator="true">,</mo><msub><mrow><mn>v1</mn><mo>:</mo><mn>d/4</mn></mrow></msub><mo stretchy="false">)</mo><mo>+⋯L_M</mo></mrow><annotation encoding="application/x-tex">(u, v) = w_0L(u_{1:d}, v_{1:d}) + w_1L(u_{1:d/2}, v_{1:</annotation></semantics></math></span></span><span class="pstrut" style="height:2.7em;"></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="strut" style="height:0.313em;"></span>d<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">/2}) + w_2L(u_{1:d/4}, v_{1:d/4}) + \cdots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">M</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">(u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span></span></span> =<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span> </span></span> w<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">0</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span></span></span></span></span><span class="pstrut" style="height:2.7em;"></span><span class="katex">1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span><span class="katex">,<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span></span></span></span></span></span></span> 1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span><span class="katex">)<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span></span> +<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span> </span></span> w<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">1</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span></span></span></span></span><span class="pstrut" style="height:2.7em;"></span><span class="katex">1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="katex">,<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span></span></span></span></span></span></span> 1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0359em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="katex">)<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span></span> +<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span> </span></span> w<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">2</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span></span></span></span></span><span class="pstrut" style="height:2.7em;"></span><span class="katex">1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/4</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="katex">,<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="minner">xml-ph</span></span></span></span></p>
<p>onde a soma é continuada calculando a perda em metade da entrada para o termo anterior até ser atingido um estrangulamento de informação. Os autores sugerem que se defina</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">w0=w1=⋯=1w_0=w_1=\cdots=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span></span></span></span> w<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">0</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span> =</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span> w</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">1</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span> =</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span> ⋯</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span> =</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span> 1.</span></span></span></p>
<p><em>Em termos simples, a perda Matryoshka é uma soma ponderada da perda original sobre subconjuntos recursivos da entrada.</em></p>
<p>Uma das principais conclusões da equação acima é que a perda de Matryoshka consegue uma aprendizagem eficiente de representações a várias escalas através da partilha de pesos entre os modelos de incorporação (o mesmo modelo é utilizado para codificar, por exemplo, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mn>u1</mn><mo>:</mo></mrow></msub></mrow><annotation encoding="application/x-tex">du_{1:d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span></span></span></span> u <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span> 1</span></span></span></span></span></span></span></span></span> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> e <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mn>u1</mn><mo>:</mo><mn>d/2u_{1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">:d/2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span></span></span></span> u <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span> 1</span></span></span></span></span></span></span></span></span> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span>) e partilhando dimensões entre escalas<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>(</mi><mrow><mn>u1</mn><mo>:</mo><mn>d/2u_{1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">:d/2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span></span></span></span> u<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span> 1</span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span> é um subconjunto de <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">uu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span></span></span></span> u).</p>
<h2 id="Matryoshka-Embeddings-and-Milvus" class="common-anchor-header">Embeddings Matryoshka e Milvus<button data-href="#Matryoshka-Embeddings-and-Milvus" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>O Milvus suporta sem problemas qualquer modelo de integração Matryoshka que possa ser carregado através de bibliotecas padrão como <a href="https://milvus.io/docs/embeddings.md">pymilvus.model</a>, <a href="https://milvus.io/docs/integrate_with_sentencetransformers.md">sentence-transformers</a> ou outras ferramentas semelhantes. Do ponto de vista do sistema, não há diferença funcional entre um modelo de incorporação normal e um modelo especificamente treinado para gerar incorporações Matryoshka.</p>
<p>Os modelos de incorporação Matryoshka mais populares incluem:</p>
<ul>
<li><p>OpenAI's <a href="https://zilliz.com/ai-models/text-embedding-3-large"><code translate="no">text-embedding-3-large</code></a></p></li>
<li><p>Nomic's <a href="https://huggingface.co/nomic-ai/nomic-embed-text-v1"><code translate="no">nomic-embed-text-v1</code></a></p></li>
<li><p>Alibaba's <a href="https://huggingface.co/Alibaba-NLP/gte-multilingual-base"><code translate="no">gte-multilingual-base</code></a></p></li>
</ul>
<p>Para obter um guia completo sobre a utilização de embeddings Matryoshka com o Milvus, consulte o bloco de notas <em><a href="https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/funnel_search_with_matryoshka.ipynb">Funnel Search with Matryoshka Embeddings</a></em>.</p>
<h2 id="Summary" class="common-anchor-header">Resumo<button data-href="#Summary" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>O embedding Matryoshka permite que os desenvolvedores criem embeddings encurtados sem sacrificar a integridade semântica, tornando-os ideais para pesquisa e armazenamento mais eficientes. Embora seja possível modificar um modelo existente, também estão disponíveis opções pré-treinadas, como as da <a href="https://zilliz.com/ai-models">OpenAI</a> e da <a href="https://zilliz.com/ai-models">Hugging Face</a>.</p>
<p>No entanto, uma limitação atual é a escassez de modelos Matryoshka embeddings de código aberto, com poucos disponíveis no hub Hugging Face. Além disso, estes modelos não são muitas vezes rotulados explicitamente como "Matryoshka", tornando-os mais difíceis de localizar. Esperamos que, com o crescente interesse, uma disponibilidade mais ampla e uma rotulagem mais clara possam surgir em breve.</p>
<p>Pronto para otimizar as suas capacidades de pesquisa? Comece já a utilizar as incorporações Milvus + Matryoshka!</p>
<h2 id="Resources" class="common-anchor-header">Recursos<button data-href="#Resources" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ul>
<li><p>Caderno de notas: <a href="https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/funnel_search_with_matryoshka.ipynb">Pesquisa de funil com embeddings Matryoshka</a></p></li>
<li><p>Artigo: <a href="https://arxiv.org/abs/2205.13147">Aprendizagem da representação Matryoshka</a></p></li>
<li><p>Artigo: <a href="https://arxiv.org/pdf/2407.19669">mGTE: Modelos Generalizados de Representação de Texto de Contexto Longo e Reranking para Recuperação de Texto Multilíngue</a></p></li>
<li><p><a href="https://milvus.io/blog/introducing-pymilvus-integrations-with-embedding-models.md">Apresentando a integração do PyMilvus com modelos de incorporação </a></p></li>
<li><p><a href="https://zilliz.com/learn/Exploring-BGE-M3-the-future-of-information-retrieval-with-milvus">Explorando o BGE-M3: O futuro da recuperação de informação com Milvus </a></p></li>
<li><p><a href="https://static.nomic.ai/reports/2024_Nomic_Embed_Text_Technical_Report.pdf">Nomic Embed: Treino de um incorporador de texto de contexto longo reproduzível</a></p></li>
<li><p><a href="https://sbert.net/examples/training/matryoshka/README.html">Treino de modelos de incorporação Matryoshka com a biblioteca Sentence Transformers</a></p></li>
<li><p><a href="https://milvus.io/bootcamp">Bootcamp Milvus</a></p></li>
</ul>
