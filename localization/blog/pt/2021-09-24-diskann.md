---
id: 2021-09-24-diskann.md
title: >-
  DiskANN, uma solução ANNS baseada em disco com alta recuperação e alto QPS em
  um conjunto de dados em escala de bilhões
author: Zilliz
date: 2021-09-24T00:00:00.000Z
desc: >-
  Leitura de documentos com os engenheiros da Zilliz para saber mais sobre o
  desempenho da DiskANN em conjuntos de dados de escala de bilhões.
cover: assets.zilliz.com/medium_1_10cebc1e50.png
tag: Engineering
---
<custom-h1>DiskANN: Uma solução ANNS baseada em disco com elevada recuperação e elevado QPS num conjunto de dados à escala de um bilião</custom-h1><blockquote>
<p>Chengming Li, engenheiro de I&amp;D da Zilliz, licenciou-se na SouthEast University com um mestrado em Ciências da Computação. Atualmente, concentra-se em problemas de ANNS em dados de elevada dimensão, incluindo soluções baseadas em gráficos e em quantização.</p>
</blockquote>
<p>"DiskANN: Fast Accurate Billion-point Nearest Neighbor Search on a Single Node" é um artigo publicado no NeurIPS em 2019. O artigo apresenta um método de última geração para realizar a construção e pesquisa de índices no conjunto de dados em escala de bilhões usando uma única máquina com apenas 64 GB de RAM e um SSD grande o suficiente. Além disso, satisfaz os três requisitos do ANNS (Approximate Nearest Neighbor Search) no conjunto de dados em grande escala: alta recuperação, baixa latência e alta densidade (número de nós em uma única máquina). Este método constrói um índice baseado em grafos num conjunto de dados SIFT-1B de milhares de milhões de escalas, utilizando uma única máquina com 64 GB de RAM e um CPU de 16 núcleos, atingindo 5000 QPS (consultas por segundo) com mais de 95% de recordação@1 e uma latência média inferior a 3 ms.</p>
<h2 id="Authors" class="common-anchor-header">Autores<button data-href="#Authors" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p><strong>Suhas Jayaram Subramanya</strong>: Antigo funcionário do Instituto de Investigação da Microsoft Índia, estudante de doutoramento da CMU. Os seus principais interesses de investigação são a computação de alto desempenho e os algoritmos de aprendizagem automática para dados em grande escala.</p>
<p><strong>Devvrit</strong>: Assistente de investigação de pós-graduação na Universidade do Texas em Austin. Os seus interesses de investigação são a ciência da computação teórica, a aprendizagem automática e a aprendizagem profunda.</p>
<p><strong>Rohan Kadekodi</strong>: Um estudante de doutoramento na Universidade do Texas. A sua direção de investigação é o sistema e o armazenamento, incluindo principalmente o armazenamento persistente, o sistema de ficheiros e o armazenamento kV.</p>
<p><strong>Ravishankar Krishaswamy</strong>: Investigador principal do instituto de investigação indiano da Microsoft. Doutor pela CMU. A direção da investigação é o algoritmo de aproximação baseado em grafos e agrupamentos.</p>
<p><strong>Harsha Vardhan Simhadri</strong>: investigador principal do instituto de investigação indiano da Microsoft. Doutor pela CMU. No passado, estudou algoritmos paralelos e sistemas de tempo de execução. Atualmente, o seu principal trabalho é desenvolver novos algoritmos e escrever modelos de programação.</p>
<h2 id="Motivations" class="common-anchor-header">Motivações<button data-href="#Motivations" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>A maior parte dos algoritmos ANNS convencionais fazem algumas concessões entre o desempenho da construção de índices, o desempenho da pesquisa e a recuperação. Os algoritmos baseados em grafos, como o HNSW e o NSG, são atualmente os métodos mais avançados em termos de desempenho de pesquisa e recuperação. Uma vez que o método de indexação baseado em grafos residentes na memória ocupa demasiada memória, é relativamente difícil indexar e pesquisar um conjunto de dados de grande escala utilizando uma única máquina com recursos de memória limitados.</p>
<p>Muitas aplicações requerem respostas rápidas da ANNS baseada na distância euclidiana no conjunto de dados à escala de mil milhões. Apresentamos de seguida duas soluções principais:</p>
<ol>
<li>Índice invertido + quantização: para agrupar o conjunto de dados em M partições e comprimir o conjunto de dados usando esquemas de quantização como PQ (Product Quantization). Esta solução produz uma recuperação baixa devido a uma perda de precisão causada pela compressão dos dados. Aumentar o topk ajuda a melhorar a recuperação, ao passo que o QPS cairia de forma correspondente.</li>
<li>Dividir e indexar: para dividir o conjunto de dados em vários fragmentos disjuntos e construir um índice na memória para cada fragmento. Quando os pedidos de consulta chegam, a pesquisa será efectuada nos índices de cada fragmento e os resultados serão devolvidos após a fusão. Esta solução provoca uma expansão excessiva da escala do conjunto de dados e, por conseguinte, são necessárias mais máquinas devido à restrição dos recursos de memória numa única máquina, o que conduz a um baixo QPS.</li>
</ol>
<p>Ambas as soluções mencionadas acima são limitadas pela restrição de memória de uma única máquina. Este documento propõe a conceção de um mecanismo de indexação residente em SSD para resolver este problema. O desafio da indexação residente em SSD é reduzir o número de acessos aleatórios ao disco e o número de pedidos de acesso ao disco.</p>
<h2 id="Contributions" class="common-anchor-header">Contributos<button data-href="#Contributions" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Este documento apresenta um esquema ANNS residente em SSD chamado DiskANN, que pode apoiar eficazmente a pesquisa em conjuntos de dados de grande escala. Este esquema baseia-se num algoritmo baseado em gráficos apresentado neste documento: Vamana. As contribuições deste artigo incluem:</p>
<ol>
<li>O DiskANN pode indexar e pesquisar um conjunto de dados de mais de 100 dimensões numa única máquina com 64GB de RAM, fornecendo mais de 95% de recall@1 com latências inferiores a 5 milissegundos.</li>
<li>Foi proposto um novo algoritmo baseado em grafos, denominado Vamana, com um raio de pesquisa mais pequeno do que os do NSG e do HNSW, para minimizar o número de acessos ao disco.</li>
<li>O Vamana pode funcionar em memória e o seu desempenho não é mais lento do que o NSG e o HNSW.</li>
<li>Os índices Vamana mais pequenos construídos em partições sobrepostas do grande conjunto de dados podem ser fundidos num único gráfico sem perder a conetividade.</li>
<li>O Vamana pode ser combinado com esquemas de quantização como o PQ. A estrutura do grafo e os dados originais são armazenados no disco, enquanto os dados comprimidos são mantidos na memória.</li>
</ol>
<h2 id="Vamana" class="common-anchor-header">Vamana<button data-href="#Vamana" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Este algoritmo é semelhante à ideia do NSG[2][4] (para aqueles que não compreendem o NSG, consulte a Referência [2], e se não quiser ler artigos, pode consultar a Referência [4]). A sua principal diferença reside na estratégia de corte. Para ser mais exato, foi adicionado um interrutor alfa à estratégia de corte do NSG. A ideia principal da estratégia de corte do NSG é que a escolha dos vizinhos do ponto alvo seja tão diversa quanto possível. Se o novo vizinho estiver mais próximo de um vizinho do ponto de destino do que o ponto de destino, não precisamos de adicionar este ponto ao conjunto de pontos vizinhos. Por outras palavras, para cada vizinho do ponto alvo, não pode haver outros pontos vizinhos dentro do raio dist (ponto alvo, ponto vizinho). Esta estratégia de corte controla efetivamente o grau de saída do grafo e é relativamente radical. Reduz o espaço de memória do índice, melhora a velocidade de pesquisa, mas também reduz a precisão da pesquisa. A estratégia de recorte de Vamana consiste em controlar livremente a escala de recorte através do parâmetro alfa. O princípio de funcionamento consiste em multiplicar a distância (um ponto vizinho, um ponto candidato) na condição de recorte por um parâmetro alfa (não inferior a 1). Só quando a dist (ponto alvo, um determinado ponto candidato) é superior à distância de referência alargada é que se adopta a estratégia de recorte, aumentando a tolerância de exclusão mútua entre vizinhos do ponto alvo.</p>
<p>O processo de indexação do Vamana é relativamente simples:</p>
<ol>
<li>Inicializar um grafo aleatório;</li>
<li>Calcular o ponto de partida, que é semelhante ao ponto de navegação do NSG. Primeiro, encontrar o centróide global e, em seguida, encontrar o ponto mais próximo do centróide global como o ponto de navegação. A diferença entre o Vamana e o NSG é que a entrada do NSG já é um gráfico do vizinho mais próximo, pelo que os utilizadores podem simplesmente fazer uma pesquisa aproximada do vizinho mais próximo no ponto do centróide diretamente no gráfico do vizinho inicial. No entanto, o Vamana inicializa um grafo de vizinho mais próximo aleatório, pelo que os utilizadores não podem efetuar uma pesquisa aproximada diretamente no grafo aleatório. Eles precisam fazer uma comparação global para obter um ponto de navegação como ponto de partida das iterações subsequentes. O objetivo deste ponto é minimizar o raio de pesquisa médio;</li>
<li>Efetuar a Pesquisa do Vizinho Mais Próximo Aproximado em cada ponto com base no grafo de vizinhos aleatório inicializado e no ponto de partida da pesquisa determinado no passo 2, tornar todos os pontos no caminho de pesquisa nos conjuntos de vizinhos candidatos e executar a estratégia de corte de arestas utilizando alfa = 1. À semelhança do NSG, a seleção do conjunto de pontos no caminho de pesquisa a partir do ponto de navegação como o conjunto de vizinhos candidatos aumentará algumas arestas longas e reduzirá efetivamente o raio de pesquisa.</li>
<li>Ajustar alfa &gt; 1 (o documento recomenda 1,2) e repetir o passo 3. Considerando que o passo 3 é baseado num gráfico aleatório do vizinho mais próximo, o gráfico é de baixa qualidade após a primeira iteração. Por conseguinte, é necessária outra iteração para melhorar a qualidade do gráfico, o que é muito importante para a taxa de recuperação.</li>
</ol>
<p>Este documento compara os três índices de grafos, ou seja, Vamana, NSG e HNSW. Em termos de indexação e desempenho de consulta, o Vamana e o NSG estão relativamente próximos, e ambos superam ligeiramente o HNSW. Consulte a secção Experiência abaixo para obter os dados.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/2_906f6a4def.png" alt="2.png" class="doc-image" id="2.png" />
   </span> <span class="img-wrapper"> <span>2.png</span> </span></p>
<p>Para visualizar o processo de construção do índice Vamana, o documento fornece um gráfico, no qual 200 pontos bidimensionais são usados para simular duas rodadas de iteração. A primeira linha utiliza alfa = 1 para aparar as arestas. Pode ver-se que a estratégia de corte é relativamente radical e que um grande número de arestas é cortado. Depois de aumentar o valor de alfa e afrouxar as condições de corte, muitas arestas são obviamente adicionadas de volta. No gráfico final, são adicionadas algumas arestas longas. Isto pode reduzir efetivamente o raio de pesquisa.</p>
<h2 id="DiskANN" class="common-anchor-header">DiscoANN<button data-href="#DiskANN" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Um computador pessoal com apenas 64 GB de memória não conseguiria armazenar nem um bilião de dados em bruto, quanto mais o índice construído com base neles. Há dois desafios pela frente: 1. Como indexar um conjunto de dados em tão grande escala com recursos de memória limitados? 2. Como calcular a distância durante a pesquisa se os dados originais não puderem ser carregados na memória?</p>
<p>O documento propõe as seguintes soluções:</p>
<ol>
<li>Para o primeiro desafio: primeiro, dividir os dados em k clusters usando k-means e, em seguida, alocar cada ponto em i clusters mais próximos. Geralmente, 2 é suficiente para o número i. Construir um índice Vamana baseado na memória para cada cluster e, finalmente, fundir k índices Vamana num só.</li>
<li>Para o segundo desafio: construir um índice nos vectores originais e consultar os vectores comprimidos. A construção de índices no vetor original garante a qualidade do gráfico, enquanto o vetor comprimido pode ser carregado na memória para uma pesquisa de granularidade grosseira. Embora a pesquisa com os vectores comprimidos possa causar uma perda de precisão, a direção geral estará correta desde que a qualidade do gráfico seja suficientemente elevada. O resultado final da distância será calculado utilizando o vetor original.</li>
</ol>
<p>A disposição dos índices do DiskANN é semelhante à dos índices gerais dos grafos. O conjunto de vizinhos de cada ponto e os dados do vetor original são armazenados em conjunto. Isto permite uma melhor utilização da localidade dos dados.</p>
<p>Como já foi referido, se os dados do índice forem armazenados no SSD, o número de acessos ao disco e os pedidos de leitura e escrita no disco têm de ser reduzidos ao máximo para garantir um baixo atraso na pesquisa. Por conseguinte, o DiskANN propõe duas estratégias de otimização:</p>
<ol>
<li>Cache hotspot: armazenar em cache todos os pontos dentro de C saltos do ponto de partida na memória. O valor de C é melhor definido entre 3 e 4.</li>
<li>Pesquisa de feixe: Simplificando, consiste em pré-carregar a informação dos vizinhos. Quando se procura um ponto p, o ponto vizinho de p tem de ser carregado a partir do disco, se não estiver na memória. Uma vez que uma pequena quantidade de operações de acesso aleatório em SSD demora aproximadamente o mesmo tempo que uma operação de acesso a um único sector em SSD, a informação de vizinhança de W pontos não acedidos pode ser carregada de cada vez. W não pode ser definido como demasiado grande ou pequeno. Um W grande desperdiçará recursos de computação e largura de banda do SSD, enquanto um W pequeno aumentará o atraso da pesquisa.</li>
</ol>
<h2 id="Experiment" class="common-anchor-header">Experiência<button data-href="#Experiment" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>A experiência consiste em três grupos:</p>
<h4 id="Comparison-among-memory-based-indexes-Vamana-VS-NSG-VS-HNSW" class="common-anchor-header">Comparação entre índices baseados em memória: Vamana VS. NSG VS. HNSW</h4><p>Conjuntos de dados: SIFT1M (128 dimensões), GIST1M (960 dimensões), DEEP1M (96 dimensões) e um conjunto de dados de 1M aleatoriamente amostrado de DEEP1B.</p>
<p>Parâmetros do índice (todos os conjuntos de dados utilizam o mesmo conjunto de parâmetros):</p>
<p>HNSW：M = 128, efc = 512.</p>
<p>Vamana: R = 70, L = 75, alfa = 1,2.</p>
<p>NSG: R = 60, L = 70, C= 500.</p>
<p>Os parâmetros de pesquisa não são fornecidos no documento, o que pode ser consistente com os parâmetros de indexação. Para a seleção de parâmetros, os parâmetros do NSG mencionados no artigo baseiam-se nos parâmetros listados no repositório GitHub do NSG para selecionar o grupo com melhor desempenho. O Vamana e o NSG são relativamente próximos, pelo que os parâmetros também são definidos de forma próxima. No entanto, não é apresentada a razão da seleção dos parâmetros do HNSW. Consideramos que o parâmetro M do HNSW foi definido como relativamente grande. Pode levar a uma comparação menos convincente entre índices baseados em grafos se os seus graus externos não forem definidos ao mesmo nível.</p>
<p>Com os parâmetros de indexação acima referidos, o tempo de indexação do Vamana, HNSW e NSG é de 129s, 219s e 480s, respetivamente. O tempo de indexação do NSG inclui o tempo para construir o grafo de vizinhança inicial com EFANN [3].</p>
<p>Curva Recall-QPS:</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/3_dcdb9452ca.png" alt="3.png" class="doc-image" id="3.png" />
   </span> <span class="img-wrapper"> <span>3.png</span> </span></p>
<p>Pode ver-se na Figura 3 que o Vamana tem um excelente desempenho nos três conjuntos de dados, semelhante ao NSG e ligeiramente melhor do que o HNSW.</p>
<p>Comparação do raio de pesquisa:</p>
<p>A partir da Figura 2.c, podemos ver que o Vamana tem o caminho de pesquisa médio mais curto sob a mesma taxa de recuperação em comparação com os do NSG e do HNSW.</p>
<h4 id="Comparison-between-a-one-time-built-index-and-a-large-merged-index" class="common-anchor-header">Comparação entre um índice construído uma única vez e um grande índice fundido</h4><p>Conjunto de dados: SIFT1B</p>
<p>Parâmetros do índice construído de uma só vez: L = 50, R = 128, alfa = 1,2. Depois de funcionar durante 2 dias numa máquina DDR3 de 1800 G, o pico de memória é de cerca de 1100 G e o grau médio de saída é de 113,9.</p>
<p>Procedimento de indexação baseado na fusão:</p>
<ol>
<li>Treinar 40 clusters no conjunto de dados utilizando kmeans;</li>
<li>Cada ponto é distribuído pelos 2 clusters mais próximos;</li>
<li>Construir um índice Vamana com L = 50, R = 64, e alfa = 1,2 para cada cluster;</li>
<li>Unir os índices de cada cluster.</li>
</ol>
<p>Esse índice gerou um índice de 384 GB com uma média de 92,1 graus fora do grau. Este índice foi executado durante 5 dias numa máquina DDR4 de 64 GB.</p>
<p>Os resultados da comparação são os seguintes (Figura 2a): 
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/4_ea421b98c3.png" alt="4.png" class="doc-image" id="4.png" />
   </span> <span class="img-wrapper"> <span>4.png</span> </span></p>
<p>Em conclusão:</p>
<ol>
<li>O índice construído uma única vez é significativamente melhor do que o índice baseado em fusão;</li>
<li>O índice baseado em fusão também é excelente;</li>
<li>O esquema de indexação baseado na fusão também é aplicável ao conjunto de dados DEEP1B (Figura 2b).</li>
</ol>
<h4 id="Disk-based-index-DiskANN-VS-FAISS-VS-IVF-OADC+G+P" class="common-anchor-header">Índice baseado em disco: DiskANN VS. FAISS VS. IVF-OADC+G+P</h4><p>O IVFOADC+G+P é um algoritmo proposto na referência [5].</p>
<p>Este documento apenas compara o DiskANN com o IVFOADC+G+P, uma vez que a referência [5] provou que o IVFOADC+G+P é melhor do que o FAISS. Além disso, o FAISS requer recursos de GPU, que não são suportados por todas as plataformas.</p>
<p>O IVF-OADC+G+P parece ser uma combinação de HNSW e IVF-PQ. Determina os clusters utilizando o HNSW e efectua a pesquisa adicionando algumas estratégias de poda ao cluster alvo.</p>
<p>O resultado é apresentado na Figura 2a. Os números 16 e 32 na figura correspondem ao tamanho do livro de códigos. O conjunto de dados é SIFT1B, quantificado por OPQ.</p>
<h4 id="Code-implementation-details" class="common-anchor-header">Pormenores da implementação do código</h4><p>O código-fonte do DiskANN é de fonte aberta em https://github.com/microsoft/DiskANN</p>
<p>Em janeiro de 2021, o código-fonte da solução de disco foi disponibilizado em código aberto.</p>
<p>De seguida, apresenta-se principalmente o processo de indexação e o processo de pesquisa.</p>
<p><strong>Criação de índices</strong></p>
<p>Existem 8 parâmetros para a construção do índice:</p>
<p>data_type: as opções incluem float/int8/uint8.</p>
<p>data_file.bin: O ficheiro binário de dados original. Os dois primeiros números inteiros do ficheiro representam, respetivamente, o número total n do vetor do conjunto de dados e a dimensão do vetor dim. Os últimos n bytes de <em>dim</em> sizeof(data_type) são dados vectoriais contínuos.</p>
<p>index_prefix_path: O prefixo do caminho do ficheiro de saída. Depois de o índice ser construído, serão gerados vários ficheiros relacionados com o índice. Este parâmetro é o prefixo comum do diretório onde estão armazenados.</p>
<p>R: O grau de saída máximo do índice global.</p>
<p>L: O parâmetro L do índice Vamana, o limite superior do tamanho do conjunto de candidatos.</p>
<p>B: O limite de memória quando se efectua uma consulta. Controla o tamanho do livro de códigos PQ, em GB.</p>
<p>M: O limite de memória ao construir um índice. Determina o tamanho do fragmento, em GB.</p>
<p>T: O número de threads.</p>
<p>Processo de indexação (função de entrada: aux_utils.cpp::build_disk_index):</p>
<ol>
<li>Gera vários nomes de arquivos de saída de acordo com index_prefix_path.</li>
<li>Verificação de parâmetros.</li>
<li>Ler o meta de data_file.bin para obter n e dim. Determinar o número m do subespaço do livro de códigos de PQ de acordo com B e n.</li>
<li>gerar_pq_pivots: Amostrar o ponto central do conjunto de treino PQ utilizando a taxa de amostragem de p = 1500000/n uniformemente para treinar PQ globalmente.</li>
<li>generate_pq_data_from_pivots: Gera o livro de códigos PQ global e guarda o ponto central e o livro de códigos separadamente.</li>
<li>build_merged_vamana_index: corta o conjunto de dados original, constrói índices Vamana em segmentos e, finalmente, funde os índices num só.</li>
</ol>
<ul>
<li>partition_with_ram_budget: Determine o número de fragmentos k de acordo com o parâmetro M. Faça uma amostragem do conjunto de dados usando kmeans, distribuindo cada ponto para dois clusters mais próximos. Fragmentar o conjunto de dados, e cada fragmento produz dois ficheiros: um ficheiro de dados e um ficheiro de ID. O ficheiro de ID e o ficheiro de dados correspondem um ao outro, e cada ID no ficheiro de ID corresponde a um vetor no ficheiro de dados. Os ID são obtidos numerando cada vetor dos dados originais de 0 a n-1. O ID é relativamente importante e está relacionado com a fusão.<ul>
<li>Amostra globalmente uniforme do conjunto de treino com uma taxa de amostragem de 1500000 / n;</li>
<li>Inicializar num_parts = 3. Iterar a partir de 3:<ul>
<li>Efetuar num_parts-means++ no conjunto de treino no passo i;</li>
<li>Utilizar uma taxa de amostragem de 0,01 para amostrar um conjunto de teste uniformemente a nível global e dividir o conjunto de teste nos 2 clusters mais próximos;</li>
<li>Contar o número de pontos em cada agrupamento e dividi-lo pela taxa de amostragem para estimar o número de pontos em cada agrupamento;</li>
<li>Estimar a memória requerida pelo maior agrupamento na etapa 3 de acordo com o tamanho do índice de Vamana; se não exceder o parâmetro M, passar à etapa iii; caso contrário, num_parts ++ voltar à etapa 2;</li>
</ul></li>
<li>Dividir o conjunto de dados original em ficheiros de grupo num_parts, cada grupo de ficheiros inclui ficheiros de dados fragmentados e ficheiros de ID correspondentes aos dados fragmentados.</li>
</ul></li>
<li>Crie índices Vamana separadamente para todas as fatias no passo a e guarde-os no disco;</li>
<li>merge_shards: funde num_parts shard Vamana num índice global:<ul>
<li>Ler o ficheiro de ID dos fragmentos num_parts no idmap. Este idmap é equivalente a estabelecer um mapeamento direto de fragmento-&gt;id;</li>
<li>Estabelecer um mapeamento inverso de id-&gt; fragmentos de acordo com o idmap, e saber em que dois fragmentos se encontra cada vetor;</li>
<li>Usar um leitor com 1GB de cache para abrir os índices Vamana de num_parts slice, e usar um escritor com 1GB de cache para abrir o ficheiro de saída, pronto a fundir;</li>
<li>Colocar num_parts pontos de navegação do índice Vamana no ficheiro do ponto central, que será utilizado na pesquisa;</li>
<li>Iniciar a fusão de acordo com o ID, de pequeno a grande, ler o conjunto de pontos vizinhos de cada vetor original em cada fragmento, por sua vez, de acordo com o mapeamento inverso, desduplicar, baralhar, truncar e escrever no ficheiro de saída. Uma vez que o fatiamento foi originalmente ordenado globalmente, e agora a fusão também está em ordem, o ID no índice final descarregado e o ID dos dados originais são uma correspondência de um para um.</li>
<li>Eliminar ficheiros temporários, incluindo ficheiros de fragmentos, índices de fragmentos e ficheiros de ID de fragmentos.</li>
</ul></li>
</ul>
<ol start="7">
<li><p>create_disk_layout: O índice global gerado no passo 6 tem apenas uma tabela de adjacência compacta. Este passo é para alinhar o índice. A tabela de adjacência e os dados originais são armazenados juntos. Ao pesquisar, carregue a tabela de adjacência e leia o vetor original em conjunto para um cálculo preciso da distância. Existe também o conceito de SECTOR, com o tamanho predefinido de 4096. Cada SECTOR contém apenas 4096 / node_size peças de informação do vetor. node_size = tamanho do vetor único + tamanho da tabela de adjacência do nó único.</p></li>
<li><p>Finalmente, faça uma amostragem uniforme global de 150000 / n, guarde-a e utilize-a para aquecimento durante a pesquisa.</p></li>
</ol>
<p><strong>Pesquisa</strong></p>
<p>Existem 10 parâmetros de pesquisa:</p>
<ul>
<li>tipo_de_índice: As opções incluem Float/int8/uint8, semelhante ao primeiro parâmetro data_type ao construir um índice.</li>
<li>index_prefix_path: Consulte o parâmetro de índice index_prefix_path.</li>
<li>num_nodes_to_cache: Número de hotspots de cache.</li>
<li>num_threads: Número de threads de pesquisa.</li>
<li>beamwidth: Limite superior do número de pontos de pré-carga. O sistema determina se está definido como 0.</li>
<li>query_file.bin: Ficheiro do conjunto de consultas.</li>
<li>truthset.bin: Ficheiro do conjunto de resultados, "null" significa que o conjunto de resultados não é fornecido, o programa calcula-o por si próprio;</li>
<li>K: topk;</li>
<li>result_output_prefix: Caminho para guardar os resultados da pesquisa;</li>
<li>L*: Lista de parâmetros de pesquisa. Podem ser adicionados vários valores. Para cada L, será fornecida informação estatística durante a pesquisa com L diferentes.</li>
</ul>
<p>Processo de pesquisa:</p>
<ol>
<li>Carregar dados relacionados: conjunto de consultas de carga, dados do ponto central PQ, dados do livro de códigos, ponto de início da pesquisa e outros dados, e ler o meta índice.</li>
<li>Utilizar o conjunto de dados amostrado durante a indexação para efetuar cached_beam_search, contar os tempos de acesso de cada ponto e carregar num_nodes_to_cache os pontos com a maior frequência de acesso à cache.</li>
<li>Existe uma operação WARMUP por defeito. Tal como no passo 2, este conjunto de dados de amostra também é utilizado para efetuar uma pesquisa_beam_search em cache.</li>
<li>De acordo com o número de parâmetros L fornecidos, cada L será executado com cached_beam_search novamente com o conjunto de consulta, e estatísticas como a taxa de recuperação e o QPS serão apresentadas. O processo de aquecimento e as estatísticas dos dados do hotspot não são contabilizados no tempo de consulta.</li>
</ol>
<p>Acerca de cached_beam_search:</p>
<ol>
<li>Encontrar o candidato mais próximo do ponto de consulta a partir do ponto de partida do candidato. A distância PQ é utilizada aqui e o ponto de partida é adicionado à fila de pesquisa.</li>
<li>Iniciar a pesquisa:</li>
</ol>
<ul>
<li>Na fila de pesquisa, não existem mais do que beam_width + 2 pontos não visitados. Se esses pontos estiverem na cache, adicione-os à fila de acertos da cache. Se não tiverem sido atingidos, adicione-os à fila de faltas. Certifique-se de que o tamanho da fila de falhas não exceda beam_width.</li>
<li>Envie pedidos assíncronos de acesso ao disco para os pontos na fila de faltas.</li>
<li>Para os pontos atingidos pela cache, utilize os dados originais e os dados da consulta para calcular a distância exacta, adicione-os à fila de resultados e, em seguida, utilize PQ para calcular a distância aos pontos vizinhos que não foram visitados antes de os adicionar à fila de pesquisa. O comprimento da fila de pesquisa é limitado por parâmetros.</li>
<li>Processar os pontos em falta armazenados em cache na etapa a, de forma semelhante à etapa c.</li>
<li>Quando a fila de pesquisa estiver vazia, a pesquisa termina e a fila de resultados topk é devolvida.</li>
</ul>
<h4 id="Summarize" class="common-anchor-header">Resumir</h4><p>Embora este seja um trabalho relativamente longo, é globalmente excelente. As ideias do artigo e do código são claras: dividir um número de baldes sobrepostos através de k-means e, em seguida, dividir os baldes para construir um índice de mapa e, finalmente, fundir os índices, o que é uma ideia relativamente nova. Quanto ao índice de grafos baseado em memória Vamana, é essencialmente uma versão inicializada aleatoriamente do NSG que pode controlar a granularidade do corte. Ao consultar, ele faz uso total do cache + pipeline, cobre parte do tempo de io e melhora o QPS. No entanto, de acordo com o documento, mesmo que as condições da máquina não sejam extraordinárias, o tempo de treino demora até 5 dias e a usabilidade é relativamente baixa. No futuro, é definitivamente necessário otimizar a formação. Do ponto de vista do código, a qualidade é relativamente elevada e pode ser utilizada diretamente no ambiente de produção.</p>
<h4 id="References" class="common-anchor-header">Referências</h4><ol>
<li><a href="https://www.microsoft.com/en-us/research/publication/diskann-fast-accurate-billion-point-nearest-neighbor-search-on-a-single-node/">Suhas Jayaram Subramanya, Fnu Devvrit, Harsha Vardhan Simhadri, Ravishankar Krishnawamy, Rohan Kadekodi. DiskANN: Pesquisa rápida e precisa do vizinho mais próximo de um bilhão de pontos em um único nó. NeurIPS 2019.</a></li>
<li>[Cong Fu, Chao Xiang, Changxu Wang e Deng Cai. Pesquisa rápida e aproximada do vizinho mais próximo com os gráficos de espalhamento de navegação. PVLDB, 12(5):461 - 474, 2019. doi: 10.14778/3303753.3303754.] (http://www.vldb.org/pvldb/vol12/p461-fu.pdf)</li>
<li>Cong Fu e Deng Cai. <a href="https://github.com/ZJULearning/efanna">GitHub - ZJULearning/efanna: biblioteca rápida para pesquisa ANN e construção de gráficos KNN.</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/50143204">Motor de busca para AI：高维数据检索工业级解决方案</a></li>
</ol>
<p>5.<a href="https://arxiv.org/abs/1802.02422"> Dmitry Baranchuk, Artem Babenko e Yury Malkov. Revisitando os índices invertidos para vizinhos mais próximos aproximados em mil milhões de escalas.</a></p>
