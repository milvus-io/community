{"codeList":["def create_feeds_train(self, batch_data):\n    hist_item = paddle.to_tensor(batch_data[0], dtype=\"int64\")\n    target_item = paddle.to_tensor(batch_data[1], dtype=\"int64\")\n    seq_len = paddle.to_tensor(batch_data[2], dtype=\"int64\")\n    return [hist_item, target_item, seq_len]\n","class Mind_Capsual_Layer(nn.Layer):\n    def __init__(self):\n        super(Mind_Capsual_Layer, self).__init__()\n        self.iters = iters\n        self.input_units = input_units\n        self.output_units = output_units\n        self.maxlen = maxlen\n        self.init_std = init_std\n        self.k_max = k_max\n        self.batch_size = batch_size\n        # B2I routing\n        self.routing_logits = self.create_parameter(\n            shape=[1, self.k_max, self.maxlen],\n            attr=paddle.ParamAttr(\n                name=\"routing_logits\", trainable=False),\n            default_initializer=nn.initializer.Normal(\n                mean=0.0, std=self.init_std))\n        # bilinear mapping\n        self.bilinear_mapping_matrix = self.create_parameter(\n            shape=[self.input_units, self.output_units],\n            attr=paddle.ParamAttr(\n                name=\"bilinear_mapping_matrix\", trainable=True),\n            default_initializer=nn.initializer.Normal(\n                mean=0.0, std=self.init_std))\n                \nclass MindLayer(nn.Layer):\n\n    def label_aware_attention(self, keys, query):\n        weight = paddle.sum(keys * query, axis=-1, keepdim=True)\n        weight = paddle.pow(weight, self.pow_p)  # [x,k_max,1]\n        weight = F.softmax(weight, axis=1)\n        output = paddle.sum(keys * weight, axis=1)\n        return output, weight\n\n    def forward(self, hist_item, seqlen, labels=None):\n        hit_item_emb = self.item_emb(hist_item)  # [B, seqlen, embed_dim]\n        user_cap, cap_weights, cap_mask = self.capsual_layer(hit_item_emb, seqlen)\n        if not self.training:\n            return user_cap, cap_weights\n        target_emb = self.item_emb(labels)\n        user_emb, W = self.label_aware_attention(user_cap, target_emb)\n\n        return self.sampled_softmax(\n            user_emb, labels, self.item_emb.weight,\n            self.embedding_bias), W, user_cap, cap_weights, cap_mask\n","def create_optimizer(self, dy_model, config):\n    lr = config.get(\"hyper_parameters.optimizer.learning_rate\", 0.001)\n    optimizer = paddle.optimizer.Adam(\n        learning_rate=lr, parameters=dy_model.parameters())\n    return optimizer\n","runner:\n  use_gpu: True\n  use_auc: False\n  train_batch_size: 128\n  epochs: 20\n  print_interval: 10\n  model_save_path: \"output_model_mind\"\n\n# hyper parameters of user-defined network\nhyper_parameters:\n  # optimizer config\n  optimizer:\n    class: Adam\n    learning_rate: 0.005\n","python -u trainer.py -m mind/config.yaml\n","python -u infer.py -m mind/config.yaml -top_n 50\n","uvicorn main:app\n","curl -X 'POST' \\\n  'http://127.0.0.1:8000/rec/insert_data' \\\n  -H 'accept: application/json' \\\n  -d ''\n","curl -X 'POST' \\\n  'http://127.0.0.1:8000/rec/recall' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"top_k\": 50,\n  \"hist_item\": [[43,23,65,675,3456,8654,123454,54367,234561],[675,3456,8654,123454,76543,1234,9769,5670,65443,123098,34219,234098]]\n}'\n","curl -X 'POST' \\\n  'http://127.0.0.1:8000/rec/count' \\\n  -H 'accept: application/json' \\\n  -d ''\n","curl -X 'POST' \\\n  'http://127.0.0.1:8000/qa/drop' \\\n  -H 'accept: application/json' \\\n  -d ''\n"],"headingContent":"","anchorList":[{"label":"O fluxo de trabalho básico de um sistema de recomendação","href":"The-basic-workflow-of-a-recommender-system","type":2,"isActive":false},{"label":"Arquitetura do sistema","href":"System-architecture","type":2,"isActive":false},{"label":"Implementação do sistema","href":"System-implementation","type":2,"isActive":false},{"label":"Recapitulação","href":"Recap","type":2,"isActive":false},{"label":"Sobre o autor","href":"About-the-author","type":2,"isActive":false},{"label":"Está à procura de mais recursos?","href":"Looking-for-more-resources","type":2,"isActive":false}]}