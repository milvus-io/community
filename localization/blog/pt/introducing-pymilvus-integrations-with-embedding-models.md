---
id: introducing-pymilvus-integrations-with-embedding-models.md
title: Apresentando a integra√ß√£o do PyMilvus com modelos de incorpora√ß√£o
author: Stephen Batifol
date: 2024-06-05T00:00:00.000Z
cover: assets.zilliz.com/Getting_started_with_Milvus_cluster_and_K8s_1_34b2c81802.png
tag: Engineering
tags: >-
  Milvus, Vector Database, Open Source, Data science, Artificial Intelligence,
  GenAI developers, Retrieval Augmented Generation, RAG
recommend: true
canonicalUrl: >-
  https://milvus.io/blog/introducing-pymilvus-integrations-with-embedding-models.md
---
<p><a href="https://milvus.io/intro">O Milvus</a> √© uma base de dados vetorial de c√≥digo aberto concebida especificamente para aplica√ß√µes de IA. Quer esteja a trabalhar em aprendizagem autom√°tica, aprendizagem profunda ou qualquer outro projeto relacionado com IA, o Milvus oferece uma forma robusta e eficiente de lidar com dados vectoriais em grande escala.</p>
<p>Agora, com a <a href="https://milvus.io/docs/embeddings.md">integra√ß√£o do m√≥dulo de modelo</a> no PyMilvus, o Python SDK para Milvus, √© ainda mais f√°cil adicionar modelos de Embedding e Reranking. Esta integra√ß√£o simplifica a transforma√ß√£o dos seus dados em vectores pesquis√°veis ou a reclassifica√ß√£o dos resultados para obter resultados mais precisos, como no <a href="https://zilliz.com/learn/Retrieval-Augmented-Generation">Retrieval Augmented Generation (RAG)</a>.</p>
<p>Neste blogue, vamos rever os modelos de incorpora√ß√£o densos, modelos de incorpora√ß√£o esparsos e re-classificadores e demonstrar como us√°-los na pr√°tica usando <a href="https://milvus.io/blog/introducing-milvus-lite.md">o Milvus Lite</a>, uma vers√£o leve do Milvus que pode ser executada localmente nas suas aplica√ß√µes Python.</p>
<h2 id="Dense-vs-Sparse-Embeddings" class="common-anchor-header">Embeddings densos vs esparsos<button data-href="#Dense-vs-Sparse-Embeddings" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Antes de mostrarmos como usar nossas integra√ß√µes, vamos dar uma olhada em duas categorias principais de embeddings vetoriais.</p>
<p><a href="https://zilliz.com/glossary/vector-embeddings">Embeddings v</a> etoriais geralmente se enquadram em duas categorias principais: <a href="https://zilliz.com/learn/sparse-and-dense-embeddings"><strong>Embeddings densos</strong> e <strong>Embeddings esparsos</strong></a>.</p>
<ul>
<li><p>Os Embeddings densos s√£o vetores de alta dimens√£o nos quais a maioria ou todos os elementos s√£o diferentes de zero, o que os torna ideais para codificar a sem√¢ntica do texto ou o significado difuso.</p></li>
<li><p>Os Embeddings esparsos s√£o vectores de alta dimens√£o com muitos elementos nulos, mais adequados para codificar conceitos exactos ou adjacentes.</p></li>
</ul>
<p>Milvus suporta ambos os tipos de embeddings e oferece pesquisa h√≠brida. <a href="https://zilliz.com/blog/hybrid-search-with-milvus">A pesquisa h√≠brida</a> permite-lhe efetuar pesquisas em v√°rios campos vectoriais dentro da mesma cole√ß√£o. Estes vectores podem representar diferentes facetas dos dados, utilizar diversos modelos de embedding ou empregar m√©todos de processamento de dados distintos, combinando os resultados atrav√©s de re-rankers.</p>
<h2 id="How-to-Use-Our-Embedding-and-Reranking-Integrations" class="common-anchor-header">Como usar nossas integra√ß√µes de incorpora√ß√£o e classifica√ß√£o<button data-href="#How-to-Use-Our-Embedding-and-Reranking-Integrations" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Nas se√ß√µes a seguir, demonstraremos tr√™s exemplos pr√°ticos de uso de nossas integra√ß√µes para gerar embeddings e conduzir pesquisas vetoriais.</p>
<h3 id="Example-1-Use-the-Default-Embedding-Function-to-Generate-Dense-Vectors" class="common-anchor-header">Exemplo 1: usar a fun√ß√£o de incorpora√ß√£o padr√£o para gerar vetores densos</h3><p>√â necess√°rio instalar o cliente <code translate="no">pymilvus</code> com o pacote <code translate="no">model</code> para usar as fun√ß√µes de embedding e reranking com o Milvus.</p>
<pre><code translate="no">pip install <span class="hljs-string">&quot;pymilvus[model]&quot;</span>
<button class="copy-code-btn"></button></code></pre>
<p>Este passo ir√° instalar <a href="https://milvus.io/docs/quickstart.md">o Milvus Lite</a>, permitindo-lhe executar o Milvus localmente dentro da sua aplica√ß√£o Python. Tamb√©m inclui o subpacote do modelo, que inclui todos os utilit√°rios para Embedding e reranking.</p>
<p>O subpacote de modelos suporta v√°rios modelos de incorpora√ß√£o, incluindo os da OpenAI, <a href="https://zilliz.com/learn/Sentence-Transformers-for-Long-Form-Text">Sentence Transformers</a>, <a href="https://zilliz.com/learn/bge-m3-and-splade-two-machine-learning-models-for-generating-sparse-embeddings">BGE-M3</a>, BM25, <a href="https://zilliz.com/learn/bge-m3-and-splade-two-machine-learning-models-for-generating-sparse-embeddings">SPLADE</a> e modelos pr√©-treinados da Jina AI.</p>
<p>Este exemplo usa o <code translate="no">DefaultEmbeddingFunction</code>, baseado no modelo <code translate="no">all-MiniLM-L6-v2</code> Sentence Transformer para simplificar. O modelo tem cerca de 70 MB e ser√° descarregado durante a primeira utiliza√ß√£o:</p>
<pre><code translate="no"><span class="hljs-keyword">from</span> pymilvus <span class="hljs-keyword">import</span> model

<span class="hljs-comment"># This will download &quot;all-MiniLM-L6-v2&quot;, a lightweight model.</span>
ef = model.DefaultEmbeddingFunction()

<span class="hljs-comment"># Data from which embeddings are to be generated</span>
docs = [
   <span class="hljs-string">&quot;Artificial intelligence was founded as an academic discipline in 1956.&quot;</span>,
   <span class="hljs-string">&quot;Alan Turing was the first person to conduct substantial research in AI.&quot;</span>,
   <span class="hljs-string">&quot;Born in Maida Vale, London, Turing was raised in southern England.&quot;</span>,
]

embeddings = ef.encode_documents(docs)

<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Embeddings:&quot;</span>, embeddings)
<span class="hljs-comment"># Print dimension and shape of embeddings</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Dim:&quot;</span>, ef.dim, embeddings[<span class="hljs-number">0</span>].shape)
<button class="copy-code-btn"></button></code></pre>
<p>O resultado esperado deve ser algo como o seguinte:</p>
<pre><code translate="no">Embeddings: [array([<span class="hljs-number">-3.09392996e-02</span>, <span class="hljs-number">-1.80662833e-02</span>,  <span class="hljs-number">1.34775648e-02</span>,  <span class="hljs-number">2.77156215e-02</span>,
      <span class="hljs-number">-4.86349640e-03</span>, <span class="hljs-number">-3.12581174e-02</span>, <span class="hljs-number">-3.55921760e-02</span>,  <span class="hljs-number">5.76934684e-03</span>,
       <span class="hljs-number">2.80773244e-03</span>,  <span class="hljs-number">1.35783911e-01</span>,  <span class="hljs-number">3.59678417e-02</span>,  <span class="hljs-number">6.17732145e-02</span>,
...
      <span class="hljs-number">-4.61330153e-02</span>, <span class="hljs-number">-4.85207550e-02</span>,  <span class="hljs-number">3.13997865e-02</span>,  <span class="hljs-number">7.82178566e-02</span>,
      <span class="hljs-number">-4.75336798e-02</span>,  <span class="hljs-number">5.21207601e-02</span>,  <span class="hljs-number">9.04406682e-02</span>, <span class="hljs-number">-5.36676683e-02</span>],
     dtype=<span class="hljs-type">float32</span>)]
Dim: <span class="hljs-number">384</span> (<span class="hljs-number">384</span>,)
<button class="copy-code-btn"></button></code></pre>
<h3 id="Example-2-Generate-Sparse-Vectors-Using-The-BM25-Model" class="common-anchor-header">Exemplo 2: Gerar vectores esparsos usando o modelo BM25</h3><p>O BM25 √© um m√©todo bem conhecido que usa frequ√™ncias de ocorr√™ncia de palavras para determinar a relev√¢ncia entre consultas e documentos. Neste exemplo, mostraremos como usar <code translate="no">BM25EmbeddingFunction</code> para gerar embeddings esparsos para consultas e documentos.</p>
<p>No BM25, √© importante calcular as estat√≠sticas nos seus documentos para obter o IDF (Inverse Document Frequency), que pode representar os padr√µes nos seus documentos. O IDF mede a quantidade de informa√ß√µes que uma palavra fornece, seja ela comum ou rara em todos os documentos.</p>
<pre><code translate="no"><span class="hljs-keyword">from</span> pymilvus.model.sparse <span class="hljs-keyword">import</span> BM25EmbeddingFunction

<span class="hljs-comment"># 1. Prepare a small corpus to search</span>
docs = [
   <span class="hljs-string">&quot;Artificial intelligence was founded as an academic discipline in 1956.&quot;</span>,
   <span class="hljs-string">&quot;Alan Turing was the first person to conduct substantial research in AI.&quot;</span>,
   <span class="hljs-string">&quot;Born in Maida Vale, London, Turing was raised in southern England.&quot;</span>,
]
query = <span class="hljs-string">&quot;Where was Turing born?&quot;</span>
bm25_ef = BM25EmbeddingFunction()

<span class="hljs-comment"># 2. Fit the corpus to get BM25 model parameters on your documents.</span>
bm25_ef.fit(docs)

<span class="hljs-comment"># 3. Store the fitted parameters to expedite future processing.</span>
bm25_ef.save(<span class="hljs-string">&quot;bm25_params.json&quot;</span>)

<span class="hljs-comment"># 4. Load the saved params</span>
new_bm25_ef = BM25EmbeddingFunction()
new_bm25_ef.load(<span class="hljs-string">&quot;bm25_params.json&quot;</span>)

docs_embeddings = new_bm25_ef.encode_documents(docs)
query_embeddings = new_bm25_ef.encode_queries([query])
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Dim:&quot;</span>, new_bm25_ef.dim, <span class="hljs-built_in">list</span>(docs_embeddings)[<span class="hljs-number">0</span>].shape)
<button class="copy-code-btn"></button></code></pre>
<h3 id="Example-3-Using-a-ReRanker" class="common-anchor-header">Exemplo 3: Utilizar um ReRanker</h3><p>Um sistema de pesquisa tem como objetivo encontrar os resultados mais relevantes de forma r√°pida e eficiente. Tradicionalmente, m√©todos como BM25 ou TF-IDF t√™m sido utilizados para classificar os resultados da pesquisa com base na correspond√™ncia de palavras-chave. Os m√©todos mais recentes, como a similaridade de cosseno baseada na incorpora√ß√£o, s√£o simples, mas podem por vezes ignorar as subtilezas da linguagem e, mais importante, a intera√ß√£o entre os documentos e a inten√ß√£o de uma consulta.</p>
<p>√â aqui que a utiliza√ß√£o de um <a href="https://zilliz.com/learn/optimize-rag-with-rerankers-the-role-and-tradeoffs">re-ranker</a> ajuda. Um re-classificador √© um modelo avan√ßado de IA que pega no conjunto inicial de resultados de uma pesquisa - muitas vezes fornecido por uma pesquisa baseada em embeddings/token - e reavalia-os para garantir que se alinham melhor com a inten√ß√£o do utilizador. N√£o se limita √† correspond√™ncia superficial de termos e considera a intera√ß√£o mais profunda entre a consulta de pesquisa e o conte√∫do dos documentos.</p>
<p>Para este exemplo, vamos utilizar o <a href="https://milvus.io/docs/integrate_with_jina.md">Jina AI Reranker</a>.</p>
<pre><code translate="no"><span class="hljs-keyword">from</span> pymilvus.model.reranker <span class="hljs-keyword">import</span> JinaRerankFunction

jina_api_key = <span class="hljs-string">&quot;&lt;YOUR_JINA_API_KEY&gt;&quot;</span>

rf = JinaRerankFunction(<span class="hljs-string">&quot;jina-reranker-v1-base-en&quot;</span>, jina_api_key)

query = <span class="hljs-string">&quot;What event in 1956 marked the official birth of artificial intelligence as a discipline?&quot;</span>

documents = [
   <span class="hljs-string">&quot;In 1950, Alan Turing published his seminal paper, &#x27;Computing Machinery and Intelligence,&#x27; proposing the Turing Test as a criterion of intelligence, a foundational concept in the philosophy and development of artificial intelligence.&quot;</span>,
   <span class="hljs-string">&quot;The Dartmouth Conference in 1956 is considered the birthplace of artificial intelligence as a field; here, John McCarthy and others coined the term &#x27;artificial intelligence&#x27; and laid out its basic goals.&quot;</span>,
   <span class="hljs-string">&quot;In 1951, British mathematician and computer scientist Alan Turing also developed the first program designed to play chess, demonstrating an early example of AI in game strategy.&quot;</span>,
   <span class="hljs-string">&quot;The invention of the Logic Theorist by Allen Newell, Herbert A. Simon, and Cliff Shaw in 1955 marked the creation of the first true AI program, which was capable of solving logic problems, akin to proving mathematical theorems.&quot;</span>
]

results = rf(query, documents)

<span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> results:
   <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Index: <span class="hljs-subst">{result.index}</span>&quot;</span>)
   <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Score: <span class="hljs-subst">{result.score:<span class="hljs-number">.6</span>f}</span>&quot;</span>)
   <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Text: <span class="hljs-subst">{result.text}</span>\n&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<p>O resultado esperado √© semelhante ao seguinte:</p>
<pre><code translate="no">Index: <span class="hljs-number">1</span>
Score: <span class="hljs-number">0.937096</span>
Text: The Dartmouth Conference <span class="hljs-keyword">in</span> <span class="hljs-number">1956</span> <span class="hljs-keyword">is</span> considered the birthplace of artificial intelligence <span class="hljs-keyword">as</span> a field; here, John McCarthy <span class="hljs-keyword">and</span> others coined the term <span class="hljs-string">&#x27;artificial intelligence&#x27;</span> <span class="hljs-keyword">and</span> laid <span class="hljs-keyword">out</span> its basic goals.

Index: <span class="hljs-number">3</span>
Score: <span class="hljs-number">0.354210</span>
Text: The invention of the Logic Theorist <span class="hljs-keyword">by</span> Allen Newell, Herbert A. Simon, <span class="hljs-keyword">and</span> Cliff Shaw <span class="hljs-keyword">in</span> <span class="hljs-number">1955</span> marked the creation of the first <span class="hljs-literal">true</span> AI program, which was capable of solving logic problems, akin to proving mathematical theorems.

Index: <span class="hljs-number">0</span>
Score: <span class="hljs-number">0.349866</span>
Text: In <span class="hljs-number">1950</span>, Alan Turing published his seminal paper, <span class="hljs-string">&#x27;Computing Machinery and Intelligence,&#x27;</span> proposing the Turing Test <span class="hljs-keyword">as</span> a criterion of intelligence, a foundational concept <span class="hljs-keyword">in</span> the philosophy <span class="hljs-keyword">and</span> development of artificial intelligence.

Index: <span class="hljs-number">2</span>
Score: <span class="hljs-number">0.272896</span>
Text: In <span class="hljs-number">1951</span>, British mathematician <span class="hljs-keyword">and</span> computer scientist Alan Turing also developed the first program designed to play chess, demonstrating an early example of AI <span class="hljs-keyword">in</span> game strategy.
<button class="copy-code-btn"></button></code></pre>
<h2 id="Star-Us-On-GitHub-and-Join-Our-Discord" class="common-anchor-header">Inscreva-nos no GitHub e junte-se ao nosso Discord!<button data-href="#Star-Us-On-GitHub-and-Join-Our-Discord" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Se gostou deste post, considere marcar Milvus com uma estrela no <a href="https://github.com/milvus-io/milvus">GitHub</a> e junte-se ao nosso <a href="https://discord.gg/FG6hMJStWu">Discord</a>! üíô</p>
