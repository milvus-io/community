---
id: Building-an-AI-Powered-Writing-Assistant-with-WPS-Office.md
title: Criar um assistente de escrita com IA para o WPS Office
author: milvus
date: 2020-07-28T03:35:40.105Z
desc: >-
  Saiba como a Kingsoft aproveitou o Milvus, um motor de pesquisa de semelhanças
  de código aberto, para criar um motor de recomendação para o assistente de
  escrita com IA do WPS Office.
cover: assets.zilliz.com/wps_thumbnail_6cb7876963.jpg
tag: Scenarios
canonicalUrl: >-
  https://zilliz.com/blog/Building-an-AI-Powered-Writing-Assistant-with-WPS-Office
---
<custom-h1>Criar um assistente de escrita com IA para o WPS Office</custom-h1><p>O WPS Office é uma ferramenta de produtividade desenvolvida pela Kingsoft com mais de 150 milhões de utilizadores em todo o mundo. O departamento de inteligência artificial (IA) da empresa criou um assistente de escrita inteligente a partir do zero, utilizando algoritmos de correspondência semântica, como o reconhecimento de intenções e o agrupamento de texto. A ferramenta existe como uma aplicação Web e como um <a href="https://walkthechat.com/wechat-mini-programs-simple-introduction/">mini-programa WeChat</a> que ajuda os utilizadores a criar rapidamente esboços, parágrafos individuais e documentos completos, bastando introduzir um título e selecionar até cinco palavras-chave.</p>
<p>O motor de recomendação do assistente de escrita utiliza o Milvus, um motor de pesquisa de semelhanças de código aberto, para alimentar o seu módulo de processamento vetorial principal. De seguida, vamos explorar o processo de criação do assistente de escrita inteligente do WPS Offices, incluindo a forma como as caraterísticas são extraídas de dados não estruturados, bem como o papel que o Milvus desempenha no armazenamento de dados e na alimentação do motor de recomendação da ferramenta.</p>
<p>Saltar para:</p>
<ul>
<li><a href="#building-an-ai-powered-writing-assistant-for-wps-office">Criar um assistente de escrita com IA para o WPS Office</a><ul>
<li><a href="#making-sense-of-unstructured-textual-data">Dar sentido a dados textuais não estruturados</a></li>
<li><a href="#using-the-tfidf-model-to-maximize-feature-extraction">Utilizar o modelo TFIDF para maximizar a extração de caraterísticas</a></li>
<li><a href="#extracting-features-with-the-bi-directional-lstm-cnns-crf-deep-learning-model">Extração de recursos com o modelo de aprendizado profundo bidirecional LSTM-CNNs-CRF</a></li>
<li><a href="#creating-sentence-embeddings-using-infersent">Criação de embeddings de frases utilizando o Infersent</a></li>
<li><a href="#storing-and-querying-vectors-with-milvus">Armazenamento e consulta de vectores com o Milvus</a></li>
<li><a href="#ai-isnt-replacing-writers-its-helping-them-write">A IA não está a substituir os escritores, está a ajudá-los a escrever</a></li>
</ul></li>
</ul>
<h3 id="Making-sense-of-unstructured-textual-data" class="common-anchor-header">Dar sentido a dados textuais não estruturados</h3><p>Tal como qualquer problema moderno que valha a pena resolver, a criação do assistente de escrita WPS começa com dados confusos. Dezenas de milhões de documentos de texto densos dos quais é necessário extrair caraterísticas significativas, para ser um pouco mais preciso. Para compreender a complexidade deste problema, considere a forma como dois jornalistas de diferentes agências noticiosas podem fazer uma reportagem sobre o mesmo tópico.</p>
<p>Embora ambos respeitem as regras, os princípios e os processos que regem a estrutura das frases, farão escolhas de palavras diferentes, criarão frases de comprimento variável e utilizarão as suas próprias estruturas de artigos para contar histórias semelhantes (ou talvez diferentes). Ao contrário dos conjuntos de dados estruturados com um número fixo de dimensões, os corpos de texto carecem inerentemente de estrutura porque a sintaxe que os rege é muito maleável. Para encontrar significado, é necessário extrair caraterísticas legíveis por máquinas de um corpus de documentos não estruturados. Mas primeiro, os dados têm de ser limpos.</p>
<p>Existem várias formas de limpar dados textuais, nenhuma das quais será abordada em pormenor neste artigo. No entanto, este é um passo importante que antecipa o processamento dos dados e pode incluir a remoção de etiquetas, a remoção de caracteres acentuados, a expansão de contracções, a remoção de caracteres especiais, a remoção de stopwords e muito mais. Uma explicação detalhada dos métodos de pré-processamento e limpeza de dados de texto pode ser encontrada <a href="https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41">aqui</a>.</p>
<h3 id="Using-the-TFIDF-model-to-maximize-feature-extraction" class="common-anchor-header">Utilizar o modelo TFIDF para maximizar a extração de caraterísticas</h3><p>Para começar a dar sentido aos dados textuais não estruturados, o modelo TFIDF (term frequency-inverse document frequency) foi aplicado ao corpus do qual o assistente de escrita WPS extrai. Este modelo utiliza uma combinação de duas métricas, a frequência de termos e a frequência inversa de documentos, para atribuir a cada palavra de um documento um valor TFIDF. A frequência de termos (TF) representa a contagem bruta de um termo num documento dividida pelo número total de termos no documento, enquanto a frequência inversa de documentos (IDF) é o número de documentos num corpus dividido pelo número de documentos em que um termo aparece.</p>
<p>O produto de TF e IDF fornece uma medida da frequência com que um termo aparece num documento multiplicada pelo grau de exclusividade da palavra no corpus. Em última análise, os valores TFIDF são uma medida da relevância de uma palavra para um documento dentro de uma coleção de documentos. Os termos são ordenados por valores TFIDF, e aqueles com valores baixos (ou seja, palavras comuns) podem ter menos peso quando se utiliza a aprendizagem profunda para extrair caraterísticas do corpus.</p>
<h3 id="Extracting-features-with-the-bi-directional-LSTM-CNNs-CRF-deep-learning-model" class="common-anchor-header">Extração de caraterísticas com o modelo de aprendizagem profunda bidirecional LSTM-CNNs-CRF</h3><p>Utilizando uma combinação de memória de curto prazo longa bidirecional (BLSTM), redes neuronais convolucionais (CNN) e campos aleatórios condicionais (CRF), é possível extrair do corpus representações ao nível das palavras e dos caracteres. O <a href="https://arxiv.org/pdf/1603.01354.pdf">modelo BLSTM-CNNs-CRF</a> utilizado para construir o assistente de escrita WPS Office funciona da seguinte forma</p>
<ol>
<li><strong>CNN:</strong> Os embeddings de caracteres são utilizados como entradas para a CNN, depois as estruturas de palavras semanticamente relevantes (ou seja, o prefixo ou o sufixo) são extraídas e codificadas em vectores de representação ao nível dos caracteres.</li>
<li><strong>BLSTM:</strong> Os vectores ao nível dos caracteres são concatenados com os vectores de incorporação de palavras e depois introduzidos na rede BLSTM. Cada sequência é apresentada para a frente e para trás em dois estados ocultos separados para captar informações passadas e futuras.</li>
<li><strong>CRF:</strong> Os vectores de saída da BLSTM são enviados para a camada CRF para descodificar conjuntamente a melhor sequência de etiquetas.</li>
</ol>
<p>A rede neural é agora capaz de extrair e classificar entidades nomeadas a partir de texto não estruturado. Este processo é designado por <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">reconhecimento de entidades nomeadas (NER)</a> e envolve a localização e classificação de categorias como nomes de pessoas, instituições, localizações geográficas, entre outras. Estas entidades desempenham um papel importante na ordenação e recuperação de dados. A partir daqui, podem ser extraídas frases-chave, parágrafos e resumos do corpus.</p>
<h3 id="Creating-sentence-embeddings-using-Infersent" class="common-anchor-header">Criação de frases incorporadas utilizando o Infersent</h3><p><a href="https://github.com/facebookresearch/InferSent">O Infersent</a>, um método supervisionado de incorporação de frases concebido pelo Facebook que incorpora frases completas no espaço vetorial, é utilizado para criar vectores que serão introduzidos na base de dados Milvus. O Infersent foi treinado utilizando o corpus Stanford Natural Language Inference (SNLI), que contém 570 mil pares de frases que foram escritas e etiquetadas por humanos. Mais informações sobre o funcionamento do Infersent podem ser encontradas <a href="https://medium.com/analytics-vidhya/sentence-embeddings-facebooks-infersent-6ac4a9fc2001">aqui</a>.</p>
<h3 id="Storing-and-querying-vectors-with-Milvus" class="common-anchor-header">Armazenamento e consulta de vectores com o Milvus</h3><p><a href="https://www.milvus.io/">O Milvus</a> é um motor de pesquisa de similaridades de código aberto que suporta a adição, eliminação, atualização e pesquisa quase em tempo real de embeddings numa escala de triliões de bytes. Para melhorar o desempenho da consulta, o Milvus permite que um tipo de índice seja especificado para cada campo de vetor. O assistente inteligente WPS Office utiliza o índice IVF_FLAT, o tipo de índice mais básico de Ficheiro Invertido (IVF), em que "flat" significa que os vectores são armazenados sem compressão ou quantização. O agrupamento é baseado no IndexFlat2, que utiliza a pesquisa exacta para a distância L2.</p>
<p>Embora o IVF_FLAT tenha uma taxa de recuperação de consulta de 100%, a sua falta de compressão resulta em velocidades de consulta comparativamente lentas. A <a href="https://milvus.io/docs/manage-partitions.md">função de particionamento</a> do Milvus é utilizada para dividir os dados em várias partes do armazenamento físico com base em regras predefinidas, tornando as consultas mais rápidas e mais exactas. Quando os vectores são adicionados ao Milvus, as etiquetas especificam a que partição os dados devem ser adicionados. As consultas dos dados vectoriais utilizam etiquetas para especificar em que partição a consulta deve ser executada. Os dados podem ainda ser divididos em segmentos dentro de cada partição para melhorar ainda mais a velocidade.</p>
<p>O assistente de escrita inteligente também utiliza clusters Kubernetes, permitindo que os contentores de aplicações sejam executados em várias máquinas e ambientes, bem como MySQL para gestão de metadados.</p>
<h3 id="AI-isn’t-replacing-writers-it’s-helping-them-write" class="common-anchor-header">A IA não está a substituir os escritores, está a ajudá-los a escrever</h3><p>O assistente de escrita da Kingsoft para o WPS Office conta com o Milvus para gerir e consultar uma base de dados com mais de 2 milhões de documentos. O sistema é altamente flexível, capaz de efetuar pesquisas quase em tempo real em conjuntos de dados à escala de um bilião. As consultas são concluídas em 0,2 segundos, em média, o que significa que podem ser gerados documentos inteiros quase instantaneamente utilizando apenas um título ou algumas palavras-chave. Embora a IA não esteja a substituir os escritores profissionais, a tecnologia que existe atualmente é capaz de aumentar o processo de escrita de formas novas e interessantes. O futuro é desconhecido, mas, pelo menos, os escritores podem esperar métodos mais produtivos e, para alguns, menos difíceis de "pôr a caneta no papel".</p>
<p>As seguintes fontes foram utilizadas para este artigo:</p>
<ul>
<li>"<a href="https://arxiv.org/pdf/1603.01354.pdf">End-to-end Sequence Labeling via Bi-diretional LSTM-CNNs-CRF</a>," Xuezhe Ma e Eduard Hovy.</li>
<li>"<a href="https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41">Métodos tradicionais para dados de texto</a>", Dipanjan (DJ) Sarkar.</li>
<li>"<a href="https://ieeexplore.ieee.org/document/8780663">Text Features Extraction based on TF-IDF Associating Semantic</a>," Qing Liu, Jing Wang, Dehai Zhang, Yun Yang, NaiYao Wang.</li>
<li>"<a href="https://medium.com/analytics-vidhya/sentence-embeddings-facebooks-infersent-6ac4a9fc2001">Understanding Sentence Embeddings using Facebook's Infersent</a>", Rehan Ahmad</li>
<li>"<a href="https://arxiv.org/pdf/1705.02364.pdf">Aprendizagem supervisionada de representações de frases universais a partir de dados de inferência de linguagem natural</a>", Alexis Conneau, Douwe Kiela, Holger Schwenk, LoÏc Barrault, Antoine Bordes.V1</li>
</ul>
<p>Leia outras <a href="https://zilliz.com/user-stories">histórias de utilizadores</a> para saber mais sobre como fazer coisas com o Milvus.</p>
