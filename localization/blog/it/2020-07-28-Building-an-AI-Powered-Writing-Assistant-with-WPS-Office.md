---
id: Building-an-AI-Powered-Writing-Assistant-with-WPS-Office.md
title: >-
  Creare un assistente di scrittura dotato di intelligenza artificiale per WPS
  Office
author: milvus
date: 2020-07-28T03:35:40.105Z
desc: >-
  Scoprite come Kingsoft ha sfruttato Milvus, un motore di ricerca di
  somiglianze open-source, per creare un motore di raccomandazione per
  l'assistente di scrittura AI di WPS Office.
cover: assets.zilliz.com/wps_thumbnail_6cb7876963.jpg
tag: Scenarios
canonicalUrl: >-
  https://zilliz.com/blog/Building-an-AI-Powered-Writing-Assistant-with-WPS-Office
---
<custom-h1>Creazione di un assistente di scrittura dotato di intelligenza artificiale per WPS Office</custom-h1><p>WPS Office è uno strumento di produttività sviluppato da Kingsoft con oltre 150 milioni di utenti in tutto il mondo. Il dipartimento di intelligenza artificiale (AI) dell'azienda ha costruito da zero un assistente di scrittura intelligente utilizzando algoritmi di corrispondenza semantica come il riconoscimento delle intenzioni e il clustering del testo. Lo strumento esiste sia come applicazione web che come <a href="https://walkthechat.com/wechat-mini-programs-simple-introduction/">mini programma WeChat</a> che aiuta gli utenti a creare rapidamente schemi, singoli paragrafi e interi documenti semplicemente inserendo un titolo e selezionando fino a cinque parole chiave.</p>
<p>Il motore di raccomandazione dell'assistente di scrittura utilizza Milvus, un motore di ricerca di similarità open-source, per alimentare il suo modulo di elaborazione vettoriale. Di seguito esploreremo il processo di costruzione dell'assistente di scrittura intelligente di WPS Offices, compreso il modo in cui vengono estratte le caratteristiche dai dati non strutturati e il ruolo svolto da Milvus nell'archiviazione dei dati e nell'alimentazione del motore di raccomandazione dello strumento.</p>
<p>Vai a:</p>
<ul>
<li><a href="#building-an-ai-powered-writing-assistant-for-wps-office">Creazione di un assistente di scrittura dotato di intelligenza artificiale per WPS Office</a><ul>
<li><a href="#making-sense-of-unstructured-textual-data">Dare un senso ai dati testuali non strutturati</a></li>
<li><a href="#using-the-tfidf-model-to-maximize-feature-extraction">Utilizzo del modello TFIDF per massimizzare l'estrazione delle caratteristiche</a></li>
<li><a href="#extracting-features-with-the-bi-directional-lstm-cnns-crf-deep-learning-model">Estrazione delle caratteristiche con il modello di deep learning bidirezionale LSTM-CNNs-CRF</a></li>
<li><a href="#creating-sentence-embeddings-using-infersent">Creazione di embeddings di frasi con Infersent</a></li>
<li><a href="#storing-and-querying-vectors-with-milvus">Memorizzazione e interrogazione di vettori con Milvus</a></li>
<li><a href="#ai-isnt-replacing-writers-its-helping-them-write">L'intelligenza artificiale non sta sostituendo gli scrittori, ma li sta aiutando a scrivere</a></li>
</ul></li>
</ul>
<h3 id="Making-sense-of-unstructured-textual-data" class="common-anchor-header">Dare un senso ai dati testuali non strutturati</h3><p>Come ogni problema moderno che valga la pena di risolvere, la costruzione dell'assistente di scrittura WPS inizia con dati disordinati. Decine di milioni di documenti di testo densi da cui estrarre caratteristiche significative, per essere un po' più precisi. Per capire la complessità di questo problema, si pensi a come due giornalisti di testate diverse potrebbero raccontare lo stesso argomento.</p>
<p>Sebbene entrambi si attengano alle regole, ai principi e ai processi che governano la struttura delle frasi, faranno scelte di parole diverse, creeranno frasi di lunghezza variabile e utilizzeranno le proprie strutture di articoli per raccontare storie simili (o forse dissimili). A differenza degli insiemi di dati strutturati con un numero fisso di dimensioni, i corpi di testo mancano intrinsecamente di struttura perché la sintassi che li governa è così malleabile. Per trovare un significato, è necessario estrarre caratteristiche leggibili dalla macchina da un corpus di documenti non strutturati. Ma prima i dati devono essere puliti.</p>
<p>Esistono diversi modi per ripulire i dati testuali, nessuno dei quali verrà trattato in modo approfondito in questo articolo. Tuttavia, si tratta di una fase importante che precede l'elaborazione dei dati e che può comprendere la rimozione di tag, l'eliminazione di caratteri accentati, l'espansione di contrazioni, l'eliminazione di caratteri speciali, l'eliminazione di stopword e altro ancora. Una spiegazione dettagliata dei metodi di pre-elaborazione e pulizia dei dati testuali è disponibile <a href="https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41">qui</a>.</p>
<h3 id="Using-the-TFIDF-model-to-maximize-feature-extraction" class="common-anchor-header">Utilizzo del modello TFIDF per massimizzare l'estrazione delle caratteristiche</h3><p>Per iniziare a dare un senso ai dati testuali non strutturati, è stato applicato il modello TFIDF (term frequency-inverse document frequency) al corpus da cui attinge l'assistente di scrittura WPS. Questo modello utilizza una combinazione di due metriche, la frequenza dei termini e la frequenza inversa dei documenti, per attribuire a ogni parola di un documento un valore TFIDF. La frequenza dei termini (TF) rappresenta il conteggio grezzo di un termine in un documento diviso per il numero totale di termini nel documento, mentre la frequenza inversa dei documenti (IDF) è il numero di documenti in un corpus diviso per il numero di documenti in cui compare un termine.</p>
<p>Il prodotto di TF e IDF fornisce una misura della frequenza con cui un termine appare in un documento moltiplicata per l'unicità della parola nel corpus. In definitiva, i valori TFIDF sono una misura della rilevanza di una parola per un documento all'interno di un insieme di documenti. I termini sono ordinati in base ai valori TFIDF e a quelli con valori bassi (cioè parole comuni) può essere attribuito un peso minore quando si utilizza il deep learning per estrarre le caratteristiche dal corpus.</p>
<h3 id="Extracting-features-with-the-bi-directional-LSTM-CNNs-CRF-deep-learning-model" class="common-anchor-header">Estrazione di caratteristiche con il modello di deep learning bidirezionale LSTM-CNNs-CRF</h3><p>Utilizzando una combinazione di memoria bidirezionale a breve termine (BLSTM), reti neurali convoluzionali (CNN) e campi casuali condizionali (CRF) è possibile estrarre dal corpus rappresentazioni a livello di parola e di carattere. Il <a href="https://arxiv.org/pdf/1603.01354.pdf">modello BLSTM-CNNs-CRF</a> utilizzato per costruire l'assistente di scrittura WPS Office funziona come segue:</p>
<ol>
<li><strong>CNN:</strong> Le incorporazioni dei caratteri vengono utilizzate come input della CNN, quindi vengono estratte le strutture di parole semanticamente rilevanti (ad esempio il prefisso o il suffisso) e codificate in vettori di rappresentazione a livello di carattere.</li>
<li><strong>BLSTM:</strong> i vettori a livello di carattere vengono concatenati con i vettori di rappresentazione delle parole e poi inseriti nella rete BLSTM. Ogni sequenza viene presentata in avanti e indietro a due stati nascosti separati per catturare le informazioni passate e future.</li>
<li><strong>CRF:</strong> i vettori di uscita del BLSTM vengono inviati allo strato CRF per decodificare congiuntamente la migliore sequenza di etichette.</li>
</ol>
<p>La rete neurale è ora in grado di estrarre e classificare entità nominate da un testo non strutturato. Questo processo è chiamato <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">riconoscimento di entità denominate (NER)</a> e comporta l'individuazione e la classificazione di categorie come nomi di persone, istituzioni, località geografiche e altro ancora. Queste entità svolgono un ruolo importante nell'ordinamento e nel richiamo dei dati. Da qui è possibile estrarre dal corpus frasi, paragrafi e riassunti chiave.</p>
<h3 id="Creating-sentence-embeddings-using-Infersent" class="common-anchor-header">Creazione di incorporazioni di frasi con Infersent</h3><p><a href="https://github.com/facebookresearch/InferSent">Infersent</a>, un metodo supervisionato di incorporamento delle frasi progettato da Facebook che incorpora frasi complete nello spazio vettoriale, viene utilizzato per creare i vettori che verranno inseriti nel database Milvus. Infersent è stato addestrato utilizzando il corpus Stanford Natural Language Inference (SNLI), che contiene 570k coppie di frasi scritte ed etichettate da esseri umani. Ulteriori informazioni sul funzionamento di Infersent sono disponibili <a href="https://medium.com/analytics-vidhya/sentence-embeddings-facebooks-infersent-6ac4a9fc2001">qui</a>.</p>
<h3 id="Storing-and-querying-vectors-with-Milvus" class="common-anchor-header">Memorizzazione e interrogazione di vettori con Milvus</h3><p><a href="https://www.milvus.io/">Milvus</a> è un motore di ricerca di similarità open source che supporta l'aggiunta, la cancellazione, l'aggiornamento e la ricerca quasi in tempo reale di embeddings su una scala di trilioni di byte. Per migliorare le prestazioni delle query, Milvus consente di specificare un tipo di indice per ogni campo vettoriale. L'assistente intelligente di WPS Office utilizza l'indice IVF_FLAT, il tipo di indice più semplice di Inverted File (IVF), dove "flat" significa che i vettori sono memorizzati senza compressione o quantizzazione. Il clustering si basa su IndexFlat2, che utilizza la ricerca esatta per la distanza L2.</p>
<p>Sebbene IVF_FLAT abbia un tasso di richiamo delle query del 100%, la mancanza di compressione comporta una velocità di interrogazione relativamente bassa. La <a href="https://milvus.io/docs/manage-partitions.md">funzione di partizionamento</a> di Milvus viene utilizzata per dividere i dati in più parti dello storage fisico in base a regole predefinite, rendendo le query più veloci e precise. Quando i vettori vengono aggiunti a Milvus, i tag specificano a quale partizione devono essere aggiunti i dati. Le interrogazioni dei dati vettoriali utilizzano i tag per specificare su quale partizione deve essere eseguita l'interrogazione. I dati possono essere ulteriormente suddivisi in segmenti all'interno di ogni partizione per migliorare ulteriormente la velocità.</p>
<p>L'assistente di scrittura intelligente utilizza anche i cluster Kubernetes, che consentono l'esecuzione di container di applicazioni su più macchine e ambienti, e MySQL per la gestione dei metadati.</p>
<h3 id="AI-isn’t-replacing-writers-it’s-helping-them-write" class="common-anchor-header">L'intelligenza artificiale non sostituisce gli scrittori, ma li aiuta a scrivere</h3><p>L'assistente di scrittura di Kingsoft per WPS Office si basa su Milvus per gestire e interrogare un database di oltre 2 milioni di documenti. Il sistema è altamente flessibile, in grado di eseguire ricerche in tempo quasi reale su set di dati di dimensioni trilionarie. Le interrogazioni vengono completate in media in 0,2 secondi, il che significa che è possibile generare quasi istantaneamente interi documenti utilizzando solo un titolo o alcune parole chiave. Anche se l'intelligenza artificiale non sta sostituendo gli scrittori professionisti, la tecnologia che esiste oggi è in grado di aumentare il processo di scrittura in modi nuovi e interessanti. Il futuro è ignoto, ma per lo meno gli scrittori possono sperare in metodi più produttivi, e per alcuni meno difficili, di "mettere la penna sulla carta".</p>
<p>Per questo articolo sono state utilizzate le seguenti fonti:</p>
<ul>
<li>"<a href="https://arxiv.org/pdf/1603.01354.pdf">End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</a>", Xuezhe Ma e Eduard Hovy.</li>
<li>"<a href="https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41">Metodi tradizionali per i dati di testo</a>", Dipanjan (DJ) Sarkar.</li>
<li>"<a href="https://ieeexplore.ieee.org/document/8780663">Estrazione di caratteristiche testuali basate sulla semantica associata TF-IDF</a>", Qing Liu, Jing Wang, Dehai Zhang, Yun Yang, NaiYao Wang.</li>
<li>"<a href="https://medium.com/analytics-vidhya/sentence-embeddings-facebooks-infersent-6ac4a9fc2001">Comprensione degli incorporamenti di frasi utilizzando Infersent di Facebook</a>", Rehan Ahmad.</li>
<li>"<a href="https://arxiv.org/pdf/1705.02364.pdf">Apprendimento supervisionato di rappresentazioni universali di frasi dai dati di inferenza del linguaggio naturale</a>", Alexis Conneau, Douwe Kiela, Holger Schwenk, LoÏc Barrault, Antoine Bordes.V1</li>
</ul>
<p>Leggete altre <a href="https://zilliz.com/user-stories">storie di utenti per</a> saperne di più su come creare cose con Milvus.</p>
