---
id: matryoshka-embeddings-detail-at-multiple-scales
title: 'Incorporamenti a matrioska: Dettaglio a più scale'
author: 'Stefan Webb, David Wang'
date: 2024-10-30T00:00:00.000Z
desc: >-
  Embeddings con dimensioni ridotte senza sacrificare l'integrità semantica,
  ideali per ricerche e archiviazioni più efficienti.
metaTitle: What are Matryoshka Embeddings?
cover: assets.zilliz.com/Introduction_to_Matryoshka_Embedding_e5a5bc2056.png
tag: Engineering
tags: Matryoshka Embeddings
recommend: true
canonicalUrl: 'https://milvus.io/blog/matryoshka-embeddings-detail-at-multiple-scales'
---
<h2 id="What-are-Matryoshka-Embeddings" class="common-anchor-header">Cosa sono le Matryoshka Embeddings?<button data-href="#What-are-Matryoshka-Embeddings" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Quando si costruiscono sistemi di <a href="https://zilliz.com/learn/vector-similarity-search">ricerca vettoriale</a> efficienti, una sfida fondamentale è la gestione dei costi di memorizzazione, mantenendo una latenza e un richiamo accettabili. I moderni <a href="https://zilliz.com/blog/choosing-the-right-embedding-model-for-your-data">modelli di embedding</a> producono vettori con centinaia o migliaia di dimensioni, creando un significativo overhead di memorizzazione e calcolo per il vettore grezzo e l'indice.</p>
<p>Tradizionalmente, i requisiti di memorizzazione vengono ridotti applicando un metodo di quantizzazione o di riduzione della dimensionalità appena prima di costruire l'indice. Ad esempio, è possibile risparmiare memoria riducendo la precisione con la <a href="https://zilliz.com/learn/scalar-quantization-and-product-quantization">quantizzazione del prodotto (PQ</a> ) o il numero di dimensioni con l'analisi delle componenti principali (PCA). Questi metodi analizzano l'intero insieme di vettori per trovarne uno più compatto che mantenga le relazioni semantiche tra i vettori.</p>
<p>Pur essendo efficaci, questi approcci standard riducono la precisione o la dimensionalità solo una volta e su un'unica scala. Ma cosa succederebbe se potessimo mantenere più livelli di dettaglio contemporaneamente, come una piramide di rappresentazioni sempre più precise?</p>
<p>Ecco le <a href="https://arxiv.org/abs/2205.13147"><strong>Matryoshka embeddings</strong></a>. Questi costrutti intelligenti, che prendono il nome dalle matrioske russe (vedi illustrazione), incorporano più scale di rappresentazione all'interno di un singolo vettore. A differenza dei metodi tradizionali di post-elaborazione, le Matryoshka embeddings apprendono questa struttura multi-scala durante il processo di addestramento iniziale. Il risultato è notevole: <strong>non solo l'embedding completo cattura la semantica dell'input, ma ogni prefisso del sottoinsieme annidato (prima metà, primo quarto, ecc.) fornisce una rappresentazione coerente, anche se meno dettagliata.</strong></p>
<p>
 <span class="img-wrapper">
   <img translate="no" src="https://assets.zilliz.com/Visualization_of_Matryoshka_embeddings_with_multiple_layers_of_detail_274f2c7aba.png" alt="Figure: Visualization of Matryoshka embeddings with multiple layers of detail" class="doc-image" id="figure:-visualization-of-matryoshka-embeddings-with-multiple-layers-of-detail" />
   <span>Figura: Visualizzazione di embedding Matryoshka con più livelli di dettaglio</span> </span></p>
<p><em>Figura: Visualizzazione delle Matryoshka embeddings con più livelli di dettaglio</em></p>
<p>Questo approccio è in netto contrasto con le <a href="https://zilliz.com/glossary/vector-embeddings">incorporazioni</a> convenzionali, dove l'uso di sottoinsiemi arbitrari delle dimensioni del vettore distrugge tipicamente il significato semantico. Con le Matryoshka embeddings, è possibile scegliere la granularità che meglio bilancia la precisione e il costo computazionale di un compito specifico.</p>
<p>Avete bisogno di una rapida ricerca approssimativa? Usate la "bambola" più piccola. Avete bisogno della massima precisione? Utilizzate l'incorporazione completa. Questa flessibilità li rende particolarmente preziosi per i sistemi che si adattano a requisiti di prestazione diversi o a vincoli di risorse.</p>
<h2 id="Inference" class="common-anchor-header">Inferenza<button data-href="#Inference" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Un'applicazione preziosa delle Matryoshka embeddings è l'accelerazione delle ricerche di similarità senza sacrificare il richiamo. Sfruttando sottoinsiemi più piccoli di embeddings di query e database - come i primi 1/32 delle loro dimensioni - possiamo costruire un indice su questo spazio ridotto che conserva ancora gran parte delle informazioni sulla somiglianza. I risultati iniziali di questo spazio di incorporamento più piccolo possono essere utilizzati direttamente. Tuttavia, esiste anche una tecnica per aumentare il richiamo e tenere conto di qualsiasi riduzione minore dovuta alla riduzione dimensionale, rendendo questo approccio efficiente ed efficace per le attività di ricerca per similarità.</p>
<p>
 <span class="img-wrapper">
   <img translate="no" src="https://assets.zilliz.com/How_the_funnel_search_works_with_Matryoshka_embeddings_8fa05a2fe7.png" alt="Figure: How the funnel search works with Matryoshka embeddings" class="doc-image" id="figure:-how-the-funnel-search-works-with-matryoshka-embeddings" />
   <span>Figura: Come funziona la ricerca a imbuto con le Matryoshka embeddings</span> </span></p>
<p><em>Figura: Come funziona la ricerca a imbuto con le Matryoshka embeddings</em></p>
<p>Per accelerare in modo efficiente la ricerca di similarità, mantenendo al contempo l'accuratezza, possiamo utilizzare un approccio di "ricerca a imbuto". In primo luogo, si esegue una ricerca di somiglianza iniziale utilizzando solo i primi 1/32 delle dimensioni dell'embedding, generando un ampio pool di elementi candidati. In seguito, si classifica questi candidati in base alla loro somiglianza con la query utilizzando i primi 1/16 delle dimensioni, tagliando una parte dell'elenco. Questo processo continua in modo iterativo, con la riclassificazione e la potatura di sottoinsiemi sempre più ampi delle dimensioni di incorporamento: 1/8, 1/4 e così via. È importante notare che viene eseguita una sola ricerca iniziale di somiglianza in questo spazio a bassa dimensione e che un solo passaggio del modello di embedding calcola l'embedding della query. Questo processo di incanalamento restringe i candidati a ogni passo ed è più veloce ed efficiente rispetto alla ricerca diretta nello spazio full-dimensionale. L'estrazione di molte corrispondenze dallo spazio 1/32-dimensionale e la loro raffinazione attraverso la ricerca a imbuto possono accelerare in modo significativo la ricerca di somiglianza, pur mantenendo un forte richiamo.</p>
<h2 id="Training" class="common-anchor-header">Formazione<button data-href="#Training" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Vediamo alcuni dettagli tecnici. Il metodo è molto semplice da applicare. Consideriamo il contesto della messa a punto di un <a href="https://zilliz.com/learn/what-is-bert">modello BERT</a> per l'incorporazione di frasi. Per convertire un modello BERT, che è stato pre-addestrato sulla perdita dei token mascherati, in un modello di embedding di frase, formiamo l'embedding di frase come la media dello strato finale, cioè la media degli embedding contestualizzati per token.</p>
<p>Una scelta di obiettivi di addestramento è la <a href="https://sbert.net/docs/package_reference/sentence_transformer/losses.html#cosentloss">perdita Cosine Sentence (CoSENT)</a>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo separator="true">;</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L(u, v; s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span></span></span></span> L <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span></span> v <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span></span> s <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mclose">)</span></span></span></span>. Si inserisce una coppia di incorporazioni di frasi, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">vu,v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span></span></span></span> u <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span></span> v, e il loro punteggio di somiglianza desiderato, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">ss</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span></span></span></span> s (si veda il link sopra per la formula). Ora, per imparare le incorporazioni Matryoshka, apportiamo una piccola modifica all'obiettivo dell'addestramento:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>LM</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo><mi>=w0L</mi><mo stretchy="false">(</mo><msub><mrow><mn>u1</mn><mo>:</mo><mi>d</mi></mrow></msub><mo separator="true">,</mo><msub><mrow><mn>v1</mn><mo>:</mo><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mi>+w1L</mi><mo stretchy="false">(</mo><msub><mrow><mn>u1</mn><mo>:</mo><mn>d/2</mn></mrow></msub><mo separator="true">,</mo><msub><mrow><mn>v1</mn><mo>:</mo><mn>d/2</mn></mrow></msub><mo stretchy="false">)</mo><mi>+w2L</mi><mo stretchy="false">(</mo><msub><mrow><mn>u1</mn><mo>:</mo><mn>d/4</mn></mrow></msub><mo separator="true">,</mo><msub><mrow><mn>v1</mn><mo>:</mo><mn>d/4</mn></mrow></msub><mo stretchy="false">)</mo><mo>+⋯L_M</mo></mrow><annotation encoding="application/x-tex">(u, v) = w_0L(u_{1:d}, v_{1:d}) + w_1L(u_{1:d/2}, v_{1:</annotation></semantics></math></span></span><span class="pstrut" style="height:2.7em;"></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="strut" style="height:0.313em;"></span>d<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">/2}) + w_2L(u_{1:d/4}, v_{1:d/4}) + \cdots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">M</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">(u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span></span></span> =<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span> </span></span> w<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">0</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span></span></span></span></span><span class="pstrut" style="height:2.7em;"></span><span class="katex">1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span><span class="katex">,<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span></span></span></span></span></span></span> 1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span><span class="katex">)<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span></span> +<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span> </span></span> w<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">1</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span></span></span></span></span><span class="pstrut" style="height:2.7em;"></span><span class="katex">1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="katex">,<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span></span></span></span></span></span></span> 1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0359em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="katex">)<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span></span> +<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span> </span></span> w<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">2</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span></span></span></span></span><span class="pstrut" style="height:2.7em;"></span><span class="katex">1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/4</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="katex">,<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="minner">xml-ph</span></span></span></span></p>
<p>dove la somma prosegue calcolando la perdita su metà dell'input del termine precedente fino a quando non viene raggiunto un collo di bottiglia informativo. Gli autori suggeriscono di impostare</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">w0=w1=⋯=1w_0=w_1=\cdots=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span></span></span></span> w<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">0</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span> =</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span> w</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">1</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span> =</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span> ⋯</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span> =</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span> 1.</span></span></span></p>
<p><em>In parole povere, la perdita Matryoshka è una somma ponderata della perdita originale su sottoinsiemi ricorsivi dell'input.</em></p>
<p>Un aspetto fondamentale dell'equazione precedente è che la perdita Matryoshka consente di apprendere in modo efficiente le rappresentazioni su più scale condividendo i pesi tra i modelli di incorporazione (lo stesso modello viene utilizzato per codificare, ad esempio, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mn>u1</mn><mo>:</mo></mrow></msub></mrow><annotation encoding="application/x-tex">du_{1:d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span></span></span></span> u <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span> 1</span></span></span></span></span></span></span></span></span> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> e <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mn>u1</mn><mo>:</mo><mn>d/2u_{1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">:d/2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span></span></span></span> u <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span> 1</span></span></span></span></span></span></span></span></span> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span>) e condividendo le dimensioni tra le scale<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>(</mi><mrow><mn>u1</mn><mo>:</mo><mn>d/2u_{1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">:d/2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span></span></span></span> u<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span> 1</span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span> è un sottoinsieme di <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">uu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span></span></span></span> u).</p>
<h2 id="Matryoshka-Embeddings-and-Milvus" class="common-anchor-header">Matryoshka Embeddings e Milvus<button data-href="#Matryoshka-Embeddings-and-Milvus" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Milvus supporta senza problemi qualsiasi modello di incorporazione Matryoshka che può essere caricato tramite librerie standard come <a href="https://milvus.io/docs/embeddings.md">pymilvus.model</a>, <a href="https://milvus.io/docs/integrate_with_sentencetransformers.md">sentence-transformers</a> o altri strumenti simili. Dal punto di vista del sistema, non c'è alcuna differenza funzionale tra un modello di embedding normale e uno specificamente addestrato per generare embedding Matryoshka.</p>
<p>I modelli di embedding Matryoshka più diffusi sono:</p>
<ul>
<li><p>OpenAI <a href="https://zilliz.com/ai-models/text-embedding-3-large"><code translate="no">text-embedding-3-large</code></a></p></li>
<li><p>Nomic <a href="https://huggingface.co/nomic-ai/nomic-embed-text-v1"><code translate="no">nomic-embed-text-v1</code></a></p></li>
<li><p>Alibaba <a href="https://huggingface.co/Alibaba-NLP/gte-multilingual-base"><code translate="no">gte-multilingual-base</code></a></p></li>
</ul>
<p>Per una guida completa all'uso degli embedding Matryoshka con Milvus, consultare il quaderno <em><a href="https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/funnel_search_with_matryoshka.ipynb">Funnel Search with Matryoshka Embeddings</a></em>.</p>
<h2 id="Summary" class="common-anchor-header">Sintesi<button data-href="#Summary" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>L'embedding Matryoshka consente agli sviluppatori di creare embeddings abbreviati senza sacrificare l'integrità semantica, rendendoli ideali per ricerche e archiviazioni più efficienti. È possibile modificare un modello esistente, ma sono disponibili anche opzioni pre-addestrate, come quelle di <a href="https://zilliz.com/ai-models">OpenAI</a> e <a href="https://zilliz.com/ai-models">Hugging Face</a>.</p>
<p>Tuttavia, un limite attuale è la scarsità di Matryoshka embeddings open-source, pochi dei quali sono disponibili sull'hub di Hugging Face. Inoltre, questi modelli spesso non sono esplicitamente etichettati come "Matryoshka", il che li rende più difficili da individuare. Si spera che, con l'aumento dell'interesse, si possa presto arrivare a una disponibilità più ampia e a un'etichettatura più chiara.</p>
<p>Siete pronti a ottimizzare le vostre capacità di ricerca? Iniziate oggi stesso con le incorporazioni Milvus + Matryoshka!</p>
<h2 id="Resources" class="common-anchor-header">Risorse<button data-href="#Resources" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ul>
<li><p>Appunti: <a href="https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/funnel_search_with_matryoshka.ipynb">Ricerca a imbuto con Matryoshka Embeddings</a></p></li>
<li><p>Documento: <a href="https://arxiv.org/abs/2205.13147">Apprendimento delle rappresentazioni Matryoshka</a></p></li>
<li><p>Paper: <a href="https://arxiv.org/pdf/2407.19669">mGTE: Modelli generalizzati di rappresentazione e riclassificazione del testo a lungo contesto per il recupero di testi multilingue</a></p></li>
<li><p><a href="https://milvus.io/blog/introducing-pymilvus-integrations-with-embedding-models.md">Introduzione all'integrazione di PyMilvus con i modelli di embedding </a></p></li>
<li><p><a href="https://zilliz.com/learn/Exploring-BGE-M3-the-future-of-information-retrieval-with-milvus">Esplorazione di BGE-M3: Il futuro del recupero di informazioni con Milvus </a></p></li>
<li><p><a href="https://static.nomic.ai/reports/2024_Nomic_Embed_Text_Technical_Report.pdf">Nomic Embed: addestramento di un incorporatore di testo a contesto lungo riproducibile</a></p></li>
<li><p><a href="https://sbert.net/examples/training/matryoshka/README.html">Addestramento di Matryoshka Embeddings con la libreria Sentence Transformers</a></p></li>
<li><p><a href="https://milvus.io/bootcamp">Bootcamp Milvus</a></p></li>
</ul>
