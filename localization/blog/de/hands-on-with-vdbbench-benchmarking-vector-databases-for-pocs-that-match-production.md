---
id: >-
  hands-on-with-vdbbench-benchmarking-vector-databases-for-pocs-that-match-production.md
title: >-
  Praktische Erfahrung mit VDBBench: Benchmarking von Vektordatenbanken f√ºr
  POCs, die der Produktion entsprechen
author: Yifan Cai
date: 2025-08-15T00:00:00.000Z
desc: >-
  Erfahren Sie, wie Sie mit VDBBench Vektordatenbanken mit echten
  Produktionsdaten testen k√∂nnen. Schritt-f√ºr-Schritt-Anleitung f√ºr
  benutzerdefinierte Datensatz-POCs, die die tats√§chliche Leistung vorhersagen.
cover: assets.zilliz.com/vdbbench_cover_min_2f86466839.png
tag: Tutorials
recommend: false
publishToMedium: true
tags: 'Milvus, vector database, vector search'
meta_keywords: >-
  VectorDBBench, POC, vector database, VDBBench, benchmarking vector database,
  how to choose a vector database
meta_title: |
  Tutorial | How to Evaluate VectorDBs that Match Production via VDBBench
origin: >-
  https://milvus.io/blog/hands-on-with-vdbbench-benchmarking-vector-databases-for-pocs-that-match-production.md
---
<p>Vektordatenbanken sind heute ein zentraler Bestandteil der KI-Infrastruktur und treiben verschiedene LLM-gest√ºtzte Anwendungen f√ºr Kundenservice, Inhaltserstellung, Suche, Empfehlungen und mehr an.</p>
<p>Bei so vielen Optionen auf dem Markt, von speziell entwickelten Vektordatenbanken wie Milvus und Zilliz Cloud bis hin zu herk√∂mmlichen Datenbanken mit Vektorsuche als Zusatz, <strong>ist die Wahl der richtigen nicht so einfach wie das Lesen von Benchmark-Tabellen.</strong></p>
<p>Die meisten Teams f√ºhren einen Proof of Concept (POC) durch, bevor sie sich festlegen, was in der Theorie klug ist - aber in der Praxis brechen viele Anbieter-Benchmarks, die auf dem Papier beeindruckend aussehen, unter realen Bedingungen zusammen.</p>
<p>Einer der Hauptgr√ºnde daf√ºr ist, dass die meisten Leistungsangaben auf veralteten Datens√§tzen aus den Jahren 2006-2012 (SIFT, GloVe, LAION) basieren, die sich ganz anders verhalten als moderne Embeddings. So verwendet SIFT beispielsweise 128-dimensionale Vektoren, w√§hrend die heutigen KI-Modelle weitaus mehr Dimensionen aufweisen - 3.072 f√ºr das neueste Modell von OpenAI, 1.024 f√ºr das von Cohere - eine gro√üe Ver√§nderung, die sich auf Leistung, Kosten und Skalierbarkeit auswirkt.</p>
<h2 id="The-Fix-Test-with-Your-Data-Not-Canned-Benchmarks" class="common-anchor-header">Die L√∂sung: Testen Sie mit Ihren Daten, nicht mit vorgefertigten Benchmarks<button data-href="#The-Fix-Test-with-Your-Data-Not-Canned-Benchmarks" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Die einfachste und effektivste L√∂sung: F√ºhren Sie Ihre POC-Evaluierung mit den Vektoren durch, die Ihre Anwendung tats√§chlich erzeugt. Das hei√üt, Sie verwenden Ihre Einbettungsmodelle, Ihre echten Abfragen und Ihre tats√§chliche Datenverteilung.</p>
<p>Genau daf√ºr ist <a href="https://milvus.io/blog/vdbbench-1-0-benchmarking-with-your-real-world-production-workloads.md"><strong>VDBBench</strong></a> - ein Open-Source-Benchmarking-Tool f√ºr Vektordatenbanken - konzipiert. Es unterst√ºtzt die Evaluierung und den Vergleich beliebiger Vektordatenbanken, einschlie√ülich Milvus, Elasticsearch, pgvector und anderer, und simuliert reale Produktionsarbeitslasten.</p>
<p><a href="https://github.com/zilliztech/VectorDBBench">VDBBench 1.0 herunterladen ‚Üí</a> |<a href="https://zilliz.com/vdbbench-leaderboard?dataset=vectorSearch&amp;__hstc=175614333.dc4bcf53f6c7d650ea8978dcdb9e7009.1727350436713.1755165753372.1755169827021.775&amp;__hssc=175614333.3.1755169827021&amp;__hsfp=1940526538"> Leaderboard anzeigen ‚Üí</a> | <a href="https://milvus.io/blog/vdbbench-1-0-benchmarking-with-your-real-world-production-workloads.md">Was ist VDBBench</a></p>
<p>Mit VDBbench k√∂nnen Sie:</p>
<ul>
<li><p><strong>Testen mit Ihren eigenen Daten</strong> aus Ihren Einbettungsmodellen</p></li>
<li><p>Simulieren Sie <strong>gleichzeitige Einf√ºgungen, Abfragen und Streaming-Ingestion</strong></p></li>
<li><p>Messung von <strong>P95/P99-Latenz, anhaltendem Durchsatz und Abrufgenauigkeit</strong></p></li>
<li><p>Benchmarking √ºber mehrere Datenbanken hinweg unter identischen Bedingungen</p></li>
<li><p>Erm√∂glicht das <strong>Testen benutzerdefinierter Datens√§tze</strong>, sodass die Ergebnisse tats√§chlich der Produktion entsprechen</p></li>
</ul>
<p>Als N√§chstes zeigen wir Ihnen, wie Sie mit VDBBench und Ihren echten Daten einen produktiven POC durchf√ºhren k√∂nnen, damit Sie eine sichere, zukunftsf√§hige Entscheidung treffen k√∂nnen.</p>
<h2 id="How-to-Evaluate-VectorDBs-with-Your-Custom-Datasets-with-VDBBench" class="common-anchor-header">Evaluierung von VectorDBs mit Ihren eigenen Datens√§tzen mit VDBBench<button data-href="#How-to-Evaluate-VectorDBs-with-Your-Custom-Datasets-with-VDBBench" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Bevor Sie beginnen, stellen Sie sicher, dass Sie Python 3.11 oder h√∂her installiert haben. Sie ben√∂tigen Vektordaten im CSV- oder NPY-Format, ca. 2-3 Stunden Zeit f√ºr die vollst√§ndige Einrichtung und den Test sowie fortgeschrittene Python-Kenntnisse f√ºr eine eventuelle Fehlerbehebung.</p>
<h3 id="Installation-and-Configuration" class="common-anchor-header">Installation und Konfiguration</h3><p>Wenn Sie nur eine Datenbank auswerten wollen, f√ºhren Sie diesen Befehl aus:</p>
<pre><code translate="no">pip install vectordb-bench
<button class="copy-code-btn"></button></code></pre>
<p>Wenn Sie alle unterst√ºtzten Datenbanken vergleichen wollen, f√ºhren Sie den Befehl aus:</p>
<pre><code translate="no">pip install vectordb-bench[<span class="hljs-built_in">all</span>]
<button class="copy-code-btn"></button></code></pre>
<p>F√ºr bestimmte Datenbank-Clients (z. B. Elasticsearch):</p>
<pre><code translate="no">pip install vectordb-bench[elastic]
<button class="copy-code-btn"></button></code></pre>
<p>Auf dieser <a href="https://github.com/zilliztech/VectorDBBench">GitHub-Seite</a> finden Sie alle unterst√ºtzten Datenbanken und ihre Installationsbefehle.</p>
<h3 id="Launching-VDBBench" class="common-anchor-header">Starten von VDBBench</h3><p>Starten Sie <strong>VDBBench</strong> mit:</p>
<pre><code translate="no">init_bench
<button class="copy-code-btn"></button></code></pre>
<p>Erwartete Konsolenausgabe: 
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/1_expected_console_output_66e1a218b7.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Die Weboberfl√§che wird lokal verf√ºgbar sein:</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/2_2e4dd7ea69.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="Data-Preparation-and-Format-Conversion" class="common-anchor-header">Datenaufbereitung und Formatkonvertierung</h3><p>VDBBench ben√∂tigt strukturierte Parquet-Dateien mit spezifischen Schemata, um konsistente Tests √ºber verschiedene Datenbanken und Datens√§tze hinweg zu gew√§hrleisten.</p>
<table>
<thead>
<tr><th style="text-align:center"><strong>Datei Name</strong></th><th style="text-align:center"><strong>Zweck</strong></th><th style="text-align:center"><strong>Erforderlich</strong></th><th style="text-align:center"><strong>Inhalt Beispiel</strong></th></tr>
</thead>
<tbody>
<tr><td style="text-align:center">train.parquet</td><td style="text-align:center">Vektorsammlung f√ºr das Einf√ºgen in die Datenbank</td><td style="text-align:center">‚úÖ</td><td style="text-align:center">Vektor-ID + Vektordaten (Liste[float])</td></tr>
<tr><td style="text-align:center">test.parquet</td><td style="text-align:center">Vektorsammlung f√ºr Abfragen</td><td style="text-align:center">‚úÖ</td><td style="text-align:center">Vektor-ID + Vektordaten (Liste[Float])</td></tr>
<tr><td style="text-align:center">nachbarn.parquet</td><td style="text-align:center">Ground Truth f√ºr Abfragevektoren (aktuelle Liste der n√§chstgelegenen Nachbarn ID)</td><td style="text-align:center">‚úÖ</td><td style="text-align:center">query_id -&gt; [top_k √§hnliche ID-Liste]</td></tr>
<tr><td style="text-align:center">scalar_labels.parquet</td><td style="text-align:center">Labels (Metadaten, die andere Einheiten als Vektoren beschreiben)</td><td style="text-align:center">‚ùå</td><td style="text-align:center">id -&gt; label</td></tr>
</tbody>
</table>
<p>Erforderliche Dateispezifikationen:</p>
<ul>
<li><p><strong>Die Trainingsvektordatei (train.parquet)</strong> muss eine ID-Spalte mit inkrementellen Ganzzahlen und eine Vektorspalte mit float32-Arrays enthalten. Die Spaltennamen sind konfigurierbar, aber die ID-Spalte muss Integer-Typen f√ºr eine korrekte Indizierung verwenden.</p></li>
<li><p>Die<strong>Testvektordatei (test.parquet)</strong> hat die gleiche Struktur wie die Trainingsdaten. Der Name der ID-Spalte muss "id" lauten, w√§hrend die Namen der Vektorspalten an Ihr Datenschema angepasst werden k√∂nnen.</p></li>
<li><p><strong>Ground Truth File (neighbors.parquet)</strong> enth√§lt die Referenz der n√§chstgelegenen Nachbarn f√ºr jede Testabfrage. Sie ben√∂tigt eine ID-Spalte, die den Testvektor-IDs entspricht, und eine neighbors-Array-Spalte, die die korrekten IDs der n√§chsten Nachbarn aus dem Trainingssatz enth√§lt.</p></li>
<li><p><strong>Die Datei mit den Skalar-Labels (scalar_labels.parquet)</strong> ist optional und enth√§lt Metadaten-Labels, die mit den Trainingsvektoren assoziiert sind und f√ºr gefilterte Suchtests n√ºtzlich sind.</p></li>
</ul>
<h3 id="Data-Format-Challenges" class="common-anchor-header">Herausforderungen an das Datenformat</h3><p>Die meisten Produktionsvektordaten liegen in Formaten vor, die nicht direkt den Anforderungen der VDBBench entsprechen. CSV-Dateien speichern Einbettungen typischerweise als String-Repr√§sentationen von Arrays, NPY-Dateien enthalten rohe numerische Matrizen ohne Metadaten, und Datenbankexporte verwenden oft JSON oder andere strukturierte Formate.</p>
<p>Die manuelle Konvertierung dieser Formate umfasst mehrere komplexe Schritte: das Parsen von String-Darstellungen in numerische Arrays, die Berechnung exakter n√§chstgelegener Nachbarn mithilfe von Bibliotheken wie FAISS, die korrekte Aufteilung von Datens√§tzen unter Wahrung der ID-Konsistenz und die Sicherstellung, dass alle Datentypen den Parquet-Spezifikationen entsprechen.</p>
<h3 id="Automated-Format-Conversion" class="common-anchor-header">Automatisierte Formatkonvertierung</h3><p>Um den Konvertierungsprozess zu optimieren, haben wir ein Python-Skript entwickelt, das die Formatkonvertierung, die Berechnung der Grundwahrheit und die richtige Datenstrukturierung automatisch durchf√ºhrt.</p>
<p><strong>CSV-Eingabeformat:</strong></p>
<pre><code translate="no"><span class="hljs-built_in">id</span>,emb,label
<span class="hljs-number">1</span>,<span class="hljs-string">&quot;[0.12,0.56,0.89,...]&quot;</span>,A
<span class="hljs-number">2</span>,<span class="hljs-string">&quot;[0.33,0.48,0.90,...]&quot;</span>,B
<button class="copy-code-btn"></button></code></pre>
<p><strong>NPY-Eingabeformat:</strong></p>
<pre><code translate="no"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
vectors = np.<span class="hljs-property">random</span>.<span class="hljs-title function_">rand</span>(<span class="hljs-number">10000</span>, <span class="hljs-number">768</span>).<span class="hljs-title function_">astype</span>(<span class="hljs-string">&#x27;float32&#x27;</span>)
np.<span class="hljs-title function_">save</span>(<span class="hljs-string">&quot;vectors.npy&quot;</span>, vectors)
<button class="copy-code-btn"></button></code></pre>
<h3 id="Conversion-Script-Implementation" class="common-anchor-header">Konvertierung Skript-Implementierung</h3><p><strong>Installation der erforderlichen Abh√§ngigkeiten:</strong></p>
<pre><code translate="no">pip install numpy pandas faiss-cpu
<button class="copy-code-btn"></button></code></pre>
<p><strong>F√ºhren Sie die Konvertierung aus:</strong></p>
<pre><code translate="no">python convert_to_vdb_format.py \
  --train data/train.csv \
  --<span class="hljs-built_in">test</span> data/test.csv \
  --out datasets/custom \
  --topk 10
<button class="copy-code-btn"></button></code></pre>
<p><strong>Parameter-Referenz:</strong></p>
<table>
<thead>
<tr><th style="text-align:center"><strong>Name des Parameters</strong></th><th style="text-align:center"><strong>Erforderlich</strong></th><th style="text-align:center"><strong>Typ</strong></th><th style="text-align:center"><strong>Beschreibung</strong></th><th style="text-align:center"><strong>Standardwert</strong></th></tr>
</thead>
<tbody>
<tr><td style="text-align:center"><code translate="no">--train</code></td><td style="text-align:center">Ja</td><td style="text-align:center">Zeichenfolge</td><td style="text-align:center">Trainingsdatenpfad, unterst√ºtzt CSV- oder NPY-Format. CSV muss die Spalte emb enthalten, andernfalls wird die Spalte id automatisch generiert.</td><td style="text-align:center">Keine</td></tr>
<tr><td style="text-align:center"><code translate="no">--test</code></td><td style="text-align:center">Ja</td><td style="text-align:center">Zeichenfolge</td><td style="text-align:center">Pfad f√ºr Abfragedaten, unterst√ºtzt CSV- oder NPY-Format. Format wie bei den Trainingsdaten</td><td style="text-align:center">Keine</td></tr>
<tr><td style="text-align:center"><code translate="no">--out</code></td><td style="text-align:center">Ja</td><td style="text-align:center">Zeichenfolge</td><td style="text-align:center">Ausgabeverzeichnispfad, speichert konvertierte Parkettdateien und Nachbarindexdateien</td><td style="text-align:center">Keine</td></tr>
<tr><td style="text-align:center"><code translate="no">--labels</code></td><td style="text-align:center">Nein</td><td style="text-align:center">Zeichenfolge</td><td style="text-align:center">Label-CSV-Pfad, muss die Spalte labels enthalten (als String-Array formatiert), wird zum Speichern von Labels verwendet</td><td style="text-align:center">Keine</td></tr>
<tr><td style="text-align:center"><code translate="no">--topk</code></td><td style="text-align:center">Nein</td><td style="text-align:center">Ganzzahl</td><td style="text-align:center">Anzahl der n√§chstgelegenen Nachbarn, die bei der Berechnung zur√ºckgegeben werden</td><td style="text-align:center">10</td></tr>
</tbody>
</table>
<p><strong>Struktur des Ausgabeverzeichnisses:</strong></p>
<pre><code translate="no">datasets/custom/
‚îú‚îÄ‚îÄ train.parquet        <span class="hljs-comment"># Training vectors</span>
‚îú‚îÄ‚îÄ test.parquet         <span class="hljs-comment"># Query vectors  </span>
‚îú‚îÄ‚îÄ neighbors.parquet    <span class="hljs-comment"># Ground Truth</span>
‚îî‚îÄ‚îÄ scalar_labels.parquet <span class="hljs-comment"># Optional scalar labels</span>
<button class="copy-code-btn"></button></code></pre>
<h3 id="Complete-Conversion-Script" class="common-anchor-header">Vollst√§ndiges Konvertierungsskript</h3><pre><code translate="no"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> argparse
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> faiss
<span class="hljs-keyword">from</span> ast <span class="hljs-keyword">import</span> literal_eval
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">load_csv</span>(<span class="hljs-params">path: <span class="hljs-built_in">str</span></span>):
    df = pd.read_csv(path)
    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;emb&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> df.columns:
        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;CSV file missing &#x27;emb&#x27; column: <span class="hljs-subst">{path}</span>&quot;</span>)
   df[<span class="hljs-string">&#x27;emb&#x27;</span>] = df[<span class="hljs-string">&#x27;emb&#x27;</span>].apply(literal_eval)
    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;id&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> df.columns:
        df.insert(<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(df)))
    <span class="hljs-keyword">return</span> df
<span class="hljs-keyword">def</span> <span class="hljs-title function_">load_npy</span>(<span class="hljs-params">path: <span class="hljs-built_in">str</span></span>):
    arr = np.load(path)
    df = pd.DataFrame({
        <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-built_in">range</span>(arr.shape[<span class="hljs-number">0</span>]),
        <span class="hljs-string">&#x27;emb&#x27;</span>: arr.tolist()
    })
    <span class="hljs-keyword">return</span> df
<span class="hljs-keyword">def</span> <span class="hljs-title function_">load_vectors</span>(<span class="hljs-params">path: <span class="hljs-built_in">str</span></span>) -&gt; pd.DataFrame:
    <span class="hljs-keyword">if</span> path.endswith(<span class="hljs-string">&#x27;.csv&#x27;</span>):
        <span class="hljs-keyword">return</span> load_csv(path)
    <span class="hljs-keyword">elif</span> path.endswith(<span class="hljs-string">&#x27;.npy&#x27;</span>):
        <span class="hljs-keyword">return</span> load_npy(path)
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;Unsupported file format: <span class="hljs-subst">{path}</span>&quot;</span>)
<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_ground_truth</span>(<span class="hljs-params">train_vectors: np.ndarray, test_vectors: np.ndarray, top_k: <span class="hljs-built_in">int</span> = <span class="hljs-number">10</span></span>):
    dim = train_vectors.shape[<span class="hljs-number">1</span>]
    index = faiss.IndexFlatL2(dim)
    index.add(train_vectors)
    _, indices = index.search(test_vectors, top_k)
    <span class="hljs-keyword">return</span> indices
<span class="hljs-keyword">def</span> <span class="hljs-title function_">save_ground_truth</span>(<span class="hljs-params">df_path: <span class="hljs-built_in">str</span>, indices: np.ndarray</span>):
    df = pd.DataFrame({
        <span class="hljs-string">&quot;id&quot;</span>: np.arange(indices.shape[<span class="hljs-number">0</span>]),
        <span class="hljs-string">&quot;neighbors_id&quot;</span>: indices.tolist()
    })
    df.to_parquet(df_path, index=<span class="hljs-literal">False</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;‚úÖ Ground truth saved successfully: <span class="hljs-subst">{df_path}</span>&quot;</span>)
<span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">train_path: <span class="hljs-built_in">str</span>, test_path: <span class="hljs-built_in">str</span>, output_dir: <span class="hljs-built_in">str</span>,
         label_path: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span>, top_k: <span class="hljs-built_in">int</span> = <span class="hljs-number">10</span></span>):
    os.makedirs(output_dir, exist_ok=<span class="hljs-literal">True</span>)
    <span class="hljs-comment"># Load training and query data</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;üì• Loading training data...&quot;</span>)
    train_df = load_vectors(train_path)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;üì• Loading query data...&quot;</span>)
    test_df = load_vectors(test_path)
    <span class="hljs-comment"># Extract vectors and convert to numpy</span>
    train_vectors = np.array(train_df[<span class="hljs-string">&#x27;emb&#x27;</span>].to_list(), dtype=<span class="hljs-string">&#x27;float32&#x27;</span>)
    test_vectors = np.array(test_df[<span class="hljs-string">&#x27;emb&#x27;</span>].to_list(), dtype=<span class="hljs-string">&#x27;float32&#x27;</span>)
    <span class="hljs-comment"># Save parquet files retaining all fields</span>
    train_df.to_parquet(os.path.join(output_dir, <span class="hljs-string">&#x27;train.parquet&#x27;</span>), index=<span class="hljs-literal">False</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;‚úÖ train.parquet saved successfully, <span class="hljs-subst">{<span class="hljs-built_in">len</span>(train_df)}</span> records total&quot;</span>)
    test_df.to_parquet(os.path.join(output_dir, <span class="hljs-string">&#x27;test.parquet&#x27;</span>), index=<span class="hljs-literal">False</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;‚úÖ test.parquet saved successfully, <span class="hljs-subst">{<span class="hljs-built_in">len</span>(test_df)}</span> records total&quot;</span>)
    <span class="hljs-comment"># Compute ground truth</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;üîç Computing Ground Truth (nearest neighbors)...&quot;</span>)
    gt_indices = compute_ground_truth(train_vectors, test_vectors, top_k=top_k)
    save_ground_truth(os.path.join(output_dir, <span class="hljs-string">&#x27;neighbors.parquet&#x27;</span>), gt_indices)
    <span class="hljs-comment"># Load and save label file (if provided)</span>
    <span class="hljs-keyword">if</span> label_path:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;üì• Loading label file...&quot;</span>)
        label_df = pd.read_csv(label_path)
        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;labels&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> label_df.columns:
            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Label file must contain &#x27;labels&#x27; column&quot;</span>)
        label_df[<span class="hljs-string">&#x27;labels&#x27;</span>] = label_df[<span class="hljs-string">&#x27;labels&#x27;</span>].apply(literal_eval)
        label_df.to_parquet(os.path.join(output_dir, <span class="hljs-string">&#x27;scalar_labels.parquet&#x27;</span>), index=<span class="hljs-literal">False</span>)
        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;‚úÖ Label file saved as scalar_labels.parquet&quot;</span>)

<span class="hljs-keyword">if</span> 
name
 == <span class="hljs-string">&quot;__main__&quot;</span>:
    parser = argparse.ArgumentParser(description=<span class="hljs-string">&quot;Convert CSV/NPY vectors to VectorDBBench data format (retaining all columns)&quot;</span>)
    parser.add_argument(<span class="hljs-string">&quot;--train&quot;</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Training data path (CSV or NPY)&quot;</span>)
    parser.add_argument(<span class="hljs-string">&quot;--test&quot;</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Query data path (CSV or NPY)&quot;</span>)
    parser.add_argument(<span class="hljs-string">&quot;--out&quot;</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Output directory&quot;</span>)
    parser.add_argument(<span class="hljs-string">&quot;--labels&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Label CSV path (optional)&quot;</span>)
    parser.add_argument(<span class="hljs-string">&quot;--topk&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">10</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Ground truth&quot;</span>)
    args = parser.parse_args()
    main(args.train, args.test, args.out, args.labels, args.topk)
<button class="copy-code-btn"></button></code></pre>
<p><strong>Ausgabe des Konvertierungsprozesses:</strong> 
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/3_conversion_process_output_0827ba75c9.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><strong>Generierte Dateien Verifizierung:</strong> 
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/4_f02cd2964e.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="Custom-Dataset-Configuration" class="common-anchor-header">Konfiguration des benutzerdefinierten Datensatzes</h3><p>Navigieren Sie zum Abschnitt Konfiguration des benutzerdefinierten Datensatzes in der Weboberfl√§che:</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/5_aa14b75b5d.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Die Konfigurationsschnittstelle bietet Felder f√ºr Metadaten des Datensatzes und die Angabe des Dateipfads:</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/6_1b64832990.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><strong>Konfigurationsparameter:</strong></p>
<table>
<thead>
<tr><th style="text-align:center"><strong>Parameter Name</strong></th><th style="text-align:center"><strong>Bedeutung</strong></th><th style="text-align:center"><strong>Konfiguration Vorschl√§ge</strong></th></tr>
</thead>
<tbody>
<tr><td style="text-align:center">Name</td><td style="text-align:center">Name des Datensatzes (eindeutiger Bezeichner)</td><td style="text-align:center">Beliebiger Name, z.B, <code translate="no">my_custom_dataset</code></td></tr>
<tr><td style="text-align:center">Ordner Pfad</td><td style="text-align:center">Verzeichnispfad der Datensatzdatei</td><td style="text-align:center">z. B., <code translate="no">/data/datasets/custom</code></td></tr>
<tr><td style="text-align:center">dim</td><td style="text-align:center">Abmessungen des Vektors</td><td style="text-align:center">Muss mit den Datendateien √ºbereinstimmen, z. B. 768</td></tr>
<tr><td style="text-align:center">Gr√∂√üe</td><td style="text-align:center">Anzahl der Vektoren (optional)</td><td style="text-align:center">Kann leer gelassen werden, das System erkennt automatisch</td></tr>
<tr><td style="text-align:center">metrischer Typ</td><td style="text-align:center">Methode der √Ñhnlichkeitsmessung</td><td style="text-align:center">√úblicherweise wird L2 (euklidischer Abstand) oder IP (inneres Produkt) verwendet.</td></tr>
<tr><td style="text-align:center">train file name</td><td style="text-align:center">Dateiname des Trainingssets (ohne .parquet-Erweiterung)</td><td style="text-align:center">Falls <code translate="no">train.parquet</code>, geben Sie <code translate="no">train</code> ein. Mehrere Dateien durch Komma trennen, z.B, <code translate="no">train1,train2</code></td></tr>
<tr><td style="text-align:center">Name der Testdatei</td><td style="text-align:center">Dateiname des Abfragesatzes (ohne die Erweiterung .parquet)</td><td style="text-align:center">Falls <code translate="no">test.parquet</code>, f√ºllen Sie <code translate="no">test</code></td></tr>
<tr><td style="text-align:center">Ground Truth Dateiname</td><td style="text-align:center">Ground Truth Dateiname (ohne .parquet-Erweiterung)</td><td style="text-align:center">Falls <code translate="no">neighbors.parquet</code>, f√ºllen Sie <code translate="no">neighbors</code></td></tr>
<tr><td style="text-align:center">train id name</td><td style="text-align:center">Name der Trainingsdaten-ID-Spalte</td><td style="text-align:center">Normalerweise <code translate="no">id</code></td></tr>
<tr><td style="text-align:center">train emb name</td><td style="text-align:center">Name der Trainingsdatenvektor-Spalte</td><td style="text-align:center">Wenn der vom Skript generierte Spaltenname <code translate="no">emb</code> lautet, f√ºllen Sie <code translate="no">emb</code></td></tr>
<tr><td style="text-align:center">test emb name</td><td style="text-align:center">Spaltenname des Testdatenvektors</td><td style="text-align:center">Normalerweise gleich wie train emb name, z.B., <code translate="no">emb</code></td></tr>
<tr><td style="text-align:center">ground truth emb name</td><td style="text-align:center">Name der Spalte "N√§chster Nachbar" in Ground Truth</td><td style="text-align:center">Wenn der Spaltenname <code translate="no">neighbors_id</code> lautet, f√ºllen Sie <code translate="no">neighbors_id</code></td></tr>
<tr><td style="text-align:center">scalar labels Dateiname</td><td style="text-align:center">(Optional) Dateiname der Labels (ohne .parquet-Erweiterung)</td><td style="text-align:center">Wenn <code translate="no">scalar_labels.parquet</code> generiert wurde, f√ºllen Sie <code translate="no">scalar_labels</code> aus, andernfalls lassen Sie die Datei leer.</td></tr>
<tr><td style="text-align:center">Label-Prozents√§tze</td><td style="text-align:center">(Optional) Filterverh√§ltnis der Etiketten</td><td style="text-align:center">z. B. <code translate="no">0.001</code>,<code translate="no">0.02</code>,<code translate="no">0.5</code>, leer lassen, wenn keine Etikettenfilterung erforderlich ist</td></tr>
<tr><td style="text-align:center">Beschreibung</td><td style="text-align:center">Beschreibung des Datensatzes</td><td style="text-align:center">Kann keinen Gesch√§ftskontext oder eine Erzeugungsmethode angeben</td></tr>
</tbody>
</table>
<p>Speichern Sie die Konfiguration, um mit der Testeinrichtung fortzufahren.</p>
<h3 id="Test-Execution-and-Database-Configuration" class="common-anchor-header">Testdurchf√ºhrung und Datenbankkonfiguration</h3><p>Rufen Sie die Schnittstelle zur Testkonfiguration auf:</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/7_3ecdcb1034.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><strong>Datenbankauswahl und -konfiguration (Milvus als Beispiel):</strong> 
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/8_356a2d8c39.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><strong>Dataset-Zuordnung:</strong> 
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/9_dataset_assignment_85ba7b24ca.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><strong>Test Metadaten und Beschriftung:</strong> 
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/10_test_metadata_and_labeling_293f6f2b99.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><strong>Testdurchf√ºhrung:</strong> 
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/11_test_execution_76acb42c98.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h2 id="Results-Analysis-and-Performance-Evaluation" class="common-anchor-header">Ergebnisanalyse und Leistungsbewertung<button data-href="#Results-Analysis-and-Performance-Evaluation" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Die Ergebnisschnittstelle bietet umfassende Leistungsanalysen:</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/12_993c536c20.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="Test-Configuration-Summary" class="common-anchor-header">Zusammenfassung der Testkonfiguration</h3><p>Bei der Evaluierung wurden Gleichzeitigkeitsgrade von 1, 5 und 10 gleichzeitigen Operationen (eingeschr√§nkt durch die verf√ºgbaren Hardwareressourcen), Vektorabmessungen von 768, eine Datensatzgr√∂√üe von 3.000 Trainingsvektoren und 3.000 Testabfragen getestet, wobei die skalare Filterung von Bezeichnungen f√ºr diesen Testlauf deaktiviert wurde.</p>
<h3 id="Critical-Implementation-Considerations" class="common-anchor-header">Kritische √úberlegungen zur Implementierung</h3><ul>
<li><p><strong>Dimensionale Konsistenz:</strong> Wenn die Vektordimensionen zwischen Trainings- und Testdatens√§tzen nicht √ºbereinstimmen, f√ºhrt dies zu sofortigen Testfehlern. √úberpr√ºfen Sie die dimensionale Ausrichtung w√§hrend der Datenvorbereitung, um Laufzeitfehler zu vermeiden.</p></li>
<li><p><strong>Genauigkeit der Grundwahrheit:</strong> Falsche Berechnungen der Grundwahrheit machen die Messungen der Wiedererkennungsrate ung√ºltig. Das mitgelieferte Konvertierungsskript verwendet FAISS mit L2-Distanz f√ºr die exakte Berechnung der n√§chsten Nachbarn und gew√§hrleistet so genaue Referenzergebnisse.</p></li>
<li><p><strong>Anforderungen an die Datensatzgr√∂√üe:</strong> Kleine Datens√§tze (unter 10.000 Vektoren) k√∂nnen aufgrund einer unzureichenden Lastgenerierung zu inkonsistenten QPS-Messungen f√ºhren. Ziehen Sie eine Skalierung der Datensatzgr√∂√üe in Betracht, um zuverl√§ssigere Durchsatztests durchzuf√ºhren.</p></li>
<li><p><strong>Ressourcenzuweisung:</strong> Speicher- und CPU-Beschr√§nkungen f√ºr Docker-Container k√∂nnen die Datenbankleistung w√§hrend der Tests k√ºnstlich einschr√§nken. √úberwachen Sie die Ressourcenauslastung und passen Sie die Containergrenzen bei Bedarf an, um eine genaue Leistungsmessung zu erm√∂glichen.</p></li>
<li><p><strong>Fehler√ºberwachung:</strong> <strong>VDBBench</strong> kann Fehler in der Konsolenausgabe protokollieren, die nicht in der Weboberfl√§che angezeigt werden. √úberwachen Sie die Terminalprotokolle w√§hrend der Testausf√ºhrung, um vollst√§ndige Diagnoseinformationen zu erhalten.</p></li>
</ul>
<h2 id="Supplemental-Tools-Test-Data-Generation" class="common-anchor-header">Erg√§nzende Tools: Erzeugung von Testdaten<button data-href="#Supplemental-Tools-Test-Data-Generation" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>F√ºr Entwicklungs- und standardisierte Testszenarien k√∂nnen Sie synthetische Datens√§tze mit kontrollierten Merkmalen erzeugen:</p>
<pre><code translate="no"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_csv</span>(<span class="hljs-params">num_records: <span class="hljs-built_in">int</span>, dim: <span class="hljs-built_in">int</span>, filename: <span class="hljs-built_in">str</span></span>):
    ids = <span class="hljs-built_in">range</span>(num_records)
    vectors = np.random.rand(num_records, dim).<span class="hljs-built_in">round</span>(<span class="hljs-number">6</span>) 
    emb_str = [<span class="hljs-built_in">str</span>(<span class="hljs-built_in">list</span>(vec)) <span class="hljs-keyword">for</span> vec <span class="hljs-keyword">in</span> vectors]
    df = pd.DataFrame({
        <span class="hljs-string">&#x27;id&#x27;</span>: ids,
        <span class="hljs-string">&#x27;emb&#x27;</span>: emb_str
    })
    df.to_csv(filename, index=<span class="hljs-literal">False</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Generated file <span class="hljs-subst">{filename}</span>, <span class="hljs-subst">{num_records}</span> records total, vector dimension <span class="hljs-subst">{dim}</span>&quot;</span>)
<span class="hljs-keyword">if</span>
name
 == <span class="hljs-string">&quot;__main__&quot;</span>:
    num_records = <span class="hljs-number">3000</span>  <span class="hljs-comment"># Number of records to generate</span>
    dim = <span class="hljs-number">768</span>  <span class="hljs-comment"># Vector dimension</span>

    generate_csv(num_records, dim, <span class="hljs-string">&quot;train.csv&quot;</span>)
    generate_csv(num_records, dim, <span class="hljs-string">&quot;test.csv&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<p>Dieses Dienstprogramm generiert Datens√§tze mit bestimmten Abmessungen und Datensatzzahlen f√ºr Prototyping- und Basistestszenarien.</p>
<h2 id="Conclusion" class="common-anchor-header">Schlussfolgerung<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Sie haben soeben gelernt, wie Sie sich aus dem "Benchmark-Theater" befreien k√∂nnen, das unz√§hlige Entscheidungen √ºber Vektordatenbanken in die Irre gef√ºhrt hat. Mit VDBBench und Ihrem eigenen Datensatz k√∂nnen Sie produktionsreife QPS-, Latenz- und Recall-Metriken generieren - kein R√§tselraten mehr anhand jahrzehntealter akademischer Daten.</p>
<p>Verlassen Sie sich nicht l√§nger auf vorgefertigte Benchmarks, die nichts mit Ihren realen Workloads zu tun haben. In nur wenigen Stunden - und nicht Wochen - sehen Sie genau, wie eine Datenbank mit <em>Ihren</em> Vektoren, Abfragen und Einschr√§nkungen funktioniert. Das bedeutet, dass Sie Ihre Entscheidung mit Zuversicht treffen k√∂nnen, sp√§tere schmerzhafte Umschreibungen vermeiden und Systeme bereitstellen k√∂nnen, die in der Produktion tats√§chlich funktionieren.</p>
<ul>
<li><p>Testen Sie VDBBench mit Ihren Workloads: <a href="https://github.com/zilliztech/VectorDBBench">https://github.com/zilliztech/VectorDBBench</a></p></li>
<li><p>Sehen Sie sich die Testergebnisse der wichtigsten Vektordatenbanken an: <a href="https://zilliz.com/vdbbench-leaderboard?dataset=vectorSearch&amp;__hstc=175614333.dc4bcf53f6c7d650ea8978dcdb9e7009.1727350436713.1755165753372.1755169827021.775&amp;__hssc=175614333.3.1755169827021&amp;__hsfp=1940526538">VDBBench-Rangliste</a></p></li>
</ul>
<p>Haben Sie Fragen oder m√∂chten Sie Ihre Ergebnisse mitteilen? Beteiligen Sie sich an der Diskussion auf<a href="https://github.com/zilliztech/VectorDBBench"> GitHub</a> oder verbinden Sie sich mit unserer Community auf <a href="https://discord.com/invite/FG6hMJStWu">Discord</a>.</p>
<hr>
<p><em>Dies ist der erste Beitrag in unserer VectorDB POC Guide-Serie mit praktischen, von Entwicklern getesteten Methoden zum Aufbau einer KI-Infrastruktur, die unter realen Bedingungen funktioniert. Bleiben Sie dran f√ºr mehr!</em></p>
