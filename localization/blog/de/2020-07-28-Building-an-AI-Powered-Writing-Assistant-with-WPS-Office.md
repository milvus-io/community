---
id: Building-an-AI-Powered-Writing-Assistant-with-WPS-Office.md
title: Entwicklung eines KI-gesteuerten Schreibassistenten für WPS Office
author: milvus
date: 2020-07-28T03:35:40.105Z
desc: >-
  Erfahren Sie, wie Kingsoft Milvus, eine Open-Source-Suchmaschine für
  Ähnlichkeiten, genutzt hat, um eine Empfehlungsmaschine für den KI-gesteuerten
  Schreibassistenten von WPS Office zu entwickeln.
cover: assets.zilliz.com/wps_thumbnail_6cb7876963.jpg
tag: Scenarios
canonicalUrl: >-
  https://zilliz.com/blog/Building-an-AI-Powered-Writing-Assistant-with-WPS-Office
---
<custom-h1>Entwicklung eines AI-gesteuerten Schreibassistenten für WPS Office</custom-h1><p>WPS Office ist ein von Kingsoft entwickeltes Produktivitätstool mit über 150 Millionen Nutzern weltweit. Die Abteilung für künstliche Intelligenz (KI) des Unternehmens hat von Grund auf einen intelligenten Schreibassistenten entwickelt, der semantische Abgleichsalgorithmen wie Absichtserkennung und Text-Clustering verwendet. Das Tool gibt es sowohl als Webanwendung als auch als <a href="https://walkthechat.com/wechat-mini-programs-simple-introduction/">WeChat-Miniprogramm</a>, das Nutzern hilft, schnell Gliederungen, einzelne Absätze und ganze Dokumente zu erstellen, indem sie einfach einen Titel eingeben und bis zu fünf Schlüsselwörter auswählen.</p>
<p>Die Empfehlungsmaschine des Schreibassistenten nutzt Milvus, eine Open-Source-Suchmaschine für Ähnlichkeiten, um ihr Kernmodul zur Vektorverarbeitung zu betreiben. Im Folgenden wird der Aufbau des intelligenten Schreibassistenten von WPS Offices erläutert, einschließlich der Extraktion von Merkmalen aus unstrukturierten Daten sowie der Rolle, die Milvus bei der Datenspeicherung und dem Betrieb der Empfehlungsmaschine des Tools spielt.</p>
<p>Springen Sie zu:</p>
<ul>
<li><a href="#building-an-ai-powered-writing-assistant-for-wps-office">Aufbau eines KI-gestützten Schreibassistenten für WPS Office</a><ul>
<li><a href="#making-sense-of-unstructured-textual-data">Unstrukturierte Textdaten sinnvoll nutzen</a></li>
<li><a href="#using-the-tfidf-model-to-maximize-feature-extraction">Verwendung des TFIDF-Modells zur Maximierung der Merkmalsextraktion</a></li>
<li><a href="#extracting-features-with-the-bi-directional-lstm-cnns-crf-deep-learning-model">Extrahieren von Merkmalen mit dem bi-direktionalen LSTM-CNNs-CRF-Modell für tiefes Lernen</a></li>
<li><a href="#creating-sentence-embeddings-using-infersent">Erstellen von Satzeinbettungen mit Infersent</a></li>
<li><a href="#storing-and-querying-vectors-with-milvus">Speichern und Abfragen von Vektoren mit Milvus</a></li>
<li><a href="#ai-isnt-replacing-writers-its-helping-them-write">KI ersetzt keine Autoren, sie hilft ihnen beim Schreiben</a></li>
</ul></li>
</ul>
<h3 id="Making-sense-of-unstructured-textual-data" class="common-anchor-header">Sinnvolle Nutzung unstrukturierter Textdaten</h3><p>Wie jedes moderne Problem, das es zu lösen gilt, beginnt die Entwicklung des WPS-Schreibassistenten mit unübersichtlichen Daten. Dutzende Millionen dichter Textdokumente, aus denen sinnvolle Merkmale extrahiert werden müssen, um genau zu sein. Um die Komplexität dieses Problems zu verstehen, stellen Sie sich vor, wie zwei Journalisten von verschiedenen Nachrichtenagenturen über dasselbe Thema berichten könnten.</p>
<p>Beide halten sich zwar an die Regeln, Prinzipien und Prozesse, die die Satzstruktur bestimmen, treffen aber unterschiedliche Wortwahl, bilden Sätze von unterschiedlicher Länge und verwenden ihre eigenen Artikelstrukturen, um ähnliche (oder vielleicht auch unterschiedliche) Geschichten zu erzählen. Im Gegensatz zu strukturierten Datensätzen mit einer festen Anzahl von Dimensionen fehlt es Textkörpern von Natur aus an Struktur, weil die Syntax, die sie regelt, so formbar ist. Um eine Bedeutung zu finden, müssen maschinenlesbare Merkmale aus einem unstrukturierten Dokumentenkorpus extrahiert werden. Doch zunächst müssen die Daten bereinigt werden.</p>
<p>Es gibt eine Vielzahl von Möglichkeiten, Textdaten zu bereinigen, auf die in diesem Artikel nicht näher eingegangen werden soll. Nichtsdestotrotz ist dies ein wichtiger Schritt, der der Verarbeitung der Daten vorausgeht und das Entfernen von Tags, das Entfernen von Akzentzeichen, das Erweitern von Kontraktionen, das Entfernen von Sonderzeichen, das Entfernen von Stoppwörtern und vieles mehr beinhalten kann. Eine ausführliche Erläuterung der Methoden zur Vorverarbeitung und Bereinigung von Textdaten finden Sie <a href="https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41">hier</a>.</p>
<h3 id="Using-the-TFIDF-model-to-maximize-feature-extraction" class="common-anchor-header">Verwendung des TFIDF-Modells zur Maximierung der Merkmalsextraktion</h3><p>Um unstrukturierte Textdaten sinnvoll zu nutzen, wurde das TFIDF-Modell (Term Frequency-Inverse Document Frequency) auf das Korpus angewendet, aus dem der WPS-Schreibassistent schöpft. Dieses Modell verwendet eine Kombination aus zwei Metriken, der Begriffshäufigkeit und der inversen Dokumentenhäufigkeit, um jedem Wort in einem Dokument einen TFIDF-Wert zuzuordnen. Die Begriffshäufigkeit (TF) ist die Anzahl der Begriffe in einem Dokument geteilt durch die Gesamtzahl der Begriffe in dem Dokument, während die inverse Dokumenthäufigkeit (IDF) die Anzahl der Dokumente in einem Korpus geteilt durch die Anzahl der Dokumente ist, in denen ein Begriff vorkommt.</p>
<p>Das Produkt aus TF und IDF ist ein Maß dafür, wie häufig ein Begriff in einem Dokument vorkommt, multipliziert mit der Einzigartigkeit des Wortes im Korpus. Letztlich sind TFIDF-Werte ein Maß dafür, wie relevant ein Wort für ein Dokument innerhalb einer Sammlung von Dokumenten ist. Begriffe werden nach TFIDF-Werten sortiert, und diejenigen mit niedrigen Werten (d. h. häufige Wörter) können bei der Verwendung von Deep Learning zur Extraktion von Merkmalen aus dem Korpus weniger stark gewichtet werden.</p>
<h3 id="Extracting-features-with-the-bi-directional-LSTM-CNNs-CRF-deep-learning-model" class="common-anchor-header">Extrahieren von Merkmalen mit dem bi-direktionalen LSTM-CNNs-CRF-Modell für tiefes Lernen</h3><p>Mit einer Kombination aus bidirektionalem Langzeitgedächtnis (BLSTM), Faltungsneuronalen Netzen (CNN) und bedingten Zufallsfeldern (CRF) können sowohl wort- als auch zeichenbezogene Repräsentationen aus dem Korpus extrahiert werden. Das <a href="https://arxiv.org/pdf/1603.01354.pdf">BLSTM-CNNs-CRF-Modell</a>, das zur Erstellung des WPS Office Schreibassistenten verwendet wurde, funktioniert wie folgt:</p>
<ol>
<li><strong>CNN:</strong> Zeicheneinbettungen werden als Input für das CNN verwendet, dann werden semantisch relevante Wortstrukturen (d.h. das Präfix oder Suffix) extrahiert und in Repräsentationsvektoren auf Zeichenebene kodiert.</li>
<li><strong>BLSTM:</strong> Die Vektoren auf Zeichenebene werden mit den Vektoren der Worteinbettung konkateniert und dann in das BLSTM-Netzwerk eingespeist. Jede Sequenz wird vorwärts und rückwärts zu zwei separaten versteckten Zuständen präsentiert, um vergangene und zukünftige Informationen zu erfassen.</li>
<li><strong>CRF:</strong> Die Ausgangsvektoren des BLSTM werden in die CRF-Schicht eingespeist, um gemeinsam die beste Label-Sequenz zu dekodieren.</li>
</ol>
<p>Das neuronale Netz ist nun in der Lage, benannte Entitäten aus unstrukturiertem Text zu extrahieren und zu klassifizieren. Dieser Prozess wird als " <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">Named Entity Recognition" (NER)</a> bezeichnet und umfasst das Auffinden und Klassifizieren von Kategorien wie Personennamen, Institutionen, geografischen Orten und anderen. Diese Entitäten spielen eine wichtige Rolle beim Sortieren und Wiederauffinden von Daten. Von hier aus können Schlüsselsätze, Absätze und Zusammenfassungen aus dem Korpus extrahiert werden.</p>
<h3 id="Creating-sentence-embeddings-using-Infersent" class="common-anchor-header">Erstellen von Satzeinbettungen mit Infersent</h3><p><a href="https://github.com/facebookresearch/InferSent">Infersent</a>, eine von Facebook entwickelte überwachte Methode zur Satzeinbettung, die ganze Sätze in den Vektorraum einbettet, wird zur Erstellung von Vektoren verwendet, die in die Milvus-Datenbank eingespeist werden. Infersent wurde mit dem Stanford Natural Language Inference (SNLI) Korpus trainiert, das 570k Satzpaare enthält, die von Menschen geschrieben und beschriftet wurden. Weitere Informationen über die Funktionsweise von Infersent finden Sie <a href="https://medium.com/analytics-vidhya/sentence-embeddings-facebooks-infersent-6ac4a9fc2001">hier</a>.</p>
<h3 id="Storing-and-querying-vectors-with-Milvus" class="common-anchor-header">Speichern und Abfragen von Vektoren mit Milvus</h3><p><a href="https://www.milvus.io/">Milvus</a> ist eine quelloffene Ähnlichkeitssuchmaschine, die das Hinzufügen, Löschen und Aktualisieren von Einbettungen sowie die Suche in nahezu Echtzeit auf einer Billionen-Byte-Skala unterstützt. Um die Abfrageleistung zu verbessern, ermöglicht Milvus die Angabe eines Indextyps für jedes Vektorfeld. Der WPS Office Smart Assistant verwendet den Index IVF_FLAT, den einfachsten Index-Typ Inverted File (IVF), wobei "flach" bedeutet, dass die Vektoren ohne Komprimierung oder Quantisierung gespeichert werden. Das Clustering basiert auf IndexFlat2, das eine exakte Suche für L2-Distanz verwendet.</p>
<p>Obwohl IVF_FLAT eine 100-prozentige Abfrageerinnerungsrate aufweist, führt die fehlende Komprimierung zu einer vergleichsweise langsamen Abfragegeschwindigkeit. Die <a href="https://milvus.io/docs/manage-partitions.md">Partitionierungsfunktion</a> von Milvus wird verwendet, um Daten auf der Grundlage vordefinierter Regeln in mehrere Teile des physischen Speichers aufzuteilen, wodurch Abfragen schneller und genauer werden. Wenn Vektoren zu Milvus hinzugefügt werden, geben Tags an, zu welcher Partition die Daten hinzugefügt werden sollen. Abfragen der Vektordaten verwenden Tags, um anzugeben, auf welcher Partition die Abfrage ausgeführt werden soll. Die Daten können innerhalb jeder Partition weiter in Segmente aufgeteilt werden, um die Geschwindigkeit weiter zu erhöhen.</p>
<p>Der intelligente Schreibassistent nutzt auch Kubernetes-Cluster, so dass Anwendungscontainer über mehrere Maschinen und Umgebungen hinweg ausgeführt werden können, sowie MySQL für die Verwaltung von Metadaten.</p>
<h3 id="AI-isn’t-replacing-writers-it’s-helping-them-write" class="common-anchor-header">KI ersetzt nicht die Autoren, sondern hilft ihnen beim Schreiben</h3><p>Der Schreibassistent von Kingsoft für WPS Office setzt auf Milvus, um eine Datenbank mit mehr als 2 Millionen Dokumenten zu verwalten und abzufragen. Das System ist hochflexibel und in der Lage, nahezu in Echtzeit eine Suche in Billionen von Datensätzen durchzuführen. Abfragen werden im Durchschnitt in 0,2 Sekunden abgeschlossen, was bedeutet, dass ganze Dokumente fast sofort mit nur einem Titel oder ein paar Schlüsselwörtern erstellt werden können. KI ersetzt zwar keine professionellen Autoren, aber die heute verfügbare Technologie ist in der Lage, den Schreibprozess auf neuartige und interessante Weise zu ergänzen. Die Zukunft ist ungewiss, aber zumindest können sich Schriftsteller auf produktivere und für einige weniger schwierige Methoden freuen, den "Stift zu Papier zu bringen".</p>
<p>Die folgenden Quellen wurden für diesen Artikel verwendet:</p>
<ul>
<li>"<a href="https://arxiv.org/pdf/1603.01354.pdf">End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</a>", Xuezhe Ma und Eduard Hovy.</li>
<li>"<a href="https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41">Traditionelle Methoden für Textdaten</a>", Dipanjan (DJ) Sarkar.</li>
<li>"<a href="https://ieeexplore.ieee.org/document/8780663">Extraktion von Textmerkmalen auf der Grundlage von TF-IDF und assoziierter Semantik</a>", Qing Liu, Jing Wang, Dehai Zhang, Yun Yang, NaiYao Wang.</li>
<li>"<a href="https://medium.com/analytics-vidhya/sentence-embeddings-facebooks-infersent-6ac4a9fc2001">Verstehen von Satzeinbettungen mit Facebooks Infersent</a>", Rehan Ahmad</li>
<li>"<a href="https://arxiv.org/pdf/1705.02364.pdf">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</a>," Alexis Conneau, Douwe Kiela, Holger Schwenk, LoÏc Barrault, Antoine Bordes.V1</li>
</ul>
<p>Lesen Sie andere <a href="https://zilliz.com/user-stories">Anwenderberichte</a>, um mehr über die Herstellung von Dingen mit Milvus zu erfahren.</p>
