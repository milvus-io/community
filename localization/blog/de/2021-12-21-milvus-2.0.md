---
id: 2021-12-21-milvus-2.0.md
title: Entwicklung der Cloud-skalierbaren Vektordatenbank Milvus
author: Jun Gu
date: 2021-12-21T00:00:00.000Z
desc: >-
  Der Denkprozess, wie wir die neue Milvus-Datenbank-Cluster-Architektur
  entworfen haben.
cover: assets.zilliz.com/Evolution_dd677ce3be.png
tag: Engineering
---
<blockquote>
<p>In diesem Artikel werden wir den Denkprozess beschreiben, wie wir die neue Milvus-Datenbank-Cluster-Architektur entwickelt haben.</p>
</blockquote>
<h2 id="Objectives-of-Milvus-vector-database" class="common-anchor-header">Zielsetzung der Milvus-Vektordatenbank<button data-href="#Objectives-of-Milvus-vector-database" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Als uns die Idee zur <a href="https://github.com/milvus-io/milvus">Milvus-Vektordatenbank</a> kam, wollten wir eine Dateninfrastruktur aufbauen, die Menschen dabei helfen kann, die Einführung von KI in ihren Unternehmen zu beschleunigen.</p>
<p>Um diese Aufgabe zu erfüllen, haben wir uns für das Milvus-Projekt zwei entscheidende Ziele gesetzt.</p>
<h3 id="Ease-of-use" class="common-anchor-header">Benutzerfreundlichkeit</h3><p>KI/ML ist ein aufstrebender Bereich, in dem ständig neue Technologien auf den Markt kommen. Die meisten Entwickler sind mit den schnell wachsenden KI-Technologien und -Tools nicht vollständig vertraut. Die Entwickler haben bereits einen Großteil ihrer Energie darauf verwendet, die Modelle zu finden, zu trainieren und zu optimieren. Es fällt ihnen schwer, zusätzliche Anstrengungen zu unternehmen, um die großen Mengen an Einbettungsvektoren zu verarbeiten, die von den Modellen erzeugt werden. Ganz zu schweigen davon, dass die Bearbeitung einer großen Datenmenge immer eine große Herausforderung darstellt.</p>
<p>Daher räumen wir der Benutzerfreundlichkeit eine sehr hohe Priorität ein, da sie die Entwicklungskosten erheblich senken kann.</p>
<h3 id="Low-running-costs" class="common-anchor-header">Niedrige Betriebskosten</h3><p>Eine der größten Hürden für den Einsatz von KI in der Produktion besteht darin, die Rentabilität der Investition zu rechtfertigen. Wir hätten mehr Möglichkeiten, unsere KI-Anwendungen mit geringeren Betriebskosten in die Produktion zu bringen. Und das würde dazu beitragen, die Marge des potenziellen Nutzens zu erhöhen.</p>
<h3 id="Design-principles-of-Milvus-20" class="common-anchor-header">Gestaltungsprinzipien von Milvus 2.0</h3><p>Mit Milvus 1.0 haben wir einen Anfang in Richtung dieser Ziele gemacht. Aber das reicht bei weitem nicht aus, insbesondere was die Skalierbarkeit und Verfügbarkeit angeht. Dann haben wir mit der Entwicklung von Milvus 2.0 begonnen, um diese Punkte zu verbessern. Zu den Grundsätzen, die wir für diese neue Version festgelegt haben, gehören:</p>
<ul>
<li>Anstreben einer hohen Skalierbarkeit und Verfügbarkeit</li>
<li>Aufbau auf einer ausgereiften Cloud-Infrastruktur und -Praxis</li>
<li>Minimale Leistungseinbußen in der Cloud</li>
</ul>
<p>Mit anderen Worten: Wir wollen den Milvus-Datenbankcluster Cloud-nativ machen.</p>
<h2 id="The-evolution-of-database-clusters" class="common-anchor-header">Die Entwicklung von Datenbank-Clustern<button data-href="#The-evolution-of-database-clusters" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Die Vektordatenbank ist eine neue Art von Datenbank, da sie neue Arten von Daten (Vektoren) verarbeitet. Sie weist jedoch dieselben Herausforderungen auf wie andere Datenbanken, mit einigen eigenen Anforderungen. Im weiteren Verlauf dieses Artikels werde ich mich darauf konzentrieren, was wir aus den bestehenden Datenbank-Cluster-Implementierungen gelernt haben und wie wir die neue Architektur der Milvus-Gruppe konzipiert haben.</p>
<p>Wenn Sie an den Implementierungsdetails der Milvus-Gruppenkomponenten interessiert sind, sollten Sie die Milvus-Dokumentation aufmerksam verfolgen. Wir werden kontinuierlich technische Artikel im Milvus GitHub Repo, auf der Milvus Website und im Milvus Blog veröffentlichen.</p>
<h3 id="The-ideal-database-cluster" class="common-anchor-header">Der ideale Datenbank-Cluster</h3><blockquote>
<p>"Klein anvisieren, klein verfehlen."</p>
</blockquote>
<p>Lassen Sie uns zunächst die kritischen Fähigkeiten auflisten, die ein <strong>idealer</strong> Datenbankcluster haben sollte.</p>
<ol>
<li>Gleichzeitigkeit und kein Single Point of Failure: Benutzer, die mit verschiedenen Gruppenmitgliedern verbunden sind, können gleichzeitig Lese- und Schreibzugriff auf dieselben Daten haben.</li>
<li>Konsistenz: Verschiedene Gruppenmitglieder sollten die gleichen Daten sehen.</li>
<li>Skalierbarkeit: Wir können jederzeit Gruppenmitglieder hinzufügen oder entfernen.</li>
</ol>
<p>Um ehrlich zu sein, sind all diese Fähigkeiten nur schwer zusammen zu bekommen. Bei den modernen Implementierungen von Datenbank-Clustern müssen die Menschen bei einigen dieser Fähigkeiten Kompromisse eingehen. Die Leute erwarten kein perfektes Datenbankcluster, solange es sich in die Benutzerszenarien einfügen lässt. Der "Shared-Everything"-Cluster kam einem idealen Datenbankcluster jedoch einst sehr nahe. Wenn wir etwas lernen wollen, sollten wir hier ansetzen.</p>
<h3 id="The-key-considerations-of-a-database-cluster" class="common-anchor-header">Die wichtigsten Überlegungen zu einem Datenbank-Cluster</h3><p>Der Shared-Everything-Cluster hat im Vergleich zu anderen modernen Implementierungen eine längere Geschichte. Db2 Data Sharing Group und Oracle RAC sind typische Beispiele für Shared-Everything-Cluster. Viele Leute denken, Shared-Everything bedeutet die gemeinsame Nutzung von Festplatten. Es ist aber weit mehr als das.</p>
<p>Ein Shared-Everything-Cluster hat nur eine Art von Datenbankmitglied in der Gruppe. Die Benutzer können sich mit einem beliebigen dieser symmetrischen Mitglieder verbinden, um auf alle Daten zuzugreifen. Was ist "alles", was gemeinsam genutzt werden muss, damit dies funktioniert?</p>
<h4 id="The-sequence-of-events-in-the-group" class="common-anchor-header">Die Abfolge der Ereignisse in der Gruppe</h4><p>Zunächst einmal ist die Reihenfolge der Gruppenereignisse entscheidend für die Lösung potenzieller Konflikte, die durch den gleichzeitigen Zugriff von verschiedenen Gruppenmitgliedern verursacht werden. Normalerweise verwenden wir die Sequenznummer des Datenbankprotokolls, um die Ereignisabfolge darzustellen. Gleichzeitig wird die Sequenznummer des Protokolldatensatzes im Allgemeinen aus dem Zeitstempel generiert.</p>
<p>Die Anforderung einer Gruppen-Ereignisfolge ist also gleichbedeutend mit dem Bedarf an einem globalen Zeitgeber. Wenn wir eine Atomuhr für die Gruppe haben könnten, wäre das fabelhaft. Milvus ist jedoch ein Open-Source-Softwareprojekt, was bedeutet, dass wir uns auf allgemein verfügbare Ressourcen verlassen sollten. Bis heute ist eine Atomuhr eine Premium-Option für große Unternehmen.</p>
<p>Wir haben die Zeitsynchronisationskomponente in Milvus 2.0 Datenbankcluster implementiert. Den Link dazu finden Sie im Anhang.</p>
<h4 id="Global-locking" class="common-anchor-header">Globale Sperren</h4><p>Die Datenbank verfügt über einen Sperrmechanismus, um gleichzeitige Zugriffskonflikte zu lösen, sei es durch optimistische oder pessimistische Sperren. In ähnlicher Weise benötigen wir globale Sperren, um gleichzeitige Zugriffskonflikte zwischen verschiedenen Gruppenmitgliedern aufzulösen.</p>
<p>Globales Sperren bedeutet, dass verschiedene Gruppenmitglieder miteinander sprechen müssen, um die Sperranforderungen auszuhandeln. Mehrere wichtige Faktoren wirken sich auf die Effizienz dieses globalen Sperrverhandlungsprozesses aus:</p>
<ul>
<li>Die Geschwindigkeit der systemübergreifenden Verbindungen</li>
<li>die Anzahl der Gruppenmitglieder, die an dem Verhandlungsprozess teilnehmen müssen</li>
<li>Die Häufigkeit von Gruppenkonflikten</li>
</ul>
<p>Die typische Gruppengröße beträgt nicht mehr als 100. Bei Db2 DSG sind es zum Beispiel 32, bei Oracle RAC 100. Diese Gruppenmitglieder werden in einem Serverraum untergebracht, der mit Glasfaserkabeln verbunden ist, um die Übertragungslatenz zu minimieren. Aus diesem Grund wird es manchmal auch als zentralisierter Cluster bezeichnet. Aufgrund der begrenzten Gruppengröße werden High-End-Server (Mainframes oder Minicomputer, die viel mehr Kapazität in Bezug auf CPU, Speicher, E/A-Kanäle usw. haben) für die gemeinsam genutzten Cluster ausgewählt.</p>
<p>Diese Hardware-Voraussetzung hat sich in der modernen Cloud-Umgebung drastisch geändert. Heutzutage bestehen Cloud-Rechenzentren aus hochdichten Serverräumen voller (Tausender) handelsüblicher X86-Server mit TCP/IP-Verbindungen. Wenn wir uns beim Aufbau des Datenbank-Clusters auf diese X86-Server verlassen, sollte die Gruppengröße auf Hunderte (oder sogar Tausende) von Rechnern ansteigen. Und in einigen Geschäftsszenarien werden wir wollen, dass diese Hunderte von X86-Maschinen in verschiedenen Regionen verteilt sind. Die Implementierung von Global Locking könnte sich daher nicht mehr lohnen, da die Leistung von Global Locking nicht gut genug ist.</p>
<p>In Milvus 2.0 werden wir die Möglichkeit des globalen Sperrens nicht implementieren. Einerseits gibt es kein Update für Vektordaten. (Die Leute sollten lieber löschen-einfügen statt aktualisieren.) Wir müssen uns also nicht um die Konflikte zwischen mehreren Schreibern für dasselbe Stück Daten in der Milvus-Gruppe mit Sharding-Anordnung kümmern. In der Zwischenzeit könnten wir MVCC (Multi-Version Concurrency Control, eine Methode zur Vermeidung von Gleichzeitigkeitskonflikten) verwenden, um die Leser-Schreiber-Konflikte zu lösen.</p>
<p>Andererseits verbraucht die Verarbeitung von Vektordaten einen viel höheren Speicherbedarf als die Verarbeitung strukturierter Daten. Bei Vektordatenbanken wird eine viel höhere Skalierbarkeit angestrebt.</p>
<h4 id="Shared-in-memory-data-cache" class="common-anchor-header">Gemeinsamer In-Memory-Datencache</h4><p>Wir können eine Datenbank-Engine kurz in zwei Teile unterteilen: die Speicher-Engine und die Rechen-Engine. Die Speicher-Engine ist für zwei wichtige Aufgaben zuständig:</p>
<ul>
<li>Schreiben von Daten in den permanenten Speicher zum Zwecke der Haltbarkeit.</li>
<li>Laden von Daten aus dem permanenten Speicher in den In-Memory-Datencache (auch Pufferpool genannt); dies ist der einzige Ort, an dem das Rechenmodul auf Daten zugreift.</li>
</ul>
<p>Was passiert, wenn Mitglied A die in Mitglied B zwischengespeicherten Daten im Datenbankcluster-Szenario aktualisiert hat? Wie könnte Mitglied B wissen, dass seine In-Memory-Daten abgelaufen sind? Der klassische Shared-Everything-Cluster verfügt über einen Mechanismus zur Pufferquerinvalidierung, um dieses Problem zu lösen. Der Mechanismus der Pufferquerinvalidierung funktioniert ähnlich wie das globale Sperren, wenn wir eine starke Konsistenz zwischen den Gruppenmitgliedern aufrechterhalten. Wie bereits erwähnt, ist dies in einer modernen Cloud-Umgebung nicht praktikabel. <strong>Daher haben wir uns entschlossen, die Konsistenzstufe in der Cloud-skalierbaren Milvus-Gruppe auf eine eventuelle Konsistenz zu senken.</strong> Auf diese Weise kann der Mechanismus der Pufferquerinvalidierung in Milvus 2.0 ein asynchroner Prozess sein.</p>
<h4 id="Shared-storage" class="common-anchor-header">Gemeinsam genutzter Speicher</h4><p>Gemeinsamer Speicher ist wahrscheinlich das erste, woran man denkt, wenn man über einen Datenbank-Cluster spricht.</p>
<p>Auch die Speicheroptionen haben sich in den letzten Jahren der Cloud-Storage-Entwicklung erheblich verändert. Das Storage Attached Network (SAN) war (und ist immer noch) die Speichergrundlage der Shared-Everything-Gruppe. In der Cloud-Umgebung gibt es jedoch kein SAN. Die Datenbank muss die lokale Festplatte nutzen, die an die virtuellen Cloud-Maschinen angeschlossen ist. Die Verwendung lokaler Festplatten bringt das Problem der Datenkonsistenz zwischen den Gruppenmitgliedern mit sich. Außerdem müssen wir uns Gedanken über die Hochverfügbarkeit der Gruppenmitglieder machen.</p>
<p>Dann hat Snowflake ein großartiges Vorbild für Cloud-Datenbanken geschaffen, die einen gemeinsam genutzten Cloud-Speicher (S3-Speicher) verwenden. Es inspiriert auch Milvus 2.0. Wie bereits erwähnt, beabsichtigen wir, uns auf eine ausgereifte Cloud-Infrastruktur zu stützen. Doch bevor wir den gemeinsam genutzten Cloud-Speicher nutzen können, müssen wir über einige Dinge nachdenken.</p>
<p>Erstens ist der S3-Speicher billig und zuverlässig, aber er ist nicht für den sofortigen R/W-Zugriff wie bei Datenbankszenarien ausgelegt. Wir müssen Datenkomponenten erstellen (die wir in Milvus 2.0 als Datenknoten bezeichnen), um den lokalen Speicher/die Festplatte und den S3-Speicher zu verbinden. Es gibt einige Beispiele (wie Alluxio, JuiceFS, etc.), von denen wir lernen können. Der Grund, warum wir diese Projekte nicht direkt integrieren können, ist, dass wir uns auf eine andere Datengranularität konzentrieren. Alluxio und JuiceFS sind für Datensätze oder POSIX-Dateien konzipiert, während wir uns auf die Ebene der Datensätze (Vektoren) konzentrieren.</p>
<p>Wenn die Vektordaten in S3 gespeichert sind, ist die Antwort für die Metadaten einfach: Sie werden in ETCD gespeichert. Was ist dann mit den Protokolldaten? In den klassischen Implementierungen basiert der Protokollspeicher ebenfalls auf einem SAN. Die Protokolldateien eines Datenbankgruppenmitglieds werden innerhalb des Datenbank-Clusters zu Zwecken der Ausfallwiederherstellung gemeinsam genutzt. Dies war also kein Problem, bis wir in die Cloud-Umgebung kamen.</p>
<p>Im Spanner-Papier veranschaulichte Google, wie sie die global verteilte Datenbank (Gruppe) mit dem Paxos-Konsensalgorithmus implementierten. Sie müssen den Datenbankcluster als Zustandsmaschinen-Replikationsgruppe programmieren. Das Redo-Log ist normalerweise der "Zustand", der in der Gruppe repliziert wird.</p>
<p>Die Redo-Log-Replikation durch Konsensalgorithmen ist ein leistungsfähiges Werkzeug, das in einigen Geschäftsszenarien erhebliche Vorteile bietet. Für die Milvus-Vektordatenbank sehen wir jedoch keine ausreichenden Anreize für die Erstellung einer State-Machine-Replikationsgruppe als Ganzes. Wir haben beschlossen, die Cloud-Messaging-Warteschlange/Plattform (Apache Pulsar, Apache Kafka usw.) als alternativen gemeinsamen Cloud-Speicher für den Protokollspeicher zu verwenden. Durch die Auslagerung des Protokollspeichers an die Messaging-Plattform ergeben sich die folgenden Vorteile.</p>
<ul>
<li>Die Gruppe ist stärker ereignisgesteuert, was bedeutet, dass viele Prozesse asynchron ablaufen können. Dies verbessert die Skalierbarkeit.</li>
<li>Die Komponenten sind lockerer gekoppelt, was die Durchführung rollierender Online-Upgrades erleichtert. Es verbessert die Verfügbarkeit und Betriebsfähigkeit.</li>
</ul>
<p>Wir werden dieses Thema in einem späteren Abschnitt erneut aufgreifen.</p>
<p>Bis hierher haben wir die wichtigsten Überlegungen zum Datenbank-Cluster zusammengefasst. Bevor wir zur Diskussion über die Milvus 2.0-Architektur übergehen, möchte ich zunächst erklären, wie wir Vektoren in Milvus verwalten.</p>
<h3 id="Data-management-and-performance-predictability" class="common-anchor-header">Datenmanagement und Leistungsvorhersage</h3><p>Milvus speichert Vektoren in Sammlungen. Die "Sammlung" ist ein logisches Konzept, das einer "Tabelle" in SQL-Datenbanken entspricht. Eine "Sammlung" kann mehrere physische Dateien zur Speicherung von Vektoren enthalten. Eine physische Datei ist ein &quot;Segment&quot;. Das "Segment" ist ein physisches Konzept wie eine Tablespace-Datei in SQL-Datenbanken. Wenn das Datenvolumen klein ist, können wir alles in einem einzigen Segment/einer einzigen physischen Datei speichern. Heutzutage haben wir es aber ständig mit großen Datenmengen zu tun. Wenn es mehrere Segmente/physikalische Dateien gibt, wie sollten wir die Daten auf verschiedene Datenpartitionen verteilen?</p>
<p>Obwohl die Daten an erster Stelle stehen und nicht die Indizes, müssen wir die Daten so speichern, wie es der Indexalgorithmus bevorzugt, damit der Datenzugriff in den meisten Fällen effizient erfolgt. Eine häufig verwendete Strategie in SQL-Datenbanken ist die Partitionierung nach dem Bereich der Partitionierungsschlüsselwerte. In der Regel wird ein geclusterter Index erstellt, um den Partitionierungsschlüssel zu erzwingen. Insgesamt ist dies ein vernünftiger Ansatz für SQL-Datenbanken. Die Daten werden in guter Form gespeichert und für E/A optimiert (Prefetch). Aber es gibt immer noch Mängel.</p>
<ul>
<li>Datenschieflage. Einige der Partitionen können viel mehr Daten enthalten als andere. Die Verteilung von Daten in der realen Welt ist nicht so einfach wie der numerische Bereich.</li>
<li>Zugriffshotspots. Einige der Datenpartitionen werden möglicherweise stärker ausgelastet.</li>
</ul>
<p>Stellen Sie sich vor, mehr Arbeitslast geht an Partitionen mit mehr Daten. In solchen Fällen müssen wir die Daten auf den Partitionen neu verteilen. (Das ist der mühsame Alltag eines DBAs.)</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/clustered_index_f4a3322668.png" alt="The Clustered index for vectors" class="doc-image" id="the-clustered-index-for-vectors" />
   </span> <span class="img-wrapper"> <span>Der geclusterte Index für Vektoren</span> </span></p>
<p>Wir können auch einen geclusterten Index für Vektoren erstellen (einen invertierten Listenindex). Dies ist jedoch nicht derselbe Fall wie bei SQL-Datenbanken. Sobald der Index in SQL-Datenbanken erstellt ist, ist es sehr effizient, auf die Daten über den Index zuzugreifen, mit weniger Berechnungen und weniger E/A-Operationen. Bei Vektordaten sind jedoch auch mit einem Index weitaus mehr Berechnungen und E/A-Vorgänge erforderlich. Daher wirken sich die oben erwähnten Mängel bei Vektordatenbank-Clustern stärker aus. Außerdem sind die Kosten für die Neuverteilung von Vektoren auf verschiedene Segmente aufgrund des Datenvolumens und der Rechenkomplexität sehr hoch.</p>
<p>In Milvus verwenden wir die Strategie der Partitionierung durch Wachstum. Wenn wir Daten in eine Vektorsammlung einspeisen, fügt Milvus die neuen Vektoren an das neueste Segment der Sammlung an. Milvus schließt das Segment, sobald es groß genug ist (der Schwellenwert ist konfigurierbar), und baut den Index für das geschlossene Segment auf. In der Zwischenzeit wird ein neues Segment erstellt, um die neuen Daten zu speichern. Diese einfache Strategie ist für die Vektorverarbeitung besser geeignet.</p>
<p>Die Vektorabfrage ist ein Prozess zur Suche nach den ähnlichsten Kandidaten in der Vektorsammlung. Es ist ein typisches MapReduce-Verfahren. Wir wollen zum Beispiel die 20 ähnlichsten Ergebnisse aus einer Vektorsammlung mit zehn Segmenten suchen. Wir können die Top 20 in jedem der Segmente suchen und dann die 20 * 10 Ergebnisse zu den endgültigen 20 Ergebnissen zusammenführen. Da jedes Segment die gleiche Anzahl von Vektoren und einen ähnlichen Index hat, ist die Verarbeitungszeit für jedes Segment fast identisch. Dies hat den Vorteil, dass die Leistung vorhersehbar ist, was bei der Planung der Größe der Datenbank-Cluster von entscheidender Bedeutung ist.</p>
<h3 id="New-paradigms-in-Milvus-20" class="common-anchor-header">Neue Paradigmen in Milvus 2.0</h3><p>In Milvus 1.0 haben wir wie bei den meisten SQL-Datenbanken eine Lese-/Schreib-Splittergruppe implementiert. Das war ein guter Versuch, den Milvus-Datenbankcluster zu skalieren. Aber die Probleme sind auch ziemlich offensichtlich.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/milvus_1_0_9b7441a58f.png" alt="Milvus database 1.0" class="doc-image" id="milvus-database-1.0" />
   </span> <span class="img-wrapper"> <span>Milvus-Datenbank 1.0</span> </span></p>
<p>In Milvus 1.0 muss sich der Schreib-/Leseknoten vollständig um das letzte Segment kümmern, einschließlich des Anhängens von Vektoren, der Suche in diesem nicht indizierten Segment, des Aufbaus eines Index usw. Da jede Sammlung nur einen Schreiber hat, ist der Schreiber sehr beschäftigt, wenn die Daten kontinuierlich in das System strömen. Die Leistung der gemeinsamen Datennutzung zwischen dem Schreib-/Leseknoten und den Leseknoten ist ebenfalls ein Problem. Außerdem müssen wir für die gemeinsame Datenspeicherung entweder auf NFS (nicht stabil) oder auf Premium-Cloud-Speicher (zu teuer) zurückgreifen.</p>
<p>Diese bestehenden Probleme sind in der Milvus-1.0-Architektur nur schwer zu lösen. Daher haben wir neue Paradigmen in das Design von Milvus 2.0 eingeführt, um diese Probleme zu lösen.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/Milvus_architecture_feaccc489d.png" alt="Milvus architecture" class="doc-image" id="milvus-architecture" />
   </span> <span class="img-wrapper"> <span>Milvus-Architektur</span> </span></p>
<h4 id="Actor-model" class="common-anchor-header">Akteursmodell</h4><p>Es gibt zwei Modelle zur Programmierung nebenläufiger Berechnungssysteme.</p>
<ul>
<li>Gemeinsamer Speicher, d.h. Gleichzeitigkeitskontrolle (Sperren) und synchrone Verarbeitung</li>
<li>Das Akteursmodell (AKA message passing) bedeutet nachrichtengesteuerte und asynchrone Verarbeitung</li>
</ul>
<p>Wir können diese beiden Modelle auch in verteilten Datenbank-Clustern anwenden.</p>
<p>Wie bereits erwähnt, verwenden die meisten hochrangigen verteilten Datenbanken die gleiche Methode: Redo-Log-Replikation durch Konsensalgorithmen. Dabei handelt es sich um eine synchrone Verarbeitung unter Verwendung von Konsensalgorithmen zum Aufbau eines verteilten gemeinsamen Speichers für Redo-Log-Einträge. Verschiedene Unternehmen und Risikokapitalgeber haben Milliarden von Dollar in diese Technologie investiert. Ich wollte mich dazu nicht äußern, bis wir mit der Arbeit an Milvus 2.0 begannen. Viele Leute halten diese Technologie für die einzige Möglichkeit, verteilte Datenbanksysteme zu realisieren. Das ist ärgerlich. Wenn ich nichts sage, könnten die Leute missverstehen, dass wir beim Design verteilter Datenbanken leichtsinnig waren.</p>
<p>In den letzten Jahren war die Redo-Log-Replikation durch Konsensalgorithmen die am meisten überschätzte Datenbanktechnologie. Dabei gibt es zwei Hauptprobleme.</p>
<ul>
<li>Die Annahme, dass die Redo-Log-Replikation besser ist, ist fragil.</li>
<li>Die Anbieter täuschen die Erwartungen der Nutzer hinsichtlich der Leistungsfähigkeit von Konsensalgorithmen.</li>
</ul>
<p>Nehmen wir an, wir haben zwei Datenbankknoten, den Quellknoten und den Zielknoten. Zu Beginn haben beide die exakte Kopie der Daten. Wir haben einige Änderungsoperationen (I/U/D SQL-Anweisungen) auf dem Quellknoten, und wir wollen den Zielknoten auf dem neuesten Stand halten. Was sollten wir tun? Am einfachsten ist es, die Operationen auf dem Zielknoten erneut abzuspielen. Dies ist jedoch nicht der effizienteste Weg.</p>
<p>Betrachtet man die laufenden Kosten einer I/U/D-Anweisung, so kann man sie in den Teil der Ausführungsvorbereitung und den Teil der physischen Arbeit unterteilen. Der Teil der Ausführungsvorbereitung umfasst die Arbeit des SQL-Parsers, des SQL-Optimierers usw. Unabhängig davon, wie viele Datensätze betroffen sind, handelt es sich um feste Kosten. Die Kosten für den physischen Arbeitsteil hängen davon ab, wie viele Datensätze betroffen sind; es handelt sich um variable Kosten. Die Idee hinter der Redo-Log-Replikation ist es, die festen Kosten auf dem Zielknoten einzusparen; wir spielen nur das Redo-Log (die physische Arbeit) auf dem Zielknoten wieder ab.</p>
<p>Der Prozentsatz der Kosteneinsparung ist der Kehrwert der Anzahl der Redo-Log-Datensätze. Wenn ein Vorgang nur einen Datensatz betrifft, sollte ich durch die Redo-Log-Replikation erhebliche Einsparungen erzielen. Was ist, wenn es sich um 10.000 Datensätze handelt? Dann sollten wir uns Gedanken über die Zuverlässigkeit des Netzes machen. Was ist zuverlässiger, das Senden des einen Vorgangs oder der 10.000 Redo-Log-Datensätze? Wie wäre es mit einer Million Datensätze? Die Redo-Log-Replikation eignet sich hervorragend für Szenarien wie Zahlungssysteme, Metadatensysteme usw. In diesen Szenarien betrifft jeder Datenbank-I/U/D-Vorgang nur eine kleine Anzahl von Datensätzen (1 oder 2). Aber es ist schwierig, mit E/A-intensiven Arbeitslasten wie Batch-Jobs zu arbeiten.</p>
<p>Die Anbieter behaupten immer, dass Konsensalgorithmen den Datenbankclustern eine starke Konsistenz verleihen können. Allerdings werden Konsensalgorithmen nur für die Replikation der Redo-Log-Einträge verwendet. Die Redo-Log-Datensätze sind auf verschiedenen Knoten konsistent, aber das bedeutet nicht, dass auch die Datenansichten auf anderen Knoten konsistent sind. Wir müssen die Redo-Log-Datensätze mit den eigentlichen Tabellensätzen zusammenführen. Selbst mit dieser synchronen Verarbeitung können wir also nur eine eventuelle Konsistenz der Datenansichten erreichen.</p>
<p>Wir sollten die Redo-Log-Replikation durch Konsensalgorithmen an den entsprechenden Stellen einsetzen. Das Metadatensystem (ETCD) und die Messaging-Plattform (z. B. Apache Pulsar), die in Milvus 2.0 verwendet werden, haben Konsensalgorithmen implementiert. Aber wie ich schon sagte, "für die Milvus-Vektordatenbank finden wir nicht genug Anreize, um eine State-Machine-Replikationsgruppe als Ganzes zu sein."</p>
<p>In Milvus 2.0 verwenden wir das Akteursmodell, um die Arbeiterknoten zu organisieren. Die Worker Nodes sind einsam. Sie sprechen nur mit der Messaging-Plattform, erhalten Befehle und senden Ergebnisse. Das klingt langweilig.</p>
<blockquote>
<p>&quot;Was ist unser Motto?&quot; - &quot;Langweilig ist immer am besten.&quot; - The Hitman's Bodyguard (2017)</p>
</blockquote>
<p>Das Akteursmodell ist asynchron. Es ist für Skalierbarkeit und Verfügbarkeit geeignet. Da die Arbeiterknoten einander nicht kennen, hat es keine Auswirkungen auf andere Arbeiterknoten, wenn einige der Arbeiterknoten hinzukommen oder entfernt werden.</p>
<h4 id="Separation-of-availability-and-durability" class="common-anchor-header">Trennung von Verfügbarkeit und Dauerhaftigkeit</h4><p>In Milvus 2.0 führen wir eher eine Operationswiedergabe als eine Protokollwiedergabe durch, da es in der Vektordatenbank keinen großen Unterschied zwischen Operationswiedergabe und Protokollwiedergabe gibt. Wir haben weder die Funktion Update noch die Funktion Insert with Select. Außerdem ist die Wiedergabe von Operationen mit dem Akteursmodell viel einfacher.</p>
<p>So können mehrere Worker Nodes die gleiche Operation von der Messaging-Plattform entsprechend ihrer Zuständigkeit ausführen. Wie ich bereits erwähnt habe, haben wir uns für den S3-Cloud-Speicher als gemeinsame Speicherebene des Milvus-Datenbankclusters entschieden. Der S3-Speicher ist sehr zuverlässig. Ist es dann notwendig, dass verschiedene Arbeitsknoten die gleichen Daten in den gemeinsamen Speicher schreiben?</p>
<p>Daher haben wir drei Rollen für die Arbeitsknoten entwickelt.</p>
<ul>
<li>Der Abfrageknoten verwaltet eine In-Memory-Datenansicht entsprechend der Zuweisung. Die Arbeit des Abfrageknotens umfasst die Durchführung der Vektorsuche und die Aktualisierung der In-Memory-Daten. Er muss jedoch keine Daten in den S3-Speicher schreiben. Er ist der speicherintensivste Knoten in der Gruppe.</li>
<li>Der Datenknoten ist für das Schreiben der neuen Daten in den S3-Speicher verantwortlich. Der Datenknoten muss die In-Memory-Datenansicht nicht pflegen, daher unterscheidet sich die Hardwarekonfiguration des Datenknotens deutlich vom Abfrageknoten.</li>
<li>Der Indexknoten erstellt Indizes für die vom Datenknoten geschlossenen Segmente, wenn die Größe der Segmente den Schwellenwert erreicht. Dies ist die CPU-intensivste Arbeit in der Gruppe.</li>
</ul>
<p>Diese drei Knotentypen repräsentieren verschiedene Arten von Arbeitslast. Sie können unabhängig voneinander skaliert werden. Wir nennen dies die Trennung von Verfügbarkeit und Haltbarkeit, die wir von der Microsoft Socrates Cloud-Datenbank gelernt haben.</p>
<h2 id="The-end-also-the-beginning" class="common-anchor-header">Das Ende, aber auch der Anfang<button data-href="#The-end-also-the-beginning" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>In diesem Artikel wurden mehrere Designentscheidungen der Milvus Vektordatenbank 2.0 besprochen.  Lassen Sie uns diese Punkte hier kurz zusammenfassen.</p>
<ul>
<li>Wir haben uns für die letztendliche Konsistenz von Milvus cluster 2.0 entschieden.</li>
<li>Wir haben die ausgereiften Cloud-Komponenten so weit wie möglich in Milvus 2.0 integriert. Wir haben die neuen Komponenten, die mit Milvus 2.0 eingeführt wurden, in den Produktionsumgebungen der Benutzer kontrolliert.</li>
<li>Durch das Akteursmodell und die Trennung von Verfügbarkeit und Dauerhaftigkeit ist Milvus 2.0 in der Cloud-Umgebung leicht zu skalieren.</li>
</ul>
<p>Bisher haben wir das Rückgrat der Cloud-skalierbaren Datenbank Milvus 2.0 gebildet, aber unser Backlog enthält viele Anforderungen aus der Milvus-Community, die erfüllt werden müssen. Wenn Sie die gleiche Mission haben ("Mehr Open-Source-Infrastruktursoftware entwickeln, um die KI-Transformation zu beschleunigen"), sind Sie herzlich eingeladen, sich der Milvus-Community anzuschließen.</p>
<p>Milvus ist ein Graduierungsprojekt der LF AI &amp; Data Foundation. Sie müssen KEINEN GAV für Milvus unterschreiben!</p>
<h2 id="Appendix" class="common-anchor-header">Anhang<button data-href="#Appendix" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Milvus-design-doc" class="common-anchor-header">Milvus Entwurfsdokument</h3><p><a href="https://github.com/milvus-io/milvus/tree/master/docs/design_docs">https://github.com/milvus-io/milvus/tree/master/docs/design_docs</a></p>
<ul>
<li><a href="https://github.com/milvus-io/milvus/blob/master/docs/design_docs/20211215-milvus_timesync.md">Milvus Zeitsynchronisation</a></li>
</ul>
<h3 id="Raft-implementation-in-C++" class="common-anchor-header">Raft-Implementierung in C++</h3><p>Wenn Sie immer noch an dem Konsensalgorithmus interessiert sind, empfehle ich Ihnen, sich <a href="https://github.com/eBay/Gringofts">das Open-Source-Projekt Gringofts von eBay</a> anzusehen. Es handelt sich um eine C++-Implementierung des Raft-Konsensalgorithmus (eine Variante der Paxos-Familie). Mein Freund Jacky und Elvis (meine ehemaligen Kollegen bei Morgan Stanley) haben es für das Online-Zahlungssystem von eBay entwickelt, das genau eines der am besten geeigneten Szenarien für diese Technologie ist.</p>
