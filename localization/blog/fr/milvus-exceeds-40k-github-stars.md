---
id: milvus-exceeds-40k-github-stars.md
title: >-
  7 ans, 2 reconstructions majeures, 40K+ GitHub Stars : L'ascension de Milvus
  en tant que principale base de donn√©es vectorielles open-source
author: Fendy Feng
date: 2025-12-02T00:00:00.000Z
cover: assets.zilliz.com/star_history_3dfceda40f.png
tag: announcements
recommend: true
publishToMedium: true
tags: 'Milvus, vector database'
meta_keywords: 'Milvus, vector database'
meta_title: >
  7 Years, 2 Major Rebuilds, 40K+ GitHub Stars: The Rise of Milvus as the
  Leading Open-Source Vector Database
desc: >-
  C√©l√©bration des 7 ans de voyage de Milvus pour devenir la premi√®re base de
  donn√©es vectorielles open-source au monde
origin: 'https://milvus.io/blog/milvus-exceeds-40k-github-stars.md'
---
<p>En juin 2025, Milvus a atteint 35 000 √©toiles GitHub. Quelques mois plus tard, nous avons <a href="https://github.com/milvus-io/milvus">franchi le cap des 40 000 √©toiles, preuve</a>non seulement de notre dynamisme, mais aussi de l'existence d'une communaut√© mondiale qui ne cesse de faire avancer l'avenir de la recherche vectorielle et multimodale.</p>
<p>Nous sommes profond√©ment reconnaissants. √Ä tous ceux qui ont marqu√© d'un ast√©risque ou d'une fourche, d√©pos√© des probl√®mes, d√©battu d'une API, partag√© un benchmark ou construit quelque chose d'incroyable avec Milvus : <strong>merci, et c'est gr√¢ce √† vous que ce projet avance aussi vite</strong>. Chaque √©toile repr√©sente plus qu'un bouton press√© - elle refl√®te quelqu'un qui choisit Milvus pour alimenter son travail, quelqu'un qui croit en ce que nous construisons, quelqu'un qui partage notre vision d'une infrastructure d'IA ouverte, accessible et performante.</p>
<p>Alors que nous c√©l√©brons, nous regardons √©galement vers l'avenir - vers les fonctionnalit√©s que vous demandez, vers les architectures que l'IA exige d√©sormais, et vers un monde o√π la compr√©hension multimodale et s√©mantique est la valeur par d√©faut de toutes les applications.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/star_history_3dfceda40f.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h2 id="The-Journey-From-Zero-to-40000+-Stars" class="common-anchor-header">Le voyage : De z√©ro √† plus de 40 000 √©toiles<button data-href="#The-Journey-From-Zero-to-40000+-Stars" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Lorsque nous avons commenc√© √† construire Milvus en 2017, le terme de <em>base de donn√©es vectorielle</em> n'existait m√™me pas. Nous n'√©tions qu'une petite √©quipe d'ing√©nieurs convaincus que les applications d'IA auraient bient√¥t besoin d'un nouveau type d'infrastructure de donn√©es - une infrastructure construite non pas pour des lignes et des colonnes, mais pour des donn√©es hautement dimensionnelles, non structur√©es et multimodales. Les bases de donn√©es traditionnelles n'√©taient pas con√ßues pour ce monde, et nous savions que quelqu'un devait r√©imaginer ce √† quoi pourraient ressembler le stockage et la recherche de donn√©es.</p>
<p>Les d√©buts ont √©t√© loin d'√™tre glorieux. La mise en place d'une infrastructure d'entreprise est un travail lent et obstin√© - des semaines pass√©es √† profiler les chemins de code, √† r√©√©crire les composants et √† remettre en question les choix de conception √† 2 heures du matin. Mais nous nous sommes accroch√©s √† une mission simple : <strong>rendre la recherche vectorielle accessible, √©volutive et fiable pour tous les d√©veloppeurs qui cr√©ent des applications d'intelligence artificielle</strong>. Cette mission nous a permis de r√©aliser les premi√®res perc√©es et d'essuyer les in√©vitables revers.</p>
<p>Et en cours de route, quelques tournants ont tout chang√© :</p>
<ul>
<li><p><strong>2019 :</strong> Nous avons mis Milvus 0.10 en open-source. Cela signifiait exposer toutes nos asp√©rit√©s - les hacks, les TODO, les √©l√©ments dont nous n'√©tions pas encore fiers. Mais la communaut√© s'est manifest√©e. Les d√©veloppeurs ont signal√© des probl√®mes que nous n'aurions jamais trouv√©s, ont propos√© des fonctionnalit√©s que nous n'avions pas imagin√©es et ont remis en question des hypoth√®ses qui ont finalement rendu Milvus plus fort.</p></li>
<li><p><strong>2020-2021 :</strong> Nous avons rejoint la LF AI &amp; <a href="https://lfaidata.foundation/projects/milvus/">Data Foundation</a>, livr√© Milvus 1.0, obtenu le dipl√¥me de la LF AI &amp; Data et remport√© le d√©fi <a href="https://big-ann-benchmarks.com/neurips21.html">BigANN</a> de recherche vectorielle √† l'√©chelle du milliard, preuve pr√©coce que notre architecture pouvait supporter une √©chelle r√©elle.</p></li>
<li><p><strong>2022 :</strong> Les utilisateurs d'entreprise avaient besoin d'une mise √† l'√©chelle native de Kubernetes, d'√©lasticit√© et d'une v√©ritable s√©paration du stockage et du calcul. Nous avons √©t√© confront√©s √† une d√©cision difficile : patcher l'ancien syst√®me ou tout reconstruire. Nous avons choisi la voie la plus difficile. <strong>Milvus 2.0 a √©t√© une r√©invention de fond en comble</strong>, introduisant une architecture cloud-native enti√®rement d√©coupl√©e qui a transform√© Milvus en une plateforme de niveau production pour les charges de travail d'IA critiques.</p></li>
<li><p><strong>2024-2025 :</strong> <a href="https://zilliz.com/">Zilliz</a> (l'√©quipe derri√®re Milvus) a √©t√© nomm√©e <a href="https://zilliz.com/resources/analyst-report/zilliz-forrester-wave-vector-database-report">leader par Forrester</a>, a d√©pass√© les 30 000 √©toiles et est maintenant au-del√† de 40 000. Elle est devenue l'√©pine dorsale de la recherche multimodale, des syst√®mes RAG, des flux de travail agentiques et de la recherche √† l'√©chelle du milliard dans les secteurs de l'√©ducation, de la finance, de la production cr√©ative, de la recherche scientifique, etc.</p></li>
</ul>
<p>Cette √©tape a √©t√© franchie non pas gr√¢ce √† un battage m√©diatique, mais gr√¢ce aux d√©veloppeurs qui ont choisi Milvus pour des charges de travail de production r√©elles et qui nous ont pouss√©s √† nous am√©liorer √† chaque √©tape du processus.</p>
<h2 id="2025-Two-Major-Releases-Massive-Performance-Gains" class="common-anchor-header">2025 : Deux versions majeures, des gains de performance massifs<button data-href="#2025-Two-Major-Releases-Massive-Performance-Gains" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>2025 a √©t√© l'ann√©e o√π Milvus est entr√© dans une nouvelle cat√©gorie. Alors que la recherche vectorielle excelle dans la compr√©hension s√©mantique, la r√©alit√© en production est simple : <strong>les d√©veloppeurs ont toujours besoin d'une correspondance pr√©cise des mots cl√©s</strong> pour les identifiants de produits, les num√©ros de s√©rie, les phrases exactes, les termes juridiques, etc. Sans recherche plein texte native, les √©quipes √©taient oblig√©es de maintenir des clusters Elasticsearch/OpenSearch ou de coller leurs propres solutions personnalis√©es, ce qui doublait les frais g√©n√©raux op√©rationnels et la fragmentation.</p>
<p><a href="https://milvus.io/blog/introduce-milvus-2-5-full-text-search-powerful-metadata-filtering-and-more.md"><strong>Milvus 2.5</strong></a> <strong>a chang√© la donne</strong>. Il a introduit une <strong>recherche hybride v√©ritablement native</strong>, combinant la recherche en texte int√©gral et la recherche vectorielle dans un moteur unique. Pour la premi√®re fois, les d√©veloppeurs pouvaient ex√©cuter des requ√™tes lexicales, des requ√™tes s√©mantiques et des filtres de m√©tadonn√©es ensemble sans avoir √† jongler avec des syst√®mes suppl√©mentaires ou √† synchroniser des pipelines. Nous avons √©galement am√©lior√© le filtrage des m√©tadonn√©es, l'analyse des expressions et l'efficacit√© de l'ex√©cution afin que les requ√™tes hybrides soient naturelles et rapides sous des charges de production r√©elles.</p>
<p><a href="https://milvus.io/blog/introduce-milvus-2-6-built-for-scale-designed-to-reduce-costs.md"><strong>Milvus 2.6</strong></a> <strong>a poursuivi sur cette lanc√©e</strong>, en ciblant les deux d√©fis les plus souvent √©voqu√©s par les utilisateurs fonctionnant √† l'√©chelle : le <strong><em>co√ªt</em> et les <em>performances</em>.</strong> Cette version a apport√© de profondes am√©liorations architecturales : des chemins d'interrogation plus pr√©visibles, une indexation plus rapide, une utilisation de la m√©moire consid√©rablement r√©duite et un stockage nettement plus efficace. De nombreuses √©quipes ont constat√© des gains imm√©diats sans modifier une seule ligne du code de l'application.</p>
<p>Voici quelques points forts de Milvus 2.6 :</p>
<ul>
<li><p><a href="https://milvus.io/docs/tiered-storage-overview.md"><strong>Stockage hi√©rarchis√©</strong></a> qui permet aux √©quipes d'√©quilibrer les co√ªts et les performances de mani√®re plus intelligente, r√©duisant les co√ªts de stockage jusqu'√† 50 %.</p></li>
<li><p>D<strong>'√©normes √©conomies de m√©moire</strong> gr√¢ce √† la <a href="https://milvus.io/blog/bring-vector-compression-to-the-extreme-how-milvus-serves-3%C3%97-more-queries-with-rabitq.md">quantification √† 1 bit RaBitQ</a> - r√©duisant l'utilisation de la m√©moire jusqu'√† 72 % tout en offrant des requ√™tes plus rapides.</p></li>
<li><p><a href="https://milvus.io/docs/full-text-search.md"><strong>Un moteur plein texte repens√©</strong></a> avec une impl√©mentation BM25 significativement plus rapide - jusqu'√† 4√ó plus rapide qu'Elasticsearch dans nos benchmarks.</p></li>
<li><p><strong>Un nouveau Path Index</strong> pour les <a href="https://milvus.io/blog/json-shredding-in-milvus-faster-json-filtering-with-flexibility.md">m√©tadonn√©es structur√©es en JSON</a>, permettant un filtrage jusqu'√† 100 fois plus rapide sur les documents complexes.</p></li>
<li><p><a href="https://milvus.io/docs/aisaq.md"><strong>AiSAQ</strong>:</a> compression √† l'√©chelle du milliard avec une r√©duction de stockage de 3200√ó et un rappel important.</p></li>
<li><p><a href="https://milvus.io/docs/geometry-operators.md"><strong>Recherche</strong></a><strong>s√©mantique +</strong> <a href="https://milvus.io/docs/geometry-operators.md"><strong>g√©ospatiale</strong></a> <strong>avec R-Tree :</strong> Combinaison de l'<em>emplacement des choses</em> et de <em>leur signification</em> pour des r√©sultats plus pertinents.</p></li>
<li><p><a href="https://zilliz.com/blog/Milvus-introduces-GPU-index-CAGRA"><strong>CAGRA+ Vamana</strong></a><strong>:</strong> R√©duction des co√ªts de d√©ploiement gr√¢ce √† un mode CAGRA hybride qui s'appuie sur le GPU, mais dont les requ√™tes sont effectu√©es par l'unit√© centrale.</p></li>
<li><p><strong>Un</strong><strong>flux de travail</strong><strong>"</strong><a href="https://milvus.io/blog/data-in-and-data-out-in-milvus-2-6.md"><strong>donn√©es entrantes, donn√©es sortantes</strong></a><strong>"</strong> qui simplifie l'ingestion et la r√©cup√©ration des donn√©es int√©gr√©es, en particulier pour les pipelines multimodaux.</p></li>
<li><p><strong>La prise en charge d'un maximum de 100 000 collections</strong> dans un seul cluster - une √©tape importante vers une v√©ritable multi-tenance √† l'√©chelle.</p></li>
</ul>
<p>Pour en savoir plus sur Milvus 2.6, consultez les <a href="https://milvus.io/docs/release_notes.md">notes de version compl√®tes</a>.</p>
<p><a href="https://zilliz.com/event/milvus-2-6-deep-dive-faster-search-lower-cost-smarter-scaling?utm_source=milvusio&amp;utm_medium=milvus-40k-stars&amp;utm_campaign=milvus-26-webinar">
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Webinar_Milvus_2_6_Webinar_5_4_Twitter_a4e8dbf7e4.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</a></p>
<h2 id="Beyond-Milvus-Open-Source-Tools-for-AI-Developers" class="common-anchor-header">Au-del√† de Milvus : des outils open-source pour les d√©veloppeurs d'IA<button data-href="#Beyond-Milvus-Open-Source-Tools-for-AI-Developers" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>En 2025, nous ne nous sommes pas content√©s d'am√©liorer Milvus, nous avons cr√©√© des outils qui renforcent l'ensemble de l'√©cosyst√®me des d√©veloppeurs d'IA. Notre objectif n'√©tait pas de suivre les tendances, mais de fournir aux d√©veloppeurs le type d'outils ouverts, puissants et transparents dont nous avons toujours souhait√© l'existence.</p>
<h3 id="DeepSearcher-Research-Without-Cloud-Lock-In" class="common-anchor-header">DeepSearcher : La recherche sans enfermement dans le nuage</h3><p>Deep Researcher d'OpenAI a prouv√© ce que les agents de raisonnement profond peuvent faire. Mais il est ferm√©, co√ªteux et enferm√© dans des API en nuage. <a href="https://github.com/zilliztech/deep-searcher"><strong>DeepSearcher</strong></a> <strong>est notre r√©ponse.</strong> Il s'agit d'un moteur de recherche approfondie local et open-source con√ßu pour tous ceux qui souhaitent des investigations structur√©es sans sacrifier le contr√¥le ou la confidentialit√©.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/deepsearcher_5cf6a4f0dc.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>DeepSearcher fonctionne enti√®rement sur votre machine, rassemblant des informations √† travers les sources, synth√©tisant les id√©es et fournissant des citations, des √©tapes de raisonnement et une tra√ßabilit√© - des caract√©ristiques essentielles pour une v√©ritable recherche, et pas seulement des r√©sum√©s de surface. Pas de bo√Æte noire. Pas de verrouillage des fournisseurs. Juste des analyses transparentes et reproductibles auxquelles les d√©veloppeurs et les chercheurs peuvent faire confiance.</p>
<h3 id="Claude-Context-Coding-Assistants-That-Actually-Understand-Your-Code" class="common-anchor-header">Claude Context : Des assistants de codage qui comprennent r√©ellement votre code</h3><p>La plupart des outils de codage d'IA se comportent encore comme des pipelines grep fantaisistes - rapides, superficiels, br√ªleurs de jetons et inconscients de la structure r√©elle du projet. <a href="https://github.com/zilliztech/claude-context"><strong>Claude Context</strong></a> change cela. Construit comme un plugin MCP, il donne enfin aux assistants de codage ce qui leur manquait : une v√©ritable compr√©hension s√©mantique de votre base de code.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/claude_context_7f608a153d.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Claude Context construit un index s√©mantique vectoriel √† travers votre projet, permettant aux agents de trouver les bons modules, de suivre les relations entre les fichiers, de comprendre l'intention au niveau de l'architecture, et de r√©pondre aux questions avec pertinence plut√¥t qu'avec des suppositions. Il r√©duit le gaspillage de jetons, augmente la pr√©cision et, surtout, permet aux assistants de codage de se comporter comme s'ils comprenaient vraiment votre logiciel plut√¥t que de faire semblant.</p>
<p>Les deux outils sont enti√®rement open source. Parce que l'infrastructure de l'IA devrait appartenir √† tout le monde et parce que l'avenir de l'IA ne devrait pas √™tre enferm√© derri√®re des murs propri√©taires.</p>
<h2 id="Trusted-by-10000+-Teams-in-Production" class="common-anchor-header">La confiance de plus de 10 000 √©quipes en production<button data-href="#Trusted-by-10000+-Teams-in-Production" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Aujourd'hui, plus de 10 000 √©quipes d'entreprise utilisent Milvus en production, qu'il s'agisse de startups √† croissance rapide ou de soci√©t√©s technologiques parmi les plus √©tablies au monde et figurant au classement Fortune 500. Les √©quipes de NVIDIA, Salesforce, eBay, Airbnb, IBM, AT&amp;T, LINE, Shopee, Roblox, Bosch et Microsoft s'appuient sur Milvus pour alimenter les syst√®mes d'IA qui fonctionnent √† chaque minute de la journ√©e. Leurs charges de travail couvrent la recherche, les recommandations, les pipelines agentiques, la recherche multimodale et d'autres applications qui poussent l'infrastructure vectorielle √† ses limites.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/logos_eb0d3ad4af.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Mais ce qui importe le plus, ce n'est pas seulement <em>qui</em> utilise Milvus, c'est <em>ce qu'ils construisent avec</em>. Dans tous les secteurs, Milvus se trouve derri√®re des syst√®mes qui fa√ßonnent la fa√ßon dont les entreprises fonctionnent, innovent et sont comp√©titives :</p>
<ul>
<li><p><strong>Des copilotes d'IA et des assistants d'entreprise</strong> qui am√©liorent l'assistance √† la client√®le, les flux de travail de vente et la prise de d√©cision interne gr√¢ce √† un acc√®s instantan√© √† des milliards d'√©l√©ments int√©gr√©s.</p></li>
<li><p><strong>La recherche s√©mantique et visuelle dans le commerce √©lectronique, les m√©dias et la publicit√©</strong>, qui permet d'augmenter le taux de conversion, d'am√©liorer la d√©couverte et d'acc√©l√©rer la production cr√©ative.</p></li>
<li><p><strong>Plateformes d'intelligence juridique, financi√®re et scientifique</strong> o√π la pr√©cision, l'auditabilit√© et la conformit√© se traduisent par des gains op√©rationnels r√©els.</p></li>
<li><p>Les<strong>moteurs de d√©tection des fraudes et des risques</strong> dans les secteurs de la fintech et de la banque, qui d√©pendent d'une correspondance s√©mantique rapide pour pr√©venir les pertes en temps r√©el.</p></li>
<li><p>Des<strong>syst√®mes RAG et agentiques √† grande √©chelle</strong> qui donnent aux √©quipes un comportement d'IA profond√©ment contextuel et conscient du domaine.</p></li>
<li><p><strong>Les couches de connaissances d'entreprise</strong> qui unifient le texte, le code, les images et les m√©tadonn√©es en un tissu s√©mantique coh√©rent.</p></li>
</ul>
<p>Et il ne s'agit pas de r√©f√©rences de laboratoire, mais de d√©ploiements de production parmi les plus exigeants au monde. Milvus tient r√©guli√®rement ses promesses :</p>
<ul>
<li><p>Recherche en moins de 50 ms sur des milliards de vecteurs</p></li>
<li><p>Des milliards de documents et d'√©v√©nements g√©r√©s dans un seul syst√®me</p></li>
<li><p>Des flux de travail 5 √† 10 fois plus rapides que les solutions alternatives</p></li>
<li><p>Des architectures multi-locataires prenant en charge des centaines de milliers de collections</p></li>
</ul>
<p>Les √©quipes choisissent Milvus pour une raison simple : <strong>il r√©pond aux besoins en termes de vitesse, de fiabilit√©, de rentabilit√© et de capacit√© √† √©voluer vers des milliards sans avoir √† d√©manteler leur architecture tous les deux ou trois mois.</strong> La confiance que ces √©quipes nous accordent est la raison pour laquelle nous continuons √† renforcer Milvus pour la d√©cennie d'IA √† venir.</p>
<p><a href="https://zilliz.com/share-your-story">
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/share_your_story_3c44c533ed.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</a></p>
<h2 id="When-You-Need-Milvus-Without-the-Ops-Zilliz-Cloud" class="common-anchor-header">Lorsque vous avez besoin de Milvus sans les op√©rations : Zilliz Cloud<button data-href="#When-You-Need-Milvus-Without-the-Ops-Zilliz-Cloud" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Milvus est gratuit, puissant et √©prouv√©. Mais c'est aussi un syst√®me distribu√©, et le bon fonctionnement des syst√®mes distribu√©s est un v√©ritable travail d'ing√©nierie. Le r√©glage de l'index, la gestion de la m√©moire, la stabilit√© du cluster, la mise √† l'√©chelle, l'observabilit√©... ces t√¢ches n√©cessitent du temps et une expertise que de nombreuses √©quipes n'ont tout simplement pas √† leur disposition. Les d√©veloppeurs voulaient la puissance de Milvus, mais sans le poids op√©rationnel qui vient in√©vitablement avec la gestion √† l'√©chelle.</p>
<p>Cette r√©alit√© nous a conduits √† une conclusion simple : si Milvus devait devenir l'infrastructure de base des applications d'IA, nous devions la rendre facile √† exploiter. C'est pourquoi nous avons cr√©√© <a href="https://zilliz.com/cloud"><strong>Zilliz Cloud</strong></a>, le service Milvus enti√®rement g√©r√©, cr√©√© et maintenu par la m√™me √©quipe que celle qui est √† l'origine du projet open-source.</p>
<p>Zilliz Cloud offre aux d√©veloppeurs le Milvus qu'ils connaissent d√©j√† et auquel ils font confiance, mais sans avoir √† provisionner des clusters, √† lutter contre les probl√®mes de performances, √† planifier des mises √† niveau ou √† s'inqui√©ter du r√©glage du stockage et de l'informatique. Et comme il inclut des optimisations impossibles √† ex√©cuter dans des environnements autog√©r√©s, il est encore plus rapide et plus fiable. <a href="https://zilliz.com/blog/cardinal-most-performant-vector-search-engine">Cardinal</a>, notre moteur vectoriel auto-optimisant de qualit√© commerciale, offre des performances 10 fois sup√©rieures √† celles du <strong>logiciel libre Milvus</strong>.</p>
<p><strong>Ce qui distingue Zilliz Cloud</strong></p>
<ul>
<li><strong>Performances auto-optimis√©es :</strong> AutoIndex ajuste automatiquement HNSW, IVF et DiskANN, offrant un rappel de plus de 96 % sans aucune configuration manuelle.</li>
</ul>
<ul>
<li><p><strong>Elastique et rentable :</strong> La tarification √† la carte, l'autoscaling sans serveur et la gestion intelligente des ressources r√©duisent souvent les co√ªts de 50 % ou plus par rapport aux d√©ploiements autog√©r√©s.</p></li>
<li><p><strong>Fiabilit√© de niveau entreprise :</strong> SLA de 99,95 % de temps de disponibilit√©, redondance multi-AZ, conformit√© SOC 2 Type II, ISO 27001 et GDPR. Prise en charge compl√®te du RBAC, du BYOC, des journaux d'audit et du chiffrement.</p></li>
<li><p><strong>D√©ploiement agnostique :</strong> Ex√©cution sur AWS, Azure, GCP, Alibaba Cloud ou Tencent Cloud - pas de d√©pendance √† l'√©gard d'un fournisseur, performances constantes partout.</p></li>
<li><p><strong>Requ√™tes en langage naturel :</strong> La prise en charge int√©gr√©e du serveur MCP vous permet d'interroger les donn√©es de mani√®re conversationnelle au lieu de r√©diger manuellement des appels d'API.</p></li>
<li><p><strong>Migration sans effort</strong>: Passez de Milvus, Pinecone, Qdrant, Weaviate, Elasticsearch ou PostgreSQL √† l'aide d'outils de migration int√©gr√©s - aucune r√©√©criture de sch√©ma ni aucun temps d'arr√™t n'est n√©cessaire.</p></li>
<li><p><strong>100% compatible avec Milvus open-source.</strong> Pas de forks propri√©taires. Pas d'enfermement. Juste Milvus, plus facile.</p></li>
</ul>
<p><strong>Milvus restera toujours open source et libre d'utilisation.</strong> Mais son fonctionnement et son exploitation fiables √† l'√©chelle de l'entreprise requi√®rent une expertise et des ressources importantes. <strong>Zilliz Cloud est notre r√©ponse √† cette lacune</strong>. D√©ploy√© dans 29 r√©gions et cinq nuages majeurs, Zilliz Cloud offre des performances, une s√©curit√© et une rentabilit√© de niveau professionnel tout en vous permettant de rester totalement align√© sur le Milvus que vous connaissez d√©j√†.</p>
<p><a href="https://cloud.zilliz.com/signup"><strong>D√©marrer l'essai gratuit ‚Üí</strong></a></p>
<h2 id="Whats-Next-Milvus-Lake" class="common-anchor-header">Prochaines √©tapes : Milvus Lake<button data-href="#Whats-Next-Milvus-Lake" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>En tant qu'√©quipe ayant introduit la base de donn√©es vectorielle, nous sommes aux premi√®res loges pour observer l'√©volution des donn√©es d'entreprise. Ce qui tenait autrefois dans des t√©raoctets de tables structur√©es se transforme rapidement en p√©taoctets - et bient√¥t en trillions - d'objets multimodaux. Texte, images, audio, vid√©o, flux de s√©ries temporelles, journaux multi-capteurs... tels sont les ensembles de donn√©es sur lesquels s'appuient les syst√®mes d'intelligence artificielle modernes.</p>
<p>Les bases de donn√©es vectorielles sont con√ßues pour les donn√©es non structur√©es et multimodales, mais elles ne constituent pas toujours le choix le plus √©conomique ou le plus judicieux sur le plan architectural, en particulier lorsque la grande majorit√© des donn√©es sont froides. Les corpus de formation pour les grands mod√®les, les journaux de perception de la conduite autonome et les ensembles de donn√©es robotiques ne n√©cessitent g√©n√©ralement pas une latence de l'ordre de la milliseconde ou une concurrence √©lev√©e. Faire passer ce volume de donn√©es par une base de donn√©es vectorielle en temps r√©el devient co√ªteux, lourd sur le plan op√©rationnel et trop complexe pour les pipelines qui n'ont pas besoin de ce niveau de performance.</p>
<p>Cette r√©alit√© nous a conduits √† notre prochaine initiative majeure : <strong>Milvus Lake - une</strong>base de donn√©es s√©mantique, index√©e et multimodale, con√ßue pour les donn√©es √† l'√©chelle de l'IA. Milvus Lake unifie les signaux s√©mantiques de toutes les modalit√©s (vecteurs, m√©tadonn√©es, √©tiquettes, descriptions g√©n√©r√©es par LLM et champs structur√©s) et les organise dans des <strong>tables √©tendues s√©mantiques</strong> ancr√©es autour d'entit√©s commerciales r√©elles. Les donn√©es qui se pr√©sentaient auparavant sous la forme de fichiers bruts et dispers√©s dans le stockage d'objets, les entrep√¥ts de donn√©es et les pipelines de mod√®les deviennent une couche s√©mantique unifi√©e et interrogeable. Les corpus multimodaux massifs se transforment en actifs g√©rables, r√©cup√©rables et r√©utilisables avec une signification coh√©rente dans l'ensemble de l'entreprise.</p>
<p>Sous le capot, Milvus Lake est construit sur une architecture <strong>manifeste + donn√©es + index</strong> propre qui traite l'indexation comme un √©l√©ment fondamental plut√¥t que comme une r√©flexion apr√®s coup. Cela permet de d√©bloquer un flux de travail " r√©cup√©rer d'abord, traiter ensuite " optimis√© pour des donn√©es froides √† l'√©chelle du trillion, offrant une latence pr√©visible, des co√ªts de stockage consid√©rablement r√©duits et une stabilit√© op√©rationnelle bien plus grande. Une approche de stockage √† plusieurs niveaux - NVMe/SSD pour les chemins d'acc√®s rapides et le stockage d'objets pour les archives profondes - associ√©e √† une compression efficace et √† des index charg√©s paresseusement pr√©serve la fid√©lit√© s√©mantique tout en gardant le contr√¥le sur les frais g√©n√©raux de l'infrastructure.</p>
<p>Milvus Lake s'int√®gre √©galement de mani√®re transparente dans l'√©cosyst√®me des donn√©es modernes, avec Paimon, Iceberg, Hudi, Spark, Ray et d'autres moteurs et formats de big data. Les √©quipes peuvent ex√©cuter le traitement par lots, les pipelines en temps quasi r√©el, la r√©cup√©ration s√©mantique, l'ing√©nierie des fonctionnalit√©s et la pr√©paration des donn√©es de formation en un seul endroit, sans avoir √† reformater leurs flux de travail existants. Qu'il s'agisse de constituer des corpus de mod√®les de base, de g√©rer des biblioth√®ques de simulations de conduite autonome, de former des agents robotiques ou d'alimenter des syst√®mes de recherche √† grande √©chelle, Milvus Lake constitue une base de donn√©es s√©mantiques extensible et rentable pour l'√®re de l'IA.</p>
<p><strong>Milvus Lake est en cours de d√©veloppement.</strong> Vous souhaitez b√©n√©ficier d'un acc√®s anticip√© ou en savoir plus ?<a href="https://zilliz.com/contact"> </a></p>
<p><a href="https://zilliz.com/contact-sales"><strong>Contactez-nous ‚Üí</strong></a></p>
<h2 id="Built-by-the-Community-For-the-Community" class="common-anchor-header">Construit par la communaut√©, pour la communaut√©<button data-href="#Built-by-the-Community-For-the-Community" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Ce qui rend Milvus sp√©cial, ce n'est pas seulement la technologie, ce sont les personnes qui la soutiennent. Notre base de contributeurs couvre le monde entier et rassemble des sp√©cialistes du calcul haute performance, des syst√®mes distribu√©s et de l'infrastructure de l'IA. Des ing√©nieurs et des chercheurs d'ARM, NVIDIA, AMD, Intel, Meta, IBM, Salesforce, Alibaba, Microsoft et bien d'autres encore ont apport√© leur expertise pour faire de Milvus ce qu'il est aujourd'hui.</p>
<p>Chaque demande d'extension, chaque rapport de bogue, chaque question trait√©e dans nos forums, chaque tutoriel cr√©√© - ces contributions permettent √† Milvus d'√™tre meilleur pour tout le monde.</p>
<p>Ce jalon vous appartient √† tous :</p>
<ul>
<li><p><strong>√Ä nos contributeurs</strong>: Merci pour votre code, vos id√©es et votre temps. Vous am√©liorez Milvus chaque jour.</p></li>
<li><p><strong>√Ä nos utilisateurs</strong>: Merci de confier √† Milvus vos charges de travail de production et de partager vos exp√©riences, qu'elles soient bonnes ou difficiles. Vos commentaires orientent notre feuille de route.</p></li>
<li><p><strong>Aux membres de notre communaut√©</strong>: Merci de r√©pondre aux questions, de r√©diger des tutoriels, de cr√©er du contenu et d'aider les nouveaux venus √† d√©marrer. Vous rendez notre communaut√© accueillante et inclusive.</p></li>
<li><p><strong>√Ä nos partenaires et int√©grateurs</strong>: Merci de construire avec nous et de faire de Milvus un citoyen de premier ordre dans l'√©cosyst√®me du d√©veloppement de l'IA.</p></li>
<li><p><strong>√Ä l'√©quipe Zilliz</strong>: Merci pour votre engagement in√©branlable envers le projet open-source et la r√©ussite de nos utilisateurs.</p></li>
</ul>
<p>Milvus s'est d√©velopp√© parce que des milliers de personnes ont d√©cid√© de construire quelque chose ensemble - ouvertement, g√©n√©reusement, et avec la conviction que l'infrastructure fondamentale de l'IA devrait √™tre accessible √† tous.</p>
<h2 id="Join-Us-on-This-Journey" class="common-anchor-header">Rejoignez-nous dans cette aventure<button data-href="#Join-Us-on-This-Journey" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Que vous construisiez votre premi√®re application de recherche vectorielle ou que vous passiez √† des milliards de vecteurs, nous serions ravis de vous compter parmi les membres de la communaut√© Milvus.</p>
<p><strong>Commencez</strong>:</p>
<ul>
<li><p><strong>‚≠ê √âtablissez-nous sur GitHub</strong>:<a href="https://github.com/milvus-io/milvus"> github.com/milvus-io/milvus</a></p></li>
<li><p>‚òÅÔ∏è <strong>Essayez gratuitement Zilliz Cloud</strong>:<a href="https://zilliz.com/"> zilliz.com/cloud</a></p></li>
<li><p>üí¨ <strong>Rejoignez notre</strong> <a href="https://discord.com/invite/8uyFbECzPX"><strong>Discord</strong></a> pour vous connecter avec des d√©veloppeurs du monde entier</p></li>
<li><p>üìö <strong>Explorez notre documentation</strong>: <a href="https://milvus.io/docs">Documentation Milvus</a></p></li>
<li><p>üí¨ <strong>R√©servez</strong> <a href="https://milvus.io/blog/join-milvus-office-hours-to-get-support-from-vectordb-experts.md"><strong>une session individuelle de 20 minutes</strong></a> pour obtenir des id√©es, des conseils et des r√©ponses √† vos questions.</p></li>
</ul>
<p>Le chemin √† parcourir est passionnant. Alors que l'IA remod√®le les industries et ouvre de nouvelles possibilit√©s, les bases de donn√©es vectorielles se situeront au c≈ìur de cette transformation. Ensemble, nous construisons le socle s√©mantique sur lequel reposent les applications modernes d'IA, et nous ne faisons que commencer.</p>
<p>Voici les prochaines 40 000 √©toiles, et √† construire <strong>ensemble</strong> l'avenir de l'infrastructure de l'IA. üéâ</p>
