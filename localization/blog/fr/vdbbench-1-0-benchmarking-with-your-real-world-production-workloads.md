---
id: vdbbench-1-0-benchmarking-with-your-real-world-production-workloads.md
title: >-
  Annonce de VDBBench 1.0 : Benchmarking de bases de donn√©es vectorielles
  open-source avec vos charges de travail de production r√©elles
author: Tian Min
date: 2025-07-04T00:00:00.000Z
desc: >-
  D√©couvrez VDBBench 1.0, un outil open-source permettant d'√©valuer les bases de
  donn√©es vectorielles √† l'aide de donn√©es r√©elles, de l'ingestion de flux et de
  charges de travail simultan√©es.
cover: assets.zilliz.com/milvus_vdb_e0e8146c90.jpeg
tag: Announcements
recommend: false
publishToMedium: true
tags: 'vector database, Milvus, vectordb benchmarking, vector search'
meta_keywords: 'VDBBench, vector database, Milvus, Zilliz Cloud, benchmarking'
meta_title: |
  VDBBench 1.0: Real-World Benchmarking for Vector Databases
origin: >-
  https://zilliz.com/blog/vdbbench-1-0-benchmarking-with-your-real-world-production-workloads
---
<p>La plupart des bancs d'essai de bases de donn√©es vectorielles testent des donn√©es statiques et des index pr√©construits. Mais les syst√®mes de production ne fonctionnent pas de cette mani√®re : les donn√©es circulent en continu pendant que les utilisateurs ex√©cutent des requ√™tes, les filtres fragmentent les index et les caract√©ristiques de performance changent radicalement sous l'effet de charges de lecture/√©criture simultan√©es.</p>
<p>Nous publions aujourd'hui <a href="https://github.com/zilliztech/VectorDBBench/releases/tag/v1.0.0"><strong>VDBBench 1.0</strong></a>, un benchmark open-source con√ßu pour tester les bases de donn√©es vectorielles dans des conditions de production r√©alistes : ingestion de donn√©es en continu, filtrage des m√©tadonn√©es avec une s√©lectivit√© variable, et charges de travail simultan√©es qui r√©v√®lent les goulets d'√©tranglement r√©els du syst√®me.</p>
<p><a href="https://github.com/zilliztech/VectorDBBench/releases/tag/v1.0.0"><strong>T√©l√©charger VDBBench 1.0 ‚Üí</strong></a> |<a href="https://zilliz.com/vdbbench-leaderboard?dataset=vectorSearch"> <strong>Voir le classement ‚Üí</strong></a></p>
<h2 id="Why-Current-Benchmarks-Are-Misleading" class="common-anchor-header">Pourquoi les tests de performance actuels sont trompeurs<button data-href="#Why-Current-Benchmarks-Are-Misleading" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Soyons honn√™tes : il existe un ph√©nom√®ne √©trange dans notre secteur. Tout le monde parle de "ne pas jouer avec les benchmarks", mais nombreux sont ceux qui adoptent exactement ce comportement. Depuis l'explosion du march√© des bases de donn√©es vectorielles en 2023, nous avons vu de nombreux exemples de syst√®mes dont les performances sont excellentes, mais qui √©chouent lamentablement en production, ce qui fait perdre du temps aux ing√©nieurs et nuit √† la cr√©dibilit√© du projet.</p>
<p>Nous avons √©t√© les premiers t√©moins de ce d√©calage. Par exemple, Elasticsearch se targue d'une vitesse d'interrogation de l'ordre de la milliseconde, mais en coulisses, l'optimisation de son index peut prendre plus de 20 heures. Quel syst√®me de production peut tol√©rer un tel temps d'arr√™t ?</p>
<p>Le probl√®me provient de trois faiblesses fondamentales :</p>
<ul>
<li><p><strong>Des ensembles de donn√©es obsol√®tes :</strong> De nombreux benchmarks s'appuient encore sur des ensembles de donn√©es anciens tels que SIFT (128 dimensions), alors que les embeddings modernes comptent de 768 √† 3 072 dimensions. Les caract√©ristiques de performance des syst√®mes fonctionnant sur des vecteurs de 128D par rapport √† 1024D+ sont fondamentalement diff√©rentes - les sch√©mas d'acc√®s √† la m√©moire, l'efficacit√© de l'index et la complexit√© de calcul changent tous radicalement.</p></li>
<li><p><strong>Mesures de vanit√© :</strong> Les rep√®res se concentrent sur la latence moyenne ou le QPS maximal, ce qui donne une image d√©form√©e de la situation. Un syst√®me dont la latence moyenne est de 10 ms mais dont la latence P99 est de 2 secondes offre une exp√©rience utilisateur d√©sastreuse. Un d√©bit maximal mesur√© sur 30 secondes ne dit rien sur les performances durables.</p></li>
<li><p><strong>Sc√©narios simplifi√©s √† l'extr√™me :</strong> La plupart des benchmarks testent les flux de travail de base "√©crire des donn√©es, construire un index, faire une requ√™te" - essentiellement des tests de niveau "Hello World". La production r√©elle implique l'ingestion continue de donn√©es tout en servant des requ√™tes, un filtrage complexe des m√©tadonn√©es qui fragmente les index, et des op√©rations de lecture/√©criture concurrentes qui se disputent les ressources.</p></li>
</ul>
<h2 id="What‚Äôs-New-in-VDBBench-10" class="common-anchor-header">Quelles sont les nouveaut√©s de VDBBench 1.0 ?<button data-href="#What‚Äôs-New-in-VDBBench-10" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>VDBBench ne se contente pas d'it√©rer sur des philosophies de benchmarking d√©pass√©es - il reconstruit le concept √† partir des premiers principes avec une croyance directrice : un benchmark n'a de valeur que s'il pr√©dit le comportement r√©el de la production.</p>
<p>Nous avons con√ßu VDBBench pour reproduire fid√®lement les conditions du monde r√©el dans trois domaines critiques : l'<strong>authenticit√© des donn√©es, les mod√®les de charge de travail et les m√©thodologies de mesure des performances.</strong></p>
<p>Examinons de plus pr√®s les nouvelles fonctionnalit√©s apport√©es √† la table.</p>
<h3 id="üöÄ-Redesigned-Dashboard-with-Production-Relevant-Visualizations" class="common-anchor-header"><strong>üöÄ Un tableau de bord redessin√© avec des visualisations pertinentes pour la production</strong></h3><p>La plupart des benchmarks se concentrent uniquement sur la production de donn√©es brutes, mais ce qui compte, c'est la fa√ßon dont les ing√©nieurs interpr√®tent et agissent sur ces r√©sultats. Nous avons repens√© l'interface utilisateur pour privil√©gier la clart√© et l'interactivit√©, ce qui vous permet de rep√©rer les √©carts de performance entre les syst√®mes et de prendre rapidement des d√©cisions en mati√®re d'infrastructure.</p>
<p>Le nouveau tableau de bord visualise non seulement les chiffres de performance, mais aussi les relations entre eux : comment le QPS se d√©grade sous diff√©rents niveaux de s√©lectivit√© des filtres, comment le rappel fluctue pendant l'ingestion en continu, et comment les distributions de latence r√©v√®lent les caract√©ristiques de stabilit√© du syst√®me.  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/vdb_1_df593dea0b.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Nous avons test√© √† nouveau les principales plateformes de bases de donn√©es vectorielles, notamment <strong>Milvus, Zilliz Cloud, Elastic Cloud, Qdrant Cloud, Pinecone et OpenSearch</strong>, avec leurs configurations les plus r√©centes et les param√®tres recommand√©s, afin de nous assurer que toutes les donn√©es de r√©f√©rence refl√®tent les capacit√©s actuelles. Tous les r√©sultats des tests sont disponibles sur le<a href="https://zilliz.com/vdbbench-leaderboard?dataset=vectorSearch"> VDBBench Leaderboard</a>.</p>
<h3 id="üè∑Ô∏è-Tag-Filtering-The-Hidden-Performance-Killer" class="common-anchor-header">üè∑Ô∏è Filtrage des balises : Le tueur de performances cach√©</h3><p>Dans le monde r√©el, les requ√™tes sont rarement isol√©es. Les applications combinent la similarit√© vectorielle et le filtrage des m√©tadonn√©es ("trouver des chaussures qui ressemblent √† cette photo mais qui co√ªtent moins de 100 $"). Cette recherche vectorielle filtr√©e cr√©e des d√©fis uniques que la plupart des benchmarks ignorent compl√®tement.</p>
<p>Les recherches filtr√©es introduisent de la complexit√© dans deux domaines critiques :</p>
<ul>
<li><p><strong>Complexit√© du filtre</strong>: Plus de champs scalaires et de conditions logiques complexes augmentent les demandes de calcul et peuvent entra√Æner un rappel insuffisant et une fragmentation de l'index du graphe.</p></li>
<li><p><strong>S√©lectivit√© du filtre</strong>: Il s'agit du "tueur de performances cach√©" que nous avons v√©rifi√© √† plusieurs reprises en production. Lorsque les conditions de filtrage deviennent tr√®s s√©lectives (filtrage de plus de 99% des donn√©es), la vitesse des requ√™tes peut fluctuer de plusieurs ordres de grandeur, et le rappel peut devenir instable car les structures d'index se battent avec des ensembles de r√©sultats √©pars.</p></li>
</ul>
<p>VDBBench teste syst√©matiquement diff√©rents niveaux de s√©lectivit√© du filtrage (de 50 % √† 99,9 %), fournissant un profil de performance complet dans ce mod√®le de production critique. Les r√©sultats r√©v√®lent souvent des √©carts de performance spectaculaires qui n'appara√Ætraient jamais dans les benchmarks traditionnels.</p>
<p><strong>Exemple</strong>: Dans les tests Cohere 1M, Milvus a maintenu un rappel constamment √©lev√© √† tous les niveaux de s√©lectivit√© du filtre, tandis qu'OpenSearch a pr√©sent√© des performances instables avec un rappel fluctuant de mani√®re significative dans diff√©rentes conditions de filtrage - tombant en dessous de 0,8 rappel dans de nombreux cas, ce qui est inacceptable pour la plupart des environnements de production.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/vdb_2_0ef89463e5.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Figure : QPS et rappel de Milvus et OpenSearch pour diff√©rents niveaux de s√©lectivit√© des filtres (test Cohere 1M).</em></p>
<h3 id="üåä-Streaming-ReadWrite-Beyond-Static-Index-Testing" class="common-anchor-header">üåä Lecture/√©criture en continu : Au-del√† des tests d'index statiques</h3><p>Les syst√®mes de production b√©n√©ficient rarement du luxe de donn√©es statiques. De nouvelles informations affluent continuellement pendant que les recherches s'ex√©cutent - un sc√©nario dans lequel de nombreuses bases de donn√©es, par ailleurs impressionnantes, s'effondrent sous la double pression du maintien des performances de recherche et de la gestion des √©critures continues.</p>
<p>Les sc√©narios de streaming de VDBBench simulent des op√©rations parall√®les r√©elles, aidant les d√©veloppeurs √† comprendre la stabilit√© du syst√®me dans des environnements √† forte circulation, en particulier l'impact de l'√©criture des donn√©es sur les performances des requ√™tes et l'√©volution des performances au fur et √† mesure que le volume des donn√©es s'accro√Æt.</p>
<p>Pour garantir des comparaisons √©quitables entre diff√©rents syst√®mes, VDBBench utilise une approche structur√©e :</p>
<ul>
<li><p>Configurer des taux d'√©criture contr√¥l√©s qui refl√®tent les charges de travail de la production cible (par exemple, 500 lignes/sec r√©parties sur 5 processus parall√®les).</p></li>
<li><p>D√©clencher des op√©rations de recherche apr√®s chaque 10 % d'ingestion de donn√©es, en alternant les modes s√©riel et simultan√©.</p></li>
<li><p>Enregistrement de mesures compl√®tes : distribution des temps de latence (y compris P99), QPS soutenu et pr√©cision de rappel.</p></li>
<li><p>Suivre l'√©volution des performances au fil du temps, √† mesure que le volume de donn√©es et le stress du syst√®me augmentent.</p></li>
</ul>
<p>Ces tests de charge contr√¥l√©s et progressifs r√©v√®lent √† quel point les syst√®mes conservent leur stabilit√© et leur pr√©cision dans le cadre d'une ingestion continue, ce que les crit√®res de r√©f√©rence traditionnels ne permettent que rarement d'appr√©hender.</p>
<p><strong>Exemple</strong>: Dans les tests de streaming Cohere 10M, Pinecone a maintenu un QPS et un rappel plus √©lev√©s tout au long du cycle d'√©criture par rapport √† Elasticsearch. Notamment, les performances de Pinecone se sont consid√©rablement am√©lior√©es apr√®s la fin de l'ingestion, d√©montrant une grande stabilit√© sous une charge soutenue, alors qu'Elasticsearch a montr√© un comportement plus erratique pendant les phases d'ingestion active.  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/vdb3_9d2a5298b0.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Figure : QPS et rappel de Pinecone par rapport √† Elasticsearch dans le test de streaming Cohere 10M (taux d'ingestion de 500 lignes/s).</p>
<p>VDBBench va encore plus loin en prenant en charge une √©tape d'optimisation optionnelle, permettant aux utilisateurs de comparer les performances de la recherche en continu avant et apr√®s l'optimisation de l'index. Il suit et rapporte √©galement le temps r√©el pass√© sur chaque √©tape, offrant un aper√ßu plus approfondi de l'efficacit√© et du comportement du syst√®me dans des conditions similaires √† celles de la production.  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/vdb4_0caee3b201.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Figure : QPS et rappel de Pinecone vs. Elasticsearch dans le test de streaming Cohere 10M apr√®s optimisation (taux d'ingestion de 500 lignes/s)</em></p>
<p>Comme le montrent nos tests, Elasticsearch a surpass√© Pinecone en termes de QPS apr√®s optimisation de l'index. Mais lorsque l'axe des x refl√®te le temps r√©el √©coul√©, il est clair qu'Elasticsearch a mis beaucoup plus de temps √† atteindre cette performance. En production, ce d√©lai est important. Cette comparaison r√©v√®le un compromis essentiel : le d√©bit maximal par rapport au temps de service.</p>
<h3 id="üî¨-Modern-Datasets-That-Reflect-Current-AI-Workloads" class="common-anchor-header">üî¨ Des ensembles de donn√©es modernes qui refl√®tent les charges de travail actuelles de l'IA</h3><p>Nous avons compl√®tement remani√© les ensembles de donn√©es utilis√©s pour l'analyse comparative des bases de donn√©es vectorielles. Au lieu d'utiliser des ensembles de tests h√©rit√©s comme SIFT et GloVe, VDBBench utilise des vecteurs g√©n√©r√©s par des mod√®les d'int√©gration de pointe comme OpenAI et Cohere, qui alimentent les applications d'IA d'aujourd'hui.</p>
<p>Pour garantir la pertinence, en particulier pour les cas d'utilisation tels que la g√©n√©ration am√©lior√©e par r√©cup√©ration (RAG), nous avons s√©lectionn√© des corpus qui refl√®tent des sc√©narios d'entreprises et de domaines sp√©cifiques du monde r√©el :</p>
<table>
<thead>
<tr><th></th><th></th><th></th><th></th><th></th></tr>
</thead>
<tbody>
<tr><td><strong>Corpus</strong></td><td><strong>Mod√®le d'int√©gration</strong></td><td><strong>Dimensions</strong></td><td><strong>Taille</strong></td><td><strong>Cas d'utilisation</strong></td></tr>
<tr><td>Wikip√©dia</td><td>Cohere V2</td><td>768</td><td>1M / 10M</td><td>Base de connaissances g√©n√©rales</td></tr>
<tr><td>BioASQ</td><td>Cohere V3</td><td>1024</td><td>1M / 10M</td><td>Domaine sp√©cifique (biom√©dical)</td></tr>
<tr><td>C4</td><td>OpenAI</td><td>1536</td><td>500K / 5M</td><td>Traitement de texte √† l'√©chelle du web</td></tr>
<tr><td>MSMarco V2</td><td>udever-bloom-1b1</td><td>1536</td><td>1M / 10M / 138M</td><td>Recherche √† grande √©chelle</td></tr>
</tbody>
</table>
<p>Ces ensembles de donn√©es simulent mieux les donn√©es vectorielles actuelles √† haut volume et √† haute dimension, ce qui permet de tester de mani√®re r√©aliste l'efficacit√© du stockage, les performances des requ√™tes et la pr√©cision de l'extraction dans des conditions correspondant aux charges de travail modernes de l'IA.</p>
<h3 id="‚öôÔ∏è-Custom-Dataset-Support-for-Industry-Specific-Testing" class="common-anchor-header">‚öôÔ∏è Prise en charge de jeux de donn√©es personnalis√©s pour des tests sp√©cifiques √† l'industrie</h3><p>Chaque entreprise est unique. L'industrie financi√®re peut avoir besoin de tests ax√©s sur l'int√©gration des transactions, tandis que les plateformes sociales s'int√©ressent davantage aux vecteurs de comportement des utilisateurs. VDBBench vous permet d'effectuer des tests avec vos propres donn√©es g√©n√©r√©es √† partir de vos mod√®les d'int√©gration sp√©cifiques pour vos charges de travail sp√©cifiques.</p>
<p>Vous pouvez personnaliser :</p>
<ul>
<li><p>les dimensions des vecteurs et les types de donn√©es</p></li>
<li><p>Le sch√©ma des m√©tadonn√©es et les mod√®les de filtrage</p></li>
<li><p>Le volume de donn√©es et les mod√®les d'ingestion</p></li>
<li><p>Les distributions de requ√™tes qui correspondent √† votre trafic de production</p></li>
</ul>
<p>Apr√®s tout, aucun ensemble de donn√©es ne raconte mieux l'histoire que vos propres donn√©es de production.</p>
<h2 id="How-VDBBench-Measures-What-Actually-Matters-in-Production" class="common-anchor-header">Comment VDBBench mesure ce qui est r√©ellement important en production<button data-href="#How-VDBBench-Measures-What-Actually-Matters-in-Production" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Production-Focused-Metric-Design" class="common-anchor-header">Conception de mesures ax√©es sur la production</h3><p>VDBBench donne la priorit√© aux mesures qui refl√®tent les performances r√©elles, et pas seulement les r√©sultats de laboratoire. Nous avons repens√© l'√©talonnage en fonction de ce qui importe r√©ellement dans les environnements de production : <strong>fiabilit√© sous charge, caract√©ristiques de latence de queue, d√©bit soutenu et pr√©servation de la pr√©cision.</strong></p>
<ul>
<li><p><strong>Latence P95/P99 pour une exp√©rience utilisateur r√©elle</strong>: La latence moyenne/m√©diane masque les valeurs aberrantes qui frustrent les utilisateurs r√©els et peuvent indiquer une instabilit√© sous-jacente du syst√®me. VDBBench se concentre sur la latence de queue comme P95/P99, r√©v√©lant la performance que 95% ou 99% de vos requ√™tes atteindront r√©ellement. Cet aspect est crucial pour la planification des accords de niveau de service (SLA) et la compr√©hension de l'exp√©rience de l'utilisateur dans le pire des cas.</p></li>
<li><p><strong>D√©bit durable sous charge</strong>: Un syst√®me qui fonctionne bien pendant 5 secondes n'est pas suffisant en production. VDBBench augmente progressivement la concurrence pour trouver le nombre maximum de requ√™tes par seconde (<code translate="no">max_qps</code>) de votre base de donn√©es - et non le nombre maximum dans des conditions courtes et id√©ales. Cette m√©thodologie r√©v√®le la capacit√© de votre syst√®me √† tenir dans le temps et vous aide √† planifier votre capacit√© de mani√®re r√©aliste.</p></li>
<li><p><strong>Un rappel √©quilibr√© par rapport √† la performance</strong>: La vitesse sans la pr√©cision n'a pas de sens. Chaque chiffre de performance dans VDBBench est associ√© √† des mesures de rappel, afin que vous sachiez exactement quelle pertinence vous √©changez pour le d√©bit. Cela permet d'√©tablir des comparaisons √©quitables entre des syst√®mes dont les compromis internes sont tr√®s diff√©rents.</p></li>
</ul>
<h3 id="Test-Methodology-That-Reflects-Reality" class="common-anchor-header">Une m√©thodologie de test qui refl√®te la r√©alit√©</h3><p>Une innovation cl√© dans la conception de VDBBench est la s√©paration des tests en s√©rie et simultan√©s, qui aide √† capturer la fa√ßon dont les syst√®mes se comportent sous diff√©rents types de charge et r√©v√®le les caract√©ristiques de performance qui comptent pour diff√©rents cas d'utilisation.</p>
<p><strong>S√©paration des mesures de latence :</strong></p>
<ul>
<li><p><code translate="no">serial_latency_p99</code> mesure les performances du syst√®me sous une charge minimale, lorsqu'une seule requ√™te est trait√©e √† la fois. Cela repr√©sente le meilleur sc√©nario pour la latence et permet d'identifier les capacit√©s de base du syst√®me.</p></li>
<li><p><code translate="no">conc_latency_p99</code> capture le comportement du syst√®me dans des conditions r√©alistes, √† haute fr√©quence, o√π plusieurs requ√™tes arrivent simultan√©ment et se disputent les ressources du syst√®me.</p></li>
</ul>
<p><strong>Structure du test de r√©f√©rence en deux phases</strong>:</p>
<ol>
<li><p><strong>Test en s√©rie</strong>: Ex√©cution mono-processus de 1 000 requ√™tes qui √©tablit la performance et la pr√©cision de base, en rapportant √† la fois <code translate="no">serial_latency_p99</code> et le rappel. Cette phase permet d'identifier le plafond th√©orique des performances.</p></li>
<li><p><strong>Test de simultan√©it√©</strong>: Simule l'environnement de production sous une charge soutenue avec plusieurs innovations cl√©s :</p>
<ul>
<li><p><strong>Simulation r√©aliste du client</strong>: Chaque processus de test fonctionne ind√©pendamment avec sa propre connexion et son propre ensemble de requ√™tes, √©vitant ainsi les interf√©rences d'√©tat partag√© qui pourraient fausser les r√©sultats.</p></li>
<li><p><strong>D√©marrage synchronis√©</strong>: Tous les processus d√©marrent simultan√©ment, ce qui garantit que le QPS mesur√© refl√®te fid√®lement les niveaux de concurrence d√©clar√©s.</p></li>
<li><p><strong>Jeux de requ√™tes ind√©pendants</strong>: √âvite les taux d'acc√®s au cache irr√©alistes qui ne refl√®tent pas la diversit√© des requ√™tes en production.</p></li>
</ul></li>
</ol>
<p>Ces m√©thodes soigneusement structur√©es garantissent que les valeurs <code translate="no">max_qps</code> et <code translate="no">conc_latency_p99</code> rapport√©es par VDBBench sont √† la fois pr√©cises et pertinentes pour la production, fournissant des informations significatives pour la planification de la capacit√© de production et la conception du syst√®me.</p>
<h2 id="Getting-Started-with-VDBBench-10" class="common-anchor-header">D√©marrer avec VDBBench 1.0<button data-href="#Getting-Started-with-VDBBench-10" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p><strong>VDBBench 1.0</strong> repr√©sente un changement fondamental vers un benchmarking pertinent pour la production. En couvrant l'√©criture continue de donn√©es, le filtrage de m√©tadonn√©es avec une s√©lectivit√© variable, et les charges de streaming avec des mod√®les d'acc√®s concurrents, il fournit l'approximation la plus proche des environnements de production r√©els disponibles aujourd'hui.</p>
<p>L'√©cart entre les r√©sultats des analyses comparatives et les performances r√©elles ne doit pas √™tre un jeu de devinettes. Si vous envisagez de d√©ployer une base de donn√©es vectorielle en production, il est utile de comprendre comment elle se comporte au-del√† des tests de laboratoire id√©alis√©s. VDBBench est open-source, transparent et con√ßu pour permettre des comparaisons significatives.</p>
<p>Ne vous laissez pas influencer par des chiffres impressionnants qui ne se traduisent pas en valeur de production. <strong>Utilisez VDBBench 1.0 pour tester des sc√©narios importants pour votre entreprise, avec vos donn√©es, dans des conditions qui refl√®tent votre charge de travail r√©elle.</strong> L'√®re des benchmarks trompeurs dans l'√©valuation des bases de donn√©es vectorielles est r√©volue - il est temps de prendre des d√©cisions bas√©es sur des donn√©es pertinentes pour la production.</p>
<p><strong>Essayez VDBBench avec vos propres charges de travail</strong><a href="https://github.com/zilliztech/VectorDBBench">: https://github.com/zilliztech/VectorDBBench</a></p>
<p><strong>Consultez les r√©sultats des tests des principales bases de donn√©es vectorielles :</strong><a href="https://zilliz.com/vdbbench-leaderboard?dataset=vectorSearch"> VDBBench Leaderboard</a></p>
<p>Vous avez des questions ou souhaitez partager vos r√©sultats ? Rejoignez la conversation sur<a href="https://github.com/zilliztech/VectorDBBench"> GitHub</a> ou connectez-vous avec notre communaut√© sur<a href="https://discord.com/invite/FG6hMJStWu"> Discord</a>.</p>
