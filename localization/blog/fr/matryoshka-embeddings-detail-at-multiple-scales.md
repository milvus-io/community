---
id: matryoshka-embeddings-detail-at-multiple-scales
title: 'Emboîtements Matryoshka : Détail à plusieurs échelles'
author: 'Stefan Webb, David Wang'
date: 2024-10-30T00:00:00.000Z
desc: >-
  Embeddings avec des dimensions réduites sans sacrifier l'intégrité sémantique,
  idéal pour une recherche et un stockage plus efficaces.
metaTitle: What are Matryoshka Embeddings?
cover: assets.zilliz.com/Introduction_to_Matryoshka_Embedding_e5a5bc2056.png
tag: Engineering
tags: Matryoshka Embeddings
recommend: true
canonicalUrl: 'https://milvus.io/blog/matryoshka-embeddings-detail-at-multiple-scales'
---
<h2 id="What-are-Matryoshka-Embeddings" class="common-anchor-header">Que sont les Matryoshka Embeddings ?<button data-href="#What-are-Matryoshka-Embeddings" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Lors de la construction de systèmes de <a href="https://zilliz.com/learn/vector-similarity-search">recherche vectorielle</a> efficaces, l'un des principaux défis consiste à gérer les coûts de stockage tout en maintenant une latence et un rappel acceptables. Les <a href="https://zilliz.com/blog/choosing-the-right-embedding-model-for-your-data">modèles d'intégration</a> modernes produisent des vecteurs comportant des centaines ou des milliers de dimensions, ce qui entraîne des coûts de stockage et de calcul importants pour le vecteur brut et l'index.</p>
<p>Traditionnellement, les besoins en stockage sont réduits par l'application d'une méthode de quantification ou de réduction de la dimensionnalité juste avant la construction de l'index. Par exemple, nous pouvons économiser de l'espace de stockage en réduisant la précision à l'aide de la <a href="https://zilliz.com/learn/scalar-quantization-and-product-quantization">quantification par produit</a> (PQ) ou le nombre de dimensions à l'aide de l'analyse en composantes principales (ACP). Ces méthodes analysent l'ensemble des vecteurs pour en trouver un plus compact qui préserve les relations sémantiques entre les vecteurs.</p>
<p>Bien qu'efficaces, ces approches standard ne réduisent la précision ou la dimensionnalité qu'une seule fois et à une seule échelle. Mais que se passerait-il si nous pouvions conserver simultanément plusieurs couches de détails, comme une pyramide de représentations de plus en plus précises ?</p>
<p>C'est là qu'interviennent les <a href="https://arxiv.org/abs/2205.13147"><strong>encastrements Matryoshka</strong></a>. Nommées d'après les poupées russes gigognes (voir illustration), ces constructions astucieuses intègrent plusieurs échelles de représentation dans un seul vecteur. Contrairement aux méthodes traditionnelles de post-traitement, les Matryoshka embeddings apprennent cette structure multi-échelle au cours du processus d'apprentissage initial. Le résultat est remarquable : <strong>non seulement l'intégration complète capture la sémantique de l'entrée, mais chaque préfixe de sous-ensemble imbriqué (première moitié, premier quart, etc.) fournit une représentation cohérente, bien que moins détaillée.</strong></p>
<p>
 <span class="img-wrapper">
   <img translate="no" src="https://assets.zilliz.com/Visualization_of_Matryoshka_embeddings_with_multiple_layers_of_detail_274f2c7aba.png" alt="Figure: Visualization of Matryoshka embeddings with multiple layers of detail" class="doc-image" id="figure:-visualization-of-matryoshka-embeddings-with-multiple-layers-of-detail" />
   <span>Figure : Visualisation des encastrements Matryoshka avec plusieurs couches de détails</span> </span></p>
<p><em>Figure : Visualisation des encastrements de Matryoshka avec plusieurs couches de détails</em></p>
<p>Cette approche contraste fortement avec les <a href="https://zilliz.com/glossary/vector-embeddings">encastrements</a> conventionnels, où l'utilisation de sous-ensembles arbitraires des dimensions du vecteur détruit généralement le sens sémantique. Avec les encastrements de Matryoshka, vous pouvez choisir la granularité qui concilie le mieux la précision de votre tâche spécifique et le coût de calcul.</p>
<p>Vous avez besoin d'une recherche approximative rapide ? Utilisez la plus petite "poupée". Vous avez besoin d'une précision maximale ? Utilisez l'intégration complète. Cette flexibilité les rend particulièrement utiles pour les systèmes qui s'adaptent à des exigences de performance différentes ou à des contraintes de ressources.</p>
<h2 id="Inference" class="common-anchor-header">Inférence<button data-href="#Inference" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>L'accélération des recherches de similarité sans sacrifier le rappel est une application précieuse des Matryoshka embeddings. En tirant parti de sous-ensembles plus petits d'encastrements de requêtes et de bases de données, tels que les 1/32 premiers de leurs dimensions, nous pouvons construire un index sur cet espace réduit qui préserve encore une grande partie des informations de similarité. Les résultats initiaux de cet espace d'intégration réduit peuvent être utilisés directement. Toutefois, il existe également une technique permettant d'augmenter le rappel et de tenir compte de toute réduction mineure résultant de la réduction des dimensions, ce qui rend cette approche à la fois efficace et efficiente pour les tâches de recherche de similarité.</p>
<p>
 <span class="img-wrapper">
   <img translate="no" src="https://assets.zilliz.com/How_the_funnel_search_works_with_Matryoshka_embeddings_8fa05a2fe7.png" alt="Figure: How the funnel search works with Matryoshka embeddings" class="doc-image" id="figure:-how-the-funnel-search-works-with-matryoshka-embeddings" />
   <span>Figure : Fonctionnement de la recherche en entonnoir avec les encastrements de Matryoshka</span> </span></p>
<p><em>Figure : Fonctionnement de la recherche en entonnoir avec les encastrements de Matryoshka</em></p>
<p>Pour accélérer efficacement la recherche de similarités tout en maintenant la précision, nous pouvons utiliser une approche de "recherche en entonnoir". Tout d'abord, nous effectuons une première recherche de similitudes en utilisant uniquement les 1/32 premiers des dimensions de l'intégration, ce qui génère un large éventail d'éléments candidats. Nous classons ensuite ces candidats en fonction de leur similarité avec la requête en utilisant les 1/16 premières dimensions, ce qui permet d'élaguer une partie de la liste. Ce processus se poursuit de manière itérative, en procédant au reclassement et à l'élagage à l'aide de sous-ensembles de plus en plus grands des dimensions d'intégration - 1/8, 1/4, et ainsi de suite. Il est important de noter que nous n'effectuons qu'une seule recherche de similarité initiale dans cet espace de dimension inférieure et qu'un seul passage du modèle d'intégration calcule l'intégration de la requête. Ce processus d'entonnoir réduit le nombre de candidats à chaque étape et est plus rapide et plus efficace qu'une recherche directe dans l'espace à pleine dimension. Le fait de tirer de nombreuses correspondances de l'espace à 1/32 dimensions et de les affiner par le biais de la recherche en entonnoir peut accélérer considérablement la recherche de similarités tout en préservant un rappel important.</p>
<h2 id="Training" class="common-anchor-header">Entraînement<button data-href="#Training" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Entrons dans quelques détails techniques. La méthode est très simple à appliquer. Considérons le contexte de l'affinement d'un <a href="https://zilliz.com/learn/what-is-bert">modèle BERT</a> pour l'intégration de phrases. Pour convertir un modèle BERT, qui a été pré-entraîné sur la perte de jeton masqué, en un modèle d'intégration de phrases, nous formons l'intégration de phrases comme la moyenne de la couche finale, c'est-à-dire la moyenne des intégrations contextualisées par jeton.</p>
<p>Un choix d'objectif d'apprentissage est la <a href="https://sbert.net/docs/package_reference/sentence_transformer/losses.html#cosentloss">perte de cosinus de la phrase (CoSENT)</a>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo separator="true">;</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L(u, v ; s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span></span></span></span> L <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span></span> v <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span></span> s <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mclose">)</span></span></span></span>. Il entre une paire d'enchâssements de phrases, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">vu,v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span></span></span></span> u <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span></span> v, et leur score de similarité souhaité, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">ss</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span></span></span></span> s (voir le lien ci-dessus pour la formule). Maintenant, pour apprendre les encastrements de Matryoshka, nous apportons une petite modification à l'objectif d'apprentissage :</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>LM</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo><mi>=w0L</mi><mo stretchy="false">(</mo><msub><mrow><mn>u1</mn><mo>:</mo><mi>d</mi></mrow></msub><mo separator="true">,</mo><msub><mrow><mn>v1</mn><mo>:</mo><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mi>+w1L</mi><mo stretchy="false">(</mo><msub><mrow><mn>u1</mn><mi>:</mi><mn>d/2</mn></mrow></msub><mo separator="true">,</mo><msub><mrow><mn>v1</mn><mi>:</mi><mn>d/2</mn></mrow></msub><mo stretchy="false">)</mo><mi>+w2L</mi><mo stretchy="false">(</mo><msub><mrow><mn>u1</mn><mo>:</mo><mn>d/4</mn></mrow></msub><mo separator="true">,</mo><msub><mrow><mn>v1</mn><mo>:</mo><mn>d/4</mn></mrow></msub><mo stretchy="false">)</mo><mo>+⋯L_M</mo></mrow><annotation encoding="application/x-tex">(u, v) = w_0L(u_{1:d}, v_{1:d}) + w_1L(u_{1:d/2}, v_{1 :</annotation></semantics></math></span></span><span class="pstrut" style="height:2.7em;"></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="strut" style="height:0.313em;"></span>d<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">/2}) + w_2L(u_{1:d/4}, v_{1:d/4}) + \cdots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">M</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">(u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span></span></span> =<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span> </span></span> w<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">0</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span></span></span></span></span><span class="pstrut" style="height:2.7em;"></span><span class="katex">1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span><span class="katex">,<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span></span></span></span></span></span></span> 1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span><span class="katex">)<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span></span> +<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span> </span></span> w<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">1</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span></span></span></span></span><span class="pstrut" style="height:2.7em;"></span><span class="katex">1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="katex">,<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span></span></span></span></span></span></span> 1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0359em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="katex">)<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span></span> +<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span> </span></span> w<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">2</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span> L<span class="katex-html" aria-hidden="true"><span class="base"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span></span></span></span></span><span class="pstrut" style="height:2.7em;"></span><span class="katex">1<span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/4</span></span></span></span></span></span></span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span><span class="katex">,<span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.1667em;"></span></span></span> v<span class="katex-html" aria-hidden="true"><span class="base"><span class="minner">xml-ph</span></span></span></span></p>
<p>où la somme se poursuit en calculant la perte sur la moitié de l'entrée du terme précédent jusqu'à ce qu'un goulot d'étranglement de l'information soit atteint. Les auteurs suggèrent de fixer</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">w0=w1=⋯=1w_0=w_1=\cdots=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span></span></span></span> w<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">0</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span> =</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span> w</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span></span></span><span class="vlist-s">1</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span> =</span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2778em;"></span></span></span></span>=<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span> 1.</span></span></span></p>
<p><em>En termes simples, la perte Matryoshka est une somme pondérée de la perte originale sur des sous-ensembles récursifs de l'entrée.</em></p>
<p>L'un des principaux enseignements de l'équation ci-dessus est que la perte de Matryoshka permet un apprentissage efficace des représentations à plusieurs échelles en partageant les poids entre les modèles d'intégration (le même modèle est utilisé pour coder, par exemple, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mn>u1</mn></mrow><mrow><mo>:</mo></mrow></msub></mrow><annotation encoding="application/x-tex">du_{1:d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span></span></span></span> u <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span> 1</span></span></span></span></span></span></span></span></span> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mn>u1</mn><mo>:</mo><mn>d/2u_{1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">:d/2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span></span></span></span> u <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span> 1</span></span></span></span></span></span></span></span></span> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span>) et en partageant les dimensions entre les échelles<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>(</mi><mrow><mn>u1</mn><mo>:</mo><mn>d/2u_{1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">:d/2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span></span></span></span> u<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span> 1</span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="mord"><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">:</span></span></span></span></span><span class="vlist-s">d/2</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span></span></span> est un sous-ensemble de <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><annotation encoding="application/x-tex">uu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span></span></span></span> u).</p>
<h2 id="Matryoshka-Embeddings-and-Milvus" class="common-anchor-header">Matryoshka Embeddings et Milvus<button data-href="#Matryoshka-Embeddings-and-Milvus" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Milvus prend en charge de manière transparente tout modèle d'intégration Matryoshka qui peut être chargé via des bibliothèques standard telles que <a href="https://milvus.io/docs/embeddings.md">pymilvus.model</a>, <a href="https://milvus.io/docs/integrate_with_sentencetransformers.md">sentence-transformers</a> ou d'autres outils similaires. Du point de vue du système, il n'y a pas de différence fonctionnelle entre un modèle d'intégration normal et un modèle spécifiquement formé pour générer des intégrations Matryoshka.</p>
<p>Les modèles d'intégration de Matryoshka les plus répandus sont les suivants :</p>
<ul>
<li><p>OpenAI <a href="https://zilliz.com/ai-models/text-embedding-3-large"><code translate="no">text-embedding-3-large</code></a></p></li>
<li><p>Nomic <a href="https://huggingface.co/nomic-ai/nomic-embed-text-v1"><code translate="no">nomic-embed-text-v1</code></a></p></li>
<li><p>Alibaba's <a href="https://huggingface.co/Alibaba-NLP/gte-multilingual-base"><code translate="no">gte-multilingual-base</code></a></p></li>
</ul>
<p>Pour un guide complet sur l'utilisation des embeddings Matryoshka avec Milvus, voir le carnet <em><a href="https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/funnel_search_with_matryoshka.ipynb">Funnel Search with Matryoshka Embeddings (Recherche en entonnoir avec les embeddings Matryoshka</a></em>).</p>
<h2 id="Summary" class="common-anchor-header">Résumé<button data-href="#Summary" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>L'intégration Matryoshka permet aux développeurs de créer des intégrations raccourcies sans sacrifier l'intégrité sémantique, ce qui les rend idéales pour une recherche et un stockage plus efficaces. Bien qu'il soit possible de modifier un modèle existant, des options pré-entraînées, telles que celles d'<a href="https://zilliz.com/ai-models">OpenAI</a> et de <a href="https://zilliz.com/ai-models">Hugging Face</a>, sont également disponibles.</p>
<p>Cependant, une limitation actuelle est la rareté des embeddings Matryoshka open-source, avec quelques uns disponibles sur le hub de Hugging Face. En outre, ces modèles ne sont souvent pas explicitement désignés comme "Matryoshka", ce qui les rend plus difficiles à localiser. Il est à espérer que l'intérêt croissant pour ces modèles se traduira bientôt par une plus grande disponibilité et un étiquetage plus clair.</p>
<p>Prêt à rationaliser vos capacités de recherche ? Commencez dès aujourd'hui à intégrer Milvus + Matryoshka !</p>
<h2 id="Resources" class="common-anchor-header">Ressources<button data-href="#Resources" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ul>
<li><p>Carnet de notes : <a href="https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/funnel_search_with_matryoshka.ipynb">Recherche en entonnoir avec Matryoshka Embeddings</a></p></li>
<li><p>Article : <a href="https://arxiv.org/abs/2205.13147">Apprentissage de la représentation Matryoshka</a></p></li>
<li><p>Article : <a href="https://arxiv.org/pdf/2407.19669">mGTE : Représentation généralisée des textes en contexte long et modèles de reclassement pour la recherche de textes multilingues</a></p></li>
<li><p><a href="https://milvus.io/blog/introducing-pymilvus-integrations-with-embedding-models.md">Présentation de l'intégration de PyMilvus avec les modèles d'intégration </a></p></li>
<li><p><a href="https://zilliz.com/learn/Exploring-BGE-M3-the-future-of-information-retrieval-with-milvus">Explorer BGE-M3 : L'avenir de la recherche d'information avec Milvus </a></p></li>
<li><p><a href="https://static.nomic.ai/reports/2024_Nomic_Embed_Text_Technical_Report.pdf">Nomic Embed : Entraînement d'un intégrateur de texte en contexte long reproductible</a></p></li>
<li><p><a href="https://sbert.net/examples/training/matryoshka/README.html">Formation de Matryoshka Embeddings avec la bibliothèque Sentence Transformers</a></p></li>
<li><p><a href="https://milvus.io/bootcamp">Bootcamp Milvus</a></p></li>
</ul>
