---
id: debugging-rag-in-3d-with-projectgolem-and-milvus.md
title: >-
  Et si vous pouviez voir pourquoi RAG √©choue ? D√©bogage de RAG en 3D avec
  Project_Golem et Milvus
author: Min Yin
date: 2026-02-18T00:00:00.000Z
cover: assets.zilliz.com/Debugging_RAG_in_3_D_f1b45f9a99_5f98979c06.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database, RAG'
meta_keywords: 'Project_Golem, milvus, RAG'
meta_title: |
  Debugging RAG in 3D with Project_Golem and Milvus
desc: >-
  D√©couvrez comment Project_Golem et Milvus rendent les syst√®mes RAG observables
  en visualisant l'espace vectoriel, en d√©boguant les erreurs de recherche et en
  adaptant la recherche vectorielle en temps r√©el.
origin: 'https://milvus.io/blog/debugging-rag-in-3d-with-projectgolem-and-milvus.md'
---
<p>Lorsque la recherche par RAG ne fonctionne pas, vous savez g√©n√©ralement qu'elle est d√©fectueuse - les documents pertinents n'apparaissent pas, ou les documents non pertinents apparaissent. Mais c'est une autre histoire que de comprendre pourquoi. Tout ce dont vous disposez, ce sont des scores de similarit√© et une liste plate de r√©sultats. Il n'y a aucun moyen de voir comment les documents sont r√©ellement positionn√©s dans l'espace vectoriel, comment les morceaux sont li√©s les uns aux autres, ou o√π votre requ√™te a atterri par rapport au contenu auquel elle aurait d√ª correspondre. En pratique, cela signifie que le d√©bogage des RAG se fait principalement par essais et erreurs : modifier la strat√©gie de d√©coupage, changer le mod√®le d'int√©gration, ajuster le top-k, et esp√©rer que les r√©sultats s'am√©liorent.</p>
<p><a href="https://github.com/CyberMagician/Project_Golem">Project_Golem</a> est un outil open-source qui rend l'espace vectoriel visible. Il utilise UMAP pour projeter des encastrements √† haute dimension en 3D et Three.js pour les rendre interactifs dans le navigateur. Au lieu de deviner pourquoi la recherche a √©chou√©, vous pouvez voir comment les morceaux se regroupent s√©mantiquement, o√π votre requ√™te atterrit et quels documents ont √©t√© r√©cup√©r√©s - le tout dans une seule interface visuelle.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/debugging_rag_in_3d_with_projectgolem_and_milvus_1_01de566e04.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>C'est extraordinaire. Cependant, le projet original Project_Golem a √©t√© con√ßu pour de petites d√©monstrations, et non pour des syst√®mes r√©els. Il s'appuie sur des fichiers plats, une recherche brute et des reconstructions de l'ensemble des donn√©es, ce qui signifie qu'il s'effondre rapidement lorsque vos donn√©es d√©passent quelques milliers de documents.</p>
<p>Pour combler cette lacune, nous avons int√©gr√© Project_Golem avec <a href="https://milvus.io/docs/release_notes.md#v268">Milvus</a> (plus pr√©cis√©ment la version 2.6.8) en tant qu'√©pine dorsale vectorielle. Milvus est une base de donn√©es vectorielles haute performance open-source qui g√®re l'ingestion en temps r√©el, l'indexation √©volutive et la recherche √† la milliseconde, tandis que Project_Golem reste concentr√© sur ce qu'il fait de mieux : rendre visible le comportement de la recherche vectorielle. Ensemble, ils transforment la visualisation 3D d'une d√©mo jouet en un outil de d√©bogage pratique pour les syst√®mes RAG de production.</p>
<p>Dans ce billet, nous allons pr√©senter Project_Golem et montrer comment nous l'avons int√©gr√© √† Milvus pour rendre le comportement de recherche vectorielle observable, √©volutif et pr√™t pour la production.</p>
<h2 id="What-Is-ProjectGolem" class="common-anchor-header">Qu'est-ce que Project_Golem ?<button data-href="#What-Is-ProjectGolem" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Le d√©bogage RAG est difficile pour une raison simple : les espaces vectoriels sont √† haute dimension et les humains ne peuvent pas les voir.</p>
<p><a href="https://github.com/CyberMagician/Project_Golem">Project_Golem</a> est un outil bas√© sur un navigateur qui vous permet de voir l'espace vectoriel dans lequel votre syst√®me RAG fonctionne. Il prend les encastrements √† haute dimension qui alimentent la recherche - typiquement 768 ou 1536 dimensions - et les projette dans une sc√®ne interactive en 3D que vous pouvez explorer directement.</p>
<p>Voici comment cela fonctionne sous le capot :</p>
<ul>
<li>R√©duction de la dimensionnalit√© avec UMAP. Project_Golem utilise UMAP pour comprimer des vecteurs √† haute dimension en trois dimensions tout en pr√©servant leurs distances relatives. Les morceaux qui sont s√©mantiquement similaires dans l'espace d'origine restent proches les uns des autres dans la projection 3D ; les morceaux qui n'ont pas de rapport entre eux se retrouvent √©loign√©s les uns des autres.</li>
<li>Rendu 3D avec Three.js. Chaque morceau de document appara√Æt comme un n≈ìud dans une sc√®ne 3D rendue dans le navigateur. Vous pouvez faire pivoter, zoomer et explorer l'espace pour voir comment vos documents se regroupent - quels sujets sont √©troitement li√©s, lesquels se chevauchent et o√π se situent les limites.</li>
<li>Mise en √©vidence au moment de la requ√™te. Lorsque vous lancez une requ√™te, la recherche s'effectue toujours dans l'espace √† haute dimension d'origine en utilisant la similarit√© cosinuso√Ødale. Mais une fois les r√©sultats obtenus, les morceaux retrouv√©s s'illuminent dans la vue en 3D. Vous pouvez imm√©diatement voir o√π votre requ√™te a atterri par rapport aux r√©sultats - et, ce qui est tout aussi important, par rapport aux documents qu'elle n'a pas retrouv√©s.</li>
</ul>
<p>C'est ce qui rend Project_Golem utile pour le d√©bogage. Au lieu de regarder une liste de r√©sultats class√©s et de deviner pourquoi un document pertinent n'a pas √©t√© retrouv√©, vous pouvez voir s'il se trouve dans un groupe √©loign√© (un probl√®me d'int√©gration), s'il se superpose √† un contenu non pertinent (un probl√®me de regroupement) ou s'il est juste en dehors du seuil de r√©cup√©ration (un probl√®me de configuration). La vue 3D transforme les scores de similarit√© abstraits en relations spatiales sur lesquelles il est possible de raisonner.</p>
<h2 id="Why-ProjectGolem-Isnt-Production-Ready" class="common-anchor-header">Pourquoi Project_Golem n'est pas pr√™t pour la production<button data-href="#Why-ProjectGolem-Isnt-Production-Ready" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Le projet_Golem a √©t√© con√ßu comme un prototype de visualisation, et il fonctionne bien pour cela. Mais son architecture repose sur des hypoth√®ses qui s'effondrent rapidement √† grande √©chelle - d'une mani√®re qui a de l'importance si vous voulez l'utiliser pour le d√©bogage de RAG dans le monde r√©el.</p>
<h3 id="Every-Update-Requires-a-Full-Rebuild" class="common-anchor-header">Chaque mise √† jour n√©cessite une reconstruction compl√®te</h3><p>Il s'agit de la limitation la plus fondamentale. Dans la conception originale, l'ajout de nouveaux documents d√©clenche une reconstruction compl√®te du pipeline : les embeddings sont r√©g√©n√©r√©s et √©crits dans des fichiers .npy, UMAP est r√©ex√©cut√© sur l'ensemble du jeu de donn√©es et les coordonn√©es 3D sont r√©export√©es sous forme de JSON.</p>
<p>M√™me √† l'√©chelle de 100 000 documents, une ex√©cution UMAP √† c≈ìur unique prend de 5 √† 10 minutes. √Ä l'√©chelle du million de documents, cela devient totalement impraticable. Vous ne pouvez pas utiliser cette m√©thode pour les ensembles de donn√©es qui changent continuellement (flux d'actualit√©s, documentation, conversations d'utilisateurs), car chaque mise √† jour implique d'attendre un cycle de retraitement complet.</p>
<h3 id="Brute-Force-Search-Doesnt-Scale" class="common-anchor-header">La recherche muscl√©e n'est pas √©volutive</h3><p>La recherche a son propre plafond. L'impl√©mentation originale utilise NumPy pour la recherche brute de similarit√© cosinus - complexit√© temporelle lin√©aire, pas d'indexation. Sur un ensemble de donn√©es d'un million de documents, une seule requ√™te peut prendre plus d'une seconde. C'est inutilisable pour un syst√®me interactif ou en ligne.</p>
<p>La pression sur la m√©moire aggrave le probl√®me. Chaque vecteur float32 de 768 dimensions occupe environ 3 Ko, de sorte qu'un ensemble de donn√©es d'un million de vecteurs n√©cessite plus de 3 Go de m√©moire - le tout charg√© dans un tableau NumPy plat sans structure d'indexation pour rendre la recherche efficace.</p>
<h3 id="No-Metadata-Filtering-No-Multi-Tenancy" class="common-anchor-header">Pas de filtrage des m√©tadonn√©es, pas de multilocation</h3><p>Dans un syst√®me RAG r√©el, la similarit√© vectorielle est rarement le seul crit√®re de recherche. Il est presque toujours n√©cessaire de filtrer par m√©tadonn√©es, comme le type de document, l'horodatage, les autorisations de l'utilisateur ou les limites de l'application. Un syst√®me RAG de support client, par exemple, doit limiter la recherche aux documents d'un locataire sp√©cifique - et non pas √† l'ensemble des donn√©es.</p>
<p>Project_Golem ne supporte rien de tout cela. Il n'y a pas d'index ANN (comme HNSW ou IVF), pas de filtrage scalaire, pas d'isolation des locataires et pas de recherche hybride. Il s'agit d'une couche de visualisation sans moteur de recherche de production.</p>
<h2 id="How-Milvus-Powers-ProjectGolem‚Äôs-Retrieval-Layer" class="common-anchor-header">Comment Milvus alimente la couche de recherche de Project_Golem<button data-href="#How-Milvus-Powers-ProjectGolem‚Äôs-Retrieval-Layer" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>La section pr√©c√©dente a identifi√© trois lacunes : les reconstructions compl√®tes √† chaque mise √† jour, la recherche par force brute et l'absence de r√©cup√©ration tenant compte des m√©tadonn√©es. Ces trois lacunes ont la m√™me origine : Project_Golem n'a pas de couche de base de donn√©es. La r√©cup√©ration, le stockage et la visualisation sont enchev√™tr√©s dans un seul pipeline, de sorte que la modification de n'importe quelle partie oblige √† tout reconstruire.</p>
<p>La solution n'est pas d'optimiser ce pipeline. Il s'agit de le s√©parer.</p>
<p>En int√©grant Milvus 2.6.8 en tant qu'√©pine dorsale vectorielle, la r√©cup√©ration devient une couche d√©di√©e, de qualit√© production, qui fonctionne ind√©pendamment de la visualisation. Milvus g√®re le stockage, l'indexation et la recherche des vecteurs. Project_Golem se concentre uniquement sur le rendu - en consommant les identifiants de documents de Milvus et en les mettant en √©vidence dans la vue 3D.</p>
<p>Cette s√©paration produit deux flux propres et ind√©pendants :</p>
<p>Flux de recherche (en ligne, au niveau de la milliseconde)</p>
<ul>
<li>Votre requ√™te est convertie en un vecteur √† l'aide des embeddings OpenAI.</li>
<li>Le vecteur de la requ√™te est envoy√© √† une collection Milvus.</li>
<li>Milvus AUTOINDEX s√©lectionne et optimise l'index appropri√©.</li>
<li>Une recherche de similarit√© cosinus en temps r√©el renvoie les ID des documents pertinents.</li>
</ul>
<p>Flux de visualisation (hors ligne, √† l'√©chelle de la d√©monstration)</p>
<ul>
<li>UMAP g√©n√®re des coordonn√©es 3D pendant l'ingestion des donn√©es (n_neighbors=30, min_dist=0.1).</li>
<li>Les coordonn√©es sont stock√©es dans golem_cortex.json.</li>
<li>Le frontend met en √©vidence les n≈ìuds 3D correspondants en utilisant les ID des documents renvoy√©s par Milvus.</li>
</ul>
<p>Le point critique : la recherche n'attend plus la visualisation. Vous pouvez ing√©rer de nouveaux documents et les rechercher imm√©diatement - la vue en 3D les rattrape selon son propre calendrier.</p>
<h3 id="What-Streaming-Nodes-Change" class="common-anchor-header">Ce que les n≈ìuds de streaming changent</h3><p>Cette ingestion en temps r√©el est assur√©e par une nouvelle fonctionnalit√© de Milvus 2.6.8 : les <a href="https://milvus.io/docs/configure_streamingnode.md#streamingNode-related-Configurations">n≈ìuds de diffusion en continu</a>. Dans les versions pr√©c√©dentes, l'ingestion en temps r√©el n√©cessitait une file d'attente de messages externe telle que Kafka ou Pulsar. Les n≈ìuds de flux d√©placent cette coordination dans Milvus lui-m√™me - les nouveaux vecteurs sont ing√©r√©s en continu, les index sont mis √† jour de mani√®re incr√©mentielle et les documents nouvellement ajout√©s deviennent imm√©diatement consultables sans reconstruction compl√®te et sans d√©pendances externes.</p>
<p>Pour le Projet_Golem, c'est ce qui rend l'architecture pratique. Vous pouvez continuer √† ajouter des documents √† votre syst√®me RAG - nouveaux articles, documents mis √† jour, contenu g√©n√©r√© par les utilisateurs - et la recherche reste √† jour sans d√©clencher le co√ªteux cycle UMAP ‚Üí JSON ‚Üí rechargement.</p>
<h3 id="Extending-Visualization-to-Million-Scale-Future-Path" class="common-anchor-header">Extension de la visualisation √† l'√©chelle du million (voie future)</h3><p>Avec cette configuration soutenue par Milvus, Project_Golem prend actuellement en charge des d√©monstrations interactives pour environ 10 000 documents. L'extraction s'√©tend bien au-del√† - Milvus g√®re des millions - mais le pipeline de visualisation repose toujours sur des ex√©cutions UMAP par lots. Pour combler cette lacune, l'architecture peut √™tre √©tendue avec un pipeline de visualisation incr√©mental :</p>
<ul>
<li><p>D√©clencheurs de mise √† jour : Le syst√®me est √† l'√©coute des √©v√©nements d'insertion dans la collection Milvus. Lorsque les documents nouvellement ajout√©s atteignent un seuil d√©fini (par exemple, 1 000 √©l√©ments), une mise √† jour incr√©mentale est d√©clench√©e.</p></li>
<li><p>Projection incr√©mentielle : Au lieu de r√©ex√©cuter l'UMAP sur l'ensemble du jeu de donn√©es, les nouveaux vecteurs sont projet√©s dans l'espace 3D existant √† l'aide de la m√©thode transform() de l'UMAP. Cela permet de pr√©server la structure globale tout en r√©duisant consid√©rablement les co√ªts de calcul.</p></li>
<li><p>Synchronisation frontale : Les fragments de coordonn√©es mis √† jour sont transmis au frontend via WebSocket, ce qui permet aux nouveaux n≈ìuds d'appara√Ætre dynamiquement sans avoir √† recharger l'ensemble de la sc√®ne.</p></li>
</ul>
<p>Au-del√† de l'√©volutivit√©, Milvus 2.6.8 permet une recherche hybride en combinant la similarit√© vectorielle avec la recherche plein texte et le filtrage scalaire. Cela ouvre la voie √† des interactions 3D plus riches, telles que la mise en √©vidence des mots cl√©s, le filtrage par cat√©gorie et le d√©coupage temporel, offrant aux d√©veloppeurs des moyens plus puissants d'explorer, de d√©boguer et de raisonner sur le comportement des RAG.</p>
<h2 id="How-to-Deploy-and-Explore-ProjectGolem-with-Milvus" class="common-anchor-header">Comment d√©ployer et explorer Project_Golem avec Milvus<button data-href="#How-to-Deploy-and-Explore-ProjectGolem-with-Milvus" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Le Projet_Golem mis √† jour est d√©sormais en open source sur <a href="https://github.com/yinmin2020/Project_Golem_Milvus">GitHub</a>. En utilisant la documentation officielle de Milvus comme ensemble de donn√©es, nous parcourons le processus complet de visualisation de l'extraction de RAG en 3D. L'installation utilise Docker et Python et est facile √† suivre, m√™me si vous partez de z√©ro.</p>
<h3 id="Prerequisites" class="common-anchor-header">Conditions pr√©alables</h3><ul>
<li>Docker ‚â• 20.10</li>
<li>Docker Compose ‚â• 2.0</li>
<li>Python ‚â• 3.11</li>
<li>Une cl√© API OpenAI</li>
<li>Un jeu de donn√©es (documentation Milvus au format Markdown).</li>
</ul>
<h3 id="1-Deploy-Milvus" class="common-anchor-header">1. D√©ployer Milvus</h3><pre><code translate="no">Download docker-compose.yml
wget https://github.com/milvus-io/milvus/releases/download/v2.6.8/milvus-standalone-docker-compose.yml -O docker-compose.yml
Start MilvusÔºàverify port mappingÔºö19530:19530Ôºâ
docker-compose up -d
Verify that the services are running
docker ps | grep milvus
You should see three containersÔºömilvus-standalone, milvus-etcd, milvus-minio
<button class="copy-code-btn"></button></code></pre>
<h3 id="2-Core-Implementation" class="common-anchor-header">2. Mise en ≈ìuvre du noyau</h3><p>Int√©gration de Milvus (ingest.py)</p>
<p>Remarque : l'impl√©mentation prend en charge jusqu'√† huit cat√©gories de documents. Si le nombre de cat√©gories d√©passe cette limite, les couleurs sont r√©utilis√©es √† la ronde.</p>
<pre><code translate="no"><span class="hljs-keyword">from</span> pymilvus <span class="hljs-keyword">import</span> MilvusClient
<span class="hljs-keyword">from</span> pymilvus.milvus_client.index <span class="hljs-keyword">import</span> IndexParams
<span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI
<span class="hljs-keyword">from</span> langchain_text_splitters <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter
<span class="hljs-keyword">import</span> umap
<span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> NearestNeighbors
<span class="hljs-keyword">import</span> json
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> glob
--- CONFIG ---
MILVUS_URI = <span class="hljs-string">&quot;http://localhost:19530&quot;</span>
COLLECTION_NAME = <span class="hljs-string">&quot;golem_memories&quot;</span>
JSON_OUTPUT_PATH = <span class="hljs-string">&quot;./golem_cortex.json&quot;</span>
Data directory (users place .md files <span class="hljs-keyword">in</span> this folder)
DATA_DIR = <span class="hljs-string">&quot;./data&quot;</span>
OpenAI Embedding Config
OPENAI_API_KEY = os.getenv(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>)
OPENAI_BASE_URL = <span class="hljs-string">&quot;https://api.openai.com/v1&quot;</span>  <span class="hljs-comment">#</span>
OPENAI_EMBEDDING_MODEL = <span class="hljs-string">&quot;text-embedding-3-small&quot;</span>
<span class="hljs-number">1536</span> dimensions
EMBEDDING_DIM = <span class="hljs-number">1536</span>
Color mapping: colors are assigned automatically <span class="hljs-keyword">and</span> reused <span class="hljs-keyword">in</span> a <span class="hljs-built_in">round</span>-robin manner
COLORS = [
[<span class="hljs-number">0.29</span>, <span class="hljs-number">0.87</span>, <span class="hljs-number">0.50</span>],
Green
[<span class="hljs-number">0.22</span>, <span class="hljs-number">0.74</span>, <span class="hljs-number">0.97</span>],
Blue
[<span class="hljs-number">0.60</span>, <span class="hljs-number">0.20</span>, <span class="hljs-number">0.80</span>],
Purple
[<span class="hljs-number">0.94</span>, <span class="hljs-number">0.94</span>, <span class="hljs-number">0.20</span>],
Gold
[<span class="hljs-number">0.98</span>, <span class="hljs-number">0.55</span>, <span class="hljs-number">0.00</span>],
Orange
[<span class="hljs-number">0.90</span>, <span class="hljs-number">0.30</span>, <span class="hljs-number">0.40</span>],
Red
[<span class="hljs-number">0.40</span>, <span class="hljs-number">0.90</span>, <span class="hljs-number">0.90</span>],
Cyan
[<span class="hljs-number">0.95</span>, <span class="hljs-number">0.50</span>, <span class="hljs-number">0.90</span>],
Magenta
]
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_embeddings</span>(<span class="hljs-params">texts</span>):
<span class="hljs-string">&quot;&quot;&quot;Batch embedding using OpenAI API&quot;&quot;&quot;</span>
client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
embeddings = []
batch_size = <span class="hljs-number">100</span>
OpenAI allows multiple texts per request
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(texts), batch_size):
batch = texts[i:i + batch_size]
response = client.embeddings.create(
model=OPENAI_EMBEDDING_MODEL,
<span class="hljs-built_in">input</span>=batch
)
embeddings.extend([item.embedding <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> response.data])
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚Ü≥ Embedded <span class="hljs-subst">{<span class="hljs-built_in">min</span>(i + batch_size, <span class="hljs-built_in">len</span>(texts))}</span>/<span class="hljs-subst">{<span class="hljs-built_in">len</span>(texts)}</span>...&quot;</span>)
<span class="hljs-keyword">return</span> np.array(embeddings)
<span class="hljs-keyword">def</span> <span class="hljs-title function_">load_markdown_files</span>(<span class="hljs-params">data_dir</span>):
<span class="hljs-string">&quot;&quot;&quot;Load all markdown files from the data directory&quot;&quot;&quot;</span>
md_files = glob.glob(os.path.join(data_dir, <span class="hljs-string">&quot;**/*.md&quot;</span>), recursive=<span class="hljs-literal">True</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> md_files:
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚ùå ERROR: No .md files found in &#x27;<span class="hljs-subst">{data_dir}</span>&#x27;&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   üëâ Create a &#x27;<span class="hljs-subst">{data_dir}</span>&#x27; folder and put your markdown files there.&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   üëâ Example: <span class="hljs-subst">{data_dir}</span>/doc1.md, <span class="hljs-subst">{data_dir}</span>/docs/doc2.md&quot;</span>)
<span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>
docs = []
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\nüìö FOUND <span class="hljs-subst">{<span class="hljs-built_in">len</span>(md_files)}</span> MARKDOWN FILES:&quot;</span>)
<span class="hljs-keyword">for</span> i, file_path <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(md_files):
filename = os.path.basename(file_path)
Categories are derived <span class="hljs-keyword">from</span> the file‚Äôs path relative to data_dir
rel_path = os.path.relpath(file_path, data_dir)
category = os.path.dirname(rel_path) <span class="hljs-keyword">if</span> os.path.dirname(rel_path) <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;default&quot;</span>
<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:
content = f.read()
docs.append({
<span class="hljs-string">&quot;title&quot;</span>: filename,
<span class="hljs-string">&quot;text&quot;</span>: content,
<span class="hljs-string">&quot;cat&quot;</span>: category,
<span class="hljs-string">&quot;path&quot;</span>: file_path
})
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   <span class="hljs-subst">{i+<span class="hljs-number">1</span>}</span>. [<span class="hljs-subst">{category}</span>] <span class="hljs-subst">{filename}</span>&quot;</span>)
<span class="hljs-keyword">return</span> docs
<span class="hljs-keyword">def</span> <span class="hljs-title function_">ingest_dense</span>():
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;üß† PROJECT GOLEM - NEURAL MEMORY BUILDER&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;=&quot;</span> * <span class="hljs-number">50</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> OPENAI_API_KEY:
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;   ‚ùå ERROR: OPENAI_API_KEY environment variable not set!&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;   üëâ Run: export OPENAI_API_KEY=&#x27;your-key-here&#x27;&quot;</span>)
<span class="hljs-keyword">return</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚Ü≥ Using OpenAI Embedding: <span class="hljs-subst">{OPENAI_EMBEDDING_MODEL}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚Ü≥ Embedding Dimension: <span class="hljs-subst">{EMBEDDING_DIM}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚Ü≥ Data Directory: <span class="hljs-subst">{DATA_DIR}</span>&quot;</span>)
<span class="hljs-number">1.</span> Load local markdown files
docs = load_markdown_files(DATA_DIR)
<span class="hljs-keyword">if</span> docs <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
<span class="hljs-keyword">return</span>
<span class="hljs-number">2.</span> Split documents into chunks
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\nüì¶ PROCESSING DOCUMENTS...&quot;</span>)
splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="hljs-number">800</span>, chunk_overlap=<span class="hljs-number">50</span>)
chunks = []
raw_texts = []
colors = []
chunk_titles = []
categories = []
<span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> docs:
doc_chunks = splitter.create_documents([doc[<span class="hljs-string">&#x27;text&#x27;</span>]])
cat_index = <span class="hljs-built_in">hash</span>(doc[<span class="hljs-string">&#x27;cat&#x27;</span>]) % <span class="hljs-built_in">len</span>(COLORS)
<span class="hljs-keyword">for</span> i, chunk <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(doc_chunks):
chunks.append({
<span class="hljs-string">&quot;text&quot;</span>: chunk.page_content,
<span class="hljs-string">&quot;title&quot;</span>: doc[<span class="hljs-string">&#x27;title&#x27;</span>],
<span class="hljs-string">&quot;cat&quot;</span>: doc[<span class="hljs-string">&#x27;cat&#x27;</span>]
})
raw_texts.append(chunk.page_content)
colors.append(COLORS[cat_index])
chunk_titles.append(<span class="hljs-string">f&quot;<span class="hljs-subst">{doc[<span class="hljs-string">&#x27;title&#x27;</span>]}</span> (chunk <span class="hljs-subst">{i+<span class="hljs-number">1</span>}</span>)&quot;</span>)
categories.append(doc[<span class="hljs-string">&#x27;cat&#x27;</span>])
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚Ü≥ Created <span class="hljs-subst">{<span class="hljs-built_in">len</span>(chunks)}</span> text chunks from <span class="hljs-subst">{<span class="hljs-built_in">len</span>(docs)}</span> documents&quot;</span>)
<span class="hljs-number">3.</span> Generate embeddings
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\nüîÆ GENERATING EMBEDDINGS...&quot;</span>)
vectors = get_embeddings(raw_texts)
<span class="hljs-number">4.</span> 3D Projection (UMAP)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nüé® CALCULATING 3D MANIFOLD...&quot;</span>)
reducer = umap.UMAP(n_components=<span class="hljs-number">3</span>, n_neighbors=<span class="hljs-number">30</span>, min_dist=<span class="hljs-number">0.1</span>, metric=<span class="hljs-string">&#x27;cosine&#x27;</span>)
embeddings_3d = reducer.fit_transform(vectors)
<span class="hljs-number">5.</span> Wiring (KNN)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;   ‚Ü≥ Wiring Synapses (finding connections)...&quot;</span>)
nbrs = NearestNeighbors(n_neighbors=<span class="hljs-number">8</span>, metric=<span class="hljs-string">&#x27;cosine&#x27;</span>).fit(vectors)
distances, indices = nbrs.kneighbors(vectors)
<span class="hljs-number">6.</span> Prepare output data
cortex_data = []
milvus_data = []
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(chunks)):
cortex_data.append({
<span class="hljs-string">&quot;id&quot;</span>: i,
<span class="hljs-string">&quot;title&quot;</span>: chunk_titles[i],
<span class="hljs-string">&quot;cat&quot;</span>: categories[i],
<span class="hljs-string">&quot;pos&quot;</span>: embeddings_3d[i].tolist(),
<span class="hljs-string">&quot;col&quot;</span>: colors[i],
<span class="hljs-string">&quot;nbs&quot;</span>: indices[i][<span class="hljs-number">1</span>:].tolist()
})
milvus_data.append({
<span class="hljs-string">&quot;id&quot;</span>: i,
<span class="hljs-string">&quot;text&quot;</span>: chunks[i][<span class="hljs-string">&#x27;text&#x27;</span>],
<span class="hljs-string">&quot;title&quot;</span>: chunk_titles[i],
<span class="hljs-string">&quot;category&quot;</span>: categories[i],
<span class="hljs-string">&quot;vector&quot;</span>: vectors[i].tolist()
})
<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(JSON_OUTPUT_PATH, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:
json.dump(cortex_data, f)
<span class="hljs-number">7.</span> Store vectors <span class="hljs-keyword">in</span> Milvus
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nüíæ STORING IN MILVUS...&quot;</span>)
client = MilvusClient(uri=MILVUS_URI)
Drop existing collection <span class="hljs-keyword">if</span> it exists
<span class="hljs-keyword">if</span> client.has_collection(COLLECTION_NAME):
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚Ü≥ Dropping existing collection &#x27;<span class="hljs-subst">{COLLECTION_NAME}</span>&#x27;...&quot;</span>)
client.drop_collection(COLLECTION_NAME)
Create new collection
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚Ü≥ Creating collection &#x27;<span class="hljs-subst">{COLLECTION_NAME}</span>&#x27; (dim=<span class="hljs-subst">{EMBEDDING_DIM}</span>)...&quot;</span>)
client.create_collection(
collection_name=COLLECTION_NAME,
dimension=EMBEDDING_DIM
)
Insert data
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚Ü≥ Inserting <span class="hljs-subst">{<span class="hljs-built_in">len</span>(milvus_data)}</span> vectors...&quot;</span>)
client.insert(
collection_name=COLLECTION_NAME,
data=milvus_data
)
Create index <span class="hljs-keyword">for</span> faster search
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;   ‚Ü≥ Creating index...&quot;</span>)
index_params = IndexParams()
index_params.add_index(
field_name=<span class="hljs-string">&quot;vector&quot;</span>,
index_type=<span class="hljs-string">&quot;AUTOINDEX&quot;</span>,
metric_type=<span class="hljs-string">&quot;COSINE&quot;</span>
)
client.create_index(
collection_name=COLLECTION_NAME,
index_params=index_params
)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\n‚úÖ CORTEX GENERATED SUCCESSFULLY!&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   üìä <span class="hljs-subst">{<span class="hljs-built_in">len</span>(chunks)}</span> memory nodes stored in Milvus&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   üìÅ Cortex data saved to: <span class="hljs-subst">{JSON_OUTPUT_PATH}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   üöÄ Run &#x27;python GolemServer.py&#x27; to start the server&quot;</span>)
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:
ingest_dense()
<button class="copy-code-btn"></button></code></pre>
<p>Visualisation frontale (GolemServer.py)</p>
<pre><code translate="no"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request, jsonify, send_from_directory
<span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI
<span class="hljs-keyword">from</span> pymilvus <span class="hljs-keyword">import</span> MilvusClient
<span class="hljs-keyword">import</span> json
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
--- CONFIG ---
Explicitly <span class="hljs-built_in">set</span> the folder to where this script <span class="hljs-keyword">is</span> located
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OpenAI Embedding Config
OPENAI_API_KEY = os.getenv(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>)
OPENAI_BASE_URL = <span class="hljs-string">&quot;https://api.openai.com/v1&quot;</span>
OPENAI_EMBEDDING_MODEL = <span class="hljs-string">&quot;text-embedding-3-small&quot;</span>
Milvus Config
MILVUS_URI = <span class="hljs-string">&quot;http://localhost:19530&quot;</span>
COLLECTION_NAME = <span class="hljs-string">&quot;golem_memories&quot;</span>
These <span class="hljs-keyword">match</span> the files generated by ingest.py
JSON_FILE = <span class="hljs-string">&quot;golem_cortex.json&quot;</span>
UPDATED: Matches your new repo filename
HTML_FILE = <span class="hljs-string">&quot;index.html&quot;</span>
app = Flask(__name__, static_folder=BASE_DIR)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\nüß† PROJECT GOLEM SERVER&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   üìÇ Serving from: <span class="hljs-subst">{BASE_DIR}</span>&quot;</span>)
--- DIAGNOSTICS ---
Check <span class="hljs-keyword">if</span> files exist before starting
missing_files = []
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(os.path.join(BASE_DIR, JSON_FILE)):
missing_files.append(JSON_FILE)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(os.path.join(BASE_DIR, HTML_FILE)):
missing_files.append(HTML_FILE)
<span class="hljs-keyword">if</span> missing_files:
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚ùå CRITICAL ERROR: Missing files in this folder:&quot;</span>)
<span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> missing_files:
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;      - <span class="hljs-subst">{f}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;   üëâ Did you run &#x27;python ingest.py&#x27; successfully?&quot;</span>)
sys.exit(<span class="hljs-number">1</span>)
<span class="hljs-keyword">else</span>:
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚úÖ Files Verified: Cortex Map found.&quot;</span>)
Check API Key
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> OPENAI_API_KEY:
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚ùå CRITICAL ERROR: OPENAI_API_KEY environment variable not set!&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;   üëâ Run: export OPENAI_API_KEY=&#x27;your-key-here&#x27;&quot;</span>)
sys.exit(<span class="hljs-number">1</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚Ü≥ Using OpenAI Embedding: <span class="hljs-subst">{OPENAI_EMBEDDING_MODEL}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;   ‚Ü≥ Connecting to Milvus...&quot;</span>)
milvus_client = MilvusClient(uri=MILVUS_URI)
Verify collection exists
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> milvus_client.has_collection(COLLECTION_NAME):
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;   ‚ùå CRITICAL ERROR: Collection &#x27;<span class="hljs-subst">{COLLECTION_NAME}</span>&#x27; not found in Milvus.&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;   üëâ Did you run &#x27;python ingest.py&#x27; successfully?&quot;</span>)
sys.exit(<span class="hljs-number">1</span>)
Initialize OpenAI client
openai_client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
--- ROUTES ---
<span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">root</span>():
Force serve the specific HTML file
<span class="hljs-keyword">return</span> send_from_directory(BASE_DIR, HTML_FILE)
<span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">serve_static</span>(<span class="hljs-params">filename</span>):
<span class="hljs-keyword">return</span> send_from_directory(BASE_DIR, filename)
<span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/query&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">query_brain</span>():
data = request.json
text = data.get(<span class="hljs-string">&#x27;query&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> text: <span class="hljs-keyword">return</span> jsonify({<span class="hljs-string">&quot;indices&quot;</span>: []})
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;üîé Query: <span class="hljs-subst">{text}</span>&quot;</span>)
Get query embedding <span class="hljs-keyword">from</span> OpenAI
response = openai_client.embeddings.create(
model=OPENAI_EMBEDDING_MODEL,
<span class="hljs-built_in">input</span>=text
)
query_vec = response.data[<span class="hljs-number">0</span>].embedding
Search <span class="hljs-keyword">in</span> Milvus
results = milvus_client.search(
collection_name=COLLECTION_NAME,
data=[query_vec],
limit=<span class="hljs-number">50</span>,
output_fields=[<span class="hljs-string">&quot;id&quot;</span>]
)
Extract indices <span class="hljs-keyword">and</span> scores
indices = [r[<span class="hljs-string">&#x27;id&#x27;</span>] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
scores = [r[<span class="hljs-string">&#x27;distance&#x27;</span>] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
<span class="hljs-keyword">return</span> jsonify({
<span class="hljs-string">&quot;indices&quot;</span>: indices,
<span class="hljs-string">&quot;scores&quot;</span>: scores
})
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;   ‚úÖ SYSTEM ONLINE: http://localhost:8000&quot;</span>)
app.run(port=<span class="hljs-number">8000</span>)
<button class="copy-code-btn"></button></code></pre>
<p>T√©l√©charger le jeu de donn√©es et le placer dans le r√©pertoire sp√©cifi√©.</p>
<pre><code translate="no">https://github.com/milvus-io/milvus-docs/tree/v2.6.x/site/en
<button class="copy-code-btn"></button></code></pre>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/debugging_rag_in_3d_with_projectgolem_and_milvus_4_3d17b01fec.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="3-Start-the-project" class="common-anchor-header">3. D√©marrer le projet</h3><p>Conversion de l'int√©gration de texte dans l'espace 3D</p>
<pre><code translate="no">python ingest.py
<button class="copy-code-btn"></button></code></pre>
<p>[image]</p>
<p>D√©marrer le service frontal</p>
<pre><code translate="no">python GolemServer.py
<button class="copy-code-btn"></button></code></pre>
<h3 id="4-Visualization-and-Interaction" class="common-anchor-header">4. Visualisation et interaction</h3><p>Une fois que le frontend a re√ßu les r√©sultats de la recherche, la luminosit√© des n≈ìuds est mise √† l'√©chelle sur la base des scores de similarit√© cosinus, tandis que les couleurs d'origine des n≈ìuds sont conserv√©es pour maintenir des groupes de cat√©gories clairs. Des lignes semi-transparentes sont trac√©es entre le point d'interrogation et chaque n≈ìud correspondant, et la cam√©ra effectue des panoramiques et des zooms pour se concentrer sur le groupe activ√©.</p>
<h4 id="Example-1-In-Domain-Match" class="common-anchor-header">Exemple 1 : Correspondance dans le domaine</h4><p>Requ√™te : "Quels sont les types d'index pris en charge par Milvus ?</p>
<p>Comportement de visualisation :</p>
<ul>
<li><p>Dans l'espace 3D, environ 15 n≈ìuds du groupe rouge intitul√© INDEXES pr√©sentent une augmentation notable de la luminosit√© (environ 2 √† 3 fois).</p></li>
<li><p>Les n≈ìuds correspondants comprennent des morceaux de documents tels que index_types.md, hnsw_index.md et ivf_index.md.</p></li>
<li><p>Des lignes semi-transparentes sont trac√©es entre le vecteur de requ√™te et chaque n≈ìud correspondant, et la cam√©ra se concentre sur le groupe rouge.</p></li>
</ul>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/debugging_rag_in_3d_with_projectgolem_and_milvus_2_c2522b6a67.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h4 id="Example-2-Out-of-Domain-Query-Rejection" class="common-anchor-header">Exemple 2 : Rejet d'une requ√™te hors domaine</h4><p>Requ√™te : "Combien co√ªte le repas KFC ?"</p>
<p>Comportement de visualisation :</p>
<ul>
<li><p>Tous les n≈ìuds conservent leur couleur d'origine et leur taille n'est que l√©g√®rement modifi√©e (moins de 1,1√ó).</p></li>
<li><p>Les n≈ìuds correspondants sont dispers√©s dans plusieurs groupes de couleurs diff√©rentes, sans concentration s√©mantique claire.</p></li>
<li><p>La cam√©ra ne d√©clenche pas d'action de mise au point, car le seuil de similarit√© (0,5) n'est pas atteint.</p></li>
</ul>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/debugging_rag_in_3d_with_projectgolem_and_milvus_3_39b9383771.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h2 id="Conclusion" class="common-anchor-header">Conclusion<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Project_Golem associ√© √† Milvus ne remplacera pas votre pipeline d'√©valuation RAG existant - mais il ajoute quelque chose qui manque totalement √† la plupart des pipelines : la possibilit√© de voir ce qui se passe dans l'espace vectoriel.</p>
<p>Avec cette configuration, vous pouvez faire la diff√©rence entre un √©chec de r√©cup√©ration caus√© par un mauvais encastrement, un √©chec caus√© par un mauvais d√©coupage et un √©chec caus√© par un seuil juste un peu trop serr√©. Ce type de diagnostic n√©cessitait auparavant de deviner et d'it√©rer. Aujourd'hui, vous pouvez le voir.</p>
<p>L'int√©gration actuelle prend en charge le d√©bogage interactif √† l'√©chelle de la d√©monstration (~10 000 documents), la base de donn√©es vectorielle de Milvus se chargeant de la r√©cup√©ration de niveau production en coulisses. Le chemin vers la visualisation √† l'√©chelle du million est trac√© mais pas encore construit - c'est donc le bon moment pour s'impliquer.</p>
<p>Consultez <a href="https://github.com/CyberMagician/Project_Golem">Project_Golem</a> sur GitHub, essayez-le avec votre propre jeu de donn√©es et voyez √† quoi ressemble votre espace vectoriel.</p>
<p>Si vous avez des questions ou souhaitez partager vos d√©couvertes, rejoignez notre <a href="https://milvusio.slack.com/join/shared_invite/zt-3nntzngkz-gYwhrdSE4~76k0VMyBfD1Q#/shared-invite/email">canal Slack</a> ou r√©servez une session <a href="https://milvus.io/blog/join-milvus-office-hours-to-get-support-from-vectordb-experts.md">Milvus Office Hours</a> pour obtenir des conseils pratiques sur votre installation.</p>
