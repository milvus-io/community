{"codeList":["pip install -r requirements.txt\n","! gdown \"https://drive.google.com/u/1/uc?id=1jdudBiUu41kL-U5lhH3ari_WBRXyedWo&export=download\"\n! tar -xf 'VOCdevkit.zip'\n! rm 'VOCdevkit.zip'\n","connections.connect(host=\"127.0.0.1\", port=19537)\nred = redis.Redis(host = '127.0.0.1', port=6379, db=0)\n","collection_name = \"image_similarity_search\"\ndim = 512\ndefault_fields = [\n    schema.FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n    schema.FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=dim)\n]\ndefault_schema = schema.CollectionSchema(fields=default_fields, description=\"Image test collection\")\ncollection = Collection(name=collection_name, schema=default_schema)\n","default_index = {\"index_type\": \"IVF_SQ8\", \"params\": {\"nlist\": 2048}, \"metric_type\": \"L2\"}\ncollection.create_index(field_name=\"vector\", index_params=default_index)\ncollection.load()\n","model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\nencoder = torch.nn.Sequential(*(list(model.children())[:-1]))\n","dataset = ImageFolderWithPaths(data_dir, transform=transforms.Compose([\n                                                transforms.Resize(256),\n                                                transforms.CenterCrop(224),\n                                                transforms.ToTensor(),\n                                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n\ndataloader = torch.utils.data.DataLoader(dataset, num_workers=0, batch_si\n","steps = len(dataloader)\nstep = 0\nfor inputs, labels, paths in dataloader:\n    with torch.no_grad():\n        output = encoder(inputs).squeeze()\n        output = output.numpy()\n\n    mr = collection.insert([output.tolist()])\n    ids = mr.primary_keys\n    for x in range(len(ids)):\n        red.set(str(ids[x]), paths[x])\n    if step%5 == 0:\n        print(\"Insert Step: \" + str(step) + \"/\" + str(steps))\n    step += 1\n","random_ids = [int(red.randomkey()) for x in range(3)]\nsearch_images = [x.decode(\"utf-8\") for x in red.mget(random_ids)]\n","transform_ops = transforms.Compose([\n                transforms.Resize(256),\n                transforms.CenterCrop(224),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\nembeddings = [transform_ops(Image.open(x)) for x in search_images]\nembeddings = torch.stack(embeddings, dim=0)\n\nwith torch.no_grad():\n    embeddings = encoder(embeddings).squeeze().numpy()\n","search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 32}}\nstart = time.time()\nresults = collection.search(embeddings, \"vector\", param=search_params, limit=3, expr=None)\nend = time.time() - start\n"],"headingContent":"Quickly Test and Deploy Vector Search Solutions with the Milvus 2.0 Bootcamp","anchorList":[]}