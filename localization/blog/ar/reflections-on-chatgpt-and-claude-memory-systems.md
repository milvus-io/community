---
id: reflections-on-chatgpt-and-claude-memory-systems.md
title: >-
  تأملات في ChatGPT وأنظمة ذاكرة كلود: ما يتطلبه الأمر لتمكين استرجاع المحادثات
  عند الطلب
author: Min Yin
date: 2026-01-09T00:00:00.000Z
cover: assets.zilliz.com/Chat_GPT_VS_Claude_cover_555fdac36d.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database'
meta_keywords: 'ChatGPT, Claude, memory systems, on-demand retrieval, conversational retrieval'
meta_title: |
  Milvus 2.6 Makes Claude-Style On-Demand Retrieval Practical
desc: >-
  اكتشف كيف يقوم كل من ChatGPT وكلود بتصميم الذاكرة بشكل مختلف، وسبب صعوبة
  استرجاع المحادثة عند الطلب، وكيف يتيح Milvus 2.6 ذلك على نطاق الإنتاج.
origin: 'https://milvus.io/blog/reflections-on-chatgpt-and-claude-memory-systems.md'
---
<p>في أنظمة وكلاء الذكاء الاصطناعي عالية الجودة، يكون تصميم الذاكرة أكثر تعقيدًا بكثير مما يبدو للوهلة الأولى. في جوهره، يجب أن يجيب على ثلاثة أسئلة أساسية: كيف يجب تخزين سجل المحادثة؟ متى يجب استرجاع السياق السابق؟ وما الذي يجب استرجاعه بالضبط؟</p>
<p>تشكل هذه الاختيارات بشكل مباشر زمن استجابة الوكيل، واستخدام الموارد، وفي النهاية سقف قدراته.</p>
<p>تبدو النماذج مثل ChatGPT و Claude "مدركة للذاكرة" بشكل متزايد كلما استخدمناها أكثر. فهي تتذكر التفضيلات، وتتكيف مع الأهداف طويلة المدى، وتحافظ على الاستمرارية عبر الجلسات. وبهذا المعنى، فهي تعمل بالفعل كوكلاء ذكاء اصطناعي مصغرين. ومع ذلك، فإن أنظمة الذاكرة الخاصة بهم مبنية على افتراضات معمارية مختلفة تمامًا.</p>
<p>تكشف تحليلات الهندسة العكسية الحديثة <a href="https://manthanguptaa.in/posts/claude_memory/">لآليات ذاكرة</a> <a href="https://manthanguptaa.in/posts/chatgpt_memory/">ChatGPT</a>وذاكرة <a href="https://manthanguptaa.in/posts/claude_memory/">كلود</a> عن تباين واضح. حيث تعتمد <strong>ChatGPT</strong> على حقن السياق المحسوب مسبقاً والتخزين المؤقت متعدد الطبقات لتوفير استمرارية خفيفة الوزن ويمكن التنبؤ بها. على النقيض من ذلك، يعتمد <strong>Claude</strong> على أسلوب RAG، والاسترجاع عند الطلب مع تحديثات ديناميكية للذاكرة لتحقيق التوازن بين عمق الذاكرة والكفاءة.</p>
<p>هاتان الطريقتان ليستا مجرد تفضيلات تصميمية - بل تتشكلان من خلال قدرة البنية التحتية. يقدّم <a href="https://milvus.io/docs/release_notes.md#v268"><strong>ميلفوس 2.6</strong></a> مزيجًا من الاسترجاع الهجين الكثيف والمتناثر، والتصفية العددية الفعّالة، والتخزين المتدرج الذي تتطلبه ذاكرة التخاطب عند الطلب، مما يجعل الاسترجاع الانتقائي سريعًا واقتصاديًا بما يكفي لنشره في أنظمة العالم الحقيقي.</p>
<p>في هذا المنشور، سنستعرض كيفية عمل نظامي ذاكرة ChatGPT وذاكرة كلود في الواقع، وسبب اختلافهما من الناحية المعمارية، وكيف أن التطورات الحديثة في أنظمة مثل Milvus تجعل الاسترجاع التخاطبي عند الطلب عملياً على نطاق واسع.</p>
<h2 id="ChatGPT’s-Memory-System" class="common-anchor-header">نظام ذاكرة ChatGPT<button data-href="#ChatGPT’s-Memory-System" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>بدلًا من الاستعلام عن قاعدة بيانات متجهة أو استرجاع المحادثات السابقة ديناميكيًا في وقت الاستدلال، يبني ChatGPT "ذاكرته" من خلال تجميع مجموعة ثابتة من مكونات السياق وإدخالها مباشرةً في كل مطالبة. يتم إعداد كل مكون مسبقاً ويحتل موقعاً معروفاً في المطالبة.</p>
<p>يحافظ هذا التصميم على التخصيص واستمرارية المحادثة كما هي مع جعل زمن الاستجابة واستخدام الرمز المميز وسلوك النظام أكثر قابلية للتنبؤ. بعبارة أخرى، الذاكرة ليست شيئًا يبحث عنه النموذج سريعًا - بل هي شيء يقوم النظام بتجميعه وتسليمه للنموذج في كل مرة يولد فيها استجابة.</p>
<p>على مستوى عالٍ، تتكون مطالبة ChatGPT الكاملة من الطبقات التالية، مرتبة من الأكثر عمومية إلى الأكثر فورية:</p>
<p>[0] تعليمات النظام</p>
<p>[1] تعليمات المطور</p>
<p>[2] البيانات الوصفية للجلسة (سريعة الزوال)</p>
<p>[3] ذاكرة المستخدم (حقائق طويلة الأمد)</p>
<p>[4] ملخص المحادثات الأخيرة (المحادثات السابقة، العناوين + مقتطفات)</p>
<p>[5] رسائل الجلسة الحالية (هذه المحادثة)</p>
<p>[6] رسالتك الأخيرة</p>
<p>من بين هذه المكونات، تشكل المكونات من [2] إلى [5] الذاكرة الفعالة للنظام، وكل منها يؤدي دورًا مميزًا.</p>
<h3 id="Session-Metadata" class="common-anchor-header">البيانات الوصفية للجلسة</h3><p>تمثل البيانات الوصفية لجلسة العمل معلومات قصيرة الأجل وغير ثابتة يتم حقنها مرة واحدة في بداية المحادثة ويتم تجاهلها عند انتهاء الجلسة. ويتمثل دورها في مساعدة النموذج على التكيف مع سياق الاستخدام الحالي بدلاً من تخصيص السلوك على المدى الطويل.</p>
<p>تلتقط هذه الطبقة إشارات حول البيئة المباشرة للمستخدم وأنماط الاستخدام الأخيرة. تتضمن الإشارات النموذجية ما يلي:</p>
<ul>
<li><p><strong>معلومات الجهاز</strong> - على سبيل المثال، ما إذا كان المستخدم على الهاتف المحمول أو سطح المكتب</p></li>
<li><p><strong>سمات الحساب</strong> - مثل فئة الاشتراك (على سبيل المثال، ChatGPT Go)، وعمر الحساب، وتكرار الاستخدام الإجمالي</p></li>
<li><p><strong>المقاييس السلوكية</strong> - بما في ذلك الأيام النشطة على مدار الأيام 1 و7 و30 يوماً الماضية، ومتوسط طول المحادثة، وتوزيع استخدام النموذج (على سبيل المثال، 49% من الطلبات التي تم التعامل معها بواسطة GPT-5)</p></li>
</ul>
<h3 id="User-Memory" class="common-anchor-header">ذاكرة المستخدم</h3><p>ذاكرة المستخدم هي طبقة الذاكرة الثابتة والقابلة للتحرير التي تتيح التخصيص عبر المحادثات. وهي تخزن معلومات مستقرة نسبيًا - مثل اسم المستخدم، ودوره أو أهدافه المهنية، والمشاريع الجارية، والنتائج السابقة، وتفضيلات التعلم - ويتم إدخالها في كل محادثة جديدة للحفاظ على الاستمرارية مع مرور الوقت.</p>
<p>يمكن تحديث هذه الذاكرة بطريقتين:</p>
<ul>
<li><p>تحدث<strong>التحديثات الصريحة</strong> عندما يدير المستخدمون الذاكرة مباشرةً بتعليمات مثل "تذكر هذا" أو "احذف هذا من الذاكرة".</p></li>
<li><p>تحدث<strong>التحديثات الضمنية</strong> عندما يحدد النظام المعلومات التي تفي بمعايير التخزين الخاصة بـ OpenAI - مثل اسم مؤكد أو مسمى وظيفي - ويحفظها تلقائيًا، مع مراعاة الموافقة الافتراضية للمستخدم وإعدادات الذاكرة.</p></li>
</ul>
<h3 id="Recent-Conversation-Summary" class="common-anchor-header">ملخص المحادثة الأخيرة</h3><p>ملخص المحادثة الأخيرة عبارة عن طبقة سياق خفيف الوزن وعابر للجلسات يحافظ على الاستمرارية دون إعادة تشغيل أو استرجاع تاريخ المحادثة الكامل. بدلًا من الاعتماد على الاسترجاع الديناميكي، كما هو الحال في الأساليب التقليدية القائمة على RAG، يتم حساب هذا الملخص مسبقًا وإدخاله مباشرةً في كل محادثة جديدة.</p>
<p>تلخص هذه الطبقة رسائل المستخدم فقط، باستثناء الردود المساعدة. وهي محدودة الحجم عن قصد - عادةً ما تكون حوالي 15 مدخلاً - وتحتفظ فقط بإشارات عالية المستوى حول الاهتمامات الحديثة بدلاً من المحتوى التفصيلي. ونظراً لأنها لا تعتمد على التضمينات أو البحث عن التشابه، فإنها تحافظ على كل من زمن الاستجابة واستهلاك الرمز المميز منخفضاً.</p>
<h3 id="Current-Session-Messages" class="common-anchor-header">رسائل الجلسة الحالية</h3><p>تحتوي رسائل الجلسة الحالية على سجل الرسائل الكامل للمحادثة الجارية وتوفر السياق قصير المدى اللازم للردود المتماسكة والمتناسقة خطوة بخطوة. تتضمن هذه الطبقة كلاً من مدخلات المستخدم وردود المساعد، ولكن فقط أثناء بقاء الجلسة نشطة.</p>
<p>ولأن النموذج يعمل ضمن حد رمز ثابت، لا يمكن أن ينمو هذا السجل إلى ما لا نهاية. عندما يتم الوصول إلى الحد الأقصى، يقوم النظام بإسقاط الرسائل الأقدم لإفساح المجال للرسائل الأحدث. يؤثر هذا الاقتطاع على الجلسة الحالية فقط: تبقى ذاكرة المستخدم طويلة المدى وملخص المحادثة الأخيرة سليمة.</p>
<h2 id="Claude’s-Memory-System" class="common-anchor-header">نظام ذاكرة كلود<button data-href="#Claude’s-Memory-System" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>يتبع كلود نهجًا مختلفًا لإدارة الذاكرة. فبدلاً من حقن حزمة كبيرة وثابتة من مكونات الذاكرة في كل مطالبة - كما يفعل ChatGPT - يجمع كلود بين ذاكرة المستخدم الدائمة مع أدوات عند الطلب والاسترجاع الانتقائي. يتم جلب السياق التاريخي فقط عندما يرى النموذج أنه ذو صلة، مما يسمح للنظام بمقايضة عمق السياق مقابل التكلفة الحسابية.</p>
<p>سياق موجه كلود منظم على النحو التالي:</p>
<p>[0] موجه النظام (تعليمات ثابتة)</p>
<p>[1] ذكريات المستخدم</p>
<p>[2] تاريخ المحادثة</p>
<p>[3] الرسالة الحالية</p>
<p>تكمن الاختلافات الرئيسية بين Claude و ChatGPT في <strong>كيفية استرجاع سجل المحادثة</strong> <strong>وكيفية تحديث ذاكرة المستخدم وصيانتها</strong>.</p>
<h3 id="User-Memories" class="common-anchor-header">ذكريات المستخدم</h3><p>في Claude، تشكّل ذكريات المستخدم طبقة سياق طويلة الأجل مشابهة في غرضها لذاكرة المستخدم في ChatGPT، ولكن مع تركيز أقوى على التحديثات التلقائية التي تعتمد على الخلفية. يتم تخزين هذه الذكريات بتنسيق منظم (مغلفة بعلامات على غرار XML) وهي مصممة للتطور تدريجيًا بمرور الوقت بأقل تدخل من المستخدم.</p>
<p>يدعم كلود مسارين للتحديث:</p>
<ul>
<li><p><strong>التحديثات الضمنية</strong> - يقوم النظام بتحليل محتوى المحادثة بشكل دوري وتحديث الذاكرة في الخلفية. لا يتم تطبيق هذه التحديثات في الوقت الحقيقي، ويتم تشذيب الذكريات المرتبطة بالمحادثات المحذوفة تدريجيًا كجزء من التحسين المستمر.</p></li>
<li><p><strong>التحديثات الصريحة</strong> - يمكن للمستخدمين إدارة الذاكرة بشكل مباشر من خلال أوامر مثل "تذكّر هذا" أو "احذف هذا"، والتي يتم تنفيذها عبر أداة مخصصة <code translate="no">memory_user_edits</code>.</p></li>
</ul>
<p>بالمقارنة مع ChatGPT، يضع Claude مسؤولية أكبر على النظام نفسه لتنقيح الذاكرة طويلة المدى وتحديثها وتشذيبها. وهذا يقلل من حاجة المستخدمين إلى تنظيم ما يتم تخزينه بنشاط.</p>
<h3 id="Conversation-History" class="common-anchor-header">تاريخ المحادثة</h3><p>بالنسبة لتاريخ المحادثة، لا يعتمد كلود على ملخص ثابت يتم حقنه في كل مطالبة. بدلاً من ذلك، فإنه يسترجع السياق السابق فقط عندما يقرر النموذج أنه ضروري، باستخدام ثلاث آليات مختلفة. هذا يتجنب نقل تاريخ غير ذي صلة إلى الأمام ويحافظ على استخدام الرمز المميز تحت السيطرة.</p>
<table>
<thead>
<tr><th style="text-align:center"><strong>المكوّن</strong></th><th style="text-align:center"><strong>الغرض</strong></th><th style="text-align:center"><strong>كيفية استخدامه</strong></th></tr>
</thead>
<tbody>
<tr><td style="text-align:center"><strong>النافذة المتجددة (المحادثة الحالية)</strong></td><td style="text-align:center">يخزّن سجل الرسائل الكامل للمحادثة الحالية (وليس ملخصًا)، على غرار سياق جلسة الدردشة في ChatGPT</td><td style="text-align:center">يتم حقنه تلقائيًا. حد الرمز المميز هو 190 ألف تقريبًا؛ يتم إسقاط الرسائل القديمة بمجرد الوصول إلى الحد الأقصى</td></tr>
<tr><td style="text-align:center"><code translate="no">conversation_search</code> <strong>أداة</strong></td><td style="text-align:center">البحث في المحادثات السابقة حسب الموضوع أو الكلمة المفتاحية، وإرجاع روابط المحادثة، والعناوين، ومقتطفات رسائل المستخدم/المساعد</td><td style="text-align:center">يتم تشغيلها عندما يحدد النموذج أن هناك حاجة إلى تفاصيل تاريخية. تشمل المعلمات <code translate="no">query</code> (مصطلحات البحث) و <code translate="no">max_results</code> (1-10)</td></tr>
<tr><td style="text-align:center"><code translate="no">recent_chats</code> <strong>الأداة</strong></td><td style="text-align:center">استرجاع المحادثات الحديثة ضمن نطاق زمني محدد (على سبيل المثال، "الأيام الثلاثة الماضية")، مع تنسيق النتائج بنفس تنسيق <code translate="no">conversation_search</code></td><td style="text-align:center">يتم تشغيلها عندما يكون السياق الحديث ذو صلة بالنطاق الزمني. تتضمن المعلمات <code translate="no">n</code> (عدد النتائج)، <code translate="no">sort_order</code> ، والنطاق الزمني</td></tr>
</tbody>
</table>
<p>من بين هذه المكونات، <code translate="no">conversation_search</code> جدير بالملاحظة بشكل خاص. ويمكنه إظهار النتائج ذات الصلة حتى بالنسبة للاستعلامات ذات الصياغة الفضفاضة أو متعددة اللغات، مما يشير إلى أنه يعمل على المستوى الدلالي بدلاً من الاعتماد على مطابقة الكلمات الرئيسية البسيطة. من المحتمل أن يتضمن ذلك استرجاعًا قائمًا على التضمين أو نهجًا هجينًا يقوم أولاً بترجمة أو تطبيع الاستعلام إلى صيغة قانونية ثم تطبيق استرجاع الكلمات المفتاحية أو الاسترجاع الهجين.</p>
<p>بشكل عام، يتميز نهج كلود للاسترجاع عند الطلب بالعديد من نقاط القوة الملحوظة:</p>
<ul>
<li><p><strong>الاسترجاع ليس تلقائيًا</strong>: يتم تشغيل استدعاءات الأداة من خلال حكم النموذج نفسه. على سبيل المثال، عندما يشير المستخدم إلى <em>"المشروع الذي ناقشناه في المرة السابقة"،</em> قد يقرر كلود استدعاء <code translate="no">conversation_search</code> لاسترجاع السياق ذي الصلة.</p></li>
<li><p><strong>سياق أكثر ثراءً عند الحاجة</strong>: يمكن أن تتضمن النتائج المسترجعة <strong>مقتطفات من ردود المساعد،</strong> في حين أن ملخصات ChatGPT تلتقط رسائل المستخدم فقط. وهذا يجعل كلود أكثر ملاءمة لحالات الاستخدام التي تتطلب سياق محادثة أعمق أو أكثر دقة.</p></li>
<li><p><strong>كفاءة أفضل بشكل افتراضي</strong>: نظراً لأن السياق التاريخي لا يتم حقنه إلا إذا كانت هناك حاجة إليه، يتجنب النظام نقل كميات كبيرة من السجل غير ذي الصلة إلى الأمام، مما يقلل من استهلاك الرموز غير الضرورية.</p></li>
</ul>
<p>المفاضلات واضحة بنفس القدر. يؤدي إدخال الاسترجاع عند الطلب إلى زيادة تعقيد النظام: يجب إنشاء الفهارس وصيانتها، وتنفيذ الاستعلامات، وترتيب النتائج، وأحيانًا إعادة ترتيبها. كما يصبح وقت الاستجابة من النهاية إلى النهاية أقل قابلية للتنبؤ من السياق المحسوب مسبقًا والمُدخل دائمًا. بالإضافة إلى ذلك، يجب أن يتعلم النموذج تحديد متى يكون الاسترجاع ضروريًا. إذا فشل هذا الحكم، فقد لا يتم جلب السياق ذي الصلة على الإطلاق.</p>
<h2 id="The-Constraints-Behind-Claude-Style-On-Demand-Retrieval" class="common-anchor-header">القيود الكامنة وراء الاسترجاع عند الطلب على نمط كلود<button data-href="#The-Constraints-Behind-Claude-Style-On-Demand-Retrieval" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>إن اعتماد نموذج الاسترجاع عند الطلب يجعل قاعدة بيانات المتجهات جزءًا مهمًا من البنية. يضع استرجاع المحادثة متطلبات عالية بشكل غير عادي على كل من التخزين وتنفيذ الاستعلام، ويجب على النظام تلبية أربعة قيود في نفس الوقت.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/constraints_b6ed74e454.jpg" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="1-Low-Latency-Tolerance" class="common-anchor-header">1. تحمل الكمون المنخفض</h3><p>في أنظمة المحادثة، يجب أن يبقى زمن انتقال P99 عادةً أقل من 20 مللي ثانية تقريبًا. التأخير الذي يتجاوز ذلك يمكن ملاحظته على الفور للمستخدمين. هذا لا يترك مجالًا كبيرًا لعدم الكفاءة: يجب تحسين البحث المتجه وتصفية البيانات الوصفية وترتيب النتائج بعناية. يمكن أن يؤدي الاختناق في أي نقطة إلى تدهور تجربة المحادثة بأكملها.</p>
<h3 id="2-Hybrid-Search-Requirement" class="common-anchor-header">2. متطلبات البحث الهجين</h3><p>غالبًا ما تشمل استعلامات المستخدم أبعادًا متعددة. ويجمع طلب مثل <em>"مناقشات حول RAG من الأسبوع الماضي"</em> بين الصلة الدلالية والتصفية المستندة إلى الوقت. إذا كانت قاعدة البيانات تدعم البحث المتجه فقط، فقد تعرض 1000 نتيجة متشابهة دلاليًا، فقط لتقوم تصفية طبقة التطبيق بتقليلها إلى عدد قليل - مما يؤدي إلى إهدار معظم العمليات الحسابية. ولكي تكون قاعدة البيانات عملية، يجب أن تدعم قاعدة البيانات أصلاً الاستعلامات المتجهة والقياسية المدمجة.</p>
<h3 id="3-Storage–Compute-Separation" class="common-anchor-header">3. الفصل بين التخزين والحساب</h3><p>يُظهر سجل المحادثات نمطًا واضحًا من الوصول الساخن والبارد. حيث يتم الاستعلام عن المحادثات الحديثة بشكل متكرر، بينما نادرًا ما يتم لمس المحادثات القديمة. إذا كان يجب أن تبقى جميع المتجهات في الذاكرة، فإن تخزين عشرات الملايين من المحادثات سيستهلك مئات الجيجابايت من ذاكرة الوصول العشوائي - وهي تكلفة غير عملية على نطاق واسع. ولكي يكون النظام قابلاً للتطبيق، يجب أن يدعم النظام الفصل بين التخزين والحوسبة مع الاحتفاظ بالبيانات الساخنة في الذاكرة والبيانات الباردة في تخزين الكائنات، مع تحميل المتجهات عند الطلب.</p>
<h3 id="4-Diverse-Query-Patterns" class="common-anchor-header">4. أنماط استعلام متنوعة</h3><p>لا يتبع استرجاع المحادثات نمط وصول واحد. فبعض الاستعلامات دلالية بحتة (على سبيل المثال، <em>"تحسين الأداء الذي ناقشناه")</em>، والبعض الآخر زمني بحت (<em>"جميع المحادثات من الأسبوع الماضي")</em>، والعديد منها يجمع بين قيود متعددة (<em>"المناقشات المتعلقة ب Python التي تشير إلى FastAPI في الأشهر الثلاثة الأخيرة")</em>. يجب على مخطط استعلامات قاعدة البيانات تكييف استراتيجيات التنفيذ مع أنواع الاستعلامات المختلفة، بدلاً من الاعتماد على بحث واحد يناسب الجميع، بحث بالقوة الغاشمة.</p>
<p>تحدد هذه التحديات الأربعة معًا القيود الأساسية لاسترجاع المحادثة. يجب على أي نظام يسعى لتنفيذ الاسترجاع عند الطلب على غرار كلود أن يعالجها جميعًا بطريقة منسقة.</p>
<h2 id="Why-Milvus-26-Works-Well-for-Conversational-Retrieval" class="common-anchor-header">لماذا يعمل ميلفوس 2.6 بشكل جيد للاسترجاع التحادثي<button data-href="#Why-Milvus-26-Works-Well-for-Conversational-Retrieval" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>تتماشى خيارات التصميم في <a href="https://milvus.io/docs/release_notes.md#v268">Milvus 2.6</a> بشكل وثيق مع المتطلبات الأساسية للاسترجاع التحادثي عند الطلب. فيما يلي تفصيل للقدرات الرئيسية وكيفية ارتباطها باحتياجات الاسترجاع التخاطبي الحقيقي.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/milvus_2_6_ce379ff42d.jpg" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="Hybrid-Retrieval-with-Dense-and-Sparse-Vectors" class="common-anchor-header">الاسترجاع الهجين مع المتجهات الكثيفة والمتناثرة</h3><p>يدعم برنامج Milvus 2.6 أصلاً تخزين المتجهات الكثيفة والمتناثرة في نفس المجموعة ودمج نتائجها تلقائيًا في وقت الاستعلام. تلتقط المتجهات الكثيفة (على سبيل المثال، التضمينات ذات 768 بُعدًا التي تم إنشاؤها بواسطة نماذج مثل BGE-M3) التشابه الدلالي، بينما تحافظ المتجهات المتفرقة (التي ينتجها عادةً BM25) على إشارات الكلمات الرئيسية الدقيقة.</p>
<p>بالنسبة إلى استعلام مثل <em>"مناقشات حول RAG من الأسبوع الماضي"، يقوم</em> برنامج Milvus بتنفيذ الاسترجاع الدلالي واسترجاع الكلمات المفتاحية بالتوازي، ثم يدمج النتائج من خلال إعادة الترتيب. مقارنةً باستخدام أي من النهجين بمفرده، توفر هذه الاستراتيجية الهجينة استرجاعًا أعلى بكثير في سيناريوهات المحادثة الحقيقية.</p>
<h3 id="Storage–Compute-Separation-and-Query-Optimization" class="common-anchor-header">الفصل بين التخزين والحساب وتحسين الاستعلامات</h3><p>يدعم Milvus 2.6 التخزين المتدرج بطريقتين:</p>
<ul>
<li><p>البيانات الساخنة في الذاكرة، والبيانات الباردة في تخزين الكائنات</p></li>
<li><p>الفهارس في الذاكرة، والبيانات المتجهة الخام في تخزين الكائنات</p></li>
</ul>
<p>باستخدام هذا التصميم، يمكن تحقيق تخزين مليون مدخل محادثة باستخدام 2 جيجابايت تقريبًا من الذاكرة و8 جيجابايت من تخزين الكائنات. مع الضبط المناسب، يمكن أن يظل زمن انتقال P99 أقل من 20 مللي ثانية، حتى مع تمكين الفصل بين التخزين والحساب.</p>
<h3 id="JSON-Shredding-and-Fast-Scalar-Filtering" class="common-anchor-header">تمزيق JSON والتصفية السريعة للكمية الحجمية</h3><p>يتيح الإصدار Milvus 2.6 من Milvus 2.6 إمكانية تمزيق JSON Shredding افتراضيًا، مما يؤدي إلى تسطيح حقول JSON المتداخلة في التخزين العمودي. يحسن هذا من أداء التصفية العددية بمقدار 3-5 أضعاف وفقًا للمعايير الرسمية (تختلف المكاسب الفعلية حسب نمط الاستعلام).</p>
<p>يتطلب استرجاع المحادثة غالبًا التصفية حسب البيانات الوصفية مثل معرّف المستخدم أو معرّف الجلسة أو النطاق الزمني. باستخدام تمزيق JSON Shredding، يمكن تنفيذ استعلامات مثل <em>"جميع المحادثات من المستخدم "أ" في الأسبوع الماضي"</em> مباشرةً على فهارس الأعمدة، دون تحليل كرات JSON الكاملة بشكل متكرر.</p>
<h3 id="Open-Source-Control-and-Operational-Flexibility" class="common-anchor-header">تحكم مفتوح المصدر ومرونة تشغيلية</h3><p>باعتباره نظامًا مفتوح المصدر، يوفر ميلفوس مستوى من التحكم المعماري والتشغيلي لا توفره الحلول المغلقة ذات الصندوق الأسود. يمكن للفرق ضبط معلمات الفهرس، وتطبيق استراتيجيات تصنيف البيانات، وتخصيص عمليات النشر الموزعة لتتناسب مع أعباء العمل الخاصة بهم.</p>
<p>تُقلل هذه المرونة من عائق الدخول: يمكن للفرق الصغيرة والمتوسطة الحجم بناء أنظمة استرجاع محادثة بملايين إلى عشرات الملايين دون الاعتماد على ميزانيات بنية تحتية ضخمة.</p>
<h2 id="Why-ChatGPT-and-Claude-Took-Different-Paths" class="common-anchor-header">لماذا اتخذ كل من ChatGPT وكلود مسارات مختلفة<button data-href="#Why-ChatGPT-and-Claude-Took-Different-Paths" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>على مستوى عالٍ، يكمن الفرق بين نظامي ذاكرة ChatGPT وClaude في كيفية تعامل كل منهما مع النسيان. يفضل ChatGPT النسيان الاستباقي: بمجرد أن تتجاوز الذاكرة الحدود الثابتة، يتم إسقاط السياق القديم. هذا يقايض الاكتمال بالبساطة وسلوك النظام الذي يمكن التنبؤ به. يفضل كلود النسيان المتأخر. من الناحية النظرية، يمكن أن ينمو سجل المحادثة دون حدود، مع تفويض الاسترجاع إلى نظام استرجاع عند الطلب.</p>
<p>إذن لماذا اختار النظامان مسارين مختلفين؟ في ظل القيود التقنية الموضحة أعلاه، تصبح الإجابة واضحة: <strong>لا تكون كل بنية قابلة للتطبيق إلا إذا كانت البنية التحتية الأساسية قادرة على دعمها</strong>.</p>
<p>لو تمت تجربة نهج كلود في عام 2020، لكان من المحتمل أن يكون غير عملي. في ذلك الوقت، كانت قواعد البيانات المتجهة غالبًا ما تتكبد مئات المللي ثانية من زمن الاستجابة، وكانت الاستعلامات الهجينة غير مدعومة بشكل جيد، وكان استخدام الموارد يتزايد بشكل باهظ مع نمو البيانات. في ظل هذه الظروف، كان من الممكن أن يتم رفض الاسترجاع عند الطلب باعتباره إفراطًا في الهندسة.</p>
<p>بحلول عام 2025، تغير المشهد. فالتقدم في البنية التحتية - مدفوعًا بأنظمة مثل <strong>Milvus 2.6 -</strong>جعل الفصل بين التخزين والحساب، وتحسين الاستعلام، والاسترجاع الهجين الكثيف والمتناثر، وتقطيع JSON Shredding قابلاً للتطبيق في الإنتاج. تقلل هذه التطورات من زمن الاستجابة وتتحكم في التكاليف وتجعل الاسترجاع الانتقائي عمليًا على نطاق واسع. نتيجة لذلك، لم تصبح الأدوات عند الطلب والذاكرة القائمة على الاسترجاع عند الطلب ممكنة فحسب، بل أصبحت جذابة بشكل متزايد، خاصةً كأساس لأنظمة على غرار الوكيل.</p>
<p>في نهاية المطاف، تتبع خيارات الهندسة المعمارية ما تتيحه البنية التحتية.</p>
<h2 id="Conclusion" class="common-anchor-header">الخاتمة<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>في أنظمة العالم الحقيقي، لا يكون تصميم الذاكرة خيارًا ثنائيًا بين السياق المحسوب مسبقًا والاسترجاع عند الطلب. عادةً ما تكون البنى الأكثر فعالية هي البنى الهجينة التي تجمع بين كلا النهجين.</p>
<p>يتمثل أحد الأنماط الشائعة في حقن منعطفات المحادثة الحديثة من خلال نافذة سياق منزلقة، وتخزين تفضيلات المستخدم المستقرة كذاكرة ثابتة، واسترجاع السجل الأقدم عند الطلب عبر البحث المتجه. مع نضوج المنتج، يمكن أن يتحول هذا التوازن تدريجيًا - من السياق المحسوب مسبقًا بشكل أساسي إلى الاسترجاع بشكل متزايد - دون الحاجة إلى إعادة تعيين معمارية معطلة.</p>
<p>حتى عند البدء بنهج محسوب مسبقًا، من المهم التصميم مع وضع الترحيل في الاعتبار. يجب تخزين الذاكرة بمعرّفات وطوابع زمنية وفئات ومراجع مصدر واضحة. عندما يصبح الاسترجاع قابلاً للتطبيق، يمكن إنشاء التضمينات للذاكرة الموجودة وإضافتها إلى قاعدة بيانات المتجهات إلى جانب البيانات الوصفية نفسها، مما يسمح بإدخال منطق الاسترجاع بشكل تدريجي وبأقل قدر من التعطيل.</p>
<p>هل لديك أسئلة أو تريد التعمق في أي ميزة في أحدث إصدار من ميلفوس؟ انضم إلى <a href="https://discord.com/invite/8uyFbECzPX">قناة Discord</a> الخاصة بنا أو قم بتسجيل المشكلات على <a href="https://github.com/milvus-io/milvus">GitHub</a>. يمكنك أيضًا حجز جلسة فردية مدتها 20 دقيقة للحصول على رؤى وإرشادات وإجابات عن أسئلتك من خلال <a href="https://milvus.io/blog/join-milvus-office-hours-to-get-support-from-vectordb-experts.md">ساعات عمل Milvus المكتبية</a>.</p>
