---
id: how-to-choose-the-right-embedding-model-for-rag.md
title: 'من Word2Vec إلى LLM2Vec: كيفية اختيار نموذج التضمين المناسب لـ RAG'
author: Rachel Liu
date: 2025-10-03T00:00:00.000Z
desc: >-
  سترشدك هذه المدونة إلى كيفية تقييم التضمينات عمليًا، حتى تتمكن من اختيار
  الأنسب لنظام RAG الخاص بك.
cover: assets.zilliz.com/Chat_GPT_Image_Oct_3_2025_05_07_11_PM_36b1ba77eb.png
tag: Tutorials
recommend: false
publishToMedium: true
tags: 'Milvus, vector database, vector search, embedding models'
meta_keywords: 'Milvus, AI Agent, embedding model vector database'
meta_title: |
  How to Choose the Right Embedding Model for RAG
origin: 'https://milvus.io/blog/how-to-choose-the-right-embedding-model-for-rag.md'
---
<p>النماذج اللغوية الكبيرة قوية، ولكن لديها نقطة ضعف معروفة: الهلوسة. يُعد <a href="https://zilliz.com/learn/Retrieval-Augmented-Generation">التوليد المعزز بالاسترجاع (RAG)</a> أحد أكثر الطرق فعالية لمعالجة هذه المشكلة. فبدلاً من الاعتماد فقط على ذاكرة النموذج، يسترجع RAG المعرفة ذات الصلة من مصدر خارجي ويدمجها في المطالبة، مما يضمن أن الإجابات تستند إلى بيانات حقيقية.</p>
<p>يتألف نظام RAG عادةً من ثلاثة مكونات رئيسية: نموذج التضمين التوجيهي نفسه، <a href="https://zilliz.com/learn/what-is-vector-database">وقاعدة بيانات متجهة</a> مثل <a href="https://milvus.io/">Milvus</a> لتخزين المعلومات والبحث فيها، ونموذج التضمين. نموذج التضمين هو ما يحول اللغة البشرية إلى متجهات يمكن قراءتها آليًا. اعتبره بمثابة المترجم بين اللغة الطبيعية وقاعدة البيانات. تحدد جودة هذا المترجم أهمية السياق المسترجع. احصل عليها بشكل صحيح، وسيرى المستخدمون إجابات دقيقة ومفيدة. إذا أخطأت، فحتى أفضل بنية تحتية تنتج عنها ضوضاء وأخطاء وحساب ضائع.</p>
<p>هذا هو سبب أهمية فهم نماذج التضمين. هناك العديد منها للاختيار من بينها - بدءًا من الأساليب القديمة مثل Word2Vec إلى النماذج الحديثة القائمة على LLM مثل عائلة تضمين النصوص في OpenAI. لكل منها مفاضلاته ونقاط قوته. سيختصر هذا الدليل كل هذه الفوضى ويوضح لك كيفية تقييم التضمينات عمليًا، حتى تتمكن من اختيار الأنسب لنظام RAG الخاص بك.</p>
<h2 id="What-Are-Embeddings-and-Why-Do-They-Matter" class="common-anchor-header">ما هي التضمينات وما أهميتها؟<button data-href="#What-Are-Embeddings-and-Why-Do-They-Matter" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>في أبسط المستويات، تقوم التضمينات بتحويل اللغة البشرية إلى أرقام يمكن للآلات فهمها. حيث يتم تعيين كل كلمة أو جملة أو مستند في فضاء متجه عالي الأبعاد، حيث تُظهر المسافة بين المتجهات العلاقات بينها. تميل النصوص ذات المعاني المتشابهة إلى التجميع معًا، بينما يميل المحتوى غير ذي الصلة إلى الابتعاد عن بعضها البعض. هذا هو ما يجعل البحث الدلالي ممكنًا - البحث عن المعنى، وليس فقط مطابقة الكلمات المفتاحية.</p>
<p>لا تعمل جميع نماذج التضمين بنفس الطريقة. فهي تنقسم عمومًا إلى ثلاث فئات، لكل منها نقاط قوة ومقايضات:</p>
<ul>
<li><p>تركز<a href="https://zilliz.com/learn/sparse-and-dense-embeddings"><strong>المتجهات المتفرقة</strong></a> (مثل BM25) على تكرار الكلمات الرئيسية وطول المستند. وهي رائعة للمطابقات الصريحة ولكنها لا تراعي المترادفات والسياق - "الذكاء الاصطناعي" و"الذكاء الاصطناعي" قد تبدو غير مترابطة.</p></li>
<li><p>تلتقط<a href="https://zilliz.com/learn/sparse-and-dense-embeddings"><strong>المتجهات الكثيفة</strong></a> (مثل تلك التي تنتجها BERT) دلالات أعمق. ويمكنها أن ترى أن عبارة "Apple تطلق Apple هاتفًا جديدًا" مرتبطة بـ "إطلاق منتج iPhone"، حتى بدون كلمات رئيسية مشتركة. الجانب السلبي هو ارتفاع التكلفة الحسابية وقلة قابلية التفسير.</p></li>
<li><p>تجمع<strong>النماذج الهجينة</strong> (مثل BGE-M3) بين الاثنين. يمكنها توليد تمثيلات متناثرة أو كثيفة أو متعددة المتجهات في وقت واحد - مما يحافظ على دقة البحث بالكلمات المفتاحية مع التقاط الفروق الدلالية الدقيقة.</p></li>
</ul>
<p>من الناحية العملية، يعتمد الاختيار على حالة الاستخدام الخاصة بك: المتجهات المتفرقة من أجل السرعة والشفافية، والكثيفة من أجل معنى أكثر ثراءً، والهجينة عندما تريد الأفضل من كلا العالمين.</p>
<h2 id="Eight-Key-Factors-for-Evaluating-Embedding-Models" class="common-anchor-header">ثمانية عوامل رئيسية لتقييم نماذج التضمين<button data-href="#Eight-Key-Factors-for-Evaluating-Embedding-Models" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="1-Context-Window" class="common-anchor-header"><strong>#1 نافذة السياق</strong></h3><p>تحدد <a href="https://zilliz.com/glossary/context-window"><strong>نافذة السياق</strong></a> مقدار النص الذي يمكن للنموذج معالجته مرة واحدة. نظرًا لأن الرمز الواحد يساوي تقريبًا 0.75 كلمة، فإن هذا الرقم يحد بشكل مباشر من طول المقطع الذي يمكن للنموذج "رؤيته" عند إنشاء التضمينات. تسمح النافذة الكبيرة للنموذج بالتقاط المعنى الكامل للمستندات الأطول؛ بينما تجبرك النافذة الصغيرة على تقطيع النص إلى أجزاء أصغر، مما قد يؤدي إلى فقدان السياق ذي المعنى.</p>
<p>على سبيل المثال، يدعم <a href="https://zilliz.com/ai-models/text-embedding-ada-002"><em>نموذج التضمين النصي OpenAI-ada-002</em></a> ما يصل إلى 8,192 رمزًا - وهو ما يكفي لتغطية ورقة بحثية كاملة، بما في ذلك الملخص والطرق والخاتمة. على النقيض من ذلك، تتطلب النماذج التي تحتوي على 512 رمزًا فقط (مثل <em>m3e-base</em>) اقتطاعًا متكررًا، مما قد يؤدي إلى فقدان التفاصيل الرئيسية.</p>
<p>الخلاصة: إذا كانت حالة استخدامك تتضمن مستندات طويلة، مثل الإيداعات القانونية أو الأوراق الأكاديمية، فاختر نموذجًا بنافذة رموز تزيد عن 8 آلاف رمز. أما بالنسبة للنصوص الأقصر، مثل محادثات دعم العملاء، فقد تكون نافذة الرموز الرمزية ذات الرمز 2K كافية.</p>
<h3 id="2-Tokenization-Unit" class="common-anchor-header"><strong>#2</strong> وحدة الترميز</h3><p>قبل أن يتم إنشاء التضمينات، يجب تقسيم النص إلى أجزاء أصغر تسمى <strong>الرموز</strong>. تؤثر كيفية حدوث هذا الترميز على كيفية تعامل النموذج مع الكلمات النادرة والمصطلحات المهنية والمجالات المتخصصة.</p>
<ul>
<li><p><strong>ترميز الكلمات الفرعية (BPE):</strong> يقسم الكلمات إلى أجزاء أصغر (على سبيل المثال، "تعاسة" → "un" + "سعادة"). هذا هو الوضع الافتراضي في برامج LLM الحديثة مثل GPT و LLaMA، وهو يعمل بشكل جيد مع الكلمات التي لا تحتوي على مفردات.</p></li>
<li><p><strong>WordPiece:</strong> تنقيح ل BPE المستخدم من قبل BERT، مصمم لتحقيق توازن أفضل بين تغطية المفردات والكفاءة.</p></li>
<li><p><strong>الترميز على مستوى الكلمات:</strong> يقسم بالكلمات الكاملة فقط. وهو بسيط ولكنه يواجه صعوبات في التعامل مع المصطلحات النادرة أو المعقدة، مما يجعله غير مناسب للمجالات التقنية.</p></li>
</ul>
<p>بالنسبة للمجالات المتخصصة مثل الطب أو القانون، فإن النماذج القائمة على الكلمات الفرعية هي الأفضل بشكل عام - يمكنها التعامل بشكل صحيح مع مصطلحات مثل <em>احتشاء عضلة القلب</em> أو <em>الاستبدال</em>. تمضي بعض النماذج الحديثة، مثل <strong>NV-Embed،</strong> إلى أبعد من ذلك من خلال إضافة تحسينات مثل طبقات الانتباه الكامنة، والتي تعزز كيفية التقاط الرموز الرمزية للمفردات المعقدة والخاصة بالمجال.</p>
<h3 id="3-Dimensionality" class="common-anchor-header">#3 الأبعاد</h3><p>تشير<a href="https://zilliz.com/glossary/dimensionality-reduction"><strong>أبعاد المتجه</strong></a> إلى طول متجه التضمين، والذي يحدد مقدار التفاصيل الدلالية التي يمكن للنموذج التقاطها. تسمح الأبعاد الأعلى (على سبيل المثال، 1,536 أو أكثر) بتمييز أدق بين المفاهيم، ولكن ذلك يأتي على حساب زيادة التخزين وبطء الاستعلامات ومتطلبات الحوسبة الأعلى. أما الأبعاد الأقل (مثل 768) فهي أسرع وأرخص، ولكنها تخاطر بفقدان المعنى الدقيق.</p>
<p>المفتاح هو التوازن. بالنسبة لمعظم التطبيقات ذات الأغراض العامة، فإن الأبعاد 768-1,536 تحقق المزيج الصحيح بين الكفاءة والدقة. أما بالنسبة للمهام التي تتطلب دقة عالية - مثل عمليات البحث الأكاديمية أو العلمية - فإن تجاوز 2000 بُعد قد يكون مفيداً. من ناحية أخرى، قد تستخدم الأنظمة ذات الموارد المحدودة (مثل عمليات النشر على الحافة) 512 بُعدًا بشكل فعال، شريطة التحقق من جودة الاسترجاع. في بعض أنظمة التوصيات خفيفة الوزن أو أنظمة التخصيص، قد تكون الأبعاد الأصغر كافية.</p>
<h3 id="4-Vocabulary-Size" class="common-anchor-header">#4 حجم المفردات</h3><p>يشير <strong>حجم المف</strong> ردات في النموذج إلى عدد الرموز الفريدة التي يمكن أن يتعرف عليها مُرمِّزها. يؤثر هذا بشكل مباشر على قدرته على التعامل مع اللغات المختلفة والمصطلحات الخاصة بالمجال. إذا كانت الكلمة أو الحرف غير موجود في المفردات، يتم تمييزها على أنها <code translate="no">[UNK]</code> ، مما قد يؤدي إلى فقدان المعنى.</p>
<p>تختلف المتطلبات حسب حالة الاستخدام. تحتاج السيناريوهات متعددة اللغات عمومًا إلى مفردات أكبر - في حدود 50 ألف رمز أو أكثر، كما في حالة <a href="https://zilliz.com/ai-models/bge-m3"><em>BGE-M3</em></a>. بالنسبة للتطبيقات الخاصة بمجال محدد، فإن تغطية المصطلحات المتخصصة هي الأكثر أهمية. على سبيل المثال، يجب أن يدعم النموذج القانوني أصلاً مصطلحات مثل <em>&quot;التقادم&quot;</em> أو <em>&quot;الاستحواذ بحسن نية</em>&quot;، بينما يجب أن يأخذ النموذج الصيني في الحسبان آلاف الأحرف وعلامات الترقيم الفريدة. بدون تغطية مفردات كافية، تنهار دقة التضمين بسرعة.</p>
<h3 id="-5-Training-Data" class="common-anchor-header"># 5 بيانات التدريب</h3><p>تحدد <strong>بيانات التدريب</strong> حدود ما "يعرفه" نموذج التضمين. تم تدريب النماذج التي تم تدريبها على بيانات واسعة ذات أغراض عامة - مثل <em>تضمين النص-ADA-002،</em> والتي تستخدم مزيجًا من صفحات الويب والكتب وويكيبيديا - تميل إلى الأداء الجيد في مختلف المجالات. ولكن عندما تحتاج إلى الدقة في المجالات المتخصصة، غالبًا ما تفوز النماذج المدربة على المجال. على سبيل المثال، يتفوق كل من <em>LegalBERT</em> و <em>BioBERT</em> على النماذج العامة في النصوص القانونية والطبية الحيوية، على الرغم من أنهما يفقدان بعض القدرة على التعميم.</p>
<p>القاعدة العامة</p>
<ul>
<li><p><strong>السيناريوهات العامة</strong> ← استخدم النماذج المدربة على مجموعات بيانات واسعة، ولكن تأكد من أنها تغطي اللغة (اللغات) المستهدفة. على سبيل المثال، تحتاج التطبيقات الصينية إلى نماذج مدربة على مجموعات بيانات صينية غنية.</p></li>
<li><p><strong>المجالات العمودية</strong> → اختر نماذج خاصة بالمجال للحصول على أفضل دقة.</p></li>
<li><p><strong>الأفضل في كلا المجالين</strong> ← تُظهر النماذج الأحدث مثل <strong>NV-Embed،</strong> التي تم تدريبها على مرحلتين باستخدام بيانات عامة وبيانات خاصة بالمجال، مكاسب واعدة في التعميم <em>ودقة</em> المجال.</p></li>
</ul>
<h3 id="-6-Cost" class="common-anchor-header"># رقم 6 التكلفة</h3><p>التكلفة لا تتعلق فقط بتسعير واجهة برمجة التطبيقات، بل تتعلق <strong>بالتكلفة الاقتصادية</strong> <strong>والتكلفة الحسابية</strong>. تعتمد نماذج واجهة برمجة التطبيقات المستضافة، مثل تلك التي تقدمها OpenAI، على الاستخدام: أنت تدفع مقابل كل مكالمة، ولكن لا تقلق بشأن البنية التحتية. وهذا يجعلها مثالية للنماذج الأولية السريعة، أو المشاريع التجريبية، أو أعباء العمل الصغيرة والمتوسطة الحجم.</p>
<p>أما الخيارات مفتوحة المصدر، مثل <em>BGE</em> أو <em>Sentence-BERT،</em> فهي مجانية الاستخدام ولكنها تتطلب بنية تحتية مُدارة ذاتياً، وعادةً ما تكون مجموعات وحدات معالجة الرسومات أو وحدات معالجة الرسوميات. وهي أكثر ملاءمة للإنتاج على نطاق واسع، حيث تعوض التوفير والمرونة على المدى الطويل تكاليف الإعداد والصيانة لمرة واحدة.</p>
<p>الخلاصة العملية: <strong>تُعد نماذج واجهة برمجة التطبيقات مثالية للتكرار السريع،</strong> في حين أن <strong>النماذج مفتوحة المصدر غالباً ما تفوز في الإنتاج على نطاق واسع</strong> بمجرد أن تأخذ في الاعتبار التكلفة الإجمالية للملكية (TCO). يعتمد اختيار المسار الصحيح على ما إذا كنت بحاجة إلى سرعة الوصول إلى السوق أو التحكم على المدى الطويل.</p>
<h3 id="-7-MTEB-Score" class="common-anchor-header"># رقم 7 نقاط MTEB</h3><p><a href="https://zilliz.com/glossary/massive-text-embedding-benchmark-(mteb)"><strong>معيار تضمين النص الضخم (MTEB)</strong></a> هو المعيار الأكثر استخدامًا لمقارنة نماذج التضمين. يقوم بتقييم الأداء عبر مهام مختلفة، بما في ذلك البحث الدلالي والتصنيف والتجميع وغيرها. تعني الدرجة الأعلى عمومًا أن النموذج لديه قابلية أقوى للتعميم عبر أنواع مختلفة من المهام.</p>
<p>ومع ذلك، فإن MTEB ليس حلاً سحرياً. فالنموذج الذي يحصل على درجات عالية بشكل عام قد يكون أداؤه ضعيفاً في حالة استخدامك المحددة. على سبيل المثال، قد يؤدي النموذج المُدرب بشكل أساسي على اللغة الإنجليزية أداءً جيدًا في معايير MTEB ولكنه قد يواجه صعوبة في التعامل مع النصوص الطبية المتخصصة أو البيانات غير الإنجليزية. تتمثل الطريقة الآمنة في استخدام MTEB كنقطة بداية ثم التحقق من صحته باستخدام <strong>مجموعات البيانات الخاصة بك</strong> قبل الالتزام.</p>
<h3 id="-8-Domain-Specificity" class="common-anchor-header"># 8 خصوصية المجال</h3><p>بعض النماذج مصممة خصيصًا لسيناريوهات محددة، وهي تتألق حيث تقصر النماذج العامة:</p>
<ul>
<li><p><strong>القانونية:</strong> <em>LegalBERT</em>: يمكن لـ <em>LegalBERT</em> التمييز بين المصطلحات القانونية الدقيقة، مثل <em>الدفاع</em> مقابل <em>الاختصاص القضائي</em>.</p></li>
<li><p><strong>الطب الحيوي:</strong> تتعامل <em>BioBERT</em> بدقة مع العبارات التقنية مثل <em>mRNA</em> أو <em>العلاج المستهدف</em>.</p></li>
<li><p><strong>متعدد اللغات:</strong> يدعم <em>BGE-M3</em> أكثر من 100 لغة، مما يجعله مناسبًا تمامًا للتطبيقات العالمية التي تتطلب الربط بين الإنجليزية والصينية واللغات الأخرى.</p></li>
<li><p><strong>استرجاع الرموز:</strong> يحقق <em>Qwen3-Embedding</em> درجات من الدرجة الأولى (81.0+) على <em>كود MTEB-Code،</em> وهو مُحسَّن للاستعلامات المتعلقة بالبرمجة.</p></li>
</ul>
<p>إذا كانت حالة الاستخدام الخاصة بك تندرج ضمن أحد هذه المجالات، يمكن للنماذج المحسّنة للمجال تحسين دقة الاسترجاع بشكل كبير. ولكن بالنسبة للتطبيقات الأوسع نطاقًا، التزم بنماذج الأغراض العامة ما لم تُظهر اختباراتك خلاف ذلك.</p>
<h2 id="Additional-Perspectives-for-Evaluating-Embeddings" class="common-anchor-header">وجهات نظر إضافية لتقييم التضمينات<button data-href="#Additional-Perspectives-for-Evaluating-Embeddings" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>بالإضافة إلى العوامل الثمانية الأساسية، هناك بعض الزوايا الأخرى التي تستحق النظر فيها إذا كنت تريد تقييمًا أعمق:</p>
<ul>
<li><p><strong>المحاذاة متعددة اللغات</strong>: بالنسبة للنماذج متعددة اللغات، لا يكفي مجرد دعم العديد من اللغات. الاختبار الحقيقي هو ما إذا كانت المساحات المتجهة متوائمة. وبعبارة أخرى، هل الكلمات المتطابقة دلاليًا - على سبيل المثال "قطة" باللغة الإنجليزية و"gato" باللغة الإسبانية - قريبة من بعضها البعض في الفضاء المتجه؟ تضمن المحاذاة القوية استرجاعًا متسقًا عبر اللغات.</p></li>
<li><p><strong>اختبار الخصومة</strong>: يجب أن يكون نموذج التضمين الجيد مستقرًا في ظل تغييرات صغيرة في المدخلات. من خلال تغذية جمل متطابقة تقريبًا (على سبيل المثال، "جلس القط على الحصيرة" مقابل "جلس القط على حصيرة")، يمكنك اختبار ما إذا كانت المتجهات الناتجة تتغير بشكل معقول أو تتقلب بشكل كبير. غالبًا ما تشير التقلبات الكبيرة إلى ضعف المتانة.</p></li>
<li><p>يشير<strong>التماسك الدلالي المحلي</strong> إلى ظاهرة اختبار ما إذا كانت الكلمات المتشابهة دلاليًا تتجمع بإحكام في الأحياء المحلية. على سبيل المثال، بالنظر إلى كلمة مثل "بنك"، يجب أن يقوم النموذج بتجميع المصطلحات ذات الصلة (مثل "ضفة النهر" و"المؤسسة المالية") بشكل مناسب مع إبقاء المصطلحات غير ذات الصلة على مسافة. يساعد قياس عدد المرات التي تتسلل فيها الكلمات "المتطفلة" أو غير ذات الصلة إلى هذه الأحياء في مقارنة جودة النموذج.</p></li>
</ul>
<p>لا تكون هذه المنظورات مطلوبة دائمًا للعمل اليومي، لكنها مفيدة لاختبار ضغط التضمينات في أنظمة الإنتاج حيث يكون الاستقرار متعدد اللغات أو الدقة العالية أو الخصومة أمرًا مهمًا حقًا.</p>
<h2 id="Common-Embedding-Models-A-Brief-History" class="common-anchor-header">نماذج التضمين الشائعة: تاريخ موجز<button data-href="#Common-Embedding-Models-A-Brief-History" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>إن قصة نماذج التضمين هي في الحقيقة قصة كيف تعلمت الآلات فهم اللغة بشكل أعمق مع مرور الوقت. لقد تخطى كل جيل حدود الجيل الذي سبقه - حيث انتقل من تمثيلات الكلمات الثابتة إلى نماذج التضمين اللغوي الكبيرة (LLM) الحالية التي يمكنها التقاط السياق الدقيق.</p>
<h3 id="Word2Vec-The-Starting-Point-2013" class="common-anchor-header">Word2Vec: نقطة البداية (2013)</h3><p>كان<a href="https://zilliz.com/glossary/word2vec">Word2Vec من Google</a> أول اختراق جعل التضمينات عملية على نطاق واسع. وقد استند إلى <em>فرضية التوزيع</em> في اللغويات، وهي فكرة أن الكلمات التي تظهر في سياقات متشابهة غالبًا ما تتشارك في المعنى. من خلال تحليل كميات هائلة من النصوص، قام برنامج Word2Vec بتعيين الكلمات في فضاء متجه حيث تتواجد المصطلحات ذات الصلة بالقرب من بعضها البعض. على سبيل المثال، تجمّعت كلمتا "بوما" و"نمر" في مكان قريب من بعضهما البعض بفضل موائلها المشتركة وسمات الصيد المشتركة.</p>
<p>يتوفر Word2Vec بنوعين:</p>
<ul>
<li><p><strong>CBOW (حقيبة الكلمات المستمرة):</strong> يتنبأ بالكلمة المفقودة من السياق المحيط بها.</p></li>
<li><p><strong>Skip-Gram:</strong> يقوم بالعكس - يتنبأ بالكلمات المحيطة من الكلمة المستهدفة.</p></li>
</ul>
<p>سمح هذا النهج البسيط والقوي في آنٍ واحد بإجراء مقارنات أنيقة مثل:</p>
<pre><code translate="no">king - man + woman = queen
<button class="copy-code-btn"></button></code></pre>
<p>بالنسبة لوقته، كان Word2Vec ثوريًا. ولكن كان لها قيدان مهمان. أولاً، كان <strong>ثابتًا</strong>: كان لكل كلمة متجه واحد فقط، لذا فإن كلمة "بنك" كانت تعني نفس الشيء سواء كانت بالقرب من كلمة "مال" أو "نهر". ثانيًا، كان يعمل على <strong>مستوى الكلمات</strong> فقط، تاركًا الجمل والوثائق خارج نطاقه.</p>
<h3 id="BERT-The-Transformer-Revolution-2018" class="common-anchor-header">بيرت: ثورة المحولات (2018)</h3><p>إذا كان Word2Vec قد أعطانا أول خريطة للمعنى، فإن <a href="https://zilliz.com/learn/what-is-bert"><strong>BERT (تمثيلات التشفير ثنائية الاتجاه من المحولات)</strong></a> أعاد رسمها بتفاصيل أكبر بكثير. تم إصدار BERT من قِبل Google في عام 2018، وكان بمثابة بداية عصر <em>الفهم الدلالي العميق</em> من خلال إدخال بنية المحولات في التضمينات. على عكس LSTMs السابقة، يمكن للمُحوِّلات فحص جميع الكلمات في تسلسل ما في وقت واحد وفي كلا الاتجاهين، مما يتيح سياقًا أكثر ثراءً بكثير.</p>
<p>جاء سحر BERT من مهمتين ذكيتين قبل التدريب:</p>
<ul>
<li><p><strong>نمذجة اللغة المقنعة (MLM):</strong> تخفي الكلمات في الجملة عشوائيًا وتجبر النموذج على التنبؤ بها، وتعلمه استنتاج المعنى من السياق.</p></li>
<li><p><strong>التنبؤ بالجملة التالية (NSP):</strong> تدرب النموذج على تحديد ما إذا كانت هناك جملتان تتبعان بعضهما البعض، مما يساعده على تعلم العلاقات بين الجمل.</p></li>
</ul>
<p>تحت الغطاء، تجمع ناقلات مدخلات BERT بين ثلاثة عناصر: تضمينات الرموز (الكلمة نفسها)، وتضمينات المقاطع (الجملة التي تنتمي إليها)، وتضمينات الموضع (مكانها في التسلسل). وقد منحت هذه العناصر مجتمعةً BERT القدرة على التقاط العلاقات الدلالية المعقدة على مستوى <strong>الجملة</strong> <strong>والمستند</strong>. وقد جعلت هذه القفزة من BERT أحدث ما توصلت إليه BERT في مهام مثل الإجابة عن الأسئلة والبحث الدلالي.</p>
<p>بالطبع، لم يكن BERT مثاليًا. فقد كانت إصداراته المبكرة محدودة <strong>بنافذة مكونة من 512 رمزًا،</strong> مما يعني أنه كان يجب تقطيع المستندات الطويلة وفقدان المعنى في بعض الأحيان. كما كانت ناقلاته الكثيفة تفتقر إلى قابلية التفسير - يمكنك أن ترى نصين متطابقين، ولكن لا يمكنك دائمًا تفسير السبب. أسقطت المتغيرات اللاحقة، مثل <strong>RoBERTa،</strong> مهمة NSP بعد أن أظهرت الأبحاث أنها لم تضف فائدة تذكر، مع الاحتفاظ بتدريب MLM القوي.</p>
<h3 id="BGE-M3-Fusing-Sparse-and-Dense-2023" class="common-anchor-header">BGE-M3: دمج المتناثر والكثيف (2023)</h3><p>بحلول عام 2023، كان المجال قد نضج بما يكفي لإدراك أنه لا توجد طريقة تضمين واحدة يمكنها إنجاز كل شيء. أدخل <a href="https://zilliz.com/learn/bge-m3-and-splade-two-machine-learning-models-for-generating-sparse-embeddings">BGE-M3</a> (BAAI General Embedding-M3)، وهو نموذج هجين مصمم خصيصًا لمهام الاسترجاع. ويتمثل ابتكاره الرئيسي في أنه لا ينتج نوعًا واحدًا فقط من المتجهات - بل يولد متجهات كثيفة ومتجهات متفرقة ومتجهات متعددة في آنٍ واحد، ويجمع بين نقاط قوتها.</p>
<ul>
<li><p>تلتقط<strong>المتجهات الكثيفة</strong> الدلالات العميقة، وتتعامل مع المترادفات وإعادة الصياغة (على سبيل المثال، "إطلاق آيفون"، ≈ "أبل تطلق هاتفًا جديدًا").</p></li>
<li><p>تقوم<strong>المتجهات المتفرقة</strong> بتعيين أوزان واضحة للمصطلحات. حتى إذا لم تظهر الكلمة المفتاحية، يمكن للنموذج استنتاج الصلة - على سبيل المثال، ربط "منتج iPhone الجديد" بـ "Apple Inc." و "هاتف ذكي".</p></li>
<li><p>تعمل<strong>المتجهات المتعددة</strong> على تحسين التضمينات الكثيفة بشكل أكبر من خلال السماح لكل رمز رمزي بالمساهمة في درجة التفاعل الخاصة به، وهو أمر مفيد للاسترجاع الدقيق.</p></li>
</ul>
<p>يعكس مسار تدريب BGE-M3 هذا التطور:</p>
<ol>
<li><p><strong>التدريب المسبق</strong> على البيانات الضخمة غير المسماة باستخدام <em>RetroMAE</em> (أداة تشفير مقنعة + أداة فك تشفير إعادة البناء) لبناء فهم دلالي عام.</p></li>
<li><p><strong>الضبط العام</strong> باستخدام التعلّم التبايني على 100 مليون زوج من النصوص، مما يعزز أداء الاسترجاع.</p></li>
<li><p><strong>الضبط الدقيق للمهمة</strong> باستخدام ضبط التعليمات وأخذ عينات سلبية معقدة لتحسين السيناريو الخاص بالسيناريو.</p></li>
</ol>
<p>النتائج مبهرة: يتعامل برنامج BGE-M3 مع تفاصيل متعددة (من مستوى الكلمة إلى مستوى المستند)، ويقدم أداءً قويًا متعدد اللغات - خاصةً في اللغة الصينية - ويوازن بين الدقة والكفاءة بشكل أفضل من معظم نظرائه. من الناحية العملية، يمثل هذا البرنامج خطوة كبيرة إلى الأمام في بناء نماذج تضمين قوية وعملية للاسترجاع على نطاق واسع.</p>
<h3 id="LLMs-as-Embedding-Models-2023–Present" class="common-anchor-header">نماذج LLMs كنماذج تضمين (2023 - حتى الآن)</h3><p>لسنوات، كانت الحكمة السائدة هي أن النماذج اللغوية الكبيرة (LLMs) التي تعتمد على وحدة فك التشفير فقط، مثل GPT، لم تكن مناسبة للتضمين. وكان يُعتقد أن اهتمامها السببي - الذي ينظر فقط إلى الرموز السابقة - يحد من الفهم الدلالي العميق. لكن الأبحاث الحديثة قلبت هذا الافتراض. فباستخدام التعديلات الصحيحة، يمكن أن تولد نماذج LLMs التضمينات التي تنافس النماذج المصممة لهذا الغرض، وأحيانًا تتفوق عليها. مثالان بارزان على ذلك هما LLM2Vec و NV-Embed.</p>
<p>تعمل<strong>LLM2Vec</strong> على تكييف LLMs LLM فقط مع ثلاثة تغييرات رئيسية:</p>
<ul>
<li><p><strong>تحويل الانتباه ثنائي الاتجاه</strong>: استبدال الأقنعة السببية بحيث يمكن لكل رمز مميز أن يحضر التسلسل الكامل.</p></li>
<li><p><strong>التنبؤ بالرمز الرمزي التالي المقنع (MNTP):</strong> هدف تدريبي جديد يشجع الفهم ثنائي الاتجاه.</p></li>
<li><p><strong>التعلّم التبايني غير الخاضع للإشراف:</strong> مستوحى من SimCSE، وهو يسحب الجمل المتشابهة دلاليًا في الفضاء المتجه.</p></li>
</ul>
<p>في حين أن<strong>NV-Embed</strong> يتخذ نهجًا أكثر انسيابية:</p>
<ul>
<li><p><strong>طبقات الانتباه الكامنة:</strong> إضافة "مصفوفات كامنة" قابلة للتدريب لتحسين تجميع التسلسل.</p></li>
<li><p><strong>التدريب المباشر ثنائي الاتجاه:</strong> ببساطة إزالة الأقنعة السببية والضبط الدقيق مع التعلم المتباين.</p></li>
<li><p><strong>تحسين متوسط تجميع التجميع:</strong> يستخدم متوسطات مرجحة عبر الرموز لتجنب "التحيز للرمز الأخير".</p></li>
</ul>
<p>والنتيجة هي أن التضمينات الحديثة القائمة على LLM تجمع بين <strong>الفهم الدلالي العميق</strong> <strong>وقابلية التوسع</strong>. ويمكنها التعامل مع <strong>نوافذ سياق طويلة جدًا (8 آلاف إلى 32 ألف رمز)</strong>، مما يجعلها قوية بشكل خاص للمهام ذات المستندات الثقيلة في البحث أو القانون أو البحث المؤسسي. ولأنهم يعيدون استخدام نفس العمود الفقري LLM، يمكنهم في بعض الأحيان تقديم تضمينات عالية الجودة حتى في البيئات الأكثر تقييدًا.</p>
<h2 id="Conclusion-Turning-Theory-into-Practice" class="common-anchor-header">الخاتمة: تحويل النظرية إلى ممارسة<button data-href="#Conclusion-Turning-Theory-into-Practice" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>عندما يتعلق الأمر باختيار نموذج التضمين، فإن النظرية لا تصل بك إلا إلى حد بعيد. الاختبار الحقيقي هو مدى جودة أدائه في <em>نظامك</em> مع <em>بياناتك</em>. يمكن لبعض الخطوات العملية أن تحدث فرقاً بين النموذج الذي يبدو جيداً على الورق والنموذج الذي يعمل بالفعل في الإنتاج:</p>
<ul>
<li><p><strong>الشاشة مع المجموعات الفرعية MTEB.</strong> استخدام المعايير، وخاصة مهام الاسترجاع، لبناء قائمة مختصرة أولية من المرشحين.</p></li>
<li><p><strong>اختبر باستخدام بيانات أعمال حقيقية.</strong> قم بإنشاء مجموعات تقييم من مستنداتك الخاصة لقياس الاستدعاء والدقة والكمون في ظل ظروف العالم الحقيقي.</p></li>
<li><p><strong>تحقق من توافق قاعدة البيانات.</strong> تتطلب المتجهات المتفرقة دعم الفهرس المقلوب، بينما تتطلب المتجهات الكثيفة عالية الأبعاد المزيد من التخزين والحساب. تأكد من أن قاعدة بياناتك المتجهة يمكن أن تستوعب اختيارك.</p></li>
<li><p><strong>تعامل مع المستندات الطويلة بذكاء.</strong> استفد من استراتيجيات التجزئة، مثل النوافذ المنزلقة، لتحقيق الكفاءة، وقم بإقرانها بنماذج نوافذ السياق الكبيرة للحفاظ على المعنى.</p></li>
</ul>
<p>من ناقلات Word2Vec الثابتة البسيطة إلى التضمينات التي تعمل بتقنية LLM مع 32 ألف سياقًا، شهدنا خطوات هائلة في كيفية فهم الآلات للغة. ولكن إليك الدرس الذي يتعلمه كل مطور في نهاية المطاف: النموذج <em>الأعلى نقاطاً</em> ليس دائماً النموذج <em>الأفضل</em> لحالة الاستخدام الخاصة بك.</p>
<p>في نهاية المطاف، لا يهتم المستخدمون بلوحات المتصدرين أو الرسوم البيانية القياسية - إنهم يريدون فقط العثور على المعلومات الصحيحة بسرعة. اختر النموذج الذي يوازن بين الدقة والتكلفة والتوافق مع نظامك، وستكون قد أنشأت شيئًا لا يثير الإعجاب نظريًا فحسب، بل يعمل حقًا في العالم الحقيقي.</p>
