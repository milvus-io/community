---
id: llm-context-pruning-a-developers-guide-to-better-rag-and-agentic-ai-results.md
title: 'تشذيب سياق LLM: دليل المطور لتحسين نتائج RAG والذكاء الاصطناعي العميل'
author: Cheney Zhang
date: 2026-01-15T00:00:00.000Z
cover: assets.zilliz.com/context_pruning_cover_d1b034ba67.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database'
meta_keywords: 'Context Pruning, RAG, long context LLMs, context engineering'
meta_title: |
  LLM Context Pruning: Improving RAG and Agentic AI Systems
desc: >-
  تعرّف على كيفية عمل تشذيب السياق في أنظمة RAG ذات السياق الطويل، وسبب أهميته،
  وكيف تمكّن نماذج مثل بروفانس من التصفية الدلالية وتؤديها عملياً.
origin: >-
  https://milvus.io/blog/llm-context-pruning-a-developers-guide-to-better-rag-and-agentic-ai-results.md
---
<p>لقد أصبحت نوافذ السياق في LLMs ضخمة في الآونة الأخيرة. يمكن أن تأخذ بعض النماذج مليون رمز أو أكثر في تمريرة واحدة، ويبدو أن كل إصدار جديد يرفع هذا الرقم إلى أعلى. إنه أمر مثير، ولكن إذا كنت قد بنيت بالفعل أي شيء يستخدم سياقًا طويلًا، فأنت تعلم أن هناك فجوة بين ما هو <em>ممكن</em> وما هو <em>مفيد</em>.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/LLM_Leaderboard_7c64e4a18c.PNG" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>فقط لأن النموذج <em>يمكنه</em> قراءة كتاب كامل في مطالبة واحدة لا يعني أنه يجب أن تعطيه واحدة. معظم المدخلات الطويلة مليئة بأشياء لا يحتاجها النموذج. بمجرد أن تبدأ بإغراق مئات الآلاف من الرموز في المطالبة، عادةً ما تحصل على استجابات أبطأ، وفواتير حوسبة أعلى، وأحيانًا إجابات أقل جودة لأن النموذج يحاول الانتباه إلى كل شيء في وقت واحد.</p>
<p>لذا، على الرغم من أن نوافذ السياق تكبر باستمرار، يصبح السؤال الحقيقي هو: <strong>ما الذي يجب أن نضعه بالفعل هناك؟</strong> وهنا يأتي دور <strong>تشذيب السياق</strong>. إنها في الأساس عملية تشذيب أجزاء السياق المسترجعة أو المجمّعة التي لا تساعد النموذج في الإجابة عن السؤال. إذا تم ذلك بشكل صحيح، فإنه يحافظ على نظامك سريعًا ومستقرًا ويمكن التنبؤ به بشكل أكبر.</p>
<p>في هذه المقالة، سنتحدث عن السبب الذي يجعل السياق الطويل يتصرف غالبًا بشكل مختلف عما تتوقعه، وكيف يساعد التقليم في إبقاء الأمور تحت السيطرة، وكيف تتناسب أدوات التقليم مثل <strong>بروفانس</strong> مع خطوط أنابيب RAG الحقيقية دون أن تجعل إعدادك أكثر تعقيدًا.</p>
<h2 id="Four-Common-Failure-Modes-in-Long-Context-Systems" class="common-anchor-header">أربعة أنماط فشل شائعة في أنظمة السياق الطويل<button data-href="#Four-Common-Failure-Modes-in-Long-Context-Systems" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>نافذة السياق الأكبر لا تجعل النموذج أكثر ذكاءً بطريقة سحرية. إذا كان هناك أي شيء، فبمجرد أن تبدأ في حشو الكثير من المعلومات في المطالبة، فإنك تفتح مجموعة جديدة كاملة من الطرق التي يمكن أن تسوء بها الأمور. إليك أربع مشكلات ستواجهها طوال الوقت عند بناء أنظمة السياق الطويل أو أنظمة RAG.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Four_Failure_Modes_e9b9bcb3b2.PNG" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="1-Context-Clash" class="common-anchor-header">1. تضارب السياق</h3><p>يحدث تضارب السياق عندما تصبح المعلومات المتراكمة عبر عدة أدوار متناقضة داخليًا.</p>
<p>على سبيل المثال، قد يقول المستخدم "أنا أحب التفاح" في بداية المحادثة ثم يقول لاحقًا "أنا لا أحب الفاكهة". عندما تبقى كلتا العبارتين في السياق، لا يكون لدى النموذج طريقة موثوقة لحل التعارض، مما يؤدي إلى استجابات غير متسقة أو مترددة.</p>
<h3 id="2-Context-Confusion" class="common-anchor-header">2. ارتباك السياق</h3><p>ينشأ ارتباك السياق عندما يحتوي السياق على كميات كبيرة من المعلومات غير ذات الصلة أو ذات الصلة الضعيفة، مما يجعل من الصعب على النموذج اختيار الإجراء أو الأداة الصحيحة.</p>
<p>تظهر هذه المشكلة بشكل خاص في الأنظمة المعززة بالأدوات. عندما يكون السياق مزدحمًا بتفاصيل غير ذات صلة، قد يسيء النموذج تفسير نية المستخدم ويختار الأداة أو الإجراء الخاطئ - ليس لأن الخيار الصحيح مفقود، ولكن لأن الإشارة مدفونة تحت الضوضاء.</p>
<h3 id="3-Context-Distraction" class="common-anchor-header">3. تشتيت السياق</h3><p>يحدث تشتيت السياق عندما تهيمن المعلومات السياقية المفرطة على انتباه النموذج، مما يقلل من اعتماده على المعرفة المدربة مسبقًا والاستدلال العام.</p>
<p>فبدلاً من الاعتماد على الأنماط المكتسبة على نطاق واسع، يفرط النموذج في ترجيح التفاصيل الحديثة في السياق، حتى عندما تكون غير مكتملة أو غير موثوقة. يمكن أن يؤدي ذلك إلى التفكير السطحي أو الهش الذي يعكس السياق بشكل وثيق للغاية بدلاً من تطبيق فهم أعلى مستوى.</p>
<h3 id="4-Context-Poisoning" class="common-anchor-header">4. تسمم السياق</h3><p>يحدث تسمم السياق عندما تدخل معلومات غير صحيحة في السياق ويتم الرجوع إليها وتعزيزها بشكل متكرر على مدى عدة أدوار.</p>
<p>يمكن أن تصبح عبارة واحدة خاطئة يتم تقديمها في وقت مبكر من المحادثة أساسًا للتفكير اللاحق. ومع استمرار الحوار، يبني النموذج على هذا الافتراض الخاطئ، مما يضاعف الخطأ ويبتعد أكثر عن الإجابة الصحيحة.</p>
<h2 id="What-Is-Context-Pruning-and-Why-It-Matters" class="common-anchor-header">ما هو تشذيب السياق وسبب أهميته<button data-href="#What-Is-Context-Pruning-and-Why-It-Matters" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>بمجرد البدء في التعامل مع السياقات الطويلة، سرعان ما تدرك أنك بحاجة إلى أكثر من حيلة لإبقاء الأمور تحت السيطرة. في الأنظمة الحقيقية، عادةً ما تجمع الفرق عادةً بين مجموعة من التكتيكات - مثل: تشذيب السياقات، وتحميل الأدوات، والتلخيص، وعزل رسائل معينة، وإلغاء تحميل السجل القديم، وما إلى ذلك. كلها تساعد بطرق مختلفة. لكن <strong>تشذيب السياق</strong> هو الذي يقرر بشكل مباشر <em>ما يتم تغذيته فعليًا</em> إلى النموذج.</p>
<p>تشذيب السياق، بعبارات بسيطة، هو عملية إزالة المعلومات غير ذات الصلة أو منخفضة القيمة أو المتضاربة تلقائيًا قبل أن تدخل إلى نافذة سياق النموذج. إنه في الأساس مرشح يحتفظ فقط بالأجزاء النصية الأكثر أهمية للمهمة الحالية.</p>
<p>قد تقوم استراتيجيات أخرى بإعادة تنظيم السياق أو ضغطه أو تنحية بعض الأجزاء جانبًا لوقت لاحق. أما التقليم فهو أكثر مباشرة: <strong>فهو يجيب على السؤال "هل يجب أن تدخل هذه القطعة من المعلومات في المطالبة على الإطلاق؟</strong></p>
<p>لهذا السبب يصبح التقليم مهمًا بشكل خاص في أنظمة RAG. البحث المتجه رائع، لكنه ليس مثاليًا. فغالبًا ما يُرجع كيسًا كبيرًا من المعلومات المرشحة - بعضها مفيد، وبعضها مرتبط بشكل فضفاض، وبعضها بعيد تمامًا عن القاعدة. إذا قمت بتفريغها جميعًا في المطالبة، فسوف تصطدم بأوضاع الفشل التي تناولناها سابقًا. يقع التقليم بين الاسترجاع والنموذج، حيث يعمل كحارس بوابة يقرر أي الأجزاء التي يجب الاحتفاظ بها.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/RAG_Pipeline_with_Context_Pruning_01a0d40819.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>عندما يعمل التقليم بشكل جيد، تظهر الفوائد على الفور: سياق أنظف، وإجابات أكثر اتساقًا، واستخدام أقل للرموز الرمزية، وآثار جانبية غريبة أقل من تسلل نص غير ذي صلة. حتى إذا لم تقم بتغيير أي شيء في إعداد الاسترجاع، فإن إضافة خطوة تشذيب قوية يمكن أن تحسن أداء النظام بشكل ملحوظ.</p>
<p>في الممارسة العملية، يعد التقليم أحد أعلى التحسينات ذات الفائدة القصوى في سياق طويل أو خط أنابيب RAG - فكرة بسيطة، وتأثير كبير.</p>
<h2 id="Provence-A-Practical-Context-Pruning-Model" class="common-anchor-header">بروفانس: نموذج عملي لتشذيب السياق<button data-href="#Provence-A-Practical-Context-Pruning-Model" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>أثناء استكشاف مناهج تشذيب السياق، صادفتُ نموذجين مقنعين مفتوحَي المصدر تم تطويرهما في <strong>مختبرات Naver Labs Europe</strong>: <a href="https://huggingface.co/naver/provence-reranker-debertav3-v1"><strong>بروفانس</strong></a> ومتغيره متعدد اللغات <a href="https://huggingface.co/naver/xprovence-reranker-bgem3-v1"><strong>XProvence</strong></a>.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/provence1_b9d2c43276.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>بروفانس هي طريقة لتدريب نموذج تقليم سياق خفيف الوزن لتوليد الاسترجاع المعزز، مع التركيز بشكل خاص على الإجابة عن الأسئلة. وبالنظر إلى سؤال المستخدم والمقطع المسترجع، فإنه يحدد ويزيل الجمل غير ذات الصلة، مع الاحتفاظ فقط بالمعلومات التي تساهم في الإجابة النهائية.</p>
<p>من خلال تشذيب المحتوى منخفض القيمة قبل التوليد، يقلل بروفانس من التشويش في مدخلات النموذج، ويقلل من المطالبات، ويقلل من زمن استنتاج LLM. كما أنه قابل للتوصيل والتشغيل، حيث يعمل مع أي نظام LLM أو نظام استرجاع دون الحاجة إلى تكامل محكم أو تغييرات معمارية.</p>
<p>يقدم Provence العديد من الميزات العملية لخطوط أنابيب RAG في العالم الحقيقي.</p>
<p><strong>1. الفهم على مستوى المستند</strong></p>
<p>يتعلل بروفانس بالمستندات ككل، بدلاً من تسجيل الجمل بمعزل عن بعضها البعض. هذا مهم لأن المستندات في العالم الحقيقي تحتوي في كثير من الأحيان على إشارات مثل "إنه" أو "هذا" أو "الطريقة أعلاه". يمكن أن تكون هذه الجمل بمعزل عن بعضها البعض غامضة أو حتى بلا معنى. عند النظر إليها في سياقها، تصبح أهميتها واضحة. من خلال نمذجة المستند بشكل كلي، ينتج بروفانس قرارات تشذيب أكثر دقة وتماسكًا.</p>
<p><strong>2. الاختيار التكيّفي للجمل</strong></p>
<p>يحدد بروفانس تلقائيًا عدد الجمل التي يجب الاحتفاظ بها من المستند المسترجع. وبدلًا من الاعتماد على قواعد ثابتة مثل "الاحتفاظ بأفضل خمس جمل"، يتكيف مع الاستعلام والمحتوى.</p>
<p>يمكن الإجابة على بعض الأسئلة بجملة واحدة، بينما يتطلب البعض الآخر عدة جمل داعمة. يتعامل Provence مع هذا التباين بشكل ديناميكي، باستخدام عتبة ملاءمة تعمل بشكل جيد عبر المجالات ويمكن تعديلها عند الحاجة - دون ضبط يدوي في معظم الحالات.</p>
<p><strong>3. كفاءة عالية مع إعادة الترتيب المتكاملة</strong></p>
<p>صُمم بروفانس ليكون فعالاً. إنه نموذج مدمج وخفيف الوزن، مما يجعله أسرع وأرخص بكثير في التشغيل من مناهج التقليم القائمة على LLM.</p>
<p>والأهم من ذلك، يمكن ل Provence الجمع بين إعادة الترتيب وتشذيب السياق في خطوة واحدة. نظرًا لأن إعادة الترتيب هي بالفعل مرحلة قياسية في خطوط أنابيب RAG الحديثة، فإن دمج التقليم في هذه المرحلة يجعل التكلفة الإضافية لتشذيب السياق قريبة من الصفر، مع الاستمرار في تحسين جودة السياق الذي يتم تمريره إلى نموذج اللغة.</p>
<p><strong>4. دعم متعدد اللغات عبر XProvence</strong></p>
<p>يحتوي بروفانس أيضًا على متغير يسمى XProvence، والذي يستخدم نفس البنية ولكن يتم تدريبه على بيانات متعددة اللغات. وهذا يمكّنها من تقييم الاستعلامات والمستندات عبر اللغات - مثل الصينية والإنجليزية والكورية - مما يجعلها مناسبة لأنظمة RAG متعددة اللغات وعبر اللغات.</p>
<h3 id="How-Provence-Is-Trained" class="common-anchor-header">كيف يتم تدريب بروفانس</h3><p>يستخدم بروفانس تصميم تدريب نظيف وفعّال يعتمد على بنية مُبرمجة متقاطعة. أثناء التدريب، يتم دمج الاستعلام وكل مقطع مسترجع في مدخل واحد ويتم ترميزهما معًا. يسمح ذلك للنموذج بملاحظة السياق الكامل لكل من السؤال والمقطع في آنٍ واحد والاستدلال مباشرةً على مدى ملاءمتهما.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/provence2_80523f7a9e.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>هذا الترميز المشترك يمكّن بروفانس من التعلم من إشارات الملاءمة الدقيقة. تم ضبط النموذج بدقة على <a href="https://zilliz.com/ai-faq/what-is-the-difference-between-bert-roberta-and-deberta-for-embeddings"><strong>DeBERTa</strong></a> باعتباره مُشفّرًا خفيف الوزن وتم تحسينه لأداء مهمتين في وقت واحد:</p>
<ol>
<li><p><strong>تسجيل درجة الملاءمة على مستوى المستند (درجة إعادة الترتيب):</strong> يتنبأ النموذج بدرجة الملاءمة للمستند بأكمله، مما يشير إلى مدى تطابقه مع الاستعلام. على سبيل المثال، تمثل الدرجة 0.8 درجة أهمية قوية.</p></li>
<li><p><strong>تصنيف الصلة على مستوى الرمز (قناع ثنائي):</strong> بالتوازي مع ذلك، يعيّن النموذج تسمية ثنائية لكل رمز مميز، مع تحديد ما إذا كان ذا صلة (<code translate="no">1</code>) أو غير ذي صلة (<code translate="no">0</code>) بالاستعلام.</p></li>
</ol>
<p>ونتيجة لذلك، يمكن للنموذج المدرّب تقييم الصلة الإجمالية للمستند وتحديد الأجزاء التي يجب الاحتفاظ بها أو إزالتها.</p>
<p>في وقت الاستدلال، يتنبأ بروفانس بتسميات الملاءمة على مستوى الرمز المميز. ثم يتم تجميع هذه التنبؤات على مستوى الجملة: يتم الاحتفاظ بالجملة إذا كانت تحتوي على رموز ذات صلة أكثر من تلك غير ذات الصلة؛ وإلا يتم تشذيبها. نظرًا لأن النموذج يتم تدريبه بإشراف على مستوى الجملة، تميل تنبؤات الرموز الرمزية داخل نفس الجملة إلى أن تكون متسقة، مما يجعل استراتيجية التجميع هذه موثوقة من الناحية العملية. يمكن أيضًا ضبط سلوك التقليم عن طريق ضبط عتبة التجميع لتحقيق تقليم أكثر تحفظًا أو أكثر قوة.</p>
<p>والأهم من ذلك هو أن بروفانس يعيد استخدام خطوة إعادة الترتيب التي تتضمنها بالفعل معظم خطوط أنابيب RAG. وهذا يعني أنه يمكن إضافة تشذيب السياق دون أي تكاليف إضافية تُذكر، مما يجعل بروفنس عمليًا بشكل خاص لأنظمة RAG في العالم الحقيقي.</p>
<h2 id="Evaluating-Context-Pruning-Performance-Across-Models" class="common-anchor-header">تقييم أداء تشذيب السياق عبر النماذج<button data-href="#Evaluating-Context-Pruning-Performance-Across-Models" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>لقد ركزنا حتى الآن على تصميم بروفانس وتدريبها. والخطوة التالية هي تقييم كيفية أدائه عمليًا: مدى جودة تشذيب السياق، ومقارنته مع المناهج الأخرى، وكيف يتصرف في ظل ظروف العالم الحقيقي.</p>
<p>وللإجابة عن هذه الأسئلة، قمنا بتصميم مجموعة من التجارب الكمية لمقارنة جودة تشذيب السياق عبر نماذج متعددة في إعدادات تقييم واقعية.</p>
<p>تركز التجارب على هدفين أساسيين:</p>
<ul>
<li><p><strong>فعالية التقليم:</strong> نقيس مدى دقة كل نموذج في الاحتفاظ بالمحتوى ذي الصلة مع إزالة المعلومات غير ذات الصلة، باستخدام مقاييس قياسية مثل الدقة والاسترجاع ودرجة F1.</p></li>
<li><p><strong>التعميم خارج المجال:</strong> نقوم بتقييم مدى جودة أداء كل نموذج على توزيعات البيانات التي تختلف عن بيانات التدريب الخاصة به، وتقييم مدى قوة كل نموذج في سيناريوهات خارج المجال.</p></li>
</ul>
<h3 id="Models-Compared" class="common-anchor-header">مقارنة النماذج</h3><ul>
<li><p><a href="https://huggingface.co/naver/provence-reranker-debertav3-v1"><strong>بروفانس</strong></a></p></li>
<li><p><a href="https://huggingface.co/naver/xprovence-reranker-bgem3-v1"><strong>إكس بروفانس</strong></a></p></li>
<li><p><a href="https://huggingface.co/opensearch-project/opensearch-semantic-highlighter-v1"><strong>أداة التظليل الدلالي OpenSearch Semantic Highlighter</strong></a> (نموذج تقليم يعتمد على بنية BERT، مصمم خصيصًا لمهام التظليل الدلالي)</p></li>
</ul>
<h3 id="Dataset" class="common-anchor-header">مجموعة البيانات</h3><p>نستخدم WikiText-2 كمجموعة بيانات للتقييم. يستمد WikiText-2 من مقالات ويكيبيديا ويحتوي على هياكل وثائق متنوعة، حيث تنتشر المعلومات ذات الصلة غالبًا عبر جمل متعددة ويمكن أن تكون العلاقات الدلالية غير تافهة.</p>
<p>والأهم من ذلك أن WikiText-2 يختلف اختلافًا كبيرًا عن البيانات المستخدمة عادةً لتدريب نماذج تشذيب السياق، بينما لا يزال يشبه محتوى العالم الحقيقي الغني بالمعارف. وهذا يجعله مناسبًا تمامًا للتقييم خارج المجال، وهو محور التركيز الرئيسي لتجاربنا.</p>
<h3 id="Query-Generation-and-Annotation" class="common-anchor-header">توليد الاستعلامات والتعليقات التوضيحية</h3><p>لإنشاء مهمة تشذيب خارج النطاق، نقوم تلقائيًا بإنشاء أزواج أسئلة وأجوبة من مجموعة ويكي تكست 2 الخام باستخدام <strong>GPT-4o-mini</strong>. تتكون كل عينة تقييم من ثلاثة مكونات:</p>
<ul>
<li><p><strong>الاستعلام:</strong> سؤال بلغة طبيعية تم إنشاؤه من المستند.</p></li>
<li><p><strong>السياق:</strong> المستند الكامل غير المعدّل.</p></li>
<li><p><strong>الحقيقة الأساسية:</strong> التعليقات التوضيحية على مستوى الجمل التي تشير إلى الجمل التي تحتوي على الإجابة (التي سيتم الاحتفاظ بها) والجمل غير ذات الصلة (التي سيتم تشذيبها).</p></li>
</ul>
<p>يُعرّف هذا الإعداد بشكل طبيعي مهمة تشذيب السياق: بالنظر إلى الاستعلام والمستند الكامل، يجب أن يحدد النموذج الجمل المهمة بالفعل. يتم تصنيف الجمل التي تحتوي على الإجابة على أنها ذات صلة ويجب الاحتفاظ بها، في حين يتم التعامل مع جميع الجمل الأخرى على أنها غير ذات صلة ويجب تشذيبها. تسمح هذه الصيغة بقياس جودة التشذيب كميًا باستخدام الدقة والاستعادة ودرجة F1.</p>
<p>والأهم من ذلك، لا تظهر الأسئلة التي تم إنشاؤها في بيانات التدريب لأي نموذج تم تقييمه. ونتيجة لذلك، يعكس الأداء التعميم الحقيقي وليس الحفظ. في المجموع، نقوم بتوليد 300 نموذج، تشمل الأسئلة البسيطة القائمة على الحقائق، ومهام التفكير متعدد القفزات، والمطالبات التحليلية الأكثر تعقيدًا، من أجل عكس أنماط الاستخدام في العالم الحقيقي بشكل أفضل.</p>
<h3 id="Evaluation-Pipeline" class="common-anchor-header">خط أنابيب التقييم</h3><p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/pipeline_77e52002fc.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>تحسين المعلمة الفائقة: لكل نموذج، نجري بحثًا شبكيًا على مساحة محددة مسبقًا من المعرفات الفائقة ونختار التكوين الذي يزيد من درجة F1.</p>
<h3 id="Results-and-Analysis" class="common-anchor-header">النتائج والتحليل</h3><p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/result_0df098152a.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>تكشف النتائج عن اختلافات واضحة في الأداء بين النماذج الثلاثة.</p>
<p>يحقق<strong>بروفانس</strong> أقوى أداء عام، حيث حصل على درجة <strong>F1 بنسبة 66.76%</strong>. كما أن الدقة<strong>(69.53%</strong>) والتذكر<strong>(64.19%</strong>) متوازنة بشكل جيد، مما يشير إلى تعميم قوي خارج المجال. يستخدم التكوين الأمثل عتبة تقليم تبلغ <strong>0.6</strong> و <strong>α = 0.051،</strong> مما يشير إلى أن درجات ملاءمة النموذج تمت معايرتها بشكل جيد وأن سلوك التقليم بديهي وسهل الضبط عمليًا.</p>
<p>يصل<strong>نموذج XProvence</strong> إلى <strong>درجة F1 تبلغ 58.97%،</strong> ويتميز <strong>باستدعاء عالٍ (75.52%)</strong> <strong>ودقة أقل (48.37%)</strong>. يعكس هذا استراتيجية تشذيب أكثر تحفظًا تعطي الأولوية للاحتفاظ بالمعلومات ذات الصلة المحتملة على إزالة الضوضاء بقوة. يمكن أن يكون هذا السلوك مرغوبًا في المجالات التي تكون فيها النتائج السلبية الخاطئة مكلفة - مثل تطبيقات الرعاية الصحية أو التطبيقات القانونية - ولكنه يزيد أيضًا من النتائج الإيجابية الخاطئة، مما يقلل من الدقة. على الرغم من هذه المفاضلة، فإن قدرة XProvence متعددة اللغات تجعله خيارًا قويًا للإعدادات غير الإنجليزية أو متعددة اللغات.</p>
<p>في المقابل، كان أداء <strong>أداة التمييز الدلالي OpenSearch Semantic Highlighter</strong> أسوأ بكثير، حيث <strong>بلغت نسبة F1 46.37%</strong> (الدقة <strong>62.35%،</strong> والتذكر <strong>36.98%</strong>). تشير الفجوة بالنسبة إلى بروفانس وإكس بروفانس إلى وجود قيود في كل من معايرة الدرجات والتعميم خارج المجال، خاصةً في ظل ظروف خارج المجال.</p>
<h2 id="Semantic-Highlighting-Another-Way-to-Find-What-Actually-Matters-in-Text" class="common-anchor-header">تسليط الضوء الدلالي: طريقة أخرى للعثور على ما يهم بالفعل في النص<button data-href="#Semantic-Highlighting-Another-Way-to-Find-What-Actually-Matters-in-Text" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>الآن بعد أن تحدثنا عن تشذيب السياق، يجدر بنا أن ننظر إلى جزء ذي صلة من اللغز: التظليل <a href="https://milvus.io/blog/zilliz-trained-and-open-sourced-bilingual-semantic-highlighting-model-for-production-ai.md"><strong>الدلالي</strong></a>. من الناحية الفنية، كلتا الميزتين تقومان بنفس المهمة الأساسية تقريبًا - فهما تسجلان أجزاء النص بناءً على مدى صلتها بالاستعلام. يكمن الفرق في كيفية استخدام النتيجة في خط الإنتاج.</p>
<p>معظم الناس يسمعون كلمة "تمييز" ويفكرون في أدوات تمييز الكلمات الرئيسية التقليدية التي تراها في Elasticsearch أو Solr. تبحث هذه الأدوات بشكل أساسي عن مطابقات الكلمات الرئيسية الحرفية وتلفها في شيء مثل <code translate="no">&lt;em&gt;</code>. إنها رخيصة ويمكن التنبؤ بها، لكنها لا تعمل إلا عندما يستخدم النص نفس الكلمات التي يستخدمها الاستعلام <em>بالضبط</em>. إذا قام المستند بإعادة الصياغة، أو استخدم مرادفات، أو صاغ الفكرة بشكل مختلف، فإن أدوات التظليل التقليدية تفوتها تمامًا.</p>
<p><strong>تسلك أدوات التمييز الدلالي طريقًا مختلفًا.</strong> فبدلاً من التحقق من التطابق التام للسلسلة، يستخدم نموذجًا لتقدير التشابه الدلالي بين الاستعلام ومختلف امتدادات النص. وهذا يتيح له تمييز المحتوى ذي الصلة حتى عندما تكون الصياغة مختلفة تمامًا. بالنسبة لخطوط أنابيب RAG، أو سير عمل الوكيل، أو أي نظام بحث بالذكاء الاصطناعي حيث يكون المعنى أكثر أهمية من الرموز، يمنحك التظليل الدلالي صورة أوضح بكثير عن <em>سبب</em> استرجاع المستند.</p>
<p>وتكمن المشكلة في أن معظم حلول التظليل الدلالي الحالية ليست مصممة لإنتاج أعباء عمل الذكاء الاصطناعي. لقد اختبرنا كل ما هو متاح، ولم يقدم أي منها مستوى الدقة أو زمن الاستجابة أو الموثوقية متعددة اللغات التي نحتاجها لأنظمة RAG والوكلاء الحقيقية. لذلك انتهى بنا المطاف بتدريب نموذجنا الخاص بنا وفتح مصادره بدلاً من ذلك: <a href="https://huggingface.co/zilliz/semantic-highlight-bilingual-v1">zilliz/semantic-hemantic-highlight-bilingual-v1</a></p>
<p>على مستوى عالٍ، <strong>يحل التقليم السياقي والتمييز الدلالي نفس المهمة الأساسية</strong>: إذا كان لديك استعلام وجزء من النص، اكتشف الأجزاء المهمة بالفعل. الفرق الوحيد هو ما يحدث بعد ذلك.</p>
<ul>
<li><p>يُسقط<strong>تشذيب السياق</strong> الأجزاء غير ذات الصلة قبل التوليد.</p></li>
<li><p>أما<strong>التظليل الدلالي</strong> فيحتفظ بالنص الكامل ولكنه يظهر بصريًا الأجزاء المهمة.</p></li>
</ul>
<p>نظرًا لأن العملية الأساسية متشابهة جدًا، يمكن للنموذج نفسه في كثير من الأحيان تشغيل كلتا الميزتين. هذا يجعل من السهل إعادة استخدام المكونات عبر المكدس ويحافظ على نظام RAG الخاص بك أبسط وأكثر كفاءة بشكل عام.</p>
<h3 id="Semantic-Highlighting-in-Milvus-and-Zilliz-Cloud" class="common-anchor-header">التظليل الدلالي في Milvus وZilliz Cloud</h3><p>أصبح التظليل الدلالي الآن مدعومًا بالكامل في <a href="https://milvus.io">Milvus</a> وZilliz <a href="https://zilliz.com/cloud"><strong>Cloud</strong></a> (الخدمة المدارة بالكامل من Milvus)، وقد أثبتت بالفعل أنها مفيدة لأي شخص يعمل مع RAG أو البحث القائم على الذكاء الاصطناعي. تعمل هذه الميزة على حل مشكلة بسيطة للغاية ولكنها مؤلمة: عندما يُرجع البحث المتجه عددًا كبيرًا من الأجزاء، كيف يمكنك أن تعرف بسرعة <em>أي الجمل داخل تلك الأجزاء مهمة بالفعل؟</em></p>
<p>بدون التظليل، ينتهي الأمر بالمستخدمين بقراءة مستندات كاملة فقط لفهم سبب استرجاع شيء ما. من خلال التظليل الدلالي المدمج في التظليل الدلالي، يقوم Milvus و Zilliz Cloud تلقائيًا بتمييز المقاطع المحددة المرتبطة دلاليًا باستعلامك - حتى لو كانت الصياغة مختلفة. لا مزيد من البحث عن تطابق الكلمات المفتاحية أو تخمين سبب ظهور قطعة ما.</p>
<p>هذا يجعل الاسترجاع أكثر شفافية بكثير. فبدلاً من مجرد إرجاع "المستندات ذات الصلة"، يُظهر Milvus <em>مكان</em> وجود الصلة. بالنسبة لخطوط أنابيب RAG، هذا مفيد بشكل خاص لأنه يمكنك أن ترى على الفور ما يفترض أن يحضره النموذج، مما يجعل تصحيح الأخطاء وبناء المطالبات أسهل بكثير.</p>
<p>لقد قمنا ببناء هذا الدعم مباشرةً في Milvus و Zilliz Cloud، لذلك لن تضطر إلى تثبيت نماذج خارجية أو تشغيل خدمة أخرى فقط للحصول على إسناد قابل للاستخدام. يتم تشغيل كل شيء داخل مسار الاسترجاع: البحث المتجه ← تسجيل الملاءمة ← الامتدادات المميزة. وهو يعمل خارج الصندوق على نطاق واسع ويدعم أعباء العمل متعدد اللغات من خلال نموذج <a href="https://huggingface.co/zilliz/semantic-highlight-bilingual-v1">zilliz/semantic-highlight-bighlight-bilingual-v1</a>.</p>
<h2 id="Looking-Ahead" class="common-anchor-header">استشراف المستقبل<button data-href="#Looking-Ahead" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>لا تزال هندسة السياق حديثة العهد، ولا يزال هناك الكثير من الأمور التي يجب اكتشافها. حتى مع عمل التقليم والتمييز الدلالي بشكل جيد داخل <a href="https://milvus.io">Milvus</a> و <a href="https://zilliz.com/cloud"><strong>Zilliz</strong></a><strong> Cloud،</strong> لم نقترب بعد من نهاية القصة. هناك مجموعة من المجالات التي لا تزال بحاجة إلى عمل هندسي حقيقي - جعل نماذج التقليم أكثر دقة دون إبطاء الأمور، والتحسن في التعامل مع الاستعلامات الغريبة أو خارج النطاق، وربط جميع الأجزاء معًا بحيث يبدو الاسترجاع ← إعادة الترتيب ← التقليم ← التظليل وكأنه خط واحد نظيف بدلاً من مجموعة من الاختراقات الملتصقة ببعضها البعض.</p>
<p>مع استمرار نمو نوافذ السياق، تزداد أهمية هذه القرارات. لم تعد الإدارة الجيدة للسياق "مكافأة لطيفة" بعد الآن؛ بل أصبحت جزءًا أساسيًا من جعل أنظمة السياق الطويل و RAG تعمل بشكل موثوق.</p>
<p>سنستمر في إجراء التجارب وقياس المعايير وشحن الأجزاء التي تُحدث فرقًا فعليًا للمطورين. الهدف واضح ومباشر: تسهيل بناء أنظمة لا تتعطل في ظل البيانات الفوضوية أو الاستعلامات غير المتوقعة أو أعباء العمل واسعة النطاق.</p>
<p>إذا كنت ترغب في التحدث عن أي من هذا - أو تحتاج فقط إلى مساعدة في تصحيح أخطاء شيء ما - يمكنك الدخول إلى <a href="https://discord.com/invite/8uyFbECzPX">قناة Discord</a> الخاصة بنا أو حجز جلسة فردية لمدة 20 دقيقة للحصول على رؤى وإرشادات وإجابات لأسئلتك من خلال<a href="https://milvus.io/blog/join-milvus-office-hours-to-get-support-from-vectordb-experts.md"> ساعات عمل Milvus المكتبية</a>.</p>
<p>يسعدنا دائمًا الدردشة وتبادل الملاحظات مع البناة الآخرين.</p>
