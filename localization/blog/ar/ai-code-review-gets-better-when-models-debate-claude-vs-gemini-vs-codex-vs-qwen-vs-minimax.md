---
id: >-
  ai-code-review-gets-better-when-models-debate-claude-vs-gemini-vs-codex-vs-qwen-vs-minimax.md
title: >-
  تتحسن مراجعة كود الذكاء الاصطناعي عندما تتناظر النماذج: كلود ضد جيميني ضد
  كودكس ضد كوين ضد ميني ماكس
author: Li Liu
date: 2026-02-26T00:00:00.000Z
cover: >-
  assets.zilliz.com/Code_Review_Benchmark_Cover_Fixed_Icons_2048x1143_11zon_1_04796f1364.jpg
tag: Engineering
recommend: false
publishToMedium: true
tags: 'AI Code Review, Qwen, Claude, Gemini, Codex'
meta_keywords: >-
  AI code review, LLM code review benchmark, Claude vs Gemini vs Codex, AI code
  review benchmark, multi-model AI debate
meta_title: |
  Claude vs Gemini vs Codex vs Qwen vs MiniMax Code Review
desc: >-
  اختبرنا كل من Claude و Gemini و Codex و Qwen و MiniMax على اكتشاف الأخطاء
  الحقيقية. وصل أفضل نموذج إلى 53%. بعد المناظرة العدائية، قفزت نسبة الكشف إلى
  80%.
origin: 'https://milvus.io/blog/ai-code-review-benchmark-multi-model-debate.md'
---
<p>لقد استخدمت مؤخرًا نماذج الذكاء الاصطناعي لمراجعة طلب سحب، وكانت النتائج متناقضة: أشار كلود إلى وجود سباق بيانات، بينما قال جيميني إن الكود نظيف. أثار هذا الأمر فضولي لمعرفة كيف ستتصرف نماذج الذكاء الاصطناعي الأخرى، لذلك قمتُ بتشغيل أحدث النماذج الرئيسية من Claude وGemini وCodx وQwen وMiniMax من خلال معيار منظم لمراجعة الشيفرة. والنتائج؟ اكتشف النموذج الأفضل أداءً 53% فقط من الأخطاء المعروفة.</p>
<p>ومع ذلك، لم ينتهِ فضولي عند هذا الحد: ماذا لو عملت نماذج الذكاء الاصطناعي هذه معًا؟ لقد جربت أن أجعلهم يتناقشون مع بعضهم البعض، وبعد خمس جولات من المناظرات العدائية، قفزت نسبة اكتشاف الأخطاء إلى 80%. أصعب الأخطاء، تلك التي تتطلب فهمًا على مستوى النظام، وصلت نسبة اكتشافها في وضع المناظرة إلى 100%.</p>
<p>يستعرض هذا المنشور تصميم التجربة، ونتائج كل نموذج، وما تكشفه آلية المناظرة حول كيفية استخدام الذكاء الاصطناعي في مراجعة التعليمات البرمجية.</p>
<h2 id="Benchmarking-Claude-Gemini-Codex-Qwen-and-MiniMax-for-code-review" class="common-anchor-header">قياس أداء كل من كلود وجيميني وكودكس وكوين وميني ماكس لمراجعة التعليمات البرمجية<button data-href="#Benchmarking-Claude-Gemini-Codex-Qwen-and-MiniMax-for-code-review" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>إذا كنت تستخدم النماذج لمراجعة التعليمات البرمجية، فربما لاحظت أنها لا تختلف في الدقة فحسب؛ بل تختلف في كيفية قراءة التعليمات البرمجية. على سبيل المثال:</p>
<p>عادةً ما يمشي كلود في سلسلة الاستدعاء من الأعلى إلى الأسفل وسيقضي وقتًا في المسارات "المملة" (معالجة الأخطاء، وإعادة المحاولات، والتنظيف). هذا غالبًا ما يختبئ فيه الخلل الحقيقي، لذا لا أكره الدقة.</p>
<p>تميل الجوزاء إلى البدء بحكم قوي ("هذا سيء" / "يبدو جيدًا") ثم تعمل بشكل عكسي لتبرير ذلك من زاوية التصميم/الهيكل. أحيانًا يكون ذلك مفيدًا. وأحيانًا يبدو الأمر وكأنه اختلس النظر ثم التزم بأخذها.</p>
<p>الدستور أكثر هدوءًا. ولكن عندما يشير إلى شيء ما، غالبًا ما يكون ملموسًا وقابلًا للتنفيذ - أقل تعليقًا، وأكثر "هذا السطر خاطئ لأن X."</p>
<p>هذه انطباعات وليست قياسات. للحصول على أرقام فعلية، قمت بإعداد معيار.</p>
<h3 id="Setup" class="common-anchor-header">الإعداد</h3><p><strong>تم اختبار خمسة نماذج رئيسية:</strong></p>
<ul>
<li><p>كلود أوبوس 4.6</p></li>
<li><p>جيميني 3 برو</p></li>
<li><p>GPT-5.2-Codex</p></li>
<li><p>Qwen-3.5-Plus</p></li>
<li><p>ميني ماكس-M2.5</p></li>
</ul>
<p><strong>الأدوات (Magpie)</strong></p>
<p>لقد استخدمت <a href="https://github.com/liliu-z/magpie">Magpie،</a> وهي أداة قياس مفتوحة المصدر قمتُ ببنائها. وتتمثل مهمتها في القيام ب "إعداد مراجعة الشيفرة" التي تقوم بها عادةً يدويًا: سحب السياق المحيط (سلاسل الاستدعاء والوحدات ذات الصلة والشيفرة المجاورة ذات الصلة) وتغذية النموذج <em>قبل</em> أن يراجع العلاقات العامة.</p>
<p><strong>حالات الاختبار (علاقات عامة ميلفوس ذات الأخطاء المعروفة)</strong></p>
<p>تتألف مجموعة البيانات من 15 طلب سحب من <a href="https://github.com/milvus-io/milvus">Milvus</a> (قاعدة بيانات مفتوحة المصدر تم إنشاؤها وصيانتها بواسطة <a href="https://zilliz.com/">Zilliz</a>). تُعدّ طلبات العلاقات العامة هذه مفيدة كمعيار مرجعي لأن كل منها تم دمجها، فقط لتتطلب لاحقًا إعادة أو إصلاح سريع بعد ظهور خطأ في الإنتاج. لذا فإن كل حالة لها خطأ معروف يمكننا تسجيلها.</p>
<p><strong>مستويات صعوبة الأخطاء</strong></p>
<p>ليس من الصعب العثور على جميع هذه الأخطاء بنفس القدر من الصعوبة، لذلك قمت بتصنيفها إلى ثلاثة مستويات صعوبة:</p>
<ul>
<li><p><strong>L1:</strong> يمكن رؤيتها من الفرق وحده (استخدام خالي من الاستخدام، خارج نطاق واحد).</p></li>
<li><p><strong>L2 (10 حالات):</strong> يتطلب فهم الكود المحيط لاكتشاف أشياء مثل التغييرات الدلالية للواجهة أو سباقات التزامن. تمثل هذه الأخطاء الأكثر شيوعًا في المراجعة اليومية للأكواد البرمجية.</p></li>
<li><p><strong>L3 (5 حالات):</strong> تتطلب فهماً على مستوى النظام لاكتشاف مشاكل مثل التناقضات بين الوحدات أو مشاكل توافق الترقية. هذه هي أصعب الاختبارات لمدى عمق قدرة النموذج على فهم قاعدة الشيفرة.</p></li>
</ul>
<p><em>ملاحظة: التقط كل النماذج جميع أخطاء L1، لذا استبعدتها من التقييم.</em></p>
<p><strong>وضعان للتقييم</strong></p>
<p>تم تشغيل كل نموذج في وضعين:</p>
<ul>
<li><p><strong>الخام:</strong> يرى النموذج العلاقات العامة فقط (الفرق + كل ما هو موجود في محتوى العلاقات العامة).</p></li>
<li><p><strong>R1:</strong> يقوم Magpie بسحب السياق المحيط (الملفات ذات الصلة / مواقع الاستدعاء / التعليمات البرمجية ذات الصلة) <em>قبل</em> مراجعة النموذج. هذا يحاكي سير العمل حيث تقوم بإعداد السياق مقدمًا بدلًا من أن تطلب من النموذج تخمين ما يحتاجه.</p></li>
</ul>
<h3 id="Results-L2-+-L3-only" class="common-anchor-header">النتائج (L2 + L3 فقط)</h3><table>
<thead>
<tr><th>الوضع</th><th>كلود</th><th>الجوزاء</th><th>كودكس</th><th>ميني ماكس</th><th>كوين</th></tr>
</thead>
<tbody>
<tr><td>خام</td><td>53% (الأول)</td><td>13% (الأخير)</td><td>33%</td><td>27%</td><td>33%</td></tr>
<tr><td>R1 (مع السياق بواسطة العقعق)</td><td>47% ⬇️</td><td>33%⬆️</td><td>27%</td><td>33%</td><td>40%⬆️</td></tr>
</tbody>
</table>
<p>أربع نتائج</p>
<p><strong>1. يهيمن كلود على المراجعة الأولية.</strong> فقد حصل على 53% في الاكتشاف الإجمالي و5/5 على أخطاء L3، دون أي مساعدة في السياق. إذا كنت تستخدم نموذجًا واحدًا ولا تريد قضاء الوقت في إعداد السياق، فإن Claude هو الخيار الأفضل.</p>
<p><strong>2. يحتاج الجوزاء إلى سياق يُسلَّم إليه.</strong> كانت نتيجته الأولية 13% هي الأقل في المجموعة، ولكن مع توفير Magpie للرمز المحيط، قفزت إلى 33%. لا يجمع Gemini السياق الخاص به بشكل جيد، لكنه يؤدي أداءً محترمًا عندما تقوم بهذا العمل مقدمًا.</p>
<p><strong>3. Qwen هو أقوى أداء بمساعدة السياق.</strong> فقد سجل 40% في وضع R1، مع 5/10 على أخطاء L2، وهي أعلى درجة في مستوى الصعوبة هذا. بالنسبة للمراجعات اليومية الروتينية الروتينية التي ترغب في إعداد السياق فيها، فإن Qwen هو اختيار عملي.</p>
<p><strong>4. المزيد من السياق لا يساعد دائمًا.</strong> لقد رفعت من مستوى الجوزاء (13% ← 33%) وMiniMax (27% ← 33%)، لكنها في الواقع أضرت بـ Claude (53% ← 47%). تتفوق Claude بالفعل في تنظيم السياق من تلقاء نفسها، لذلك من المحتمل أن المعلومات الإضافية قد أحدثت ضوضاء بدلاً من الوضوح. العبرة المستفادة: طابق سير العمل مع النموذج، بدلاً من افتراض أن المزيد من السياق أفضل عالميًا.</p>
<p>تتوافق هذه النتائج مع تجربتي اليومية. كلود في القمة ليس مفاجئًا. تسجيل Gemini درجات أقل مما كنت أتوقعه أمر منطقي في الإدراك المتأخر: عادةً ما أستخدم Gemini في المحادثات متعددة الأدوار حيث أقوم بتكرار تصميم أو مطاردة مشكلة معًا، وهو يؤدي أداءً جيدًا في هذا الإعداد التفاعلي. هذا المعيار عبارة عن خط أنابيب ثابت أحادي المسار، وهو بالضبط الشكل الذي يكون فيه Gemini أضعف ما يكون. سيُظهر قسم المناظرة لاحقًا أنه عندما تعطي Gemini تنسيقًا عدائيًا متعدد الجولات يتحسن أداؤه بشكل ملحوظ.</p>
<h2 id="Let-AI-Models-Debate-with-Each-Other" class="common-anchor-header">دع نماذج الذكاء الاصطناعي تتناظر مع بعضها البعض<button data-href="#Let-AI-Models-Debate-with-Each-Other" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>أظهر كل نموذج نقاط قوة ونقاط عمياء مختلفة في المعايير الفردية. لذا أردت أن أختبر: ماذا يحدث إذا قامت النماذج بمراجعة عمل بعضها البعض بدلاً من مجرد الكود؟</p>
<p>لذا أضفت طبقة مناظرة فوق نفس المعيار. تشارك جميع النماذج الخمسة في خمس جولات:</p>
<ul>
<li><p>في الجولة 1، يراجع كل نموذج نفس العلاقات العامة بشكل مستقل.</p></li>
<li><p>بعد ذلك، أبث جميع المراجعات الخمسة لجميع المشاركين.</p></li>
<li><p>في الجولة 2، يقوم كل نموذج بتحديث موقفه بناءً على النماذج الأربعة الأخرى.</p></li>
<li><p>أكرر حتى الجولة 5.</p></li>
</ul>
<p>في النهاية، لا يتفاعل كل نموذج مع الرمز فقط - بل يتفاعل مع الحجج التي تم نقدها ومراجعتها بالفعل عدة مرات.</p>
<p>لكي لا يتحول هذا الأمر إلى "اتفاق النماذج بصوت عالٍ"، فرضت قاعدة صارمة واحدة: <strong>يجب أن يشير كل ادعاء إلى كود محدد كدليل،</strong> ولا يمكن للنموذج أن يقول "نقطة جيدة" فقط - يجب أن يشرح سبب تغيير رأيه.</p>
<h3 id="Results-Best-Solo-vs-Debate-Mode" class="common-anchor-header">النتائج: أفضل وضع منفرد مقابل وضع المناظرة</h3><table>
<thead>
<tr><th>الوضع</th><th>L2 (10 حالات)</th><th>L3 (5 حالات)</th><th>إجمالي الكشف</th></tr>
</thead>
<tbody>
<tr><td>أفضل فردي (كلود خام)</td><td>3/10</td><td>5/5</td><td>53%</td></tr>
<tr><td>المناظرة (جميع النماذج الخمسة)</td><td>7/10 (مضاعفة)</td><td>5/5 (تم القبض على الجميع)</td><td>80%</td></tr>
</tbody>
</table>
<h3 id="What-stands-out" class="common-anchor-header">ما يبرز</h3><p><strong>1. تضاعف اكتشاف L2.</strong> قفزت الأخطاء الروتينية متوسطة الصعوبة من 3/10 إلى 7/10. هذه هي الأخطاء التي تظهر بشكل متكرر في قواعد البرمجة الحقيقية، وهي بالضبط الفئة التي تخطئ فيها النماذج الفردية بشكل غير متسق. أكبر مساهمة لآلية المناقشة هي سد هذه الثغرات اليومية.</p>
<p><strong>2. أخطاء L3: صفر أخطاء.</strong> في عمليات تشغيل النماذج الفردية، اكتشف كلود فقط كل الأخطاء الخمسة على مستوى النظام L3. في وضع المناظرة، طابقت المجموعة هذه النتيجة، مما يعني أنك لم تعد بحاجة إلى المراهنة على النموذج الصحيح للحصول على تغطية L3 كاملة.</p>
<p><strong>3. المناظرة تملأ النقاط العمياء بدلاً من رفع السقف.</strong> لم تكن الأخطاء على مستوى النظام هي الجزء الصعب بالنسبة للفرد الأقوى. كان لدى كلود بالفعل تلك الأخطاء. تتمثل المساهمة الأساسية لآلية المناظرة في تصحيح ضعف كلود في أخطاء L2 الروتينية، حيث اكتشف كلود الفردي 3 فقط من أصل 10، لكن مجموعة المناظرة اكتشفت 7. من هنا تأتي القفزة التي بلغت 53% → 80%.</p>
<h3 id="What-debate-actually-looks-like-in-practice" class="common-anchor-header">كيف تبدو المناظرة في الواقع العملي</h3><p>تُظهر الأرقام أعلاه أن المناظرة ناجحة، ولكن هناك مثال ملموس يوضح <em>سبب</em> نجاحها. إليك شرحًا موجزًا لكيفية تعامل النماذج الخمسة مع <strong>PR #</strong>44474، الذي قدم التحميل البطيء للمفاتيح الأساسية أثناء البحث.</p>
<p><a href="https://github.com/milvus-io/milvus/pull/44474"><strong>العلاقات العامة رقم 44474:</strong></a> تحسين التحميل البطيء الذي غيّر البحث لجلب المفاتيح الأساسية عند الطلب بدلاً من تحميلها كلها مقدمًا.</p>
<p><strong>الجولة 1</strong></p>
<p>افتتح الجوزاء بقوة:</p>
<p>"هذه العلاقات العامة هي حقل ألغام من الممارسات السيئة، والسلوك غير المحدد المحتمل، وتراجعات الأداء المتخفية في شكل "تحسين".</p>
<p>ركز كل من كلود وكوين على السلوك والأداء غير المحدد، وتوافقا على نفس الاهتمام:</p>
<p>“The C++ memory model doesn’t guarantee safety for concurrent writes to different indices of the same vector without proper synchronization.”</p>
<p>وجد الثلاثة مشاكل حقيقية، لكن لم يكتشف أي منهم الخطأ الأعمق. ثم قام Codex، الذي بالكاد تحدث، بالإشارة إلى شيء لم ينتبه إليه الآخرون: يتم تغيير حجم المتجه <code translate="no">primary_keys_</code> ، ولكن لا يتم ملء سوى المواضع التي تمر خلال مرحلة الاختزال. يتم ترك كل موضع آخر كقيمة صفرية.</p>
<p><strong>الجولة 2</strong></p>
<p>التقط كلود اكتشاف كودكس وتتبع النتيجة النهائية:</p>
<p>"لقد وجدتها: <code translate="no">SortEqualScoresByPks</code> يعمل قبل <code translate="no">ReduceResultData</code>. لذلك عندما يتم تنفيذ <code translate="no">SortEqualScoresByPks</code> ، لم يتم جلب أي PKs بشكل كسول حتى الآن. يكون متجه <code translate="no">primary_keys_</code> بأكمله مليئًا بقيم PkType الافتراضية المكوّنة افتراضيًا."</p>
<p>بعبارات واضحة، يتم تشغيل دالة الفرز قبل أن يتم تحميل المفاتيح، لذا فهي تقوم بفرز الأصفار. اعترف كلود بالخطأ صراحةً:</p>
<p>"حددت Codex-cli خطأً حقيقيًا خطيرًا في التصحيح. لقد فاتني هذا في جولتي الأولى."</p>
<h2 id="Which-Combination-of-Models-Can-Find-the-Most-Bugs" class="common-anchor-header">أي مجموعة من النماذج يمكنها العثور على أكبر عدد من الأخطاء؟<button data-href="#Which-Combination-of-Models-Can-Find-the-Most-Bugs" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>حدثت القفزة من 53% إلى 80% لأن النماذج الخمسة غطت النقاط العمياء لبعضها البعض. ولكن لا يستطيع الجميع تحمل تكلفة إعداد وتشغيل خمسة نماذج خلال خمس جولات من المناقشة لكل مراجعة برمجية.</p>
<p><strong>لذلك قمت باختبار النسخة الأبسط: إذا كان بإمكانك تشغيل نموذجين فقط، فأي نموذجين فقط يجعلك تقترب من سقف النماذج المتعددة؟</strong></p>
<p>لقد استخدمت عمليات التشغيل <strong>بمساعدة السياق (R1)</strong> وقمت بحساب عدد الأخطاء المعروفة الـ 15 التي وجدها كل نموذج:</p>
<ul>
<li><p><strong>كلود:</strong> 7/15 (47%)</p></li>
<li><p><strong>كوين:</strong> 6/15 (40%)</p></li>
<li><p><strong>جيميني:</strong> 5/15 (33%)</p></li>
<li><p><strong>ميني ماكس:</strong> 5/15 (33%)</p></li>
<li><p><strong>كودكس:</strong> 4/15 (27%)</p></li>
</ul>
<p>ما يهم إذن ليس فقط عدد الأخطاء التي يعثر عليها كل نموذج، بل الأخطاء <em>التي</em> يفوتها. من بين الأخطاء الثمانية التي فاتت كلاود 8 أخطاء، اكتشف Gemini 3 أخطاء: حالة سباق التزامن، ومشكلة توافق واجهة برمجة تطبيقات التخزين السحابي، وفقدان التحقق من الأذونات. وبالانتقال إلى الاتجاه الآخر، فاتت Gemini معظم أخطاء هياكل البيانات والأخطاء المنطقية العميقة، بينما اكتشف Claude جميع هذه الأخطاء تقريبًا. نقاط ضعفهما بالكاد تتداخل، وهو ما يجعلهما ثنائيًا قويًا.</p>
<table>
<thead>
<tr><th>الاقتران بين النموذجين</th><th>التغطية المشتركة</th></tr>
</thead>
<tbody>
<tr><td>كلود + جيميني</td><td>10/15</td></tr>
<tr><td>كلود + كوين</td><td>9/15</td></tr>
<tr><td>كلود + كودكس</td><td>8/15</td></tr>
<tr><td>كلود + ميني ماكس</td><td>8/15</td></tr>
</tbody>
</table>
<p>جميع النماذج الخمسة معًا غطت 11 من أصل 15، مما يترك 4 أخطاء لم يلاحظها كل نموذج.</p>
<p><strong>كلود + جيميني،</strong> كزوج من نموذجين، يصل بالفعل إلى 91% من سقف الخمسة نماذج. بالنسبة لهذا المعيار، فهو المزيج الأكثر كفاءة.</p>
<p>ومع ذلك، فإن Claude + Gemini ليس أفضل اقتران لكل نوع من أنواع الأخطاء. عندما قسمت النتائج حسب فئة الأخطاء، ظهرت صورة أكثر دقة:</p>
<table>
<thead>
<tr><th>نوع الخطأ</th><th>المجموع</th><th>كلود</th><th>الجوزاء</th><th>كودكس</th><th>ميني ماكس</th><th>كوين</th></tr>
</thead>
<tbody>
<tr><td>ثغرات التحقق من الصحة</td><td>4</td><td>3</td><td>2</td><td>1</td><td>1</td><td>3</td></tr>
<tr><td>دورة حياة بنية البيانات</td><td>4</td><td>3</td><td>1</td><td>1</td><td>3</td><td>1</td></tr>
<tr><td>السباقات المتزامنة</td><td>2</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>التوافق</td><td>2</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>المنطق العميق</td><td>3</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td></tr>
<tr><td>المجموع الكلي</td><td>15</td><td>7</td><td>5</td><td>4</td><td>5</td><td>6</td></tr>
</tbody>
</table>
<p>يكشف تحليل نوع الخطأ عن سبب عدم وجود ثنائي واحد هو الأفضل عالميًا.</p>
<ul>
<li><p>بالنسبة لأخطاء دورة حياة بنية البيانات، تعادل كلود وميني ماكس بنسبة 3/4.</p></li>
<li><p>بالنسبة لثغرات التحقق من الصحة، تعادل كلود وكوين بنسبة 3/4.</p></li>
<li><p>بالنسبة لمشكلات التزامن والتوافق، سجل Claude صفرًا في كليهما، وGemini هو الذي يسد تلك الثغرات.</p></li>
<li><p>لا يوجد نموذج يغطي كل شيء، لكن كلود يغطي النطاق الأوسع ويقترب من كونه نموذجًا عامًّا.</p></li>
</ul>
<p>أغفل كل نموذج أربعة أخطاء. أحدها يتعلق بأولوية قاعدة ANTLR النحوية. كان أحدها عدم تطابق دلالات قفل القراءة/الكتابة عبر الدوال. تطلب أحدها فهم الاختلافات في منطق العمل بين أنواع الضغط. وأحدها كان خطأ مقارنة صامتًا حيث استخدم أحد المتغيرات ميغابايت واستخدم آخر بايت.</p>
<p>القاسم المشترك بين هذه الأخطاء الأربعة هو أن الشيفرة صحيحة من الناحية النحوية. الأخطاء موجودة في الافتراضات التي حملها المطور في رأسه، وليس في الفرق، ولا حتى في الكود المحيط. هذا تقريبًا هو المكان الذي تصل فيه مراجعة كود الذكاء الاصطناعي إلى سقفها اليوم.</p>
<h2 id="After-Finding-Bugs-Which-Model-is-the-Best-at-Fixing-Them" class="common-anchor-header">بعد العثور على الأخطاء، ما هو النموذج الأفضل في إصلاحها؟<button data-href="#After-Finding-Bugs-Which-Model-is-the-Best-at-Fixing-Them" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>في مراجعة التعليمات البرمجية، العثور على الأخطاء هو نصف العمل. والنصف الآخر هو إصلاحها. لذا، بعد جولات المناقشة، أضفتُ تقييم الأقران لقياس مدى فائدة اقتراحات الإصلاح التي يقدمها كل نموذج.</p>
<p>لقياس ذلك، أضفت جولة تقييم الأقران بعد المناظرة. افتتح كل نموذج جلسة جديدة وقام بدور الحكم المجهول، حيث قام كل نموذج بتقييم تقييمات النماذج الأخرى. تم تعيين النماذج الخمسة بشكل عشوائي للمراجع أ/ب/ج/د/هـ/هـ، لذا لم يعرف أي قاضٍ أي نموذج أنتج أي مراجعة. قام كل حكم بتسجيل النقاط على أربعة أبعاد، تم تقييمها من 1 إلى 10: الدقة والقدرة على العمل والعمق والوضوح.</p>
<table>
<thead>
<tr><th>النموذج</th><th>الدقة</th><th>قابلية التنفيذ</th><th>العمق</th><th>الوضوح</th><th>الإجمال</th></tr>
</thead>
<tbody>
<tr><td>كوين</td><td>8.6</td><td>8.6</td><td>8.5</td><td>8.7</td><td>8.6 (تعادل 1)</td></tr>
<tr><td>كلود</td><td>8.4</td><td>8.2</td><td>8.8</td><td>8.8</td><td>8.6 (تعادل 1)</td></tr>
<tr><td>الدستور الغذائي</td><td>7.7</td><td>7.6</td><td>7.1</td><td>7.8</td><td>7.5</td></tr>
<tr><td>الجوزاء</td><td>7.4</td><td>7.2</td><td>6.7</td><td>7.6</td><td>7.2</td></tr>
<tr><td>ميني ماكس</td><td>7.1</td><td>6.7</td><td>6.9</td><td>7.4</td><td>7.0</td></tr>
</tbody>
</table>
<p>تعادل كوين وكلود في المركز الأول بهامش واضح. سجل كلاهما نقاطًا عالية باستمرار في جميع الأبعاد الأربعة، في حين أن كوين وGemini وMiniMax سجلوا نقاطًا كاملة أو أكثر أقل من ذلك. والجدير بالذكر أن Gemini، الذي أثبت قيمته كشريك في اكتشاف الأخطاء لكلود في تحليل الاقتران، يحتل المرتبة القريبة من القاع في جودة المراجعة. من الواضح أن البراعة في اكتشاف المشكلات والبراعة في شرح كيفية إصلاحها مهارتان مختلفتان.</p>
<h2 id="Conclusion" class="common-anchor-header">الخلاصة<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p><strong>كلود</strong> هو الشخص الذي تثق به في أصعب المراجعات. فهو يعمل من خلال سلاسل المكالمات بأكملها، ويتبع مسارات منطقية عميقة، ويسحب السياق الخاص به دون الحاجة إلى إطعامه بالملعقة. في الأخطاء على مستوى النظام L3، لا شيء آخر يقترب من ذلك. قد يفرط في الثقة بالرياضيات في بعض الأحيان، ولكن عندما يثبت نموذج آخر خطأه، فإنه يمتلكها ويتابع أين تعطل منطقه. استخدمه للأكواد الأساسية والأخطاء التي لا يمكنك تفويتها.</p>
<p>يأتي<strong>الجوزاء</strong> ساخنًا. لديه آراء قوية حول أسلوب التعليمات البرمجية والمعايير الهندسية، وهو سريع في تأطير المشاكل هيكليًا. الجانب السلبي هو أنه غالبًا ما يبقى على السطح ولا يتعمق بما فيه الكفاية، وهذا هو السبب في أنه حصل على درجات منخفضة في تقييم الأقران. حيث يكتسب Gemini مكانته حقًا كمنافس: حيث يجبر النماذج الأخرى على إعادة التحقق من عملها مرة أخرى. يقترن مع كلود من أجل المنظور الهيكلي الذي يتخطاه كلود أحيانًا.</p>
<p>بالكاد ينطق<strong>كودكس</strong> بكلمة واحدة. ولكن عندما تفعل، فإنها مهمة. معدل إصابته للأخطاء الحقيقية مرتفع، ولديه موهبة في التقاط الشيء الوحيد الذي تجاوزه الجميع. في مثال العلاقات العامة رقم 44474، كان الدستور الغذائي هو النموذج الذي اكتشف مشكلة المفاتيح الأساسية ذات القيمة الصفرية التي أطلقت السلسلة بأكملها. فكر فيه على أنه المراجع التكميلي الذي يلتقط ما فات نموذجك الأساسي.</p>
<p><strong>كوين</strong> هو الأكثر شمولاً من بين الخمسة. تطابقت جودة مراجعاته مع كلود، وهو جيد بشكل خاص في تجميع وجهات النظر المختلفة في اقتراحات إصلاحية يمكنك العمل عليها بالفعل. كما أنه يتمتع بأعلى معدل اكتشاف L2 في وضع مساعدة السياق، مما يجعله افتراضيًا قويًا لمراجعات العلاقات العامة اليومية. نقطة الضعف الوحيدة: في المناظرات الطويلة متعددة الجولات، يفقد أحيانًا تتبع السياق السابق ويبدأ في إعطاء إجابات غير متسقة في الجولات اللاحقة.</p>
<p>كان<strong>MiniMax</strong> الأضعف في العثور على الأخطاء من تلقاء نفسه. من الأفضل استخدامه لملء مجموعة متعددة النماذج بدلاً من استخدامه كمراجع مستقل.</p>
<h2 id="Limitations-of-This-Experiment" class="common-anchor-header">حدود هذه التجربة<button data-href="#Limitations-of-This-Experiment" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>هناك بعض المحاذير لإبقاء هذه التجربة في منظورها الصحيح:</p>
<p><strong>حجم العينة صغير.</strong> لا يوجد سوى 15 من العلاقات العامة، وكلها من نفس مشروع Go/C+++G (Milvus). هذه النتائج لا يمكن تعميمها على جميع اللغات أو قواعد الشفرات. تعامل معها على أنها اتجاهية وليست نهائية.</p>
<p><strong>النماذج عشوائية بطبيعتها.</strong> يمكن أن يؤدي تشغيل نفس المطالبة مرتين إلى نتائج مختلفة. الأرقام في هذا المنشور هي لقطة واحدة، وليست قيمة متوقعة ثابتة. يجب أخذ تصنيفات النماذج الفردية على محمل الجد، على الرغم من أن الاتجاهات الأوسع (النقاش يتفوق على الأفراد، والنماذج المختلفة تتفوق في أنواع الأخطاء المختلفة) متسقة.</p>
<p><strong>تم إصلاح ترتيب التحدث.</strong> استخدمت المناظرة نفس الترتيب في جميع الجولات، مما قد يكون أثر على كيفية استجابة نماذج التحدث اللاحقة. يمكن لتجربة مستقبلية أن تجعل الترتيب عشوائيًا في كل جولة للتحكم في ذلك.</p>
<h2 id="Try-it-yourself" class="common-anchor-header">جرب بنفسك<button data-href="#Try-it-yourself" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>جميع الأدوات والبيانات من هذه التجربة مفتوحة المصدر:</p>
<ul>
<li><p><a href="https://github.com/liliu-z/magpie"><strong>Magpie</strong></a>: أداة مفتوحة المصدر تجمع سياق التعليمات البرمجية (سلاسل الاستدعاء، والعلاقات العامة ذات الصلة، والوحدات المتأثرة) وتنظم مناظرة متعددة النماذج لمراجعة التعليمات البرمجية.</p></li>
<li><p><a href="https://github.com/liliu-z/ai-code-review-arena"><strong>AI-CodeReview-Arena</strong></a>: خط أنابيب التقييم الكامل والتكوينات والنصوص البرمجية.</p></li>
<li><p><a href="https://github.com/liliu-z/ai-code-review-arena/blob/main/prs/manifest.yaml"><strong>حالات الاختبار</strong></a>: جميع العلاقات العامة الـ 15 مع الأخطاء المعروفة المشروحة.</p></li>
</ul>
<p>جاءت جميع الأخطاء في هذه التجربة من طلبات سحب حقيقية في <a href="https://github.com/milvus-io/milvus">Milvus،</a> وهي قاعدة بيانات متجهة مفتوحة المصدر مصممة لتطبيقات الذكاء الاصطناعي. لدينا مجتمع نشط جدًا على <a href="https://discord.com/invite/8uyFbECzPX">Discord</a> <a href="https://milvusio.slack.com/join/shared_invite/zt-3nntzngkz-gYwhrdSE4~76k0VMyBfD1Q#/shared-invite/email">وSlack،</a> ونود أن يقوم المزيد من الأشخاص بالبحث في الكود. وإذا انتهى بك الأمر إلى تشغيل هذا المعيار على قاعدة البيانات الخاصة بك، يرجى مشاركة النتائج! أشعر بالفضول حقًا لمعرفة ما إذا كانت الاتجاهات ثابتة عبر اللغات والمشاريع المختلفة.</p>
<h2 id="Keep-Reading" class="common-anchor-header">تابع القراءة<button data-href="#Keep-Reading" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ul>
<li><p><a href="https://milvus.io/blog/glm5-vs-minimax-m25-vs-gemini-3-deep-think.md">GLM-5 مقابل MiniMax M2.5 مقابل Gemini 3 Deep Think: أي نموذج يناسب مكدس عملاء الذكاء الاصطناعي لديك؟</a></p></li>
<li><p><a href="https://milvus.io/blog/adding-persistent-memory-to-claude-code-with-the-lightweight-memsearch-plugin.md">إضافة ذاكرة ثابتة إلى كود Claude مع المكوّن الإضافي memsearch خفيف الوزن</a></p></li>
<li><p><a href="https://milvus.io/blog/we-extracted-openclaws-memory-system-and-opensourced-it-memsearch.md">استخرجنا نظام ذاكرة OpenClaw وقمنا بفتح مصادره (memsearch)</a></p></li>
</ul>
