---
id: paper-reading-hm-ann-when-anns-meets-heterogeneous-memory.md
title: قراءة الورقة البحثية ｜HM-ANN عندما تلتقي ANNS مع الذاكرة غير المتجانسة
author: Jigao Luo
date: 2021-08-26T07:18:47.925Z
desc: HM-ANN بحث فعال عن أقرب جار بمليار نقطة على الذاكرة غير المتجانسة
cover: assets.zilliz.com/blog_cover_4a9807b9e0.png
tag: Engineering
canonicalUrl: >-
  https://zilliz.com/blog/paper-reading-hm-ann-when-anns-meets-heterogeneous-memory
---
<custom-h1>قراءة الورقة البحثية ｜ HM-ANN: عندما تلتقي الشبكة العصبية العصبية بذاكرة غير متجانسة</custom-h1><p><a href="https://proceedings.neurips.cc/paper/2020/file/788d986905533aba051261497ecffcbb-Paper.pdf">HM-ANN: البحث الفعال عن أقرب جار بمليار نقطة على الذاكرة غير المتجانسة</a> هي ورقة بحثية تم قبولها في مؤتمر 2020 حول أنظمة معالجة المعلومات العصبية<a href="https://nips.cc/Conferences/2020">(NeurIPS 2020</a>). في هذه الورقة البحثية، تم اقتراح خوارزمية جديدة للبحث عن التشابه القائم على الرسم البياني تسمى HM-ANN. تراعي هذه الخوارزمية كلاً من عدم تجانس الذاكرة وعدم تجانس البيانات في بيئة الأجهزة الحديثة. وتتيح خوارزمية HM-ANN إمكانية البحث عن التشابه على نطاق مليار على جهاز واحد بدون تقنيات الضغط. تمثّل الذاكرة غير المتجانسة (HM) مزيجًا من ذاكرة الوصول العشوائي الديناميكية الديناميكية (DRAM) السريعة ولكن الصغيرة وذاكرة ثابتة بطيئة ولكن كبيرة (PMem). تحقق HM-ANN زمن انتقال منخفض للبحث ودقة بحث عالية، خاصةً عندما لا يمكن أن تتسع مجموعة البيانات في DRAM. تتمتع الخوارزمية بميزة واضحة مقارنةً بحلول البحث التقريبي لأقرب جار (ANN) الحديثة.</p>
<custom-h1>الدافع</custom-h1><p>منذ نشأتها، طرحت خوارزميات البحث في الشبكة العصبية الاصطناعية مفاضلة أساسية بين دقة الاستعلام وزمن الاستجابة للاستعلام بسبب سعة DRAM المحدودة. لتخزين الفهارس في DRAM للوصول السريع إلى الاستعلام، من الضروري الحد من عدد نقاط البيانات أو تخزين المتجهات المضغوطة، وكلاهما يضر بدقة البحث. تتمتع الفهارس المستندة إلى الرسم البياني (على سبيل المثال: العالم الصغير القابل للتنقل الهرمي القابل للتنقل HNSW) بأداء وقت تشغيل استعلام ودقة استعلام فائقة. ومع ذلك، يمكن أن تستهلك هذه الفهارس أيضًا DRAM بمستوى 1 تيرابايت عند التشغيل على مجموعات بيانات بمليار حجم.</p>
<p>هناك حلول بديلة أخرى لتجنب السماح لـ DRAM بتخزين مجموعات بيانات بمليار حجم بتنسيق خام. عندما تكون مجموعة البيانات كبيرة جدًا بحيث لا يمكن وضعها في الذاكرة على جهاز واحد، يتم استخدام أساليب مضغوطة مثل تكميم نقاط مجموعة البيانات. ولكن عادةً ما يكون استرجاع هذه الفهارس مع مجموعة البيانات المضغوطة منخفضًا بسبب فقدان الدقة أثناء التكميم. يستكشف سوبرامانيا وآخرون [1] الاستفادة من محرك الأقراص ذي الحالة الصلبة (SSD) لتحقيق بحث على نطاق المليار في الشبكة العصبية الاصطناعية باستخدام جهاز واحد باستخدام نهج يسمى Disk-ANN، حيث يتم تخزين مجموعة البيانات الخام على SSD والتمثيل المضغوط على DRAM.</p>
<custom-h1>مقدمة في الذاكرة غير المتجانسة</custom-h1><p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/image_32_d26cfa9480.png" alt="1.png" class="doc-image" id="1.png" />
   </span> <span class="img-wrapper"> <span>1.png</span> </span></p>
<p>تمثل الذاكرة غير المتجانسة (HM) مزيجًا من ذاكرة DRAM سريعة ولكن صغيرة الحجم وذاكرة PMem بطيئة ولكن كبيرة. يعد DRAM جهازًا عاديًا يمكن العثور عليه في كل خادم حديث، ويكون الوصول إليه سريعًا نسبيًا. تعمل تقنيات PMem الجديدة، مثل وحدات الذاكرة الثابتة Intel® Optane™ DC DC Persistent Memory Modules، على سد الفجوة بين الفلاش المستند إلى NAND (SSD) وDDRAM، مما يزيل عنق الزجاجة في الإدخال/الإخراج. تتسم الذاكرة الثابتة PMem بالمتانة مثل أقراص SSD، ويمكن معالجتها مباشرةً بواسطة وحدة المعالجة المركزية، مثل الذاكرة. اكتشف رينين وآخرون [2] أن عرض النطاق الترددي للقراءة في PMem أقل بمقدار 2.6×، وعرض النطاق الترددي للكتابة أقل بمقدار 7.5× من DRAM في بيئة التجربة المهيأة.</p>
<custom-h1>تصميم HM-ANN</custom-h1><p>HM-ANN عبارة عن خوارزمية بحث دقيقة وسريعة على نطاق مليار خوارزمية بحث في الشبكة العصبية الاصطناعية تعمل على جهاز واحد دون ضغط. يعمم تصميم HM-ANN فكرة HNSW، التي يتناسب هيكلها الهرمي بشكل طبيعي مع HM. تتألف HNSW من طبقات متعددة - تحتوي الطبقة 0 فقط على مجموعة البيانات كاملة، وتحتوي كل طبقة متبقية على مجموعة فرعية من العناصر من الطبقة التي تحتها مباشرةً.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/2_25a1836e8b.png" alt="2.png" class="doc-image" id="2.png" />
   </span> <span class="img-wrapper"> <span>2.png</span> </span></p>
<ul>
<li>تستهلك العناصر الموجودة في الطبقات العليا، والتي تتضمن فقط مجموعات فرعية من مجموعة البيانات، جزءًا صغيرًا من مساحة التخزين بأكملها. هذه الملاحظة تجعلها مرشحة بشكل لائق لوضعها في DRAM. وبهذه الطريقة، من المتوقع أن تحدث غالبية عمليات البحث على HM-ANN في الطبقات العليا، مما يزيد من الاستفادة من خاصية الوصول السريع لـ DRAM. ومع ذلك، في حالات HNSW، تحدث معظم عمليات البحث في الطبقة السفلية.</li>
<li>تحمل الطبقة السفلية مجموعة البيانات بالكامل، مما يجعلها مناسبة لوضعها في PMem. نظرًا لأن الوصول إلى الطبقة 0 أبطأ، فمن الأفضل أن يتم الوصول إلى جزء صغير فقط من كل استعلام وتقليل تردد الوصول.</li>
</ul>
<h2 id="Graph-Construction-Algorithm" class="common-anchor-header">خوارزمية بناء الرسم البياني<button data-href="#Graph-Construction-Algorithm" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/3_dd9627c753.png" alt="3.png" class="doc-image" id="3.png" />
   </span> <span class="img-wrapper"> <span>3.png</span> </span></p>
<p>الفكرة الرئيسية في بناء HM-ANN هي إنشاء طبقات عليا عالية الجودة، من أجل توفير تنقل أفضل للبحث في الطبقة 0. وبالتالي فإن معظم الوصول إلى الذاكرة يحدث في DRAM، ويتم تقليل الوصول في PMem. ولجعل ذلك ممكناً، تحتوي خوارزمية بناء HM-ANN على مرحلة إدراج من أعلى إلى أسفل ومرحلة ترقية من أسفل إلى أعلى.</p>
<p>تُنشئ مرحلة الإدراج من أعلى لأسفل رسمًا بيانيًا لعالم صغير قابل للملاحة حيث يتم وضع الطبقة السفلية على PMem.</p>
<p>تقوم مرحلة الترقية من أسفل إلى أعلى بتعزيز النقاط المحورية من الطبقة السفلية لتشكيل الطبقات العليا التي يتم وضعها على DRAM دون فقدان الكثير من الدقة. إذا تم إنشاء إسقاط عالي الجودة للعناصر من الطبقة 0 في الطبقة 1، يعثر البحث في الطبقة 0 على أقرب جيران دقيقين للاستعلام مع عدد قليل من القفزات.</p>
<ul>
<li>بدلاً من استخدام الاختيار العشوائي لـ HNSW للترقية، يستخدم HM-ANN استراتيجية ترقية عالية الدرجة لترقية العناصر ذات الدرجة الأعلى في الطبقة 0 إلى الطبقة 1. بالنسبة للطبقات الأعلى، تقوم شبكة HM-ANN بترقية العقد ذات الدرجة العالية إلى الطبقة العليا بناءً على معدل الترقية.</li>
<li>تقوم HM-ANN بترقية المزيد من العُقد من الطبقة 0 إلى الطبقة 1 وتعيين حد أقصى لعدد أكبر من الجيران لكل عنصر في الطبقة 1. يتم تحديد عدد العقد في الطبقات العليا حسب مساحة DRAM المتاحة. نظرًا لأن الطبقة 0 غير مخزنة في DRAM، فإن جعل كل طبقة مخزنة في DRAM أكثر كثافة يزيد من جودة البحث.</li>
</ul>
<h2 id="Graph-Seach-Algorithm" class="common-anchor-header">خوارزمية بحث الرسم البياني<button data-href="#Graph-Seach-Algorithm" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/4_a5a7f29c93.png" alt="4.png" class="doc-image" id="4.png" />
   </span> <span class="img-wrapper"> <span>4.png</span> </span></p>
<p>تتألف خوارزمية البحث من مرحلتين: البحث السريع في الذاكرة والبحث المتوازي للطبقة 0 مع الجلب المسبق.</p>
<h3 id="Fast-memory-search" class="common-anchor-header">البحث السريع في الذاكرة</h3><p>كما هو الحال في HNSW، يبدأ البحث في DRAM عند نقطة الدخول في الطبقة العليا جدًا ثم يقوم بالبحث السريع من الأعلى إلى الطبقة 2. لتضييق مساحة البحث في الطبقة 0، تقوم HM-ANN بإجراء البحث في الطبقة 1 بميزانية بحث مع <code translate="no">efSearchL1</code> ، مما يحد من حجم القائمة المرشحة في الطبقة 1. يتم استخدام هؤلاء المرشحين في القائمة كنقاط دخول متعددة للبحث في الطبقة 0، لتحسين جودة البحث في الطبقة 0. بينما يستخدم HNSW نقطة دخول واحدة فقط، ويتم التعامل مع الفجوة بين الطبقة 0 والطبقة 1 بشكل خاص في HM-ANN أكثر من الفجوات بين أي طبقتين أخريين.</p>
<h3 id="Parallel-layer-0-search-with-prefetching" class="common-anchor-header">البحث المتوازي في الطبقة 0 مع الجلب المسبق</h3><p>في الطبقة السفلية، تقوم HM-ANN بتقسيم المرشحين المذكورين أعلاه بالتساوي من البحث في الطبقة 1 وترى أنهم نقاط دخول لإجراء بحث متوازي متعدد البداية 1 مع الجلب المسبق. يتم جمع أفضل المرشحين من كل بحث للعثور على أفضل المرشحين. كما هو معروف، فإن الانتقال من الطبقة 1 إلى الطبقة 0 هو بالضبط الانتقال إلى PMem. يخفي البحث المتوازي زمن انتقال PMem ويستفيد بأفضل استخدام لعرض النطاق الترددي للذاكرة، لتحسين جودة البحث دون زيادة وقت البحث.</p>
<p>يطبّق HM-ANN مخزنًا مؤقتًا مُدارًا برمجيًا في DRAM لجلب البيانات مسبقًا من PMem قبل الوصول إلى الذاكرة. عند البحث في الطبقة 1، تقوم HM-ANN بنسخ العناصر المجاورة للعناصر المرشحة في <code translate="no">efSearchL1</code> واتصالات العناصر المجاورة في الطبقة 1 بشكل غير متزامن من PMem إلى المخزن المؤقت. عندما يحدث البحث في الطبقة 0، يكون جزء من البيانات التي سيتم الوصول إليها قد تم ضبطه مسبقًا في DRAM، مما يخفي زمن الوصول إلى PMem ويؤدي إلى وقت استعلام أقصر. يتطابق ذلك مع هدف تصميم HM-ANN، حيث تحدث معظم عمليات الوصول إلى الذاكرة في DRAM ويتم تقليل عمليات الوصول إلى الذاكرة في PMem.</p>
<custom-h1>التقييم</custom-h1><p>في هذه الورقة، تم إجراء تقييم شامل. تم إجراء جميع التجارب على جهاز مزود بمعالج Intel Xeon Gold 6252 CPU@2.3GHz. ويستخدم DDR4 (96 جيجابايت) كذاكرة سريعة و Optane DC PMM (1.5 تيرابايت) كذاكرة بطيئة. تم تقييم خمس مجموعات بيانات: BIGANN، وDEEP1B، وSIFT1M، وDEEP1M، وGIST1M. بالنسبة للاختبارات على نطاق المليار، تم تضمين المخططات التالية: الأساليب القائمة على التكميم على نطاق المليار (IMI+OPQ وL&amp;C)، والأساليب غير القائمة على الضغط (HNSW وNSG).</p>
<h2 id="Billion-scale-algorithm-comparison" class="common-anchor-header">مقارنة خوارزمية على نطاق المليار<button data-href="#Billion-scale-algorithm-comparison" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/5_4297db66a9.png" alt="5.png" class="doc-image" id="5.png" />
   </span> <span class="img-wrapper"> <span>5.png</span> </span></p>
<p>في الجدول 1، تتم مقارنة وقت الإنشاء والتخزين لمختلف الفهارس القائمة على الرسم البياني. يستغرق HNSW أقصر وقت بناء، وتحتاج HM-ANN إلى وقت إضافي بنسبة 8% من HNSW. أما من حيث استخدام التخزين بالكامل، فإن فهارس HM-ANN أكبر بنسبة 5-13% من HSNW، لأنها تروج لمزيد من العقد من الطبقة 0 إلى الطبقة 1.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/6_f363e64d3f.png" alt="6.png" class="doc-image" id="6.png" />
   </span> <span class="img-wrapper"> <span>6.png</span> </span></p>
<p>في الشكل 1، يتم تحليل أداء الاستعلام للفهارس المختلفة. يُظهر الشكل 1 (أ) و (ب) أن HM-ANN يحقق أعلى نسبة استرجاع &gt; 95% خلال 1 مللي ثانية. يوضح الشكلان 1 © و (د) أن HM-ANN يحقق أعلى نسبة استرجاع لـ 100 %&gt; 90% خلال 4 مللي ثانية. توفر شبكة HM-ANN أفضل أداء في زمن الاستجابة مقابل الاستدعاء مقارنةً بجميع الأساليب الأخرى.</p>
<h2 id="Million-scale-algorithm-comparison" class="common-anchor-header">مقارنة الخوارزمية على نطاق المليون<button data-href="#Million-scale-algorithm-comparison" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/7_a5c23de240.png" alt="7.png" class="doc-image" id="7.png" />
   </span> <span class="img-wrapper"> <span>7.png</span> </span></p>
<p>في الشكل 2، يتم تحليل أداء الاستعلام لمختلف الفهارس في إعداد DRAM خالص. يتم تقييم HNSW، وNSG، وHM-ANN مع مجموعات البيانات الثلاث ذات المقياس المليوني التي تتناسب مع DRAM. لا يزال HM-ANN يحقق أداء استعلام أفضل من HNSW. والسبب في ذلك هو أن العدد الإجمالي لعمليات حساب المسافة من HM-ANN أقل (بمتوسط 850/استعلام) من HNSW (بمتوسط 900/استعلام) لتحقيق هدف الاستدعاء بنسبة 99%.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/image_33_f99d31f322.png" alt="8.png" class="doc-image" id="8.png" />
   </span> <span class="img-wrapper"> <span>8.png</span> </span></p>
<h2 id="Effectiveness-of-high-degree-promotion" class="common-anchor-header">فعالية الترقية عالية الدرجة<button data-href="#Effectiveness-of-high-degree-promotion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>في الشكل 3، تتم مقارنة استراتيجيات الترقية العشوائية والترقية عالية الدرجة في نفس التكوين. تتفوق الترقية عالية الدرجة على خط الأساس. تؤدي الترقية عالية الدرجة 1.8 مرة و4.3 مرة و3.9 مرة أسرع من الترقية العشوائية للوصول إلى أهداف الاستدعاء بنسبة 95% و99% و99.5% على التوالي.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/image_34_3af47e0842.png" alt="10.png" class="doc-image" id="10.png" />
   </span> <span class="img-wrapper"> <span>10.png</span> </span></p>
<h2 id="Performance-benefit-of-memory-management-techniques" class="common-anchor-header">فائدة أداء تقنيات إدارة الذاكرة<button data-href="#Performance-benefit-of-memory-management-techniques" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>يحتوي الشكل 5 على سلسلة من الخطوات بين HNSW و HM-ANN لتوضيح كيفية مساهمة كل تحسين من تحسينات HM-ANN في تحسيناته. يرمز BP إلى الترقية من الأسفل إلى الأعلى أثناء بناء الفهرس. يرمز PL0 إلى البحث المتوازي من الطبقة 0، بينما يرمز DP إلى الجلب المسبق للبيانات من PMem إلى DRAM. خطوة بخطوة، يتم دفع أداء البحث في HM-ANN خطوة بخطوة.</p>
<custom-h1>خاتمة</custom-h1><p>تقوم خوارزمية جديدة للفهرسة والبحث القائمة على الرسم البياني تسمى HM-ANN، بتعيين التصميم الهرمي للشبكات العصبية الشبكية العصبية القائمة على الرسم البياني مع عدم تجانس الذاكرة في HM. تُظهر التقييمات أن HM-ANN تنتمي إلى أحدث الفهارس الجديدة في مجموعات بيانات بمليار نقطة.</p>
<p>نلاحظ وجود اتجاه في الأوساط الأكاديمية وكذلك في الصناعة، حيث يتم التركيز على بناء الفهارس على أجهزة التخزين الدائمة. لتخفيف الضغط على DRAM، فإن Disk-ANN [1] هو فهرس مبني على أقراص التخزين الثابتة، والذي يكون إنتاجه أقل بكثير من PMem. ومع ذلك، لا يزال بناء HM-ANN يستغرق بضعة أيام، حيث لا توجد فروق كبيرة مقارنةً بـ Disk-ANN. نحن نعتقد أنه من الممكن تحسين وقت بناء HM-ANN، عندما نستخدم خصائص PMem بعناية أكبر، على سبيل المثال أن نكون على دراية بتفاصيل PMem (256 بايت) واستخدام تعليمات التدفق لتجاوز خطوط التخزين المؤقت. نعتقد أيضًا أنه سيكون هناك المزيد من الأساليب المقترحة مع أجهزة تخزين متينة في المستقبل.</p>
<custom-h1>المرجع</custom-h1><p>[1]: سوهاس جايارام سوبرامانيا وديفريت وروهان كاديكودي ورافيشانكار كريشاسوامي ورافيشانكار كريشاسوامي: DiskANN: بحث دقيق سريع دقيق بمليار نقطة لأقرب جار على عقدة واحدة، NIPS، 2019</p>
<p><a href="https://www.microsoft.com/en-us/research/publication/diskann-fast-accurate-billion-point-nearest-neighbor-search-on-a-single-node/">DiskANN: بحث سريع ودقيق بمليار نقطة لأقرب جار على عقدة واحدة - Microsoft Research</a></p>
<p><a href="https://papers.nips.cc/paper/2019/hash/09853c7fb1d3f8ee67a61b6bf4a7f8e6-Abstract.html">DiskANN: بحث دقيق سريع بمليار نقطة لأقرب جار على عقدة واحدة</a></p>
<p>[2]: ألكسندر فان رينن ولوكاس فوغل وفيكتور ليس وتوماس نيومان وألفونس كيمبر: أساسيات الإدخال/الإخراج للذاكرة الثابتة، CoRR &amp; DaMoN، 2019</p>
<p><a href="https://dl.acm.org/doi/abs/10.1145/3329785.3329930">https://dl.acm.org/doi/abs/10.1145/3329785.3329930</a></p>
<p><a href="https://arxiv.org/abs/1904.01614">أساسيات الإدخال/الإخراج للذاكرة الثابتة</a></p>
