---
id: >-
  is-rag-become-outdated-now-long-running-agents-like-claude-cowork-are-emerging.md
title: >-
  هل أصبحت RAG قديمة العهد الآن مع ظهور وكلاء يعملون منذ فترة طويلة مثل كلود
  كورك؟
author: Min Yin
date: 2026-1-27
desc: >-
  تحليل متعمق لذاكرة كلود كورك طويلة الأمد، وذاكرة الوكيل القابلة للكتابة،
  ومقايضات RAG، ولماذا لا تزال قواعد البيانات المتجهة مهمة.
cover: assets.zilliz.com/RAG_vs_Long_Running_Agents_fc67810cf8.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database, claude, RAG'
meta_keywords: >-
  Claude Cowork long-term memory, RAG vs Claude Cowork, vector databases for AI
  agents
meta_title: |
  RAG vs Long-Running Agents: Is RAG Obsolete? 
origin: >-
  https://milvus.io/blog/is-rag-become-outdated-now-long-running-agents-like-claude-cowork-are-emerging.md
---
<p><a href="https://support.claude.com/en/articles/13345190-getting-started-with-cowork">Claude Cowork</a> هي ميزة وكيل جديدة في تطبيق Claude Desktop. من وجهة نظر المطورين، هو في الأساس عداء مهام آلي ملفوف حول النموذج: يمكنه قراءة وتعديل وإنشاء ملفات محلية، ويمكنه تخطيط مهام متعددة الخطوات دون الحاجة إلى المطالبة يدويًا بكل خطوة. فكّر في الأمر على أنه نفس الحلقة الموجودة خلف Claude Code، ولكن مكشوف على سطح المكتب بدلًا من المنصة.</p>
<p>القدرة الرئيسية لـ Cowork هي قدرته على العمل لفترات طويلة دون فقدان الحالة. فهي لا تصطدم بمهلة المحادثة المعتادة أو إعادة تعيين السياق. يمكنه الاستمرار في العمل وتتبع النتائج الوسيطة وإعادة استخدام المعلومات السابقة عبر الجلسات. هذا يعطي انطباعًا بوجود "ذاكرة طويلة الأمد"، على الرغم من أن الآليات الأساسية تشبه إلى حد كبير حالة المهمة المستمرة + الترحيل السياقي. في كلتا الحالتين، تختلف التجربة عن نموذج الدردشة التقليدي، حيث يتم إعادة تعيين كل شيء ما لم تقم ببناء طبقة الذاكرة الخاصة بك.</p>
<p>هذا يطرح سؤالين عمليين للمطورين:</p>
<ol>
<li><p><strong>إذا كان بإمكان النموذج أن يتذكر المعلومات السابقة بالفعل، فأين لا يزال RAG أو RAG الوكيل مناسبًا؟ هل سيتم استبدال RAG؟</strong></p></li>
<li><p><strong>إذا كنا نريد وكيلًا محليًا على غرار Cowork، كيف يمكننا تنفيذ الذاكرة طويلة المدى بأنفسنا؟</strong></p></li>
</ol>
<p>تتناول بقية هذه المقالة هذه الأسئلة بالتفصيل وتشرح كيف تتناسب قواعد البيانات المتجهة مع مشهد "الذاكرة النموذجية" الجديد هذا.</p>
<h2 id="Claude-Cowork-vs-RAG-What’s-the-Difference" class="common-anchor-header">كلود كاورك مقابل RAG: ما الفرق بينهما؟<button data-href="#Claude-Cowork-vs-RAG-What’s-the-Difference" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>كما ذكرت سابقًا، كلود كاوورك هو وضع وكيل داخل كلود ديسك توب يمكنه قراءة وكتابة الملفات المحلية، وتقسيم المهام إلى خطوات أصغر، ومواصلة العمل دون فقدان الحالة. يحتفظ بسياق العمل الخاص به، لذلك لا تتم إعادة تعيين المهام متعددة الساعات مثل جلسة الدردشة العادية.</p>
<p>يحل<strong>RAG</strong> (التوليد المعزز للاسترجاع) مشكلة مختلفة: منح النموذج إمكانية الوصول إلى المعرفة الخارجية. يمكنك فهرسة بياناتك في قاعدة بيانات متجهة، واسترداد الأجزاء ذات الصلة لكل استعلام، وتغذيتها في النموذج. يُستخدم على نطاق واسع لأنه يوفر لتطبيقات LLM شكلاً من أشكال "الذاكرة طويلة المدى" للمستندات والسجلات وبيانات المنتجات وغيرها.</p>
<p>إذا كان كلا النظامين يساعدان النموذج على "التذكر"، فما الفرق الفعلي؟</p>
<h3 id="How-Cowork-Handles-Memory" class="common-anchor-header">كيف يتعامل Cowork مع الذاكرة</h3><p>ذاكرة كاوورك للقراءة والكتابة. يحدد الوكيل المعلومات من المهمة الحالية أو المحادثة الحالية ذات الصلة، ويخزنها كمدخلات ذاكرة، ويسترجعها لاحقًا مع تقدم المهمة. يسمح ذلك لـ Cowork بالحفاظ على الاستمرارية عبر عمليات سير العمل طويلة الأمد - خاصةً تلك التي تنتج حالة وسيطة جديدة أثناء تقدمها.</p>
<h3 id="How-RAG-and-Agentic-RAG-Handle-Memory" class="common-anchor-header">كيفية تعامل RAG و RAG العميل مع الذاكرة</h3><p>إن RAG القياسي هو استرجاع يحركه الاستعلام: يسأل المستخدم عن شيء ما، ويقوم النظام بجلب المستندات ذات الصلة، ويستخدمها النموذج للإجابة. وتبقى مجموعة الاسترجاع مستقرة ومُنسخة، ويتحكم المطورون فيما يدخلها بالضبط.</p>
<p>يوسّع نموذج الاسترجاع العميل الحديث هذا النمط. يمكن للنموذج أن يقرر متى يتم استرجاع المعلومات وما الذي يجب استرجاعه وكيفية استخدامه أثناء تخطيط أو تنفيذ سير العمل. يمكن لهذه الأنظمة تشغيل المهام الطويلة واستدعاء الأدوات، على غرار Cowork. ولكن حتى مع RAG الوكيل، تظل طبقة الاسترجاع موجهة نحو المعرفة وليس نحو الحالة. يسترجع الوكيل الحقائق الموثوقة؛ فهو لا يكتب حالة مهمته المتطورة في مجموعة البيانات.</p>
<p>طريقة أخرى للنظر إلى الأمر:</p>
<ul>
<li><p><strong>تعتمد ذاكرة كاوورك على المهام:</strong> يقوم الوكيل بكتابة وقراءة حالته المتطورة الخاصة به.</p></li>
<li><p><strong>أما RAG فهي مدفوعة بالمعرفة:</strong> يسترجع النظام المعلومات الثابتة التي يجب أن يعتمد عليها النموذج.</p></li>
</ul>
<h2 id="Reverse-Engineering-Claude-Cowork-How-It-Builds-Long-Running-Agent-Memory" class="common-anchor-header">الهندسة العكسية كلود كلود كاورك: كيف يبني ذاكرة عميل طويلة الأمد<button data-href="#Reverse-Engineering-Claude-Cowork-How-It-Builds-Long-Running-Agent-Memory" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>يحظى Cowork بالكثير من الضجيج لأنه يتعامل مع المهام متعددة الخطوات دون أن ينسى باستمرار ما كان يقوم به. من وجهة نظر المطور، أتساءل <strong>كيف يحافظ على الحالة عبر هذه الجلسات الطويلة؟</strong> لم تنشر أنثروبيك الأجزاء الداخلية، ولكن استنادًا إلى تجارب المطورين السابقة مع وحدة ذاكرة كلود، يمكننا تجميع نموذج ذهني لائق.</p>
<p>يبدو أن Claude يعتمد على إعداد هجين: <strong>طبقة ذاكرة طويلة الأمد ثابتة بالإضافة إلى أدوات استرجاع عند الطلب.</strong> بدلاً من حشو المحادثة الكاملة في كل طلب، يسحب كلود بشكل انتقائي السياق السابق فقط عندما يقرر أنه ذو صلة. يتيح ذلك للنموذج الحفاظ على دقة عالية دون أن يستهلك الرموز في كل مرة.</p>
<p>إذا حللت بنية الطلب، سيبدو تقريبًا هكذا:</p>
<pre><code translate="no">[<span class="hljs-meta">0</span>] Static system instructions
[<span class="hljs-meta">1</span>] <span class="hljs-function">User <span class="hljs-title">memory</span> (<span class="hljs-params"><span class="hljs-built_in">long</span>-term</span>)
[2] Retrieved / pruned conversation history
[3] Current user message
</span><button class="copy-code-btn"></button></code></pre>
<p>السلوك المثير للاهتمام ليس البنية نفسها - بل كيف يقرر النموذج ما يجب تحديثه ومتى يتم الاسترجاع.</p>
<h3 id="User-Memory-The-Persistent-Layer" class="common-anchor-header">ذاكرة المستخدم: الطبقة الدائمة</h3><p>يحتفظ كلود بمخزن ذاكرة طويل الأمد يتم تحديثه بمرور الوقت. وعلى عكس نظام ذاكرة ChatGPT الأكثر قابلية للتنبؤ، يبدو نظام Claude أكثر "حيوية". يخزن الذكريات في كتل تشبه XML ويقوم بتحديثها بطريقتين:</p>
<ul>
<li><p><strong>تحديثات ضمنية:</strong> في بعض الأحيان يقرر النموذج أن شيئًا ما هو تفضيل أو حقيقة مستقرة ويكتبها بهدوء إلى الذاكرة. هذه التحديثات ليست فورية؛ تظهر بعد عدة أدوار، ويمكن أن تتلاشى الذكريات القديمة إذا اختفت المحادثة ذات الصلة.</p></li>
<li><p><strong>تحديثات صريحة:</strong> يمكن للمستخدمين تعديل الذاكرة مباشرةً باستخدام الأداة <code translate="no">memory_user_edits</code> ("تذكر س"، "انسَ ص"). هذه الكتابات فورية وتتصرف مثل عملية CRUD.</p></li>
</ul>
<p>تقوم كلود بتشغيل الاستدلال في الخلفية لتقرير ما يستحق الاستمرار، ولا تنتظر تعليمات صريحة.</p>
<h3 id="Conversation-Retrieval-The-On-Demand-Part" class="common-anchor-header">استرجاع المحادثة: الجزء عند الطلب</h3><p><em>لا</em> يحتفظ كلود بملخص متجدد مثل العديد من أنظمة LLM. بدلًا من ذلك، لديه مجموعة أدوات من دوال الاسترجاع التي يمكنه استدعاؤها كلما اعتقد أنه يفتقد السياق. لا تحدث مكالمات الاسترجاع هذه في كل دور - حيث يقوم النموذج بتشغيلها بناءً على حكمه الداخلي الخاص.</p>
<p>الدالة البارزة هي <code translate="no">conversation_search</code>. عندما يقول المستخدم شيئًا مبهمًا مثل "هذا المشروع من الشهر الماضي"، غالبًا ما يطلق كلود هذه الأداة لاستخراج المنعطفات ذات الصلة. ما يلاحظ أنه لا يزال يعمل عندما تكون الصياغة غامضة أو بلغة مختلفة. هذا يعني بوضوح</p>
<ul>
<li><p>نوعًا من المطابقة الدلالية (التضمينات)</p></li>
<li><p>ربما مقترنة بالتطبيع أو الترجمة الخفيفة</p></li>
<li><p>البحث عن الكلمات الرئيسية في طبقات من أجل الدقة</p></li>
</ul>
<p>في الأساس، هذا يشبه إلى حد كبير نظام RAG مصغر مدمج داخل مجموعة أدوات النموذج.</p>
<h3 id="How-Claude’s-Retrieval-Behavior-Differs-From-Basic-History-Buffers" class="common-anchor-header">كيف يختلف سلوك كلود في الاسترجاع عن مخازن السجل الأساسية</h3><p>من الاختبارات والسجلات، تبرز بعض الأنماط:</p>
<ul>
<li><p><strong>الاسترجاع ليس تلقائيًا.</strong> يختار النموذج متى يستدعيها. إذا اعتقد أن لديه بالفعل سياقًا كافيًا، فلن يزعج نفسه.</p></li>
<li><p><strong>تتضمن الأجزاء المسترجعة</strong> <em>كلاً من</em> <strong>رسائل المستخدم والمساعد.</strong> هذا مفيد - فهو يحافظ على فارق بسيط أكثر من ملخصات المستخدم فقط.</p></li>
<li><p><strong>يبقى استخدام الرمز المميز عاقلاً.</strong> نظرًا لعدم حقن السجل في كل دور، لا تتضخم الجلسات الطويلة بشكل غير متوقع.</p></li>
</ul>
<p>بشكل عام، يبدو الأمر بشكل عام وكأنه نموذج LLM معزز بالاسترجاع، باستثناء أن الاسترجاع يحدث كجزء من حلقة التفكير الخاصة بالنموذج.</p>
<p>هذه البنية ذكية، ولكنها ليست مجانية:</p>
<ul>
<li><p>يضيف الاسترجاع وقتًا إضافيًا ومزيدًا من "الأجزاء المتحركة" (الفهرسة والترتيب وإعادة الترتيب).</p></li>
<li><p>يخطئ النموذج أحيانًا في الحكم على ما إذا <em>كان</em> يحتاج إلى السياق أم لا، مما يعني أنك ترى "النسيان الكلاسيكي" على الرغم من توفر البيانات.</p></li>
<li><p>يصبح التصحيح أكثر تعقيدًا لأن سلوك النموذج يعتمد على مشغلات الأداة غير المرئية، وليس فقط المدخلات السريعة.</p></li>
</ul>
<h3 id="Claude-Cowork-vs-Claude-Codex-in-handling-long-term-memory" class="common-anchor-header">كلود كورك مقابل كلود كودكس في التعامل مع الذاكرة طويلة المدى</h3><p>على النقيض من إعداد Claude المثقل بالاسترجاع، يتعامل ChatGPT مع الذاكرة بطريقة أكثر تنظيماً وقابلية للتنبؤ. بدلاً من القيام بعمليات بحث دلالية أو التعامل مع المحادثات القديمة كمخزن متجه صغير، يقوم ChatGPT بحقن الذاكرة مباشرةً في كل جلسة من خلال المكونات التالية ذات الطبقات</p>
<ul>
<li><p>ذاكرة المستخدم</p></li>
<li><p>البيانات الوصفية للجلسة</p></li>
<li><p>رسائل الجلسة الحالية</p></li>
</ul>
<p><strong>ذاكرة المستخدم</strong></p>
<p>ذاكرة المستخدم هي طبقة التخزين الرئيسية طويلة الأجل - الجزء الذي يستمر عبر الجلسات ويمكن للمستخدم تحريره. وهي تخزن أشياء قياسية جدًا: الاسم، والخلفية، والمشاريع الجارية، وتفضيلات التعلم، وهذا النوع من الأشياء. يتم حقن هذه الكتلة في كل محادثة جديدة في البداية، لذلك يبدأ النموذج دائمًا برؤية متسقة للمستخدم.</p>
<p>يقوم ChatGPT بتحديث هذه الطبقة بطريقتين:</p>
<ul>
<li><p><strong>تحديثات صريحة:</strong> يمكن للمستخدمين إخبار النموذج أن "يتذكر هذا" أو "ينسى ذلك"، وتتغير الذاكرة على الفور. هذه في الأساس واجهة برمجة تطبيقات CRUD يعرضها النموذج من خلال اللغة الطبيعية.</p></li>
<li><p><strong>تحديثات ضمنية:</strong> إذا اكتشف النموذج معلومات تناسب قواعد OpenAI للذاكرة طويلة المدى - مثل المسمى الوظيفي أو التفضيلات - ولم يقم المستخدم بتعطيل الذاكرة، فسيضيفها بهدوء من تلقاء نفسه.</p></li>
</ul>
<p>من وجهة نظر المطورين، هذه الطبقة بسيطة وحتمية وسهلة التفكير. لا عمليات بحث مضمنة، ولا إرشادات حول ما يجب جلبه.</p>
<p><strong>البيانات الوصفية لجلسة العمل</strong></p>
<p>تقع البيانات الوصفية لجلسة العمل في الطرف الآخر من الطيف. إنها قصيرة العمر، وغير ثابتة، ويتم حقنها مرة واحدة فقط في بداية الجلسة. فكر فيها كمتغيرات بيئة للمحادثة. يتضمن ذلك أشياء مثل</p>
<ul>
<li><p>الجهاز الذي تستخدمه</p></li>
<li><p>حالة الحساب/الاشتراك</p></li>
<li><p>أنماط الاستخدام التقريبي (الأيام النشطة، توزيع النموذج، متوسط طول المحادثة)</p></li>
</ul>
<p>تساعد هذه البيانات الوصفية النموذج على تشكيل الاستجابات للبيئة الحالية - على سبيل المثال، كتابة إجابات أقصر على الهاتف المحمول - دون تلويث الذاكرة طويلة المدى.</p>
<p><strong>رسائل الجلسة الحالية</strong></p>
<p>هذا هو تاريخ النافذة المنزلقة القياسية: جميع الرسائل في المحادثة الحالية حتى الوصول إلى حد الرمز المميز. عندما تصبح النافذة كبيرة جدًا، يتم إسقاط المنعطفات الأقدم تلقائيًا.</p>
<p>والأهم من ذلك أن هذا الإخلاء <strong>لا</strong> يمس ذاكرة المستخدم أو الملخصات العابرة للجلسات. فقط تاريخ المحادثة المحلي يتقلص.</p>
<p>يظهر الاختلاف الأكبر عن Claude في كيفية تعامل ChatGPT مع المحادثات "الحديثة وليس الحالية". سيتصل كلود بأداة بحث لاسترداد السياق السابق إذا اعتقد أنه ذو صلة. لا يقوم ChatGPT بذلك.</p>
<p>بدلاً من ذلك، يحتفظ ChatGPT <strong>بملخص</strong> خفيف للغاية <strong>عبر الجلسات</strong> يتم حقنه في كل محادثة. بعض التفاصيل الأساسية حول هذه الطبقة:</p>
<ul>
<li><p>تلخص <strong>رسائل المستخدم فقط،</strong> وليس رسائل المساعدين.</p></li>
<li><p>يخزن مجموعة صغيرة جدًا من العناصر - 15 عنصرًا تقريبًا - ما يكفي فقط لالتقاط المواضيع أو الاهتمامات الثابتة.</p></li>
<li><p><strong>لا</strong> تقوم <strong>بحساب التضمين ولا ترتيب التشابه، ولا تقوم باستدعاءات الاسترجاع</strong>. إنه في الأساس سياق تم مضغه مسبقًا، وليس بحثًا ديناميكيًا.</p></li>
</ul>
<p>من من منظور هندسي، يستبدل هذا النهج المرونة بإمكانية التنبؤ. لا توجد فرصة لحدوث فشل استرجاع غريب، ويبقى زمن انتقال الاستدلال مستقرًا لأنه لا يتم جلب أي شيء على الفور. الجانب السلبي هو أن ChatGPT لن يسحب بعض الرسائل العشوائية من ستة أشهر مضت ما لم يتم إدخالها في طبقة الملخص.</p>
<h2 id="Challenges-to-Making-Agent-Memory-Writable" class="common-anchor-header">تحديات جعل ذاكرة الوكيل قابلة للكتابة<button data-href="#Challenges-to-Making-Agent-Memory-Writable" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>عندما ينتقل الوكيل من <strong>ذاكرة للقراءة فقط</strong> (RAG النموذجية) إلى <strong>ذاكرة قابلة للكتابة - حيث</strong>يمكنه تسجيل إجراءات المستخدم وقراراته وتفضيلاته - فإن التعقيد يقفز بسرعة. أنت لم تعد تسترجع المستندات فقط؛ أنت تحافظ على حالة متنامية يعتمد عليها النموذج.</p>
<p>يجب على نظام الذاكرة القابلة للكتابة أن يحل ثلاث مشاكل حقيقية:</p>
<ol>
<li><p><strong>ماذا تتذكر:</strong> يحتاج الوكيل إلى قواعد لتحديد الأحداث أو التفضيلات أو الملاحظات التي تستحق الاحتفاظ بها. بدون ذلك، إما أن ينفجر حجم الذاكرة أو تمتلئ بالضوضاء.</p></li>
<li><p><strong>كيفية تخزين الذاكرة وترتيبها:</strong> ليست كل الذاكرة متساوية. فالعناصر الحديثة والحقائق طويلة الأجل والملاحظات سريعة الزوال تحتاج جميعها إلى طبقات تخزين وسياسات احتفاظ واستراتيجيات فهرسة مختلفة.</p></li>
<li><p><strong>كيفية الكتابة بسرعة دون تعطيل الاسترجاع:</strong> يجب كتابة الذاكرة باستمرار، لكن التحديثات المتكررة يمكن أن تؤدي إلى تدهور جودة الفهرس أو إبطاء الاستعلامات إذا لم يكن النظام مصممًا للإدخالات عالية الإنتاجية.</p></li>
</ol>
<h3 id="Challenge-1-What-Is-Worth-Remembering" class="common-anchor-header">التحدي 1: ما الذي يستحق التذكر؟</h3><p>لا يجب أن ينتهي كل ما يفعله المستخدم في الذاكرة طويلة المدى. إذا قام شخص ما بإنشاء ملف مؤقت وحذفه بعد خمس دقائق، فإن تسجيل ذلك إلى الأبد لا يساعد أي شخص. هذه هي الصعوبة الأساسية: <strong>كيف يقرر النظام ما هو مهم بالفعل؟</strong></p>
<p><strong>(1) الطرق الشائعة للحكم على الأهمية</strong></p>
<p>تعتمد فرق العمل عادةً على مزيج من الاستدلال:</p>
<ul>
<li><p><strong>المستند إلى الوقت</strong>: الإجراءات الحديثة أكثر أهمية من الإجراءات القديمة</p></li>
<li><p><strong>قائم على التكرار</strong>: الملفات أو الإجراءات التي يتم الوصول إليها بشكل متكرر أكثر أهمية</p></li>
<li><p><strong>على أساس النوع</strong>: بعض الأشياء بطبيعتها أكثر أهمية (على سبيل المثال، ملفات تكوين المشروع مقابل ملفات ذاكرة التخزين المؤقت)</p></li>
</ul>
<p><strong>(2) عند تعارض القواعد</strong></p>
<p>غالبًا ما تتعارض هذه الإشارات. ملف تم إنشاؤه الأسبوع الماضي ولكن تم تحريره بكثافة اليوم - هل يجب أن يفوز العمر أم النشاط؟ لا توجد إجابة واحدة "صحيحة"، وهذا هو السبب في أن تسجيل الأهمية يميل إلى الفوضى بسرعة.</p>
<p><strong>(3) كيف تساعد قواعد البيانات المتجهة</strong></p>
<p>تمنحك قواعد بيانات المتجهات آليات لفرض قواعد الأهمية دون تنظيف يدوي:</p>
<ul>
<li><p><strong>TTL:</strong> يمكن لـ Milvus إزالة البيانات تلقائيًا بعد وقت محدد</p></li>
<li><p><strong>الاضمحلال:</strong> يمكن تقليل ترجيح المتجهات الأقدم حتى تتلاشى بشكل طبيعي من الاسترجاع</p></li>
</ul>
<h3 id="Challenge-2-Memory-Tiering-in-Practice" class="common-anchor-header">التحدي 2: تصنيف الذاكرة في الممارسة العملية</h3><p>كلما طالت مدة تشغيل العملاء، تتراكم الذاكرة. إن الاحتفاظ بكل شيء في التخزين السريع غير مستدام، لذا يحتاج النظام إلى طريقة لتقسيم الذاكرة إلى طبقات <strong>ساخنة</strong> (يتم الوصول إليها بشكل متكرر) <strong>وباردة</strong> (نادراً ما يتم الوصول إليها).</p>
<p><strong>(1) تحديد متى تصبح الذاكرة باردة</strong></p>
<p>في هذا النموذج، تشير <em>الذاكرة الساخنة</em> إلى البيانات المحفوظة في ذاكرة الوصول العشوائي للوصول إليها بوقت وصول منخفض، بينما تشير <em>الذاكرة الباردة</em> إلى البيانات المنقولة إلى القرص أو تخزين الكائنات لتقليل التكلفة.</p>
<p>يمكن التعامل مع تحديد متى تصبح الذاكرة باردة بطرق مختلفة. تستخدم بعض الأنظمة نماذج خفيفة الوزن لتقدير الأهمية الدلالية للإجراء أو الملف بناءً على معناه واستخدامه الأخير. ويعتمد البعض الآخر على منطق بسيط قائم على القواعد، مثل نقل الذاكرة التي لم يتم الوصول إليها لمدة 30 يومًا أو لم تظهر في نتائج الاسترجاع لمدة أسبوع. قد يقوم المستخدمون أيضًا بوضع علامة صريحة على ملفات أو إجراءات معينة على أنها مهمة، مما يضمن بقاءها ساخنة دائمًا.</p>
<p><strong>(2) مكان تخزين الذاكرة الساخنة والباردة</strong></p>
<p>بمجرد تصنيفها، يتم تخزين الذكريات الساخنة والباردة بشكل مختلف. تبقى الذاكرة الساخنة في ذاكرة الوصول العشوائي (RAM) وتستخدم للمحتوى الذي يتم الوصول إليه بشكل متكرر، مثل سياق المهام النشطة أو إجراءات المستخدم الأخيرة. يتم نقل الذاكرة الباردة إلى الأقراص أو أنظمة تخزين الكائنات مثل S3، حيث يكون الوصول إليها أبطأ ولكن تكاليف التخزين أقل بكثير. تعمل هذه المفاضلة بشكل جيد لأن الذاكرة الباردة نادراً ما تكون هناك حاجة إليها وعادةً ما يتم الوصول إليها فقط للرجوع إليها على المدى الطويل.</p>
<p><strong>(3) كيف تساعد قواعد البيانات المتجهة</strong></p>
<p>تدعم<strong>Milvus و Zilliz Cloud</strong> هذا النمط من خلال تمكين التخزين المتدرج الساخن والبارد مع الحفاظ على واجهة استعلام واحدة، بحيث تبقى المتجهات التي يتم الوصول إليها بشكل متكرر في الذاكرة وتنتقل البيانات القديمة إلى التخزين الأقل تكلفة تلقائيًا.</p>
<h3 id="Challenge-3-How-Fast-Should-Memory-Be-Written" class="common-anchor-header">التحدي 3: ما مدى سرعة كتابة الذاكرة؟</h3><p>عادةً ما تكتب أنظمة RAG التقليدية البيانات على دفعات. تتم إعادة بناء الفهارس دون اتصال بالإنترنت - غالبًا بين عشية وضحاها - ولا تصبح قابلة للبحث إلا في وقت لاحق. يعمل هذا النهج مع قواعد المعرفة الثابتة، لكنه لا يناسب ذاكرة الوكيل.</p>
<p><strong>(1) لماذا تحتاج ذاكرة الوكيل إلى كتابات في الوقت الفعلي</strong></p>
<p>يجب أن تلتقط ذاكرة الوكيل إجراءات المستخدم فور حدوثها. إذا لم يتم تسجيل إجراء ما على الفور، فقد يفتقر منعطف المحادثة التالي إلى السياق المهم. لهذا السبب، تتطلب أنظمة الذاكرة القابلة للكتابة كتابات في الوقت الحقيقي بدلاً من التحديثات المتأخرة غير المتصلة بالإنترنت.</p>
<p><strong>(2) التوتر بين سرعة الكتابة وجودة الاسترجاع</strong></p>
<p>تتطلب الذاكرة في الوقت الحقيقي وقت استجابة منخفض جداً للكتابة. في الوقت نفسه، تعتمد عملية الاسترجاع عالية الجودة على فهارس مبنية بشكل جيد، ويستغرق بناء الفهرس وقتًا. إن إعادة بناء فهرس لكل عملية كتابة مكلف للغاية، ولكن تأخير الفهرسة يعني أن البيانات المكتوبة حديثًا تظل غير مرئية مؤقتًا للاسترجاع. تقع هذه المفاضلة في مركز تصميم الذاكرة القابلة للكتابة.</p>
<p><strong>(3) كيف تساعد قواعد البيانات المتجهة</strong></p>
<p>تعالج قواعد البيانات المتجهة هذه المشكلة عن طريق فصل الكتابة عن الفهرسة. أحد الحلول الشائعة هو تدفق الكتابة وإجراء عمليات بناء الفهرس التدريجي. باستخدام <strong>Milvus</strong> كمثال، تتم كتابة البيانات الجديدة أولاً إلى مخزن مؤقت في الذاكرة، مما يسمح للنظام بالتعامل مع الكتابات عالية التردد بكفاءة. حتى قبل إنشاء فهرس كامل، يمكن الاستعلام عن البيانات المخزنة مؤقتًا في غضون ثوانٍ من خلال الدمج الديناميكي أو البحث التقريبي.</p>
<p>عندما يصل المخزن المؤقت إلى عتبة محددة مسبقًا، يقوم النظام ببناء الفهارس على دفعات واستمرارها. وهذا يحسّن أداء الاسترجاع على المدى الطويل دون عرقلة عمليات الكتابة في الوقت الفعلي. من خلال فصل الاستيعاب السريع عن بناء الفهرس الأبطأ، يحقق Milvus توازنًا عمليًا بين سرعة الكتابة وجودة البحث التي تعمل بشكل جيد لذاكرة الوكيل.</p>
<h2 id="Conclusion" class="common-anchor-header">الخلاصة<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>تعطينا Cowork لمحة عن فئة جديدة من الوكلاء - ثابتة، وذات حالة، وقادرة على نقل السياق عبر جداول زمنية طويلة. لكنه يوضح أيضًا شيئًا آخر: الذاكرة طويلة المدى ليست سوى نصف الصورة. لبناء وكلاء جاهزين للإنتاج يتمتعون بالاستقلالية والموثوقية في آنٍ واحد، ما زلنا بحاجة إلى استرجاع منظم عبر قواعد معرفية كبيرة ومتطورة.</p>
<p>تتعامل RAG مع حقائق العالم، بينما تتعامل الذاكرة القابلة للكتابة مع الحالة الداخلية للوكيل. وتوجد قواعد البيانات المتجهة عند نقطة التقاطع حيث توفر الفهرسة والبحث الهجين والتخزين القابل للتطوير الذي يمكّن كلا الطبقتين من العمل معًا.</p>
<p>ومع استمرار نضج الوكلاء الذين يعملون لفترة طويلة، من المرجح أن تتقارب بنياتهم مع هذا التصميم الهجين. يعد Cowork إشارة قوية إلى أين تتجه الأمور - ليس نحو عالم بدون RAG، ولكن نحو وكلاء مع مكدسات ذاكرة أكثر ثراءً مدعومة بقواعد بيانات متجهة تحتها.</p>
<p>إذا كنت ترغب في استكشاف هذه الأفكار أو الحصول على المساعدة في الإعداد الخاص بك، <strong>انضم إلى</strong> <a href="https://milvusio.slack.com/join/shared_invite/zt-3nntzngkz-gYwhrdSE4~76k0VMyBfD1Q#/shared-invite/email">قناة Slack</a> <strong>الخاصة بنا</strong> للدردشة مع مهندسي Milvus. وللمزيد من الإرشادات العملية، يمكنك دائمًا <strong>حجز</strong> <strong>جلسة</strong> <a href="https://milvus.io/blog/join-milvus-office-hours-to-get-support-from-vectordb-experts.md"><strong>ساعات عمل Milvus المكتبية</strong></a> <strong>.</strong></p>
