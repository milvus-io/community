---
id: >-
  efficient-vector-similarity-search-recommender-workflows-using-milvus-nvidia-merlin.md
title: بحث فعال عن التشابه المتجه في سير عمل الموصي باستخدام ميلفوس مع إنفيديا ميرلين
author: Burcin Bozkaya
date: 2023-12-15T00:00:00.000Z
desc: >-
  مقدمة عن تكامل NVIDIA Merlin وMilvus في بناء أنظمة التوصية وقياس أدائها في
  سيناريوهات مختلفة.
cover: assets.zilliz.com/nvidia_4921837ca6.png
tag: Engineering
tags: >-
  Milvus, Vector Database, Open Source, Data science, Artificial Intelligence,
  Vector Management, NVIDIA, Merlin
recommend: true
canonicalUrl: >-
  https://zilliz.com/blog/efficient-vector-similarity-search-recommender-workflows-using-milvus-nvidia-merlin
---
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/nvidia_4921837ca6.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>نُشرت هذه التدوينة لأول مرة على <a href="https://medium.com/nvidia-merlin/efficient-vector-similarity-search-in-recommender-workflows-using-milvus-with-nvidia-merlin-84d568290ee4">قناة NVIDIA Merlin على موقع NVIDIA Merlin،</a> وتم تحريرها وإعادة نشرها هنا بإذن. وقد شارك في كتابته كل من <a href="https://medium.com/u/743df9db1666?source=post_page-----84d568290ee4--------------------------------">بورسين بوزكايا</a> <a href="https://medium.com/u/279d4c25a145?source=post_page-----84d568290ee4--------------------------------">وويليام هيكس</a> من NVIDIA <a href="https://medium.com/u/3e8a3c67a8a5?source=post_page-----84d568290ee4--------------------------------">وفيليب هالتماير</a> <a href="https://github.com/liliu-z">ولي ليو</a> من Zilliz.</em></p>
<h2 id="Introduction" class="common-anchor-header">مقدمة<button data-href="#Introduction" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>تتألف أنظمة التوصية الحديثة (Recsys) من خطوط أنابيب التدريب/الاستدلال التي تتضمن مراحل متعددة من إدخال البيانات، والمعالجة المسبقة للبيانات، والتدريب على النموذج، وضبط المعلمات الفائقة لاسترجاع العناصر ذات الصلة وتصنيفها وترتيبها وتسجيلها. أحد المكونات الأساسية لخط أنابيب نظام التوصية هو استرجاع أو اكتشاف الأشياء الأكثر صلة بالمستخدم، خاصة في وجود كتالوجات عناصر كبيرة. تتضمن هذه الخطوة عادةً بحثًا <a href="https://zilliz.com/glossary/anns">تقريبيًا لأقرب جار (ANN)</a> على قاعدة بيانات مفهرسة لتمثيلات متجهة منخفضة الأبعاد (أي تضمينات) لسمات المنتج والمستخدم التي تم إنشاؤها من نماذج التعلم العميق التي تتدرب على التفاعلات بين المستخدمين والمنتجات/الخدمات.</p>
<p>يتكامل إطار عمل<a href="https://github.com/NVIDIA-Merlin">NVIDIA Merlin،</a> وهو إطار عمل مفتوح المصدر تم تطويره لتدريب النماذج المتكاملة لتقديم توصيات على أي نطاق، مع فهرس <a href="https://zilliz.com/learn/what-is-vector-database">قاعدة بيانات متجهية</a> فعالة وإطار عمل بحث. أحد هذه الأطر التي حظيت باهتمام كبير في الآونة الأخيرة هو <a href="https://zilliz.com/what-is-milvus">"ميلفوس</a>"، وهو قاعدة بيانات متجهات مفتوحة المصدر أنشأتها <a href="https://zilliz.com/">شركة Zilliz</a>. يوفر فهرسًا سريعًا وقدرات استعلام. أضافت Milvus مؤخرًا <a href="https://zilliz.com/blog/getting-started-with-gpu-powered-milvus-unlocking-10x-higher-performance">دعم تسريع GPU</a> الذي يستخدم وحدات معالجة الرسومات NVIDIA GPU لدعم سير عمل الذكاء الاصطناعي. يعد دعم تسريع وحدة معالجة الرسومات خبرًا رائعًا لأن مكتبة البحث المتسارع في المتجهات تجعل الاستعلامات المتزامنة السريعة ممكنة، مما يؤثر إيجابًا على متطلبات زمن الاستجابة في أنظمة التوصية الحالية، حيث يتوقع المطورون العديد من الطلبات المتزامنة. لدى Milvus أكثر من 5 ملايين عملية سحب لـ docker، وحوالي 23 ألف نجمة على GitHub (اعتبارًا من سبتمبر 2023)، وأكثر من 5000 عميل من عملاء المؤسسات، ومكون أساسي للعديد من التطبيقات (انظر <a href="https://medium.com/vector-database/tagged/use-cases-of-milvus">حالات</a> الاستخدام).</p>
<p>توضح هذه المدونة كيفية عمل Milvus مع إطار عمل Merlin Recsys في وقت التدريب والاستدلال. نوضح كيف يكمل برنامج Milvus برنامج Merlin في مرحلة استرجاع العناصر من خلال بحث عالي الكفاءة في تضمين المتجهات من أعلى k وكيف يمكن استخدامه مع خادم الاستدلال NVIDIA Triton Inference Server (TIS) في وقت الاستدلال (انظر الشكل 1). <strong>تُظهر نتائجنا المعيارية تسريعًا مذهلًا يتراوح بين 37 ضعفًا و91 ضعفًا باستخدام Milvus المعزز بوحدة معالجة الرسومات الذي يستخدم NVIDIA RAFT مع التضمينات المتجهة التي تم إنشاؤها بواسطة Merlin Models.</strong> يتوفر هنا الكود الذي نستخدمه لإظهار تكامل Merlin-Milvus والنتائج المعيارية التفصيلية للمقارنة، إلى جانب <a href="https://github.com/zilliztech/VectorDBBench">المكتبة</a> التي سهلت دراستنا المعيارية.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Multistage_recommender_system_with_Milvus_ee891c4ad5.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>الشكل 1. نظام التوصية متعدد المراحل مع إطار عمل ميلفوس الذي يساهم في مرحلة الاسترجاع. مصدر الشكل الأصلي متعدد المراحل: <a href="https://medium.com/nvidia-merlin/recommender-systems-not-just-recommender-models-485c161c755e">منشور المدونة</a> هذا.</em></p>
<h2 id="The-challenges-facing-recommenders" class="common-anchor-header">التحديات التي تواجه الموصين<button data-href="#The-challenges-facing-recommenders" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>نظرًا لطبيعة نظام التوصيات متعدد المراحل وتوافر العديد من المكونات والمكتبات التي تدمجها، فإن التحدي الكبير هو دمج جميع المكونات بسلاسة في خط أنابيب متكامل. نهدف إلى إظهار أن التكامل يمكن أن يتم بأقل جهد ممكن في أمثلة دفاتر الملاحظات التي نقدمها.</p>
<p>التحدي الآخر لسير عمل التوصية هو تسريع بعض أجزاء خط الأنابيب. في حين أنه من المعروف أنها تلعب دورًا كبيرًا في تدريب الشبكات العصبية الكبيرة، إلا أن وحدات معالجة الرسومات ليست سوى إضافات حديثة لقواعد البيانات المتجهة والبحث في الشبكات العصبية الاصطناعية. مع تزايد حجم مخزون منتجات التجارة الإلكترونية أو قواعد بيانات الوسائط المتدفقة وعدد المستخدمين الذين يستخدمون هذه الخدمات، يجب أن توفر وحدات المعالجة المركزية الأداء المطلوب لخدمة ملايين المستخدمين في تدفقات عمل Recsys ذات الأداء العالي. أصبح تسريع وحدة معالجة الرسومات في أجزاء خط الأنابيب الأخرى ضروريًا لمواجهة هذا التحدي. يعالج الحل الوارد في هذه المدونة هذا التحدي من خلال إظهار كفاءة البحث في الشبكة العنكبوتية عند استخدام وحدات معالجة الرسومات.</p>
<h2 id="Tech-stacks-for-the-solution" class="common-anchor-header">المكدسات التقنية للحل<button data-href="#Tech-stacks-for-the-solution" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>لنبدأ أولاً بمراجعة بعض الأساسيات اللازمة لإجراء عملنا.</p>
<ul>
<li><p>NVIDIA <a href="https://github.com/NVIDIA-Merlin/Merlin">Merlin</a>: مكتبة مفتوحة المصدر مع واجهات برمجة تطبيقات عالية المستوى تسرّع من عمليات التوصية على وحدات معالجة الرسومات NVIDIA.</p></li>
<li><p><a href="https://github.com/NVIDIA-Merlin/NVTabular">NVTabular</a>: للمعالجة المسبقة للبيانات المجدولة المدخلة وهندسة الميزات.</p></li>
<li><p><a href="https://github.com/NVIDIA-Merlin/models">نماذج Merlin Models</a>: لتدريب نماذج التعلم العميق، وللتعلم، في هذه الحالة، متجهات تضمين المستخدم والعنصر من بيانات تفاعل المستخدم.</p></li>
<li><p><a href="https://github.com/NVIDIA-Merlin/systems">أنظمة Merlin</a>: لدمج نموذج التوصية القائم على TensorFlow مع عناصر أخرى (على سبيل المثال، مخزن الميزات، والبحث في الشبكة الاصطناعية مع Milvus) ليتم تقديمها مع TIS.</p></li>
<li><p><a href="https://github.com/triton-inference-server/server">خادم Triton Inference Server</a>: لمرحلة الاستدلال حيث يتم تمرير متجه ميزة المستخدم، ويتم إنشاء توصيات المنتج.</p></li>
<li><p>الاحتواء: كل ما سبق متاح عبر الحاويات التي توفرها NVIDIA في <a href="https://catalog.ngc.nvidia.com/">كتالوج NGC</a>. استخدمنا حاوية Merlin TensorFlow 23.06 المتوفرة <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow">هنا</a>.</p></li>
<li><p><a href="https://github.com/milvus-io/milvus/releases/tag/v2.3.0">Milvus 2.3</a>: لإجراء الفهرسة والاستعلام عن المتجهات المسرعة بوحدة معالجة الرسومات.</p></li>
<li><p><a href="https://github.com/milvus-io/milvus/releases">Milvus 2.2.11</a>: نفس الإصدار<a href="https://github.com/milvus-io/milvus/releases">2.2.11</a>: كما هو مذكور أعلاه، ولكن لإجراء ذلك على وحدة المعالجة المركزية.</p></li>
<li><p><a href="https://zilliz.com/product/integrations/python">Pymilvus SDK</a>: للاتصال بخادم Milvus، وإنشاء فهارس قاعدة بيانات المتجهات، وتشغيل الاستعلامات عبر واجهة Python.</p></li>
<li><p><a href="https://github.com/feast-dev/feast">Feast</a>: لحفظ واسترجاع سمات المستخدم والعنصر في مخزن ميزات (مفتوح المصدر) كجزء من خط أنابيب RecSys الشامل.</p></li>
</ul>
<p>يتم استخدام العديد من المكتبات والأطر الأساسية أيضًا تحت الغطاء. على سبيل المثال، يعتمد Merlin على مكتبات NVIDIA الأخرى، مثل cuDF و Dask، وكلاهما متاح ضمن <a href="https://github.com/rapidsai/cudf">RAPIDS cuDF</a>. وبالمثل، يعتمد Milvus على <a href="https://github.com/rapidsai/raft">NVIDIA RAFT</a> للأوليات على تسريع وحدة معالجة الرسومات والمكتبات المعدلة مثل <a href="https://zilliz.com/learn/hierarchical-navigable-small-worlds-HNSW">HNSW</a> و <a href="https://zilliz.com/blog/set-up-with-facebook-ai-similarity-search-faiss">FAISS</a> للبحث.</p>
<h2 id="Understanding-vector-databases-and-Milvus" class="common-anchor-header">فهم قواعد البيانات المتجهة وميلفوس<button data-href="#Understanding-vector-databases-and-Milvus" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p><a href="https://zilliz.com/glossary/anns">أقرب جار تقريبي (ANN)</a> هي وظيفة لا تستطيع قواعد البيانات العلائقية التعامل معها. تم تصميم قواعد البيانات العلائقية للتعامل مع البيانات المجدولة ذات الهياكل المحددة مسبقًا والقيم القابلة للمقارنة المباشرة. وتعتمد فهارس قواعد البيانات العلائقية على ذلك لمقارنة البيانات وإنشاء هياكل تستفيد من معرفة ما إذا كانت كل قيمة أقل من أو أكبر من الأخرى. لا يمكن مقارنة المتجهات المضمنة ببعضها البعض مباشرةً بهذه الطريقة، حيث نحتاج إلى معرفة ما تمثله كل قيمة في المتجه. فلا يمكننا تحديد ما إذا كان أحد المتجهين أقل من الآخر بالضرورة. الشيء الوحيد الذي يمكننا فعله هو حساب المسافة بين المتجهين. إذا كانت المسافة بين المتجهين صغيرة، فيمكننا افتراض أن السمات التي يمثلانها متشابهة، وإذا كانت كبيرة، فيمكننا افتراض أن البيانات التي يمثلانها أكثر اختلافًا. ومع ذلك، فإن هذه الفهارس الفعّالة تأتي بتكلفة؛ فحساب المسافة بين متجهين مكلف حسابيًا، كما أن فهارس المتجهات غير قابلة للتكيف بسهولة وأحيانًا غير قابلة للتعديل. نظرًا لهذين القيدين، فإن دمج هذه الفهارس أكثر تعقيدًا في قواعد البيانات العلائقية، وهذا هو السبب في الحاجة إلى <a href="https://zilliz.com/blog/what-is-a-real-vector-database">قواعد بيانات متجهات مصممة لهذا الغرض</a>.</p>
<p>تم إنشاء<a href="https://zilliz.com/what-is-milvus">Milvus</a> لحل المشاكل التي تواجهها قواعد البيانات العلائقية مع المتجهات وتم تصميمه من الألف إلى الياء للتعامل مع هذه المتجهات المدمجة وفهارسها على نطاق واسع. ولتحقيق شارة السحابة الأصلية، تفصل Milvus بين الحوسبة والتخزين ومهام الحوسبة المختلفة - الاستعلام، ومعالجة البيانات، والفهرسة. يمكن للمستخدمين توسيع نطاق كل جزء من أجزاء قاعدة البيانات للتعامل مع حالات الاستخدام الأخرى، سواء أكان ذلك في حالة ثقل إدخال البيانات أو ثقل البحث. إذا كان هناك تدفق كبير لطلبات الإدخال، يمكن للمستخدم توسيع نطاق عقد الفهرس أفقياً وعمودياً بشكل مؤقت للتعامل مع الإدخال. وبالمثل، إذا لم يتم استيعاب أي بيانات، ولكن هناك العديد من عمليات البحث، يمكن للمستخدم تقليل عقد الفهرس وزيادة عقد الاستعلام بدلاً من ذلك لزيادة الإنتاجية. تطلب منا تصميم هذا النظام (انظر الشكل 2) التفكير بعقلية الحوسبة المتوازية، مما أدى إلى نظام محسّن للحوسبة مع وجود العديد من الأبواب المفتوحة لمزيد من التحسينات.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Milvus_system_design_bb3a44c9cc.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>الشكل 2. تصميم نظام ميلفوس</em></p>
<p>يستخدم ميلفوس أيضًا العديد من مكتبات الفهرسة الحديثة لمنح المستخدمين أكبر قدر ممكن من التخصيص لنظامهم. ويحسنها بإضافة القدرة على التعامل مع عمليات CRUD، والبيانات المتدفقة، والتصفية. سنناقش لاحقًا كيف تختلف هذه الفهارس وما هي إيجابيات وسلبيات كل منها.</p>
<h2 id="Example-solution-integration-of-Milvus-and-Merlin" class="common-anchor-header">مثال على الحل: دمج ميلفوس وميرلين<button data-href="#Example-solution-integration-of-Milvus-and-Merlin" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>يوضح مثال الحل الذي نقدمه هنا تكامل ميلفوس مع ميرلين في مرحلة استرجاع العناصر (عندما يتم استرجاع العناصر الأكثر صلة من خلال بحث الشبكة العنكبوتية). نستخدم مجموعة بيانات واقعية من <a href="https://www.kaggle.com/datasets/chadgostopp/recsys-challenge-2015">تحدي RecSys،</a> الموضح أدناه. نقوم بتدريب نموذج التعلّم العميق ثنائي الأبراج الذي يتعلم التضمينات المتجهة للمستخدمين والعناصر. يوفر هذا القسم أيضًا مخطط عملنا المعياري، بما في ذلك المقاييس التي نجمعها ونطاق المعلمات التي نستخدمها.</p>
<p>يتضمن نهجنا</p>
<ul>
<li><p>استيعاب البيانات والمعالجة المسبقة</p></li>
<li><p>تدريب نموذج التعلّم العميق ثنائي الأبراج</p></li>
<li><p>بناء فهرس ميلفوس</p></li>
<li><p>البحث عن تشابه ميلفوس</p></li>
</ul>
<p>نصف بإيجاز كل خطوة ونحيل القارئ إلى <a href="https://github.com/bbozkaya/merlin-milvus/tree/main/notebooks">دفاتر ملاحظاتنا</a> للحصول على التفاصيل.</p>
<h3 id="Dataset" class="common-anchor-header">مجموعة البيانات</h3><p>توفر شركة YOOCHOOSE GmbH مجموعة البيانات التي نستخدمها في هذا التكامل والدراسة المعيارية <a href="https://www.kaggle.com/datasets/chadgostopp/recsys-challenge-2015">لتحدي RecSys 2015</a> وهي متاحة على Kaggle. وهي تحتوي على أحداث نقر/شراء المستخدم من بائع تجزئة أوروبي عبر الإنترنت مع سمات مثل معرّف الجلسة والطابع الزمني ومعرّف العنصر المرتبط بالنقر/الشراء وفئة العنصر، وهي متاحة في ملف yoochoose-clicks.dat. الجلسات مستقلة، ولا يوجد أي تلميح للمستخدمين العائدين، لذلك نتعامل مع كل جلسة على أنها تنتمي لمستخدم مميز. تحتوي مجموعة البيانات على 9,249,729 جلسة فريدة (مستخدمين) و 52,739 عنصرًا فريدًا.</p>
<h3 id="Data-ingestion-and-preprocessing" class="common-anchor-header">استيعاب البيانات والمعالجة المسبقة</h3><p>الأداة التي نستخدمها في المعالجة المسبقة للبيانات هي <a href="https://github.com/NVIDIA-Merlin/NVTabular">NVTabular،</a> وهي أداة هندسة ميزات قابلة للتطوير بشكل كبير ومكون المعالجة المسبقة في Merlin. نحن نستخدم NVTabular لقراءة البيانات في ذاكرة وحدة معالجة الرسومات، وإعادة ترتيب الميزات حسب الضرورة، وتصديرها إلى ملفات الباركيه، وإنشاء تقسيم تدريب-تحقق من صحة التدريب. ينتج عن ذلك 7,305,761 مستخدمًا فريدًا و49,008 عنصرًا فريدًا للتدريب عليها. نقوم أيضًا بتصنيف كل عمود وقيمه إلى قيم صحيحة. مجموعة البيانات جاهزة الآن للتدريب باستخدام نموذج البرجين.</p>
<h3 id="Model-training" class="common-anchor-header">تدريب النموذج</h3><p>نستخدم نموذج التعلّم العميق <a href="https://github.com/NVIDIA-Merlin/models/blob/main/examples/05-Retrieval-Model.ipynb">ثنائي الأبراج</a> لتدريب وتوليد تضمينات المستخدمين والعناصر، والتي ستُستخدم لاحقًا في فهرسة المتجهات والاستعلام. بعد تدريب النموذج، يمكننا استخراج تضمينات المستخدم والعنصر المكتسبة.</p>
<p>الخطوتان التاليتان اختياريتان: نموذج <a href="https://arxiv.org/abs/1906.00091">DLRM</a> مدرب على ترتيب العناصر المسترجعة للتوصية ومخزن الميزات المستخدم (في هذه الحالة، <a href="https://github.com/feast-dev/feast">Feast</a>) لتخزين واسترجاع ميزات المستخدم والعنصر. نقوم بتضمينها لاكتمال سير العمل متعدد المراحل.</p>
<p>أخيرًا، نقوم بتصدير تضمينات المستخدم والعنصر إلى ملفات باركيه، والتي يمكن إعادة تحميلها لاحقًا لإنشاء فهرس متجه Milvus.</p>
<h3 id="Building-and-querying-the-Milvus-index" class="common-anchor-header">بناء فهرس ميلفوس والاستعلام عنه</h3><p>يسهل Milvus فهرسة المتجهات والبحث عن التشابه عبر "خادم" يتم تشغيله على جهاز الاستدلال. في دفتر ملاحظاتنا رقم 2، قمنا بإعداد ذلك من خلال تثبيت خادم Milvus وPymilvus، ثم بدء تشغيل الخادم بمنفذ الاستماع الافتراضي الخاص به. بعد ذلك، نوضح بناء فهرس بسيط (IVF_FLAT) والاستعلام عنه باستخدام الدالتين <code translate="no">setup_milvus</code> و <code translate="no">query_milvus</code> ، على التوالي.</p>
<h2 id="Benchmarking" class="common-anchor-header">قياس الأداء<button data-href="#Benchmarking" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>لقد صممنا مقياسين معياريين لتوضيح حالة استخدام مكتبة فهرسة/بحث متجهية سريعة وفعالة مثل Milvus.</p>
<ol>
<li><p>باستخدام Milvus لإنشاء فهارس متجهات باستخدام مجموعتين من التضمينات التي أنشأناها: 1) تضمينات مستخدمين ل 7.3 مليون مستخدم فريد، مقسمة كمجموعة تدريب بنسبة 85% (للفهرسة) ومجموعة اختبار بنسبة 15% (للاستعلام)، و2) تضمينات عناصر ل 49 ألف منتج (مع تقسيم 50-50 بين التدريب والاختبار). يتم إجراء هذا المعيار بشكل مستقل لكل مجموعة بيانات متجه، ويتم الإبلاغ عن النتائج بشكل منفصل.</p></li>
<li><p>استخدام Milvus لإنشاء فهرس متجه لمجموعة بيانات تضمين 49 ألف عنصر والاستعلام عن 7.3 مليون مستخدم فريد مقابل هذا الفهرس للبحث عن التشابه.</p></li>
</ol>
<p>في هذه المعايير، استخدمنا في هذه المعايير خوارزميات فهرسة IVFPPQ و HNSW التي تم تنفيذها على وحدة معالجة الرسومات ووحدة المعالجة المركزية، إلى جانب مجموعات مختلفة من المعلمات. التفاصيل متاحة <a href="https://github.com/bbozkaya/merlin-milvus/tree/main/results">هنا</a>.</p>
<p>تُعد المفاضلة بين جودة البحث والإنتاجية أحد الاعتبارات المهمة في الأداء، خاصةً في بيئة الإنتاج. يسمح Milvus بالتحكم الكامل في معلمات الفهرسة لاستكشاف هذه المفاضلة لحالة استخدام معينة لتحقيق نتائج بحث أفضل مع الحقيقة الأساسية. قد يعني هذا زيادة التكلفة الحسابية في شكل معدل إنتاجية منخفض أو استعلامات في الثانية (QPS). نحن نقيس جودة بحث الشبكة العصبية الاصطناعية باستخدام مقياس الاستدعاء ونقدم منحنيات QPS-الاستدعاء التي توضح المفاضلة. يمكن للمرء بعد ذلك تحديد المستوى المقبول لجودة البحث بالنظر إلى موارد الحوسبة أو متطلبات زمن الاستجابة/الإنتاجية لحالة العمل.</p>
<p>لاحظ أيضًا حجم دفعة الاستعلام (nq) المستخدم في معاييرنا. هذا مفيد في تدفقات العمل حيث يتم إرسال طلبات متزامنة متعددة إلى الاستدلال (على سبيل المثال، التوصيات غير المتصلة بالإنترنت المطلوبة وإرسالها إلى قائمة مستلمي البريد الإلكتروني أو التوصيات عبر الإنترنت التي تم إنشاؤها عن طريق تجميع الطلبات المتزامنة التي تصل ومعالجتها جميعًا مرة واحدة). واعتماداً على حالة الاستخدام، يمكن أن يساعد نظام معلومات النقل أيضاً في معالجة هذه الطلبات على دفعات.</p>
<h3 id="Results" class="common-anchor-header">النتائج</h3><p>نقوم الآن بالإبلاغ عن النتائج للمجموعات الثلاث من المعايير على كل من وحدة المعالجة المركزية ووحدة معالجة الرسوميات، باستخدام أنواع الفهرس HNSW (وحدة المعالجة المركزية فقط) و IVF_PQ (وحدة المعالجة المركزية ووحدة معالجة الرسوميات) التي نفذها Milvus.</p>
<h4 id="Items-vs-Items-vector-similarity-search" class="common-anchor-header">العناصر مقابل بحث تشابه متجه العناصر</h4><p>باستخدام مجموعة البيانات الأصغر حجمًا هذه، يأخذ كل تشغيل لمجموعة معلمات معينة 50% من متجهات العناصر كمتجهات استعلام ويستعلم عن أفضل 100 متجه متشابه من البقية. يُنتج HNSW و IVF_PQ استرجاعًا عاليًا مع إعدادات المعلمات التي تم اختبارها، في النطاق 0.958-1.0 و 0.665-0.997 على التوالي. تشير هذه النتيجة إلى أن أداء HNSW أفضل من حيث الاستدعاء، لكن IVF_PQ مع إعدادات قائمة n الصغيرة ينتج عنه استدعاء مماثل إلى حد كبير. يجب أن نلاحظ أيضًا أن قيم الاستدعاء يمكن أن تختلف بشكل كبير اعتمادًا على معلمات الفهرسة والاستعلام. تم الحصول على القيم التي نبلغ عنها بعد إجراء تجارب أولية مع نطاقات معلمات عامة والتكبير أكثر في مجموعة فرعية مختارة.</p>
<p>يتراوح الوقت الإجمالي لتنفيذ جميع الاستعلامات على وحدة المعالجة المركزية باستخدام HNSW لمجموعة معلمات معينة بين 5.22 و5.33 ثانية (أسرع كلما زاد m، دون تغيير نسبيًا مع ef) ومع IVF_PQ بين 13.67 و14.67 ثانية (أبطأ كلما زاد nlist وnprobe). إن تسريع وحدة معالجة الرسومات له تأثير ملحوظ، كما هو موضح في الشكل 3.</p>
<p>يوضح الشكل 3 المفاضلة بين معدل الاسترجاع والإنتاجية على جميع عمليات التشغيل المكتملة على وحدة المعالجة المركزية ووحدة معالجة الرسومات باستخدام مجموعة البيانات الصغيرة هذه باستخدام IVF_PQ. وجدنا أن وحدة معالجة الرسومات توفر تسريعًا يتراوح بين 4 أضعاف إلى 15 ضعفًا عبر جميع مجموعات المعلمات التي تم اختبارها (تسريع أكبر كلما زاد nprobe). يتم حساب ذلك من خلال أخذ نسبة QPS من وحدة معالجة الرسومات على QPS من عمليات تشغيل وحدة المعالجة المركزية لكل مجموعة معلمات. وبشكلٍ عام، تمثل هذه المجموعة تحديًا بسيطًا لوحدة المعالجة المركزية أو وحدة معالجة الرسوميات، وتظهر احتمالات زيادة السرعة مع مجموعات البيانات الأكبر، كما هو موضح أدناه.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/GPU_speedup_with_Milvus_IVF_PQ_item_item_d32de8443d.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>الشكل 3. تسريع وحدة معالجة الرسومات باستخدام خوارزمية Milvus IVF_PQ التي تعمل على وحدة معالجة الرسومات NVIDIA A100 (بحث تشابه عنصر-عنصر)</em></p>
<h4 id="Users-vs-Users-vector-similarity-search" class="common-anchor-header">المستخدمون مقابل بحث تشابه متجه المستخدمين</h4><p>مع مجموعة البيانات الثانية الأكبر حجمًا (7.3 مليون مستخدم)، قمنا بتخصيص 85% (حوالي 6.2 مليون) من المتجهات ك "تدريب" (مجموعة المتجهات المراد فهرستها)، وال 15% المتبقية (حوالي 1.1 مليون) "اختبار" أو مجموعة متجهات الاستعلام. يؤدي كل من HNSW و IVF_PQ أداءً جيدًا بشكل استثنائي في هذه الحالة، حيث تبلغ قيم الاسترجاع 0.884-1.0 و 0.922-0.999 على التوالي. ومع ذلك، فهي أكثر تطلبًا من الناحية الحسابية، خاصةً مع IVF_PQ على وحدة المعالجة المركزية. يتراوح إجمالي الوقت اللازم لتنفيذ جميع الاستعلامات على وحدة المعالجة المركزية مع HNSW من 279.89 إلى 295.56 ثانية ومع IVF_PQ من 3082.67 إلى 10932.33 ثانية. لاحظ أن أزمنة الاستعلام هذه تراكمية ل 1.1 مليون متجه تم الاستعلام عنها، لذلك يمكن القول إن الاستعلام الواحد ضد الفهرس لا يزال سريعًا جدًا.</p>
<p>ومع ذلك، قد لا يكون الاستعلام المستند إلى وحدة المعالجة المركزية قابلاً للتطبيق إذا كان الخادم الاستدلالي يتوقع عدة آلاف من الطلبات المتزامنة لتشغيل الاستعلامات مقابل مخزون من ملايين العناصر.</p>
<p>توفر وحدة معالجة الرسومات A100 سرعة فائقة تتراوح من 37 ضعفًا إلى 91 ضعفًا (بمتوسط 76.1 ضعفًا) عبر جميع مجموعات المعلمات مع IVF_PQ من حيث الإنتاجية (QPS)، كما هو موضح في الشكل 4. يتوافق هذا مع ما لاحظناه مع مجموعة البيانات الصغيرة، مما يشير إلى أن أداء وحدة معالجة الرسومات يتوسع بشكل معقول باستخدام Milvus مع ملايين من متجهات التضمين.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/GPU_speedup_with_Milvus_IVF_PQ_algorithm_user_user_c91f4e4164.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>الشكل 4. تسريع وحدة معالجة الرسومات باستخدام خوارزمية Milvus IVF_PQ التي تعمل على وحدة معالجة الرسومات NVIDIA A100 (بحث التشابه بين المستخدم والمستخدم)</em></p>
<p>يوضح الشكل 5 التفصيلي التالي مفاضلة الاستدعاء-QPS لجميع مجموعات المعلمات التي تم اختبارها على وحدة المعالجة المركزية ووحدة معالجة الرسومات باستخدام IVF_PQ. توضح كل مجموعة نقاط (أعلى لوحدة معالجة الرسوميات وأسفل لوحدة المعالجة المركزية) في هذا الرسم البياني المفاضلة التي تمت مواجهتها عند تغيير معلمات فهرسة/استعلام المتجهات نحو تحقيق استرجاع أعلى على حساب انخفاض الإنتاجية. لاحظ الخسارة الكبيرة في QPS في حالة وحدة معالجة الرسومات عندما يحاول المرء تحقيق مستويات استدعاء أعلى.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Recall_Throughput_tradeoff_519b2289e5.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>الشكل 5. مفاضلة الاستدعاء-الإنتاجية لجميع مجموعات المعلمات التي تم اختبارها على وحدة المعالجة المركزية ووحدة معالجة الرسومات باستخدام IVF_PQ (المستخدمون مقابل المستخدمين)</em></p>
<h4 id="Users-vs-Items-vector-similarity-search" class="common-anchor-header">المستخدمون مقابل بحث تشابه متجه العناصر</h4><p>أخيرًا، نأخذ في الاعتبار حالة استخدام واقعية أخرى حيث يتم الاستعلام عن متجهات المستخدمين مقابل متجهات العناصر (كما هو موضح في المفكرة 01 أعلاه). في هذه الحالة، يتم فهرسة 49 ألف متجه عنصر، ويتم الاستعلام عن 7.3 مليون متجه مستخدم مقابل أكثر 100 عنصر تشابهًا.</p>
<p>هذا هو المكان الذي تصبح فيه الأمور مثيرة للاهتمام لأن الاستعلام عن 7.3 مليون على دفعات من 1000 مقابل فهرس مكون من 49 ألف عنصر يبدو مستهلكًا للوقت على وحدة المعالجة المركزية لكل من HNSW و IVF_PQ. يبدو أن وحدة معالجة الرسوميات تتعامل مع هذه الحالة بشكل أفضل (انظر الشكل 6). يتم احتساب أعلى مستويات الدقة بواسطة IVF_PQ على وحدة المعالجة المركزية عندما تكون nlist = 100 في حوالي 86 دقيقة في المتوسط، ولكنها تختلف بشكل كبير مع زيادة قيمة nprobe (51 دقيقة عندما تكون nprobe = 5 مقابل 128 دقيقة عندما تكون nprobe = 20). تعمل وحدة معالجة الرسومات NVIDIA A100 على تسريع الأداء بشكل كبير بمعامل 4 أضعاف إلى 17 ضعفًا (تسريع أعلى كلما زادت قيمة nprobe). تذكّر أن خوارزمية IVF_PQ، من خلال تقنية التكميم الخاصة بها، تقلل أيضًا من بصمة الذاكرة وتوفر حل بحث ANN قابل للتطبيق حسابيًا مع تسريع وحدة معالجة الرسومات.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/GPU_speedup_with_Milvus_IVF_PQ_algorithm_user_item_504462fcc0.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>الشكل 6. تسريع وحدة معالجة الرسومات باستخدام خوارزمية Milvus IVF_PQ التي تعمل على وحدة معالجة الرسومات NVIDIA A100 (بحث تشابه عنصر المستخدم)</em></p>
<p>على غرار الشكل 5، تظهر في الشكل 7 مفاضلة الاستدعاء-الإنتاجية لجميع مجموعات المعلمات التي تم اختبارها باستخدام IVF_PQ. هنا، لا يزال بإمكان المرء أن يرى كيف يمكن للمرء أن يتخلى قليلاً عن بعض الدقة في بحث الشبكة العنكبوتية الاصطناعية لصالح زيادة الإنتاجية، على الرغم من أن الاختلافات أقل وضوحًا، خاصة في حالة تشغيل وحدة معالجة الرسومات. يشير هذا إلى أنه يمكن للمرء أن يتوقع مستويات عالية نسبيًا من الأداء الحسابي مع وحدة معالجة الرسومات مع تحقيق استرجاع عالٍ في الوقت نفسه.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Recall_Throughput_tradeoff_user_items_0abce91c5e.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>الشكل 7. مفاضلة الاستدعاء-الإنتاجية لجميع مجموعات المعلمات التي تم اختبارها على وحدة المعالجة المركزية ووحدة معالجة الرسومات باستخدام IVF_PQ (المستخدمون مقابل العناصر)</em></p>
<h2 id="Conclusion" class="common-anchor-header">الخاتمة<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>يسعدنا مشاركة بعض الملاحظات الختامية إذا كنت قد وصلت إلى هذا الحد. نود أن نذكرك بأن تعقيدات Recsys الحديثة وطبيعتها متعددة المراحل تستلزم الأداء والكفاءة في كل خطوة. نأمل أن تكون هذه المدونة قد قدمت لك أسبابًا مقنعة للتفكير في استخدام ميزتين هامتين في خطوط أنابيب RecSys الخاصة بك:</p>
<ul>
<li><p>تتيح لك مكتبة أنظمة Merlin Systems من NVIDIA Merlin من NVIDIA Merlin إمكانية توصيل <a href="https://github.com/milvus-io/milvus/tree/2.3.0">Milvus</a> بسهولة، وهو محرك بحث متجه فعال مسرّع بوحدة معالجة الرسومات.</p></li>
<li><p>استخدم وحدة معالجة الرسومات لتسريع العمليات الحسابية لفهرسة قاعدة البيانات المتجهة، والبحث في الشبكة العنكبوتية باستخدام تقنية مثل <a href="https://github.com/rapidsai/raft">RAPIDS RAFT</a>.</p></li>
</ul>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/summary_benchmark_results_ae33fbe514.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>تشير هذه النتائج إلى أن التكامل بين Merlin-Milvus المقدم هو تكامل عالي الأداء وأقل تعقيدًا بكثير من الخيارات الأخرى للتدريب والاستدلال. كما أن كلا الإطارين يتم تطويرهما بنشاط، ويتم إضافة العديد من الميزات الجديدة (على سبيل المثال، فهارس قاعدة البيانات المتجهة الجديدة المسرعة بوحدة معالجة الرسومات من قبل Milvus) في كل إصدار. إن حقيقة أن البحث عن التشابه المتجهي هو عنصر حاسم في العديد من مهام سير العمل، مثل الرؤية الحاسوبية ونمذجة اللغات الكبيرة وأنظمة التوصية، يجعل هذا الجهد أكثر جدارة بالاهتمام.</p>
<p>في الختام، نود أن نشكر كل من ساهم في هذا الجهد في إنتاج هذا العمل ومنشور المدونة من فريقي Zilliz/Milvus وMerlin وفريق RAFT. نتطلع إلى الاستماع إليكم، إذا أتيحت لكم الفرصة لتطبيق Merlin وMilvus في نظامي Recsys أو سير العمل الآخر.</p>
