---
id: >-
  embedding-first-chunking-second-smarter-rag-retrieval-with-max-min-semantic-chunking.md
title: >-
  التضمين أولاً، ثم التقطيع: استرجاع RAG الأكثر ذكاءً مع التقطيع الدلالي الأقصى
  الأدنى
author: Rachel Liu
date: 2025-12-24T00:00:00.000Z
cover: assets.zilliz.com/maxmin_cover_8be0b87409.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database'
meta_keywords: 'Max–Min Semantic Chunking, Milvus, RAG, chunking strategies'
meta_title: |
  Max–Min Semantic Chunking: Top Chunking Strategy to Improve RAG Performance
desc: >-
  تعرّف على كيفية تعزيز التقطيع الدلالي الأقصى والأصغر دقة RAG باستخدام نهج
  التضمين أولاً الذي ينشئ أجزاءً أكثر ذكاءً ويحسّن جودة السياق ويوفر أداءً أفضل
  في الاسترجاع.
origin: >-
  https://milvus.io/blog/embedding-first-chunking-second-smarter-rag-retrieval-with-max-min-semantic-chunking.md
---
<p>أصبح<a href="https://zilliz.com/learn/Retrieval-Augmented-Generation">التوليد المعزّز للاسترجاع (RAG)</a> هو النهج الافتراضي لتوفير السياق والذاكرة لتطبيقات الذكاء الاصطناعي - حيث يعتمد عليه وكلاء الذكاء الاصطناعي ومساعدو دعم العملاء وقواعد المعرفة وأنظمة البحث.</p>
<p>في كل خط أنابيب RAG تقريبًا، تكون العملية القياسية هي نفسها: أخذ المستندات، وتقسيمها إلى أجزاء، ثم تضمين هذه الأجزاء لاسترجاع التشابه في قاعدة بيانات متجهة مثل <a href="https://milvus.io/">Milvus</a>. نظرًا لأن <strong>التقطيع</strong> يحدث مقدمًا، فإن جودة هذه الأجزاء تؤثر بشكل مباشر على مدى جودة استرجاع النظام للمعلومات ومدى دقة الإجابات النهائية.</p>
<p>تكمن المشكلة في أن استراتيجيات التقطيع التقليدية عادةً ما تقسم النص دون أي فهم دلالي. فالتقطيع ذو الطول الثابت يعتمد على عدد الرموز الرمزية، والتقطيع التكراري يستخدم بنية على مستوى السطح، ولكن كلاهما يتجاهل المعنى الفعلي للنص. ونتيجة لذلك، غالبًا ما يتم فصل الأفكار ذات الصلة، ويتم تجميع الأسطر غير ذات الصلة معًا، ويتم تجزئة السياق المهم.</p>
<p>أما<a href="https://link.springer.com/article/10.1007/s10791-025-09638-7"><strong>التقطيع الدلالي الأقصى-الأدنى</strong></a> فيتناول المشكلة بشكل مختلف. فبدلاً من التقطيع أولاً، يقوم بتضمين النص مقدمًا ويستخدم التشابه الدلالي لتحديد مكان تشكيل الحدود. من خلال التضمين قبل التقطيع، يمكن لخط الأنابيب تتبع التحولات الطبيعية في المعنى بدلاً من الاعتماد على حدود الطول التعسفية.</p>
<p>ناقشنا في مدونتنا السابقة طرقًا مثل التقطيع <a href="https://milvus.io/blog/smarter-retrieval-for-rag-late-chunking-with-jina-embeddings-v2-and-milvus.md"><strong>المتأخر</strong></a> من جينا للذكاء الاصطناعي التي ساعدت في تعميم فكرة "التضمين أولًا" وأثبتت إمكانية نجاحها عمليًا. يعتمد <strong>الحد الأقصى للتقطيع الدلالي</strong> على نفس المفهوم بقاعدة بسيطة تحدد متى يتغير المعنى بما يكفي لتبرير وجود قطعة جديدة. في هذا المنشور، سنستعرض في هذا المقال كيفية عمل Max-Min ونفحص نقاط قوته وحدوده بالنسبة لأعباء عمل RAG الحقيقية.</p>
<h2 id="How-a-Typical-RAG-Pipeline-Works" class="common-anchor-header">كيفية عمل خط أنابيب RAG النموذجي<button data-href="#How-a-Typical-RAG-Pipeline-Works" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>تتبع معظم خطوط أنابيب RAG، بغض النظر عن إطار العمل، نفس خط التجميع المكون من أربع مراحل. ربما تكون قد كتبت نسخة من هذا بنفسك:</p>
<h3 id="1-Data-Cleaning-and-Chunking" class="common-anchor-header">1. تنظيف البيانات وتقطيعها</h3><p>يبدأ خط التجميع بتنظيف المستندات الخام: إزالة الرؤوس والتذييلات ونص التنقل وأي شيء ليس محتوى حقيقيًا. بمجرد إزالة التشويش، يتم تقسيم النص إلى أجزاء أصغر. تستخدم معظم الفرق الأجزاء ذات الحجم الثابت - عادةً 300-800 رمز - لأنها تحافظ على نموذج التضمين قابلاً للإدارة. الجانب السلبي هو أن التقسيمات تعتمد على الطول وليس على المعنى، لذلك يمكن أن تكون الحدود اعتباطية.</p>
<h3 id="2-Embedding-and-Storage" class="common-anchor-header">2. التضمين والتخزين</h3><p>يتم بعد ذلك تضمين كل جزء باستخدام نموذج تضمين مثل نموذج OpenAI <a href="https://zilliz.com/ai-models/text-embedding-3-small"><code translate="no">text-embedding-3-small</code></a> أو مشفر BAAI. يتم تخزين المتجهات الناتجة في قاعدة بيانات متجهات مثل <a href="https://milvus.io/">Milvus</a> أو <a href="https://zilliz.com/cloud">Zilliz Cloud</a>. تتعامل قاعدة البيانات مع الفهرسة والبحث عن التشابه حتى تتمكن من مقارنة الاستعلامات الجديدة بسرعة مع جميع القطع المخزنة.</p>
<h3 id="3-Querying" class="common-anchor-header">3. الاستعلام</h3><p>عندما يطرح المستخدم سؤالاً - على سبيل المثال، <em>"كيف يقلل RAG من الهلوسة؟</em> - يقوم النظام بتضمين الاستعلام وإرساله إلى قاعدة البيانات. تقوم قاعدة البيانات بإرجاع الأجزاء الأعلى-ك التي تكون متجهاتها الأقرب إلى الاستعلام. هذه هي أجزاء النص التي سيعتمد عليها النموذج للإجابة عن السؤال.</p>
<h3 id="4-Answer-Generation" class="common-anchor-header">4. توليد الإجابة</h3><p>يتم تجميع الأجزاء المسترجعة مع استعلام المستخدم وإدخالها في نموذج توليد الإجابات. يقوم النموذج بإنشاء إجابة باستخدام السياق المقدم كأساس.</p>
<p><strong>يقع التقطيع في بداية هذا الخط بأكمله، ولكن له تأثير كبير</strong>. إذا كانت الأجزاء تتوافق مع المعنى الطبيعي للنص، فإن الاسترجاع يبدو دقيقًا ومتسقًا. أما إذا تم تقطيع الأجزاء في أماكن غير مناسبة، فسيواجه النظام صعوبة أكبر في العثور على المعلومات الصحيحة، حتى مع وجود تضمينات قوية وقاعدة بيانات متجهة سريعة.</p>
<h3 id="The-Challenges-of-Getting-Chunking-Right" class="common-anchor-header">تحديات الحصول على التقطيع الصحيح</h3><p>تستخدم معظم أنظمة RAG اليوم واحدة من طريقتين أساسيتين للتقطيع، وكلاهما له قيود.</p>
<p><strong>1. التقطيع بالحجم الثابت</strong></p>
<p>هذه هي أبسط طريقة: تقسيم النص حسب عدد ثابت من الرموز أو الأحرف. إنه سريع ويمكن التنبؤ به، ولكنه غير مدرك تمامًا لقواعد اللغة أو الموضوعات أو الانتقالات. يمكن تقطيع الجمل إلى نصفين. وأحيانًا حتى الكلمات. تميل التضمينات التي تحصل عليها من هذه التجزئات إلى أن تكون صاخبة لأن الحدود لا تعكس كيفية تنظيم النص بالفعل.</p>
<p><strong>2. التقسيم التكراري للأحرف</strong></p>
<p>هذه الطريقة أكثر ذكاءً بعض الشيء. فهي تقسم النص بشكل هرمي بناءً على إشارات مثل الفقرات أو فواصل الأسطر أو الجمل. إذا كان القسم طويلًا جدًا، فإنه يقسمه بشكل متكرر. يكون الناتج أكثر تماسكًا بشكل عام، ولكنه لا يزال غير متناسق. فبعض المستندات تفتقر إلى بنية واضحة أو لديها أطوال أقسام غير متساوية، مما يضر بدقة الاسترجاع. وفي بعض الحالات، لا يزال هذا النهج ينتج أجزاءً تتجاوز نافذة سياق النموذج.</p>
<p>تواجه كلتا الطريقتين نفس المفاضلة: الدقة مقابل السياق. تعمل الأجزاء الأصغر على تحسين دقة الاسترجاع ولكنها تفقد السياق المحيط؛ بينما تحافظ الأجزاء الأكبر على المعنى ولكنها تخاطر بإضافة ضوضاء غير ذات صلة. إن تحقيق التوازن الصحيح هو ما يجعل التقطيع أمرًا أساسيًا - ومُحبطًا - في تصميم نظام RAG.</p>
<h2 id="Max–Min-Semantic-Chunking-Embed-First-Chunk-Second" class="common-anchor-header">التجزئة الدلالية القصوى والدقيقة: التضمين أولاً، التقطيع ثانياً<button data-href="#Max–Min-Semantic-Chunking-Embed-First-Chunk-Second" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>في عام 2025، نشر S.R. Bhat وآخرون <a href="https://arxiv.org/abs/2505.21700"><em>إعادة التفكير في حجم القطع لاسترجاع المستندات الطويلة: تحليل متعدد البيانات</em></a>. كانت إحدى النتائج الرئيسية التي توصلوا إليها هي أنه لا يوجد حجم <strong>"أفضل"</strong> واحد للقطعة لاسترجاع المستندات الطويلة. تميل الأجزاء الصغيرة (64-128 رمزًا) إلى العمل بشكل أفضل مع الأسئلة الوقائعية أو الأسئلة ذات نمط البحث، بينما تساعد الأجزاء الأكبر (512-1024 رمزًا) في المهام السردية أو مهام التفكير عالي المستوى. بعبارة أخرى، دائمًا ما يكون التقطيع ذو الحجم الثابت حلاً وسطًا.</p>
<p>وهذا يثير سؤالاً طبيعياً: بدلاً من اختيار طول واحد على أمل الحصول على الأفضل، هل يمكننا التقطيع حسب المعنى بدلاً من الحجم؟ <a href="https://link.springer.com/article/10.1007/s10791-025-09638-7"><strong>التقطيع الدلالي الأقصى - الحد الأدنى</strong></a> هو أحد الأساليب التي وجدتها والتي تحاول القيام بذلك بالضبط.</p>
<p>الفكرة بسيطة: <strong>التضمين أولاً، ثم التقطيع ثانياً</strong>. فبدلاً من تقسيم النص ثم تضمين أي أجزاء تتساقط، تقوم الخوارزمية بتضمين <em>جميع الجمل</em> في البداية. ثم تستخدم العلاقات الدلالية بين تضمين تلك الجمل لتقرير أين يجب أن تذهب الحدود.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/embed_first_chunk_second_94f69c664c.png" alt="Diagram showing embed-first chunk-second workflow in Max-Min Semantic Chunking" class="doc-image" id="diagram-showing-embed-first-chunk-second-workflow-in-max-min-semantic-chunking" />
   </span> <span class="img-wrapper"> <span>رسم تخطيطي يوضح سير عمل التضمين أولاً ثم التقطيع أولاً ثم التقطيع ثانياً في التقطيع الدلالي ماكس-مين</span> </span></p>
<p>من الناحية المفاهيمية، تتعامل هذه الطريقة مع التقطيع كمشكلة تجميع مقيّد في مساحة التضمين. تتصفح المستند بالترتيب، جملة واحدة في كل مرة. بالنسبة لكل جملة، تقارن الخوارزمية تضمينها مع تلك الموجودة في القطعة الحالية. إذا كانت الجملة الجديدة قريبة من الناحية الدلالية بما فيه الكفاية، فإنها تنضم إلى القطعة. إذا كانت بعيدة جدًا، تبدأ الخوارزمية بقطعة جديدة. القيد الرئيسي هو أن القطع يجب أن تتبع ترتيب الجملة الأصلي - لا إعادة ترتيب ولا تجميع عام.</p>
<p>والنتيجة هي مجموعة من القطع ذات الطول المتغير التي تعكس المكان الذي يتغير فيه معنى المستند فعليًا، بدلاً من المكان الذي يصل فيه عداد الأحرف إلى الصفر.</p>
<h2 id="How-the-Max–Min-Semantic-Chunking-Strategy-Works" class="common-anchor-header">كيف تعمل استراتيجية التقطيع الدلالي القصوى والدقيقة<button data-href="#How-the-Max–Min-Semantic-Chunking-Strategy-Works" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>تحدد استراتيجية التقطيع الدلالي القصوى-الدقيقة حدود القطع من خلال مقارنة كيفية ارتباط الجمل ببعضها البعض في الفضاء المتجه عالي الأبعاد. وبدلاً من الاعتماد على الأطوال الثابتة، فإنها تنظر في كيفية تغير المعنى عبر المستند. يمكن تقسيم العملية إلى ست خطوات:</p>
<h3 id="1-Embed-all-sentences-and-start-a-chunk" class="common-anchor-header">1. تضمين جميع الجمل وبدء جزء مقطوع</h3><p>يقوم نموذج التضمين بتحويل كل جملة في المستند إلى تضمين متجه. يعالج الجمل بالترتيب. If the first <em>n–k</em> sentences form the current chunk C, the following sentence (sₙ₋ₖ₊₁) needs to be evaluated: should it join C, or start a new chunk?</p>
<h3 id="2-Measure-how-consistent-the-current-chunk-is" class="common-anchor-header">2. قياس مدى اتساق القطعة الحالية</h3><p>ضمن القطعة C، احسب الحد الأدنى لتشابه جيب التمام الزوجي بين جميع تضمينات الجمل. تعكس هذه القيمة مدى ترابط الجمل داخل القطعة. يشير انخفاض الحد الأدنى للتشابه إلى أن الجمل أقل ترابطًا، مما يشير إلى أن القطعة قد تحتاج إلى التقسيم.</p>
<h3 id="3-Compare-the-new-sentence-to-the-chunk" class="common-anchor-header">3. قارن الجملة الجديدة بالقطعة</h3><p>بعد ذلك، قم بحساب الحد الأقصى لجيب التمام للتشابه بين الجملة الجديدة وأي جملة موجودة بالفعل في C. يعكس هذا مدى توافق الجملة الجديدة دلاليًا مع القطعة الموجودة.</p>
<h3 id="4-Decide-whether-to-extend-the-chunk-or-start-a-new-one" class="common-anchor-header">4. قرّر ما إذا كنت تريد توسيع القطعة أو البدء بقطعة جديدة</h3><p>هذه هي القاعدة الأساسية:</p>
<ul>
<li><p>إذا كان <strong>الحد الأقصى للتشابه بين الجملة الجديدة</strong> والجزء <strong>C</strong> <strong>أكبر من أو يساوي</strong> <strong>الحد الأدنى للتشابه داخل C،</strong> → تتناسب الجملة الجديدة وتبقى في الجزء C.</p></li>
<li><p>خلاف ذلك، → ابدأ جزءًا جديدًا.</p></li>
</ul>
<p>هذا يضمن أن كل قطعة تحافظ على اتساقها الدلالي الداخلي.</p>
<h3 id="5-Adjust-thresholds-as-the-document-changes" class="common-anchor-header">5. ضبط العتبات مع تغير المستند</h3><p>لتحسين جودة القطع، يمكن تعديل المعلمات مثل حجم القطعة وعتبات التشابه بشكل ديناميكي. يسمح ذلك للخوارزمية بالتكيف مع هياكل المستندات المختلفة والكثافة الدلالية.</p>
<h3 id="6-Handle-the-first-few-sentences" class="common-anchor-header">6. التعامل مع الجمل القليلة الأولى</h3><p>عندما تحتوي القطعة على جملة واحدة فقط، تتعامل الخوارزمية مع المقارنة الأولى باستخدام عتبة تشابه ثابتة. إذا كان التشابه بين الجملة 1 والجملة 2 أعلى من تلك العتبة، فإنهما يشكلان جزءًا واحدًا. إذا لم يكن كذلك، يتم فصلهما على الفور.</p>
<h2 id="Strengths-and-Limitations-of-Max–Min-Semantic-Chunking" class="common-anchor-header">نقاط القوة والقصور في التقطيع الدلالي الأقصى الأدنى<button data-href="#Strengths-and-Limitations-of-Max–Min-Semantic-Chunking" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>يحسّن التقطيع الدلالي الأقصى-أدنى تقطيع دلالي من كيفية تقسيم أنظمة RAG للنص باستخدام المعنى بدلاً من الطول، ولكنه ليس حلاً سحريًا. فيما يلي نظرة عملية على ما تقوم به بشكل جيد وأين لا تزال قاصرة.</p>
<h3 id="What-It-Does-Well" class="common-anchor-header">ما هو جيد</h3><p>يتحسن التقطيع الدلالي الأقصى والأصغر على التقطيع التقليدي بثلاث طرق مهمة:</p>
<h4 id="1-Dynamic-meaning-driven-chunk-boundaries" class="common-anchor-header"><strong>1. حدود القطع الديناميكية المبنية على المعنى</strong></h4><p>على عكس المقاربات ذات الحجم الثابت أو القائمة على الهيكل، تعتمد هذه الطريقة على التشابه الدلالي لتوجيه عملية التقطيع. فهي تقارن الحد الأدنى للتشابه داخل القطعة الحالية (مدى تماسكها) بالحد الأقصى للتشابه بين الجملة الجديدة وتلك القطعة (مدى ملاءمتها). إذا كان هذا الأخير أعلى، تنضم الجملة إلى القطعة؛ وإلا تبدأ قطعة جديدة.</p>
<h4 id="2-Simple-practical-parameter-tuning" class="common-anchor-header"><strong>2. ضبط بسيط وعملي للمعلمات</strong></h4><p>تعتمد الخوارزمية على ثلاثة بارامترات أساسية فقط:</p>
<ul>
<li><p><strong>الحد الأقصى لحجم القطعة</strong></p></li>
<li><p><strong>الحد الأدنى للتشابه</strong> بين أول جملتين، و</p></li>
<li><p><strong>وعتبة التشابه</strong> لإضافة جمل جديدة.</p></li>
</ul>
<p>تتكيف هذه المعلمات تلقائيًا مع السياق - تتطلب القطع الأكبر حجمًا عتبات تشابه أكثر صرامة للحفاظ على التماسك.</p>
<h4 id="3-Low-processing-overhead" class="common-anchor-header"><strong>3. نفقات معالجة منخفضة</strong></h4><p>نظرًا لأن خط أنابيب RAG يحسب بالفعل تضمين الجمل، فإن التقطيع الدلالي Max-Min Semantic Chunking لا يضيف عمليات حسابية ثقيلة. كل ما يحتاجه هو مجموعة من عمليات التحقق من تشابه جيب التمام أثناء المسح من خلال الجمل. وهذا يجعلها أرخص من العديد من تقنيات التقطيع الدلالي التي تتطلب نماذج إضافية أو تجميعًا متعدد المراحل.</p>
<h3 id="What-It-Still-Can’t-Solve" class="common-anchor-header">ما لا تستطيع حلّه بعد</h3><p>يحسّن التقطيع الدلالي الأقصى-الأدنى من حدود القطع، لكنه لا يلغي جميع تحديات تجزئة المستندات. ونظرًا لأن الخوارزمية تعالج الجمل بالترتيب وتقوم بالتجميع محليًا فقط، فلا يزال بإمكانها أن تفوت العلاقات بعيدة المدى في المستندات الأطول أو الأكثر تعقيدًا.</p>
<p>إحدى المشكلات الشائعة هي <strong>تجزئة السياق</strong>. عندما تنتشر المعلومات المهمة عبر أجزاء مختلفة من المستند، قد تضع الخوارزمية هذه الأجزاء في أجزاء منفصلة. وعندها تحمل كل قطعة جزءًا من المعنى فقط.</p>
<p>على سبيل المثال، في ملاحظات الإصدار Milvus 2.4.13، كما هو موضح أدناه، قد تحتوي إحدى القطع على معرّف الإصدار بينما تحتوي أخرى على قائمة الميزات. يعتمد استعلام مثل <em>"ما هي الميزات الجديدة التي تم تقديمها في الإصدار 2.4.13 من ملفوس 2.4.13؟</em> إذا تم تقسيم هذه التفاصيل عبر أجزاء مختلفة، فقد لا يربط نموذج التضمين بينهما، مما يؤدي إلى استرجاع أضعف.</p>
<ul>
<li>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/v2413_a98e1b1f99.png" alt="Example showing context fragmentation in Milvus 2.4.13 Release Notes with version identifier and feature list in separate chunks" class="doc-image" id="example-showing-context-fragmentation-in-milvus-2.4.13-release-notes-with-version-identifier-and-feature-list-in-separate-chunks" />
   </span> <span class="img-wrapper"> <span>مثال يُظهر تجزئة السياق في ملاحظات الإصدار Milvus 2.4.13 مع معرف الإصدار وقائمة الميزات في أجزاء منفصلة</span> </span></li>
</ul>
<p>يؤثر هذا التجزئة أيضًا على مرحلة توليد LLM. إذا كان مرجع الإصدار في جزء واحد وأوصاف الميزة في جزء آخر، فإن النموذج يتلقى سياقًا غير مكتمل ولا يمكنه التفكير بشكل واضح في العلاقة بين الاثنين.</p>
<p>للتخفيف من حدة هذه الحالات، غالبًا ما تستخدم الأنظمة تقنيات مثل النوافذ المنزلقة أو حدود القطع المتداخلة أو عمليات المسح متعددة المسارات. هذه الأساليب تعيد تقديم بعض السياق المفقود وتقلل من التجزئة وتساعد خطوة الاسترجاع على الاحتفاظ بالمعلومات ذات الصلة.</p>
<h2 id="Conclusion" class="common-anchor-header">الخاتمة<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>لا يعد التقطيع الدلالي الأقصى الأدنى حلًا سحريًا لكل مشكلة من مشاكل RAG، ولكنه يعطينا طريقة أكثر عقلانية للتفكير في حدود القطع. فبدلاً من السماح لحدود الرموز بتقرير أين يتم تقطيع الأفكار، فإنه يستخدم التضمينات لاكتشاف أين يتحول المعنى بالفعل. بالنسبة للعديد من المستندات في العالم الحقيقي - واجهات برمجة التطبيقات، والمواصفات، والسجلات، وملاحظات الإصدار، وأدلة استكشاف الأخطاء وإصلاحها - يمكن لهذا وحده أن يرفع جودة الاسترجاع بشكل ملحوظ.</p>
<p>ما يعجبني في هذا النهج هو أنه يتناسب بشكل طبيعي مع خطوط أنابيب RAG الحالية. إذا كنت تقوم بالفعل بتضمين الجمل أو الفقرات، فإن التكلفة الإضافية هي في الأساس بعض فحوصات تشابه جيب التمام. لا تحتاج إلى نماذج إضافية أو تجميع معقد أو معالجة مسبقة ثقيلة الوزن. وعندما تنجح، فإن الأجزاء التي تنتجها تبدو أكثر "إنسانية" - أقرب إلى كيفية تجميع المعلومات ذهنيًا عند القراءة.</p>
<p>لكن هذه الطريقة لا تزال لديها نقاط عمياء. فهي ترى المعنى محليًا فقط، ولا يمكنها إعادة ربط المعلومات المتباعدة عن قصد. لا تزال النوافذ المتداخلة والمسح متعدد المسارات وغيرها من حيل الحفاظ على السياق ضرورية، خاصةً بالنسبة للمستندات التي تكون فيها المراجع والتفسيرات بعيدة عن بعضها البعض.</p>
<p>ومع ذلك، فإن التقطيع الدلالي ماكس-مين ينقلنا في الاتجاه الصحيح: بعيدًا عن التقطيع التعسفي للنص ونحو خطوط أنابيب الاسترجاع التي تحترم بالفعل الدلالات. إذا كنت تستكشف طرقًا لجعل RAG أكثر موثوقية، فإن الأمر يستحق التجربة.</p>
<p>هل لديك أسئلة أو تريد التعمق في تحسين أداء RAG؟ انضم إلى <a href="https://discord.com/invite/8uyFbECzPX">Discord</a> الخاص بنا وتواصل مع المهندسين الذين يقومون ببناء وضبط أنظمة الاسترجاع الحقيقية كل يوم.</p>
