---
id: >-
  introducing-aisaq-in-milvus-billion-scale-vector-search-got-3200-cheaper-on-memory.md
title: >-
  تقديم AISAQ في Milvus: البحث عن المتجهات بمليارات الدولارات أصبح أرخص بـ 3,200
  مرة على الذاكرة
author: Martin Li
date: 2025-12-10T00:00:00.000Z
cover: assets.zilliz.com/AISAQ_Cover_66b628b762.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database'
meta_keywords: 'Milvus2.6, AISAQ, DISKANN, vector search'
meta_title: |
  AISAQ in Milvus Cuts Memory 3,200× for Billion-Scale Search
desc: >-
  اكتشف كيف يقلل Milvus من تكاليف الذاكرة بمقدار 3200 مرة باستخدام AISAQ، مما
  يتيح إمكانية البحث عن مليار متجه قابل للتطوير دون تحميل DRAM.
origin: >-
  https://milvus.io/blog/introducing-aisaq-in-milvus-billion-scale-vector-search-got-3200-cheaper-on-memory.md
---
<p>لقد أصبحت قواعد بيانات المتجهات بنية تحتية أساسية لأنظمة الذكاء الاصطناعي ذات المهام الحرجة، وتتزايد أحجام بياناتها بشكل كبير - وغالبًا ما تصل إلى مليارات المتجهات. عند هذا النطاق، يصبح كل شيء أصعب: الحفاظ على زمن انتقال منخفض، والحفاظ على الدقة، وضمان الموثوقية، والعمل عبر النسخ المتماثلة والمناطق. ولكن هناك تحدٍ واحد يميل إلى الظهور مبكرًا ويهيمن على القرارات المعمارية - التكلفة<strong>.</strong></p>
<p>لتوفير بحث سريع، تحتفظ معظم قواعد البيانات المتجهة بهياكل الفهرسة الرئيسية في DRAM (ذاكرة الوصول العشوائي الديناميكية)، وهي أسرع مستويات الذاكرة وأكثرها تكلفة. هذا التصميم فعال من حيث الأداء، لكنه لا يتناسب مع حجم البيانات. يتناسب استخدام DRAM مع حجم البيانات بدلاً من حركة مرور الاستعلام، وحتى مع الضغط أو التفريغ الجزئي لذاكرة الوصول العشوائي الديناميكية، يجب أن تبقى أجزاء كبيرة من الفهرس في الذاكرة. ومع نمو مجموعات البيانات، سرعان ما تصبح تكاليف الذاكرة عاملاً مقيدًا.</p>
<p>يدعم Milvus بالفعل <strong>DISKANN،</strong> وهو نهج ANN قائم على القرص يقلل من ضغط الذاكرة عن طريق نقل جزء كبير من الفهرس إلى SSD. ومع ذلك، لا يزال DISKANN يعتمد على DRAM للتمثيلات المضغوطة المستخدمة أثناء البحث. يأخذ <a href="https://milvus.io/docs/release_notes.md#v264">Milvus 2.6</a> هذا الأمر إلى أبعد من ذلك مع <a href="https://milvus.io/docs/aisaq.md">AISAQ،</a> وهو فهرس متجه قائم على القرص مستوحى من <a href="https://milvus.io/docs/diskann.md">DISKANN</a> يخزن جميع البيانات المهمة للبحث على القرص. في عبء عمل بمليار متجه، يقلل هذا من استخدام الذاكرة من <strong>32 جيجابايت إلى حوالي 10 ميغابايت - أي</strong> <strong>تخفيض بمقدار 3,200 مرة - مع</strong>الحفاظ على الأداء العملي.</p>
<p>في الأقسام التالية، نوضح في الأقسام التالية كيفية عمل البحث المتجه القائم على الرسم البياني ومن أين تأتي تكاليف الذاكرة، وكيف يعيد AISAQ تشكيل منحنى التكلفة للبحث المتجه على نطاق المليار متجه.</p>
<h2 id="How-Conventional-Graph-Based-Vector-Search-Works" class="common-anchor-header">كيفية عمل البحث المتجه التقليدي المستند إلى الرسم البياني<button data-href="#How-Conventional-Graph-Based-Vector-Search-Works" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p><strong>البحث</strong> عن<strong>المتجهات</strong> هو عملية إيجاد نقاط البيانات التي يكون تمثيلها العددي الأقرب إلى استعلام في فضاء عالي الأبعاد. تعني كلمة "الأقرب" ببساطة أصغر مسافة وفقًا لدالة المسافة، مثل مسافة جيب التمام أو مسافة L2. على مقياس صغير، يكون هذا واضحًا ومباشرًا: احسب المسافة بين الاستعلام وكل متجه، ثم أرجع أقربها. لكن على نطاق واسع، على سبيل المثال على نطاق المليار، سرعان ما يصبح هذا النهج بطيئًا جدًا بحيث لا يكون عمليًا.</p>
<p>لتجنّب المقارنات الشاملة، تعتمد أنظمة البحث التقريبي لأقرب جار (ANNS) الحديثة على <strong>مؤشرات قائمة على الرسم البياني</strong>. بدلاً من مقارنة استعلام مقابل كل متجه، ينظم الفهرس المتجهات في <strong>رسم بياني</strong>. تمثل كل عقدة متجهًا، وتربط الحواف المتجهات المتقاربة عدديًا. تسمح هذه البنية للنظام بتضييق مساحة البحث بشكل كبير.</p>
<p>يتم بناء الرسم البياني مسبقًا، بناءً على العلاقات بين المتجهات فقط. لا يعتمد على الاستعلامات. عندما يصل استعلام، تكون مهمة النظام هي <strong>التنقل في الرسم البياني بكفاءة</strong> وتحديد المتجهات ذات المسافة الأصغر إلى الاستعلام - دون مسح مجموعة البيانات بأكملها.</p>
<p>يبدأ البحث من <strong>نقطة دخول</strong> محددة مسبقًا في الرسم البياني. قد تكون نقطة البداية هذه بعيدة عن الاستعلام، لكن الخوارزمية تحسّن موقعها خطوة بخطوة من خلال التحرك نحو المتجهات التي تبدو أقرب إلى الاستعلام. خلال هذه العملية، يحافظ البحث على بنيتين داخليتين للبيانات تعملان معًا: <strong>قائمة مرشحة</strong> <strong>وقائمة نتائج</strong>.</p>
<p>وأهم خطوتين خلال هذه العملية هما توسيع قائمة المرشحين وتحديث قائمة النتائج.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/whiteboard_exported_image_84f8324275.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="Expanding-the-Candidate-List" class="common-anchor-header">توسيع قائمة المرشحين</h3><p>تمثل <strong>القائمة المرشحة</strong> المكان الذي يمكن أن ينتقل إليه البحث بعد ذلك. وهي عبارة عن مجموعة ذات أولوية من عقد الرسم البياني التي تبدو واعدة بناءً على المسافة التي تفصلها عن الاستعلام.</p>
<p>في كل تكرار، تقوم الخوارزمية</p>
<ul>
<li><p><strong>تختار أقرب مرشح تم اكتشافه حتى الآن.</strong> من قائمة المرشحين، تختار المتجه ذا المسافة الأصغر إلى الاستعلام.</p></li>
<li><p><strong>تسترجع جيران ذلك المتجه من الرسم البياني.</strong> هؤلاء الجيران هم المتجهات التي تم تحديدها أثناء إنشاء الفهرس على أنها قريبة من المتجه الحالي.</p></li>
<li><p><strong>يقيّم الجيران الذين لم تتم زيارتهم ويضيفهم إلى القائمة المرشحة.</strong> لكل جار لم يتم استكشافه بالفعل، تحسب الخوارزمية المسافة التي تفحصها إلى الاستعلام. يتم تخطي الجيران الذين تمت زيارتهم سابقًا، بينما يتم إدراج الجيران الجدد في قائمة المرشحين إذا ظهروا واعدين.</p></li>
</ul>
<p>من خلال توسيع قائمة المرشحين بشكل متكرر، يستكشف البحث مناطق ذات صلة متزايدة من الرسم البياني. يسمح ذلك للخوارزمية بالتحرك بثبات نحو إجابات أفضل أثناء فحص جزء صغير فقط من جميع المتجهات.</p>
<h3 id="Updating-the-Result-List" class="common-anchor-header">تحديث قائمة النتائج</h3><p>في الوقت نفسه، تحتفظ الخوارزمية <strong>بقائمة نتائج</strong>، والتي تسجل أفضل المرشحين الذين تم العثور عليهم حتى الآن للإخراج النهائي. ومع تقدم البحث، فإنها</p>
<ul>
<li><p><strong>يتتبع أقرب المتجهات التي صادفها أثناء اجتيازها.</strong> يتضمن ذلك المتجهات المختارة للتوسيع بالإضافة إلى المتجهات الأخرى التي تم تقييمها على طول الطريق.</p></li>
<li><p><strong>يخزن مسافاتها إلى الاستعلام.</strong> وهذا يجعل من الممكن ترتيب المتجهات المرشحة والحفاظ على أقرب أقرب جيرانها الحاليين.</p></li>
</ul>
<p>مع مرور الوقت، ومع تقييم المزيد من المرشحين وإيجاد تحسينات أقل، تستقر قائمة النتائج. وبمجرد أن يصبح من غير المحتمل أن ينتج المزيد من استكشاف الرسم البياني متجهات أقرب، ينتهي البحث ويعيد قائمة النتائج كإجابة نهائية.</p>
<p>بعبارات بسيطة، <strong>تتحكم القائمة المرشحة في الاست</strong>كشاف، بينما <strong>تجسد قائمة النتائج أفضل الإجابات المكتشفة حتى الآن</strong>.</p>
<h2 id="The-Trade-Off-in-Graph-Based-Vector-Search" class="common-anchor-header">المفاضلة في البحث المستند إلى الرسم البياني للمتجهات<button data-href="#The-Trade-Off-in-Graph-Based-Vector-Search" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>هذا النهج القائم على الرسم البياني هو ما يجعل البحث المتجه واسع النطاق عمليًا في المقام الأول. من خلال التنقل في الرسم البياني بدلاً من مسح كل متجه، يمكن للنظام العثور على نتائج عالية الجودة مع لمس جزء صغير فقط من مجموعة البيانات.</p>
<p>ومع ذلك، فإن هذه الكفاءة لا تأتي مجانًا. يكشف البحث القائم على الرسم البياني عن مفاضلة أساسية بين <strong>الدقة والتكلفة.</strong></p>
<ul>
<li><p>يؤدي استكشاف المزيد من الجيران إلى تحسين الدقة من خلال تغطية جزء أكبر من الرسم البياني وتقليل فرصة فقدان أقرب الجيران الحقيقيين.</p></li>
<li><p>في الوقت نفسه، يضيف كل توسع إضافي عملًا إضافيًا: المزيد من حسابات المسافة، والمزيد من عمليات الوصول إلى بنية الرسم البياني، والمزيد من قراءات البيانات المتجهة. كلما كان البحث أعمق أو أوسع، تتراكم هذه التكاليف. واعتمادًا على كيفية تصميم الفهرس، فإنها تظهر على شكل استخدام أعلى لوحدة المعالجة المركزية، أو زيادة الضغط على الذاكرة، أو إدخال/إخراج إضافي على القرص.</p></li>
</ul>
<p>يعد تحقيق التوازن بين هذه القوى المتعارضة - الاستدعاء العالي مقابل الاستخدام الفعال للموارد - أمرًا أساسيًا في تصميم البحث القائم على الرسم البياني.</p>
<p>تم تصميم كل من <a href="https://milvus.io/blog/diskann-explained.md"><strong>DISKANN</strong></a> و <strong>AISAQ</strong> حول نفس هذا التوتر، لكنهما يتخذان خيارات معمارية مختلفة حول كيفية دفع هذه التكاليف ومكان دفعها.</p>
<h2 id="How-DISKANN-Optimizes-Disk-Based-Vector-Search" class="common-anchor-header">كيف يقوم DISKANN بتحسين البحث المتجه القائم على الأقراص<button data-href="#How-DISKANN-Optimizes-Disk-Based-Vector-Search" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/DISKANN_9c9c6a734f.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>DISKANN هو الحل الأكثر تأثيراً للشبكات العصبية الاصطناعية القائمة على الأقراص حتى الآن، وهو بمثابة خط الأساس الرسمي لمسابقة NeurIPS Big ANN، وهو معيار عالمي للبحث المتجه على نطاق المليار. لا تكمن أهميته في الأداء فحسب، بل تكمن أهميته في ما أثبتته: <strong>لا يجب أن يكون بحث الشبكة العصبية الاصطناعية القائم على الرسم البياني في الذاكرة بالكامل ليكون سريعاً</strong>.</p>
<p>من خلال الجمع بين التخزين القائم على أقراص التخزين ذات الحالة الثابتة (SSD) والهياكل المختارة بعناية داخل الذاكرة، أثبت DISKANN أن البحث المتجه واسع النطاق يمكن أن يحقق دقة عالية وزمن استجابة منخفض على الأجهزة السلعية - دون الحاجة إلى آثار أقدام ضخمة من ذاكرة DRAM. وهو يقوم بذلك من خلال إعادة التفكير في <em>أجزاء البحث التي يجب أن تكون سريعة</em> <em>والأجزاء التي يمكن أن تتحمل الوصول الأبطأ</em>.</p>
<p><strong>على مستوى عالٍ، يحتفظ DISKANN بالبيانات الأكثر وصولًا في الذاكرة، بينما ينقل البنى الأكبر والأقل وصولًا إلى القرص.</strong> يتم تحقيق هذا التوازن من خلال عدة خيارات تصميم رئيسية.</p>
<h3 id="1-Using-PQ-Distances-to-Expand-the-Candidate-List" class="common-anchor-header">1. استخدام مسافات PQ لتوسيع قائمة المرشحين</h3><p>توسيع قائمة المرشحين هي العملية الأكثر تكرارًا في البحث القائم على الرسم البياني. تتطلب كل عملية توسيع تقدير المسافة بين متجه الاستعلام وجيران العقدة المرشحة. يتطلب إجراء هذه العمليات الحسابية باستخدام متجهات كاملة عالية الأبعاد قراءات عشوائية متكررة من القرص - وهي عملية مكلفة من الناحية الحسابية ومن حيث الإدخال/الإخراج.</p>
<p>يتفادى DISKANN هذه التكلفة عن طريق ضغط المتجهات إلى <strong>أكواد التكميم الكمي للمنتج (PQ)</strong> والاحتفاظ بها في الذاكرة. تكون أكواد PQ أصغر بكثير من المتجهات الكاملة، ولكنها لا تزال تحتفظ بمعلومات كافية لتقدير المسافة تقريبًا.</p>
<p>أثناء التوسيع المرشح، يحسب DISKANN المسافات باستخدام رموز PQ المودعة في الذاكرة بدلاً من قراءة المتجهات الكاملة من SSD. وهذا يقلل بشكل كبير من إدخال/إخراج الأقراص أثناء اجتياز الرسم البياني، مما يسمح للبحث بتوسيع المرشحين بسرعة وكفاءة مع إبقاء معظم حركة مرور SSD خارج المسار الحرج.</p>
<h3 id="2-Co-Locating-Full-Vectors-and-Neighbor-Lists-on-Disk" class="common-anchor-header">2. الاشتراك في تحديد موقع المتجهات الكاملة والقوائم المجاورة على القرص</h3><p>لا يمكن ضغط جميع البيانات أو الوصول إليها تقريبًا. بمجرد تحديد المرشحين الواعدين، لا يزال البحث بحاجة إلى الوصول إلى نوعين من البيانات للحصول على نتائج دقيقة:</p>
<ul>
<li><p><strong>قوائم الج</strong>يران، لمواصلة اجتياز الرسم البياني</p></li>
<li><p><strong>المتجهات الكاملة (غير المضغوطة)</strong>، لإعادة الترتيب النهائي</p></li>
</ul>
<p>يتم الوصول إلى هذه الهياكل بشكل أقل تكرارًا من أكواد PQ، لذلك يخزنها DISKANN على SSD. لتقليل الحمل الزائد على القرص، يضع DISKANN قائمة جيران كل عقدة ومتجهها الكامل في نفس المنطقة الفعلية على القرص. وهذا يضمن أن قراءة واحدة على قرص SSD يمكنها استرداد كليهما.</p>
<p>من خلال تجميع البيانات ذات الصلة في مكان واحد، يقلل DISKANN من عدد عمليات الوصول العشوائي إلى القرص المطلوبة أثناء البحث. يعمل هذا التحسين على تحسين كفاءة التوسيع وإعادة الترتيب على حد سواء، خاصةً على نطاق واسع.</p>
<h3 id="3-Parallel-Node-Expansion-for-Better-SSD-Utilization" class="common-anchor-header">3. التوسيع المتوازي للعقدة من أجل استخدام أفضل لقرص SSD</h3><p>البحث في الشبكة العصبية الاصطناعية القائمة على الرسم البياني هو عملية تكرارية. إذا كان كل تكرار يقوم بتوسيع عقدة مرشحة واحدة فقط، يصدر النظام قراءة قرص واحد فقط في كل مرة، تاركًا معظم عرض النطاق الترددي المتوازي لمحرك أقراص الحالة الصلبة غير مستخدم. لتجنب عدم الكفاءة هذه، يقوم DISKANN بتوسيع عدة مرشحين في كل تكرار ويرسل طلبات قراءة متوازية إلى قرص SSD. يستفيد هذا النهج بشكل أفضل من النطاق الترددي المتاح ويقلل من إجمالي عدد التكرارات المطلوبة.</p>
<p>تتحكم المعلمة <strong>beam_width_ratio</strong> في عدد المرشحين الذين يتم توسيعهم بالتوازي: <strong>عرض الحزمة = عدد أنوية وحدة المعالجة المركزية × نسبة_عرض_عرض_الحزمة.</strong> تؤدي النسبة الأعلى إلى توسيع نطاق البحث - مما قد يحسن الدقة - ولكنها تزيد أيضًا من الحوسبة وإدخال/إخراج القرص.</p>
<p>ولتعويض ذلك، يقدم DISKANN <code translate="no">search_cache_budget_gb_ratio</code> الذي يحتفظ بالذاكرة لتخزين البيانات التي يتم الوصول إليها بشكل متكرر مؤقتًا، مما يقلل من القراءات المتكررة على القرص الصلب. تساعد هذه الآليات مجتمعةً DISKANN على تحقيق التوازن بين الدقة وزمن الاستجابة وكفاءة الإدخال/الإخراج.</p>
<h3 id="Why-This-Matters--and-Where-the-Limits-Appear" class="common-anchor-header">سبب أهمية ذلك - وأين تظهر الحدود</h3><p>يعد تصميم DISKANN خطوة كبيرة إلى الأمام في البحث المتجه القائم على القرص. من خلال الاحتفاظ بأكواد PQ في الذاكرة ودفع الهياكل الأكبر إلى SSD، فإنه يقلل بشكل كبير من بصمة الذاكرة مقارنةً بفهارس الرسوم البيانية داخل الذاكرة بالكامل.</p>
<p>في الوقت نفسه، لا تزال هذه البنية تعتمد على <strong>DRAM دائم التشغيل</strong> للبيانات المهمة للبحث. يجب أن تظل رموز PQ، وذاكرة التخزين المؤقت، وهياكل التحكم مقيمة في الذاكرة للحفاظ على كفاءة عملية العبور. ومع نمو مجموعات البيانات إلى مليارات المتجهات وعمليات النشر التي تضيف نسخًا متماثلة أو مناطق متماثلة، يمكن أن تظل متطلبات الذاكرة هذه عاملاً مقيدًا.</p>
<p>هذه هي الفجوة التي صُمم <strong>AISAQ</strong> لمعالجتها.</p>
<h2 id="How-AISAQ-Works-and-Why-It-Matters" class="common-anchor-header">كيفية عمل AISAQ وسبب أهميته<button data-href="#How-AISAQ-Works-and-Why-It-Matters" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>يعتمد AISAQ على الأفكار الأساسية وراء DISKANN مباشرةً ولكنه يقدم تحولاً حاسمًا: فهو يلغي <strong>الحاجة إلى الاحتفاظ ببيانات PQ في DRAM</strong>. فبدلاً من التعامل مع المتجهات المضغوطة على أنها هياكل مهمة للبحث ودائمة في الذاكرة، ينقلها AISAQ إلى SSD ويعيد تصميم كيفية وضع بيانات الرسم البياني على القرص للحفاظ على كفاءة اجتيازها.</p>
<p>ولتحقيق ذلك، يعيد AISAQ تنظيم تخزين العُقد بحيث يتم ترتيب البيانات المطلوبة أثناء البحث في الرسم البياني - المتجهات الكاملة وقوائم الجيران ومعلومات PQ - على القرص في أنماط محسّنة للوصول إلى الموقع. والهدف ليس فقط دفع المزيد من البيانات إلى القرص الأكثر اقتصادًا، بل القيام بذلك <strong>دون تعطيل عملية البحث الموصوفة سابقًا</strong>.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/AISAQ_244e661794.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>لتحقيق التوازن بين الأداء وكفاءة التخزين في ظل أعباء العمل المختلفة، يوفر AISAQ وضعين للتخزين على القرص. تختلف هذه الأوضاع بشكل أساسي في كيفية تخزين البيانات المضغوطة PQ والوصول إليها أثناء البحث.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/aisaq_vs_diskann_35ebee3c64.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="AISAQ-performance-Optimized-for-Speed" class="common-anchor-header">أداء AISAQ: مُحسَّن للسرعة</h3><p>يحافظ AISAQ-performance على جميع البيانات على القرص مع الحفاظ على انخفاض النفقات العامة للإدخال/الإخراج من خلال تجميع البيانات.</p>
<p>في هذا الوضع:</p>
<ul>
<li><p>يتم تخزين المتجه الكامل لكل عقدة وقائمة الحواف ورموز PQ الخاصة بجيرانها معًا على القرص.</p></li>
<li><p>لا تزال زيارة عقدة ما تتطلب <strong>قراءة SSD واحدة</strong> فقط، لأن جميع البيانات اللازمة لتوسيع المرشح وتقييمه يتم تجميعها على قرص واحد.</p></li>
</ul>
<p>من من منظور خوارزمية البحث، يعكس هذا بشكل وثيق نمط وصول DISKANN. يظل توسيع المرشح فعالاً، ويكون أداء وقت التشغيل قابلاً للمقارنة، على الرغم من أن جميع البيانات المهمة للبحث موجودة الآن على القرص.</p>
<p>تتمثل المفاضلة في نفقات التخزين الزائدة. نظرًا لأن بيانات PQ الخاصة بالجار قد تظهر في صفحات قرص متعددة العقد، فإن هذا التخطيط يقدم تكرارًا ويزيد بشكل كبير من حجم الفهرس الكلي.</p>
<p><strong>ولذلك، فإن وضع AISAQ-Performance يعطي الأولوية لوقت الاستجابة المنخفض للإدخال/الإخراج على كفاءة القرص.</strong></p>
<h3 id="AISAQ-scale-Optimized-for-Storage-Efficiency" class="common-anchor-header">مقياس AISAQAQ: مُحسَّن لكفاءة التخزين</h3><p>يتبع AISAQ-Scale النهج المعاكس. فهو مصمم <strong>لتقليل استخدام القرص</strong> مع الاحتفاظ بجميع البيانات على SSD.</p>
<p>في هذا الوضع:</p>
<ul>
<li><p>يتم تخزين بيانات PQ على القرص بشكل منفصل، دون تكرار.</p></li>
<li><p>هذا يزيل التكرار ويقلل بشكل كبير من حجم الفهرس.</p></li>
</ul>
<p>وتتمثل المفاضلة في أن الوصول إلى عقدة ورموز PQ المجاورة لها قد يتطلب <strong>قراءات متعددة على قرص SS</strong>D، مما يزيد من عمليات الإدخال/الإخراج أثناء توسيع المرشح. إذا تُرك هذا الأمر دون تحسينه، سيؤدي ذلك إلى إبطاء البحث بشكل كبير.</p>
<p>للتحكم في هذا الحمل الزائد، يقدم وضع AISAQ-Scale تحسينين إضافيين:</p>
<ul>
<li><p><strong>إعادة ترتيب بيانات PQ،</strong> والتي ترتب ناقلات PQ حسب أولوية الوصول لتحسين الموقع وتقليل القراءات العشوائية.</p></li>
<li><p><strong>ذاكرة تخزين مؤقتة لبيانات PQ في DRAM</strong> (<code translate="no">pq_cache_size</code>)، والتي تخزن بيانات PQ التي يتم الوصول إليها بشكل متكرر وتتجنب القراءات المتكررة على القرص للإدخالات الساخنة.</p></li>
</ul>
<p>وبفضل هذه التحسينات، يحقق وضع AISAQ-Scale كفاءة تخزين أفضل بكثير من وضع AISAQ-Performance، مع الحفاظ على أداء البحث العملي. ويظل هذا الأداء أقل من أداء DISKANN أو AISAQ-Performance، ولكن بصمة الذاكرة أصغر بكثير.</p>
<h3 id="Key-Advantages-of-AISAQ" class="common-anchor-header">المزايا الرئيسية لنظام AISAQ</h3><p>من خلال نقل جميع البيانات الحرجة للبحث إلى القرص وإعادة تصميم كيفية الوصول إلى تلك البيانات، يغير AISAQ بشكل أساسي التكلفة وقابلية التوسع في البحث المتجه القائم على الرسم البياني. يوفر تصميمه ثلاث مزايا مهمة.</p>
<p><strong>1. استخدام DRAM أقل بما يصل إلى 3,200 × 3,200 مرة</strong></p>
<p>يقلل تكميم المنتج بشكل كبير من حجم المتجهات عالية الأبعاد، ولكن على نطاق مليار، لا تزال بصمة الذاكرة كبيرة. حتى بعد الضغط، يجب الاحتفاظ برموز PQ في الذاكرة أثناء البحث في التصاميم التقليدية.</p>
<p>على سبيل المثال، في معيار <strong>SIFT1B،</strong> وهو معيار يحتوي على مليار متجه ذي 128 بُعد، تتطلب أكواد PQ وحدها ما يقرب من <strong>30-120 جيجابايت من ذاكرة DRAM،</strong> اعتمادًا على التكوين. سيتطلب تخزين المتجهات الكاملة غير المضغوطة <strong> حوالي 480</strong> جيجابايت إضافية. في حين أن PQ يقلل من استخدام الذاكرة بمقدار 4-16×، فإن البصمة المتبقية لا تزال كبيرة بما يكفي للسيطرة على تكلفة البنية التحتية.</p>
<p>يزيل AISAQ هذا الشرط بالكامل. من خلال تخزين أكواد PQ على قرص SSD بدلاً من DRAM، لم تعد الذاكرة تستهلكها بيانات الفهرس الثابتة. يتم استخدام DRAM فقط للهياكل خفيفة الوزن والعابرة مثل القوائم المرشحة والبيانات الوصفية للتحكم. من الناحية العملية، يقلل هذا من استخدام الذاكرة من عشرات الجيجابايت إلى <strong>حوالي 10 ميغابايت</strong>. في تكوين تمثيلي على نطاق مليار، تنخفض ذاكرة DRAM من <strong>32 جيجابايت إلى 10</strong> ميغابايت، أي <strong>بتخفيض 3,200 مرة</strong>.</p>
<p>بالنظر إلى أن تخزين أقراص SSD يكلف حوالي <strong>1/30 من سعر وحدة السعة</strong> مقارنةً بذاكرة DRAM، فإن هذا التحول له تأثير مباشر وكبير على التكلفة الإجمالية للنظام.</p>
<p><strong>2. لا توجد نفقات إضافية للإدخال/الإخراج</strong></p>
<p>عادةً ما يؤدي نقل رموز PQ من الذاكرة إلى القرص إلى زيادة عدد عمليات الإدخال/الإخراج أثناء البحث. يتجنب AISAQ ذلك من خلال التحكم بعناية في <strong>تخطيط البيانات وأنماط الوصول</strong>. فبدلاً من تشتيت البيانات ذات الصلة عبر القرص، يقوم AISAQ بتجميع رموز PQ والمتجهات الكاملة والقوائم المجاورة بحيث يمكن استرجاعها معًا. وهذا يضمن أن التوسيع المرشح لا يقدم قراءات عشوائية إضافية.</p>
<p>ولإعطاء المستخدمين التحكم في المفاضلة بين حجم الفهرس وكفاءة الإدخال/الإخراج، يقدم AISAQ المعلمة <code translate="no">inline_pq</code> ، والتي تحدد مقدار بيانات PQ المخزنة في كل عقدة:</p>
<ul>
<li><p><strong>inline_pq أقل:</strong> حجم فهرس أصغر، ولكنه قد يتطلب إدخال/إخراج إضافي</p></li>
<li><p><strong>أعلى inline_pq</strong> أعلى<strong>:</strong> حجم فهرس أكبر، لكنه يحافظ على الوصول للقراءة الواحدة</p></li>
</ul>
<p>عند تكوينه باستخدام <strong>inline_pq = max_degree،</strong> يقرأ AISAQ المتجه الكامل للعقدة وقائمة الجيران وجميع رموز PQ في عملية قرص واحدة، مما يطابق نمط الإدخال/الإخراج الخاص ب DISKANN مع الاحتفاظ بجميع البيانات على SSD.</p>
<p><strong>3. الوصول المتسلسل إلى PQ يحسن كفاءة الحساب</strong></p>
<p>في DISKANN، يتطلب توسيع عقدة مرشحة وصولًا عشوائيًا إلى الذاكرة R لجلب رموز PQ لجيرانها R. يتخلص AISAQ من هذه العشوائية عن طريق استرداد جميع رموز PQ في عملية إدخال/إخراج واحدة وتخزينها بالتتابع على القرص.</p>
<p>يوفر التخطيط المتسلسل فائدتين مهمتين:</p>
<ul>
<li><p><strong>تعد قراءات SSD المتسلسلة أسرع بكثير</strong> من القراءات العشوائية المبعثرة.</p></li>
<li><p><strong>تعد البيانات المتجاورة أكثر ملاءمة لذاكرة التخزين المؤقت،</strong> مما يتيح لوحدات المعالجة المركزية حساب مسافات PQ بكفاءة أكبر.</p></li>
</ul>
<p>وهذا يحسن كلاً من السرعة والقدرة على التنبؤ بحسابات مسافات PQ ويساعد على تعويض تكلفة أداء تخزين رموز PQ على SSD بدلاً من DRAM.</p>
<h2 id="AISAQ-vs-DISKANN-Performance-Evaluation" class="common-anchor-header">AISAQ مقابل DISKANN: تقييم الأداء<button data-href="#AISAQ-vs-DISKANN-Performance-Evaluation" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>بعد فهم كيفية اختلاف AISAQ عن DISKANN من الناحية المعمارية، فإن السؤال التالي واضح ومباشر: <strong>كيف تؤثر خيارات التصميم هذه على الأداء واستخدام الموارد في الممارسة العملية؟</strong> يقارن هذا التقييم بين AISAQ و DISKANN عبر ثلاثة أبعاد هي الأكثر أهمية على نطاق مليار: <strong>أداء البحث، واستهلاك الذاكرة، واستخدام القرص</strong>.</p>
<p>ندرس على وجه الخصوص، كيف يتصرف AISAQAQ مع تغير كمية بيانات PQ المضمنة (<code translate="no">INLINE_PQ</code>). تتحكم هذه المعلمة بشكل مباشر في المفاضلة بين حجم الفهرس وإدخال/إخراج القرص وكفاءة وقت التشغيل. نقوم أيضًا بتقييم كلا النهجين على <strong>أحمال عمل المتجهات منخفضة وعالية الأبعاد، نظرًا لأن الأبعاد تؤثر بشدة على تكلفة حساب المسافة</strong> ومتطلبات التخزين.</p>
<h3 id="Setup" class="common-anchor-header">الإعداد</h3><p>أُجريت جميع التجارب على نظام أحادي العقدة لعزل سلوك الفهرس وتجنب التداخل من تأثيرات الشبكة أو النظام الموزع.</p>
<p><strong>تكوين الأجهزة:</strong></p>
<ul>
<li><p>وحدة المعالجة المركزية: وحدة المعالجة المركزية Intel® Xeon® Platinum 8375C بسرعة 2.90 جيجاهرتز</p></li>
<li><p>الذاكرة: السرعة: 3200 طن متري/ثانية، النوع: DDR4، الحجم: 32 جيجابايت</p></li>
<li><p>القرص: 500 جيجابايت NVMe SSD</p></li>
</ul>
<p><strong>معلمات بناء الفهرس</strong></p>
<pre><code translate="no">{
  <span class="hljs-string">&quot;max_degree&quot;</span>: <span class="hljs-number">48</span>,
  <span class="hljs-string">&quot;search_list_size&quot;</span>: <span class="hljs-number">100</span>,
  <span class="hljs-string">&quot;inline_pq&quot;</span>: <span class="hljs-number">0</span>/<span class="hljs-number">12</span>/<span class="hljs-number">24</span>/<span class="hljs-number">48</span>,  <span class="hljs-comment">// AiSAQ only</span>
  <span class="hljs-string">&quot;pq_code_budget_gb_ratio&quot;</span>: <span class="hljs-number">0.125</span>,
  <span class="hljs-string">&quot;search_cache_budget_gb_ratio&quot;</span>: <span class="hljs-number">0.0</span>,
  <span class="hljs-string">&quot;build_dram_budget_gb&quot;</span>: <span class="hljs-number">32.0</span>
}
<button class="copy-code-btn"></button></code></pre>
<p><strong>معلمات الاستعلام</strong></p>
<pre><code translate="no">{
  <span class="hljs-string">&quot;k&quot;</span>: <span class="hljs-number">100</span>,
  <span class="hljs-string">&quot;search_list_size&quot;</span>: <span class="hljs-number">100</span>,
  <span class="hljs-string">&quot;beamwidth&quot;</span>: <span class="hljs-number">8</span>
}
<button class="copy-code-btn"></button></code></pre>
<h3 id="Benchmark-Method" class="common-anchor-header">الطريقة المعيارية</h3><p>تم اختبار كلٍ من DISKANN و AISAQ باستخدام <a href="https://milvus.io/docs/knowhere.md">Knowhere،</a> محرك البحث المتجه مفتوح المصدر المستخدم في Milvus. تم استخدام مجموعتي بيانات في هذا التقييم:</p>
<ul>
<li><p><strong>SIFT128D (1 مليون متجه):</strong> معيار معروف ذو 128 بُعدًا يُستخدم عادةً في البحث عن واصف الصور. <em>(حجم مجموعة البيانات الأولية ≈ 488 ميغابايت)</em></p></li>
<li><p><strong>Cohere768D (1 مليون متجه):</strong> مجموعة تضمين 768 بُعدًا نموذجية للبحث الدلالي القائم على المحول. <em>(حجم مجموعة البيانات الأولية ≈ 2930 ميغابايت)</em></p></li>
</ul>
<p>تعكس مجموعات البيانات هذه سيناريوهين متميزين في العالم الحقيقي: ميزات الرؤية المدمجة والتضمينات الدلالية الكبيرة.</p>
<h3 id="Results" class="common-anchor-header">النتائج</h3><p><strong>Sift128D1M (المتجه الكامل ~ 488 ميغابايت)</strong></p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Sift128_D1_M_706a5b4e23.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><strong>Cohere768D1M (متجه كامل ~ 2930 ميغابايت)</strong></p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Cohere768_D1_M_8dfa3dffb7.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="Analysis" class="common-anchor-header">التحليل</h3><p><strong>مجموعة بيانات SIFT128D</strong></p>
<p>على مجموعة بيانات SIFT128D، يمكن لـ AISAQ أن يضاهي أداء DISKANN عندما يتم تسطير جميع بيانات PQ بحيث تتناسب البيانات المطلوبة لكل عقدة بالكامل مع صفحة SSD واحدة بسعة 4 كيلوبايت (INLINE_PQ = 48). في ظل هذا التكوين، يتم تجميع كل جزء من المعلومات المطلوبة أثناء البحث:</p>
<ul>
<li><p>متجه كامل 512B</p></li>
<li><p>قائمة الجيران 48 × 4 + 4 = 196B</p></li>
<li><p>رموز PQ للجيران: 48 × (512 ب × 0.125 ب) ≈ 3072 ب</p></li>
<li><p>الإجمالي: 3780B</p></li>
</ul>
<p>نظرًا لأن العقدة بأكملها تتسع لصفحة واحدة فقط، يلزم إدخال/إخراج واحد فقط لكل وصول، ويتجنب AISAQ القراءات العشوائية لبيانات PQ الخارجية.</p>
<p>ومع ذلك، عندما يتم تسطير جزء فقط من بيانات PQ، يجب جلب رموز PQ المتبقية من مكان آخر على القرص. يؤدي هذا إلى إدخال عمليات إدخال/إخراج عشوائية إضافية، مما يزيد بشكل حاد من الطلب على IOPS ويؤدي إلى انخفاض كبير في الأداء.</p>
<p><strong>مجموعة بيانات Cohere768D</strong></p>
<p>على مجموعة بيانات Cohere768D، يكون أداء AISAQ أسوأ من أداء DISKANN. والسبب هو أن المتجه المكون من 768 بُعدًا لا يتناسب ببساطة مع صفحة SSD واحدة سعة 4 كيلوبايت:</p>
<ul>
<li><p>متجه كامل 3072B</p></li>
<li><p>قائمة الجيران 48 × 4 + 4 = 196B</p></li>
<li><p>رموز PQ للجيران: 48 × (3072 ب × 0.125 ب) ≈ 18432 ب</p></li>
<li><p>الإجمالي: 21,700 ب (≈ 6 صفحات)</p></li>
</ul>
<p>في هذه الحالة، حتى لو تم تسطير جميع أكواد PQ، فإن كل عقدة تمتد على عدة صفحات. وبينما يظل عدد عمليات الإدخال/الإخراج ثابتًا، يجب أن تنقل كل عملية إدخال/إخراج بيانات أكثر بكثير، مما يستهلك نطاقًا تردديًا أسرع بكثير. بمجرد أن يصبح عرض النطاق الترددي هو العامل المحدد، لا يمكن ل AISAQ مواكبة DISKANN - خاصةً في أعباء العمل عالية الأبعاد حيث تنمو آثار البيانات لكل عقدة بسرعة.</p>
<p><strong>ملاحظة:</strong></p>
<p>عادةً ما يزيد تخطيط التخزين في AISAQ من حجم الفهرس على القرص بمقدار <strong>4× إلى 6×</strong>. هذه مفاضلة متعمدة: يتم تجميع المتجهات الكاملة والقوائم المجاورة ورموز PQ على القرص لتمكين الوصول الفعال لصفحة واحدة أثناء البحث. وعلى الرغم من أن هذا يزيد من استخدام أقراص SSD، إلا أن سعة القرص أرخص بكثير من DRAM وتتوسع بسهولة أكبر في أحجام البيانات الكبيرة.</p>
<p>من الناحية العملية، يمكن للمستخدمين ضبط هذه المفاضلة من خلال ضبط نسب الضغط <code translate="no">INLINE_PQ</code> و PQ. هذه المعلمات تجعل من الممكن تحقيق التوازن بين أداء البحث وبصمة القرص والتكلفة الإجمالية للنظام بناءً على متطلبات عبء العمل، بدلاً من التقيّد بحدود الذاكرة الثابتة.</p>
<h2 id="Conclusion" class="common-anchor-header">الخلاصة<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>تتغير اقتصاديات الأجهزة الحديثة. لا تزال أسعار DRAM مرتفعة، في حين أن أداء محركات أقراص SSD قد تقدم بسرعة - توفر محركات أقراص SSD 5.0 الآن عرض نطاق ترددي يتجاوز <strong>14 جيجابايت/ثانية</strong>. ونتيجة لذلك، أصبحت البنى التي تحول البيانات المهمة للبحث من ذاكرة DRAM باهظة الثمن إلى تخزين أقراص SSD بأسعار معقولة أكثر إقناعاً. مع تكلفة سعة أقراص SSD التي تبلغ <strong>أقل من 30 ضعفاً لكل جيجابايت من</strong> ذاكرة DRAM، لم تعد هذه الاختلافات هامشية - فهي تؤثر بشكل كبير على تصميم النظام.</p>
<p>يعكس AISAQ هذا التحول. من خلال التخلص من الحاجة إلى تخصيص ذاكرة كبيرة ودائمة التشغيل، فإنه يمكّن أنظمة البحث المتجه من التوسع بناءً على حجم البيانات ومتطلبات عبء العمل بدلاً من حدود DRAM. يتماشى هذا النهج مع الاتجاه الأوسع نطاقاً نحو <strong>بنيات "التخزين الشامل"</strong>، حيث تلعب محركات أقراص الحالة الصلبة السريعة دوراً محورياً ليس فقط في الاستمرارية ولكن في الحوسبة النشطة والبحث.</p>
<p>ومن غير المرجح أن يقتصر هذا التحول على قواعد البيانات المتجهة. حيث بدأت أنماط تصميم مماثلة في الظهور بالفعل في معالجة الرسوم البيانية وتحليلات السلاسل الزمنية وحتى أجزاء من الأنظمة العلائقية التقليدية، حيث يعيد المطورون التفكير في الافتراضات القديمة حول مكان وجود البيانات لتحقيق أداء مقبول. ومع استمرار تطور اقتصاديات الأجهزة في التطور، ستتبعها هياكل الأنظمة.</p>
<p>لمزيد من التفاصيل حول التصاميم التي تمت مناقشتها هنا، راجع الوثائق:</p>
<ul>
<li><p><a href="https://milvus.io/docs/aisaq.md">AISAQ | وثائق ملفوس</a></p></li>
<li><p><a href="https://milvus.io/docs/diskann.md">DISKANN | وثائق ميلفوس</a></p></li>
</ul>
<p>هل لديك أسئلة أو ترغب في التعمق في أي ميزة من أحدث إصدار من ميلفوس؟ انضم إلى<a href="https://discord.com/invite/8uyFbECzPX"> قناة Discord</a> الخاصة بنا أو قم بتسجيل المشكلات على<a href="https://github.com/milvus-io/milvus"> GitHub</a>. يمكنك أيضًا حجز جلسة فردية مدتها 20 دقيقة للحصول على رؤى وإرشادات وإجابات لأسئلتك من خلال<a href="https://milvus.io/blog/join-milvus-office-hours-to-get-support-from-vectordb-experts.md"> ساعات عمل Milvus المكتبية</a>.</p>
<h2 id="Learn-More-about-Milvus-26-Features" class="common-anchor-header">تعرف على المزيد حول ميزات Milvus 2.6<button data-href="#Learn-More-about-Milvus-26-Features" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ul>
<li><p><a href="https://milvus.io/blog/introduce-milvus-2-6-built-for-scale-designed-to-reduce-costs.md">تقديم ميلفوس 2.6: بحث متجه ميسور التكلفة على نطاق المليار</a></p></li>
<li><p><a href="https://milvus.io/blog/data-in-and-data-out-in-milvus-2-6.md">تقديم وظيفة التضمين: كيف يعمل ملفوس 2.6 على تبسيط عملية البحث في المتجهات والبحث الدلالي</a></p></li>
<li><p><a href="https://milvus.io/blog/json-shredding-in-milvus-faster-json-filtering-with-flexibility.md">تمزيق JSON في ميلفوس: تصفية JSON أسرع ب 88.9 مرة مع المرونة</a></p></li>
<li><p><a href="https://milvus.io/blog/unlocking-true-entity-level-retrieval-new-array-of-structs-and-max-sim-capabilities-in-milvus.md">فتح الاسترجاع الحقيقي على مستوى الكيان: قدرات صفيف الهياكل الجديدة وقدرات MAX_SIM في Milvus</a></p></li>
<li><p><a href="https://milvus.io/blog/minhash-lsh-in-milvus-the-secret-weapon-for-fighting-duplicates-in-llm-training-data.md">MinHash LSH في ميلفوس: السلاح السري لمكافحة التكرارات في بيانات تدريب LLM </a></p></li>
<li><p><a href="https://milvus.io/blog/bring-vector-compression-to-the-extreme-how-milvus-serves-3%C3%97-more-queries-with-rabitq.md">الارتقاء بضغط المتجهات إلى أقصى الحدود: كيف يخدم ميلفوس 3 أضعاف الاستعلامات باستخدام RaBitQ</a></p></li>
<li><p><a href="https://milvus.io/blog/benchmarks-lie-vector-dbs-deserve-a-real-test.md">تكذب المعايير - قواعد بيانات المتجهات تستحق اختبارًا حقيقيًا </a></p></li>
<li><p><a href="https://milvus.io/blog/we-replaced-kafka-pulsar-with-a-woodpecker-for-milvus.md">استبدلنا كافكا/بولسار بنقار الخشب في ميلفوس </a></p></li>
<li><p><a href="https://milvus.io/blog/how-to-filter-efficiently-without-killing-recall.md">البحث المتجه في العالم الحقيقي: كيفية التصفية بكفاءة دون قتل التذكر</a></p></li>
</ul>
