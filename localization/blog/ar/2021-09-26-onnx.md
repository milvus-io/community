---
id: 2021-09-26-onnx.md
title: معالجة النماذج باستخدام ONNX
date: 2021-09-26T00:00:00.000Z
desc: كيفية استخدام نماذج متعددة للبحث عن الصور استنادًا إلى ONNX وMilvus
cover: assets.zilliz.com/medium_1_cfb009269a.png
tag: Engineering
canonicalUrl: >-
  https://zilliz.com/blog/combine-ai-models-for-image-search-using-onnx-and-milvus
---
<custom-h1>دمج نماذج الذكاء الاصطناعي للبحث عن الصور باستخدام ONNX وMilvus</custom-h1><p>تبادل الشبكة العصبية المفتوحة (ONNX) هو تنسيق مفتوح مصمم لتمثيل نماذج التعلم الآلي. منذ أن تم فتح مصادره في عام 2017، تطورت ONNX لتصبح معيارًا للذكاء الاصطناعي، حيث توفر لبنات بناء لنماذج التعلم الآلي والتعلم العميق. يُحدد ONNX تنسيق ملف مشترك لتمكين مطوري الذكاء الاصطناعي من استخدام النماذج مع مختلف أطر العمل والأدوات وأوقات التشغيل والمُجمِّعات، ويساعد على زيادة سرعة الابتكار في مجتمع الذكاء الاصطناعي.</p>
<p>Milvus هي قاعدة بيانات متجهة مفتوحة المصدر تتسم بالمرونة العالية والموثوقية والسرعة الفائقة. وهي تدعم إضافة المتجهات وحذفها وتحديثها والبحث عنها في الوقت الفعلي تقريباً. يحتوي Milvus على مجموعة شاملة من واجهات برمجة التطبيقات البديهية، ودعم للعديد من مكتبات الفهرس المعتمدة على نطاق واسع (مثل Faiss وNMSLIB وAnnoy)، مما يبسط عملية اختيار الفهرس لسيناريو معين. يتميز برنامج Milvus بسهولة استخدامه، وقد تم استخدامه في مئات المنظمات والمؤسسات في جميع أنحاء العالم، بما في ذلك البحث عن الصور والصوت والفيديو، والتوصيات، وروبوت الدردشة، والبحث عن الأدوية الجديدة، وما إلى ذلك.</p>
<p>ستقدم لك هذه المقالة كيفية استخدام نماذج متعددة للبحث عن الصور استنادًا إلى ONNX و Milvus. يأخذ نموذجي VGG16 وResNet50 كأمثلة، ويستخدم ONNX لتشغيل نماذج ذكاء اصطناعي مختلفة لتوليد متجهات الميزات، وأخيرًا يقوم باسترجاع متجهات الميزات في Milvus لإرجاع صور متشابهة.</p>
<h2 id="Process-Models-with-ONNX" class="common-anchor-header">معالجة النماذج باستخدام ONNX<button data-href="#Process-Models-with-ONNX" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>يمكن تبادل تنسيق ONNX بسهولة بين نماذج الذكاء الاصطناعي. على سبيل المثال، يمكن تحويل نموذج TensorFlow إلى تنسيق ONNX وتشغيله في بيئة Caffe. في هذا المثال، نقوم في هذا المثال بتحويل نموذج ResNet50 المدرّب مسبقًا ضمن إطار عمل Keras إلى تنسيق ONNX، ثم نستدعي نموذج VGG16 بتنسيق ONNX لتحليل النماذج المختلفة.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> keras.applications.resnet50 <span class="hljs-keyword">import</span> ResNet50
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># load keras-resnet50 model and save as a floder</span>
model_resnet50 = ResNet50(include_top=<span class="hljs-literal">False</span>, pooling=<span class="hljs-string">&#x27;max&#x27;</span>, weights=<span class="hljs-string">&#x27;imagenet&#x27;</span>)
tf.saved_model.save(model_resnet50, <span class="hljs-string">&quot;keras_resnet50_model&quot;</span>)

<span class="hljs-comment"># convert resnet50 model to onnx</span>
! python -m tf2onnx.convert --saved-model <span class="hljs-string">&quot;keras_resnet50_model&quot;</span> --output <span class="hljs-string">&quot;onnx_resnet50.onnx&quot;</span>
<button class="copy-code-btn"></button></code></pre>
<p>ملاحظة: عند استخدامنا للواجهة <code translate="no">keras2onnx.convert_keras(model, model.name)</code> لتحويل النموذج، سيعيد الخطأ <code translate="no">AttributeError:'KerasTensor' object has no attribute'graph'</code>. ثم يمكننا استخدام أمر Python's Bash للتحويل وفقًا للحل على Stack Overflow.</p>
<h2 id="Extract-Feature-Vectors-using-Models" class="common-anchor-header">استخراج متجهات الميزات باستخدام النماذج<button data-href="#Extract-Feature-Vectors-using-Models" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>بعد تحويل نموذج ResNet50 إلى تنسيق ONNX، يمكنك استخراج متجه الميزة للصورة مباشرةً من خلال الاستدلال. ملاحظة: يجب تطبيع متجهات السمات بعد الاستخراج.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># get the image vectors with onnx model</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_onnx_vectors</span>(<span class="hljs-params">onnx_model, img_path</span>):
    img = image.load_img(img_path, target_size=(<span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=<span class="hljs-number">0</span>)
    x = preprocess_input(x)
    
    sess = onnxruntime.InferenceSession(onnx_model)
    x = x <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(x, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">else</span> [x]
    feed = <span class="hljs-built_in">dict</span>([(<span class="hljs-built_in">input</span>.name, x[n]) <span class="hljs-keyword">for</span> n, <span class="hljs-built_in">input</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sess.get_inputs())])
    feat = sess.run(<span class="hljs-literal">None</span>, feed)[<span class="hljs-number">0</span>]
    
    norm_feat = feat[<span class="hljs-number">0</span>] / LA.norm(feat[<span class="hljs-number">0</span>])
    norm_feat = [i.item() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> norm_feat]
    <span class="hljs-keyword">return</span> norm_feat
<button class="copy-code-btn"></button></code></pre>
<p>استخدم نموذج VGG16 بتنسيق ONNX لمعالجة بيانات الصورة:</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># generate vectors with ResNet50 and VGG16 ONNX model</span>
2vec_resnet = get_onnx_vectors(<span class="hljs-string">&quot;onnx_resnet50.onnx&quot;</span>, <span class="hljs-string">&quot;./pic/example.jpg&quot;</span>)
3vec_vgg = get_onnx_vectors(<span class="hljs-string">&quot;onnx_vgg16.onnx&quot;</span>, <span class="hljs-string">&quot;./pic/example.jpg&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Store-Vector-Data" class="common-anchor-header">تخزين البيانات المتجهة<button data-href="#Store-Vector-Data" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>لا يمكن معالجة البيانات غير المهيكلة مثل الصور مباشرةً بواسطة الكمبيوتر، ولكن يمكن تحويلها إلى متجهات من خلال نموذج الذكاء الاصطناعي ثم تحليلها بواسطة الكمبيوتر. تم تصميم قاعدة البيانات المتجهة Milvus لتشغيل تحليل البيانات غير المهيكلة الضخمة. يمكنها تخزين البيانات المتجهة وإجراء تحليل شبه فوري. أولاً، قم بإنشاء مجموعة من النموذج المطابق في Milvus، ثم أدخل متجهات الصورة.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> milvus <span class="hljs-keyword">import</span> *

<span class="hljs-comment"># create collections in Milvus</span>
milvus.create_collection(resnet_collection_param)
milvus.create_collection(vgg_collection_param)

<span class="hljs-comment"># insert data to Milvus and return ids</span>
status, resnet_ids = milvus.insert(resnet_collection_name, resnet_vectors)
status, vgg_ids = milvus.insert(vgg_collection_name, vgg_vectors)
<button class="copy-code-btn"></button></code></pre>
<p>بعد إدراج البيانات بنجاح، سيعيد Milvus المعرف المطابق للمتجه، ومن ثم يمكننا العثور على الصورة حسب المعرف. نظرًا لأن Milvus 1.1 المستخدم في هذه الحالة لا يدعم التصفية العددية (التي يدعمها Milvus 2.0 الآن)، يتم استخدام Redis لتخزين معرف المتجه والقيمة الرئيسية لمسار الصورة.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> redis
<span class="hljs-keyword">def</span> <span class="hljs-title function_">img_ids_to_redis</span>(<span class="hljs-params">img_directory, res_ids</span>):
  <span class="hljs-keyword">for</span> img, ids <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(images, res_ids):
    redis.<span class="hljs-built_in">set</span>(ids, img)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Search-for-Similar-Images" class="common-anchor-header">البحث عن الصور المتشابهة<button data-href="#Search-for-Similar-Images" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>بعد تخزين البيانات، يمكننا استرجاع المتجه. يدعم ميلفوس طرقًا متعددة لحساب المسافة، بما في ذلك المسافة الإقليدية والضرب الداخلي ومسافة هامينج. يعتمد البحث عن تشابه الصور في هذه المقالة على حساب المسافة الإقليدية بين المتجهات في Milvus، ويعيد معرّف المتجه المتشابه ثم يعثر على الصورة المطابقة للمعرّف في Redis.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># search in Milvus and return the similarly results with ids</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">search_in_milvus</span>(<span class="hljs-params">collection_name, search_vector</span>):
    status, results = milvus.search(collection_name, TOP_K, [search_vector])
    <span class="hljs-built_in">print</span>(status)
    re_ids = [x.<span class="hljs-built_in">id</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
    re_distance = [x.distance <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
    <span class="hljs-keyword">return</span> re_ids, re_distance
    
<span class="hljs-comment"># get the images according the result ids</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_sim_imgs</span>(<span class="hljs-params">collection_name, search_vector</span>):
    ids, distance = search_in_milvus(collection_name, search_vector)
    img = [red.get(i).decode(<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ids]
    <span class="hljs-keyword">return</span> ids, distance, img
<button class="copy-code-btn"></button></code></pre>
<p>بأخذ نموذجي VGG16 وResNet50 كأمثلة، تعرض هذه المقالة معالجة نماذج متعددة من خلال ONNX ودمج نماذج متعددة مع Milvus لاسترجاع المتجهات المتشابهة للحصول على صور متشابهة. يعتمد النموذجان المذكوران أعلاه على إطار عمل Keras، والذي يمكنه استخراج متجهات السمات بسرعة. يمكن أن نرى من دفتر الملاحظات أنه على الرغم من أن نتائج بحث ميلفوس عن الصور على مجموعة بيانات COCO استنادًا إلى هذين النموذجين متشابهة، إلا أن المسافات الإقليدية بينهما ليست متشابهة. يمكنك أيضًا محاولة مقارنة نتائج البحث للنموذجين باستخدام مجموعات بيانات أخرى.</p>
<p>Milvus عبارة عن قاعدة بيانات متجهات عالية الأداء ومتوفرة بشكل كبير يمكن استخدامها لمعالجة متجهات السمات التي تم إنشاؤها من بيانات ضخمة غير منظمة. لمزيد من الحلول، يمكنك الرجوع إلى <a href="https://github.com/milvus-io/bootcamp">معسكر تدريب Milvus</a>.</p>
<h2 id="References" class="common-anchor-header">المراجع<button data-href="#References" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ol>
<li>https://github.com/onnx/onnx</li>
<li>https://onnx.ai/</li>
<li>https://milvus.io/cn/</li>
<li>https://github.com/milvus-io/bootcamp</li>
</ol>
<h3 id="About-author" class="common-anchor-header">نبذة عن المؤلف</h3><p>شيو تشين، مهندسة بيانات في شركة Zilliz، تخرجت من جامعة زيليز وحصلت على شهادة في علوم الحاسب الآلي. منذ انضمامها إلى Zilliz، كانت تستكشف حلولاً لـ Milvus في مجالات مختلفة، مثل تحليل الصوت والفيديو، واسترجاع الصيغ الجزيئية، وما إلى ذلك، مما أثرى سيناريوهات التطبيق في المجتمع بشكل كبير. وهي تستكشف حاليًا المزيد من الحلول المثيرة للاهتمام. في أوقات فراغها، تحب الرياضة والقراءة.</p>
