---
id: >-
  when-context-engineering-is-done-right-hallucinations-can-spark-ai-creativity.md
title: >-
  عندما تتم هندسة السياق بشكل صحيح، يمكن أن تكون الهلوسة شرارة إبداع الذكاء
  الاصطناعي
author: James Luan
date: 2025-09-30T00:00:00.000Z
desc: >-
  اكتشف لماذا لا تكون هلوسات الذكاء الاصطناعي مجرد أخطاء بل هي شرارات من الإبداع
  - وكيف تحولها هندسة السياق إلى نتائج موثوقة وواقعية.
cover: assets.zilliz.com/Chat_GPT_Image_Oct_1_2025_10_42_15_AM_101639b3bf.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database, AI Agents, Context Engineering'
meta_keywords: 'Milvus, vector database, AI Agents, Context Engineering'
meta_title: |
  If Context Engineering Done Right, Hallucinations Can Spark AI Creativity
origin: >-
  https://milvus.io/blog/when-context-engineering-is-done-right-hallucinations-can-spark-ai-creativity.md
---
<p>لفترة طويلة، تعامل الكثير منا - وأنا منهم - مع هلوسات LLM على أنها ليست أكثر من عيوب. وقد تم بناء سلسلة أدوات كاملة حول القضاء عليها: أنظمة الاسترجاع، وحواجز الحماية، والضبط الدقيق، وغير ذلك. لا تزال هذه الضمانات ذات قيمة. ولكن كلما درستُ أكثر كيف تولد النماذج استجابات فعلية - وكيف تتلاءم أنظمة مثل <a href="https://milvus.io/"><strong>ميلفوس</strong></a> مع خطوط أنابيب الذكاء الاصطناعي الأوسع - كلما قل اعتقادي بأن الهلوسة هي مجرد إخفاقات. في الواقع، يمكن أن تكون أيضاً شرارة إبداع الذكاء الاصطناعي.</p>
<p>إذا نظرنا إلى الإبداع البشري، نجد نفس النمط. فكل اختراق يعتمد على قفزات خيالية. لكن هذه القفزات لا تأتي أبداً من العدم. فالشعراء يتقنون أولاً الإيقاع والوزن قبل أن يخرقوا القواعد. ويعتمد العلماء على نظريات راسخة قبل أن يغامروا في منطقة غير مجربة. ويعتمد التقدم على هذه القفزات، طالما أنها تستند إلى معرفة وفهم راسخين.</p>
<p>ويعمل العلماء بنفس الطريقة. تنبثق ما يسمى ب "الهلوسات" أو "القفزات" - التشبيهات والارتباطات والاستقراءات - من نفس العملية التوليدية التي تسمح للنماذج بإجراء الروابط وتوسيع نطاق المعرفة وإبراز الأفكار التي تتجاوز ما تم تدريبهم عليه بشكل صريح. لا تنجح كل قفزة، ولكن عندما تنجح، يمكن أن تكون النتائج مقنعة.</p>
<p>لهذا السبب أرى أن <strong>هندسة السياق</strong> هي الخطوة التالية الحاسمة. فبدلاً من محاولة القضاء على كل هلوسة، يجب أن نركز على <em>توجيهها</em>. من خلال تصميم السياق الصحيح، يمكننا تحقيق التوازن - إبقاء النماذج مبدعة بما يكفي لاستكشاف آفاق جديدة، مع ضمان بقائها راسخة بما يكفي لتكون محل ثقة.</p>
<h2 id="What-is-Context-Engineering" class="common-anchor-header">ما هي هندسة السياق؟<button data-href="#What-is-Context-Engineering" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>ماذا نعني بالضبط <em>بهندسة</em> السياق؟ قد يكون المصطلح جديداً، لكن هذه الممارسة تتطور منذ سنوات. تقنيات مثل RAG، والمطالبة، واستدعاء الدالة، و MCP كلها محاولات مبكرة لحل نفس المشكلة: تزويد النماذج بالبيئة المناسبة لإنتاج نتائج مفيدة. تتعلق هندسة السياق بتوحيد هذه الأساليب في إطار عمل متماسك.</p>
<h2 id="The-Three-Pillars-of-Context-Engineering" class="common-anchor-header">الركائز الثلاث لهندسة السياق<button data-href="#The-Three-Pillars-of-Context-Engineering" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>تعتمد هندسة السياق الفعالة على ثلاث طبقات مترابطة:</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/context_engineering_1_8f2b39c5e7.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="1-The-Instructions-Layer--Defining-Direction" class="common-anchor-header">1. طبقة التعليمات - تحديد الاتجاه</h3><p>تتضمن هذه الطبقة المطالبات والأمثلة القليلة والعروض التوضيحية. إنه نظام الملاحة الخاص بالنموذج: ليس مجرد عبارة غامضة "اتجه شمالاً"، بل طريق واضح مع نقاط طريق. تضع التعليمات جيدة التنظيم الحدود، وتحدد الأهداف، وتقلل من الغموض في سلوك النموذج.</p>
<h3 id="2-The-Knowledge-Layer--Supplying-Ground-Truth" class="common-anchor-header">2. طبقة المعرفة - توفير الحقيقة الأساسية</h3><p>هنا نضع الحقائق والرموز والوثائق والحالة التي يحتاجها النموذج للتفكير بفعالية. بدون هذه الطبقة، يرتجل النظام من ذاكرة غير مكتملة. باستخدامها، يمكن للنموذج أن يؤسس مخرجاته على بيانات خاصة بالمجال. وكلما كانت المعرفة أكثر دقة وملاءمة كلما كان الاستدلال أكثر موثوقية.</p>
<h3 id="3-The-Tools-Layer--Enabling-Action-and-Feedback" class="common-anchor-header">3. طبقة الأدوات - تمكين العمل والتغذية الراجعة</h3><p>تغطي هذه الطبقة واجهات برمجة التطبيقات، واستدعاءات الوظائف، والتكاملات الخارجية. وهي ما يمكّن النظام من الانتقال من الاستدلال إلى التنفيذ - استرداد البيانات أو إجراء العمليات الحسابية أو تشغيل سير العمل. وبنفس القدر من الأهمية، توفر هذه الأدوات تغذية راجعة في الوقت الفعلي يمكن ربطها مرة أخرى في منطق النموذج. هذه التغذية الراجعة هي ما يتيح التصحيح والتكيف والتحسين المستمر. ومن الناحية العملية، هذا هو ما يحول الآلات ذات المسؤولية المحدودة من مستجيبين سلبيين إلى مشاركين نشطين في النظام.</p>
<p>هذه الطبقات ليست صوامع - فهي تعزز بعضها البعض. فالتعليمات تحدد الوجهة، والمعرفة توفر المعلومات للعمل بها، والأدوات تحول القرارات إلى أفعال وتغذي النتائج مرة أخرى في الحلقة. إذا تم تنسيقها بشكل جيد، فإنها تخلق بيئة يمكن أن تكون فيها النماذج مبدعة ويمكن الاعتماد عليها.</p>
<h2 id="The-Long-Context-Challenges-When-More-Becomes-Less" class="common-anchor-header">تحديات السياق الطويل: عندما يصبح المزيد أقل<button data-href="#The-Long-Context-Challenges-When-More-Becomes-Less" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>تُعلن العديد من نماذج الذكاء الاصطناعي الآن عن نوافذ بملايين الرموز - وهو ما يكفي لحوالي 75000 سطر من التعليمات البرمجية أو مستند مكون من 750 ألف كلمة. لكن المزيد من السياق لا يؤدي تلقائياً إلى نتائج أفضل. في الممارسة العملية، تقدم السياقات الطويلة جداً أنماط فشل متميزة يمكن أن تقلل من الاستدلال والموثوقية.</p>
<h3 id="Context-Poisoning--When-Bad-Information-Spreads" class="common-anchor-header">تسمم السياق - عندما تنتشر المعلومات السيئة</h3><p>بمجرد دخول معلومات خاطئة إلى سياق العمل - سواء في الأهداف أو الملخصات أو الحالة الوسيطة - يمكن أن تعرقل عملية الاستدلال بأكملها. يقدم <a href="https://arxiv.org/pdf/2507.06261">تقرير Gemini 2.5 من DeepMind</a> مثالاً واضحاً على ذلك. أخطأ وكيل LLM الذي يلعب بوكيمون في قراءة حالة اللعبة وقرر أن مهمته هي "اصطياد الأسطوري الذي لا يمكن اصطياده". تم تسجيل هذا الهدف غير الصحيح كحقيقة واقعة، مما أدى بالوكيل إلى إنشاء استراتيجيات متقنة ولكنها مستحيلة.</p>
<p>وكما هو موضح في المقتطف أدناه، فإن السياق المسموم أوقع النموذج في حلقة مفرغة - تكرار الأخطاء، وتجاهل المنطق السليم، وتعزيز نفس الخطأ حتى انهارت عملية التفكير بأكملها.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_1_Excerpt_from_Gemini_2_5_Tech_Paper_e89adf9eed.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>الشكل 1: مقتطف من <a href="https://arxiv.org/pdf/2507.06261">ورقة Gemini 2.5 التقنية</a></p>
<h3 id="Context-Distraction--Lost-in-the-Details" class="common-anchor-header">تشتيت السياق - الضياع في التفاصيل</h3><p>مع توسع نوافذ السياق، يمكن أن تبدأ النماذج في زيادة الوزن الزائد للنسخة وعدم استخدام ما تعلمته أثناء التدريب. على سبيل المثال، يدعم برنامج Gemini 2.5 Pro من DeepMind's Gemini 2.5 Pro نافذة من مليون رمز ولكنه <a href="https://arxiv.org/pdf/2507.06261">يبدأ في الانجراف نحو 100,000 رمز تقريبًا - أي إعادة تدوير</a>الإجراءات السابقة بدلاً من توليد استراتيجيات جديدة. تُظهر <a href="https://www.databricks.com/blog/long-context-rag-performance-llms">أبحاث داتابريكس</a> أن النماذج الأصغر، مثل Llama 3.1-405B، تصل إلى هذا الحد في وقت أقرب بكثير عند حوالي 32,000 رمز. إنه تأثير بشري مألوف: الكثير من القراءة في الخلفية، فتفقد الحبكة.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_2_Excerpt_from_Gemini_2_5_Tech_Paper_56d775c59d.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>الشكل 2: مقتطف من <a href="https://arxiv.org/pdf/2507.06261">ورقة Gemini 2.5 التقنية</a></p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_3_Long_context_performance_of_GPT_Claude_Llama_Mistral_and_DBRX_models_on_4_curated_RAG_datasets_Databricks_Docs_QA_Finance_Bench_Hot_Pot_QA_and_Natural_Questions_Source_Databricks_99086246b9.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>الشكل 3: الشكل 3: أداء السياق الطويل لنماذج GPT وClaude وLlama وMistral وDBRX على 4 مجموعات بيانات RAG المنسقة (Databricks DocsQA وFinanceBench وHotPotQA وNatural Questions) [المصدر:</em> <a href="https://www.databricks.com/blog/long-context-rag-performance-llms"><em>Databricks</em></a><em>]</em></p>
<h3 id="Context-Confusion--Too-Many-Tools-in-the-Kitchen" class="common-anchor-header">ارتباك السياق - أدوات كثيرة جدًا في المطبخ</h3><p>إضافة المزيد من الأدوات لا يساعد دائمًا. تُظهر <a href="https://gorilla.cs.berkeley.edu/leaderboard.html">لوحة Berkeley Function-Calling-Calling Leaderboard</a> أنه عندما يعرض السياق قوائم أدوات واسعة النطاق - غالبًا ما تحتوي على العديد من الخيارات غير ذات الصلة - تقل موثوقية النموذج، ويتم استدعاء الأدوات حتى عندما لا تكون هناك حاجة إليها. أحد الأمثلة الواضحة على ذلك: فشل Llama 3.1-8B المكمّل مع توفر 46 أداة، لكنه نجح عندما تم تقليص المجموعة إلى 19 أداة. إنها مفارقة الاختيار بالنسبة لأنظمة الذكاء الاصطناعي - خيارات كثيرة جداً، وقرارات أسوأ.</p>
<h3 id="Context-Clash--When-Information-Conflicts" class="common-anchor-header">تضارب السياق - عندما تتعارض المعلومات</h3><p>تضيف التفاعلات متعددة الأدوار نمط فشل متميز: يتضاعف سوء الفهم المبكر مع تفرع الحوار. في <a href="https://arxiv.org/pdf/2505.06120v1">تجارب مايكروسوفت و Salesforce،</a> كان أداء كل من أنظمة الذكاء الاصطناعي ذات الوزن المفتوح والمغلق أسوأ بشكل ملحوظ في الإعدادات متعددة الأدوار مقارنةً بالإعدادات ذات الدور الواحد - بمتوسط انخفاض بنسبة 39% عبر ست مهام توليد. بمجرد أن يدخل افتراض خاطئ في حالة المحادثة، ترثه الأدوار اللاحقة وتضخم الخطأ.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_4_LL_Ms_get_lost_in_multi_turn_conversations_in_experiments_21f194b02d.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>الشكل 4: تضيع الفرضيات الخاطئة في المحادثات متعددة الأدوار في التجارب</em></p>
<p>يظهر التأثير حتى في النماذج الأمامية. عندما تم توزيع المهام المعيارية عبر المنعطفات، انخفضت درجة أداء نموذج o3 من OpenAI من <strong>98.1</strong> إلى <strong>64.1</strong>. إن القراءة الخاطئة الأولية "تحدد" نموذج العالم بشكل فعال؛ فكل رد يبني عليه، مما يحول التناقض الصغير إلى نقطة عمياء متصلبة ما لم يتم تصحيحه بشكل صريح.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_4_The_performance_scores_in_LLM_multi_turn_conversation_experiments_414d3a0b3f.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>الشكل 4: درجات الأداء في تجارب محادثة LLM متعددة الأدوار</em></p>
<h2 id="Six-Strategies-to-Tame-Long-Context" class="common-anchor-header">ست استراتيجيات لترويض السياق الطويل<button data-href="#Six-Strategies-to-Tame-Long-Context" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>لا يكمن الحل لتحديات السياق الطويل في التخلي عن القدرة - بل في هندستها بانضباط. فيما يلي ست استراتيجيات رأيناها تنجح عملياً:</p>
<h3 id="Context-Isolation" class="common-anchor-header">عزل السياق</h3><p>تقسيم تدفقات العمل المعقدة إلى عوامل متخصصة ذات سياقات معزولة. يركز كل وكيل على مجاله الخاص دون تداخل، مما يقلل من خطر انتشار الأخطاء. وهذا لا يحسّن الدقة فحسب، بل يتيح أيضاً التنفيذ المتوازي، تماماً مثل فريق هندسي منظم بشكل جيد.</p>
<h3 id="Context-Pruning" class="common-anchor-header">تشذيب السياق</h3><p>تدقيق وتشذيب السياق بانتظام. قم بإزالة التفاصيل الزائدة والمعلومات القديمة والآثار غير ذات الصلة. فكّر في الأمر على أنه إعادة هيكلة: نظف التعليمات البرمجية والتبعيات الميتة، مع ترك الأساسيات فقط. يتطلب التقليم الفعال معايير واضحة لما ينتمي وما لا ينتمي.</p>
<h3 id="Context-Summarization" class="common-anchor-header">تلخيص السياق</h3><p>ليس من الضروري نقل التواريخ الطويلة بالكامل. وبدلاً من ذلك، قم بتلخيصها في ملخصات موجزة تلتقط فقط ما هو ضروري للخطوة التالية. يحتفظ التلخيص الجيد بالحقائق والقرارات والقيود المهمة، مع التخلص من التكرار والتفاصيل غير الضرورية. الأمر أشبه باستبدال مواصفات من 200 صفحة بموجز تصميم من صفحة واحدة لا يزال يمنحك كل ما تحتاجه للمضي قدمًا.</p>
<h3 id="Context-Offloading" class="common-anchor-header">تفريغ السياق</h3><p>لا يجب أن تكون كل التفاصيل جزءًا من السياق المباشر. احتفظ بالبيانات غير الحرجة في أنظمة خارجية - قواعد المعرفة أو مخازن المستندات أو قواعد البيانات المتجهة مثل Milvus - ولا تجلبها إلا عند الحاجة. هذا يخفف العبء المعرفي للنموذج مع الحفاظ على إمكانية الوصول إلى المعلومات الأساسية.</p>
<h3 id="Strategic-RAG" class="common-anchor-header">الاسترجاع الاستراتيجي</h3><p>لا يكون استرجاع المعلومات قويًا إلا إذا كان انتقائيًا. قم بإدخال المعرفة الخارجية من خلال التصفية الصارمة وضوابط الجودة، مما يضمن أن النموذج يستهلك مدخلات ذات صلة ودقيقة. كما هو الحال مع أي خط أنابيب للبيانات: القمامة في، القمامة خارج - ولكن مع الاسترجاع عالي الجودة، يصبح السياق أحد الأصول وليس عائقًا.</p>
<h3 id="Optimized-Tool-Loading" class="common-anchor-header">التحميل الأمثل للأدوات</h3><p>لا يعني المزيد من الأدوات أداءً أفضل. تظهر الدراسات أن الموثوقية تنخفض بشكل حاد بعد حوالي 30 أداة متاحة. قم بتحميل الوظائف التي تتطلبها مهمة معينة فقط، وبوابة الوصول إلى الباقي. يعزز صندوق الأدوات المرن الدقة ويقلل من الضوضاء التي يمكن أن تطغى على عملية صنع القرار.</p>
<h2 id="The-Infrastructure-Challenge-of-Context-Engineering" class="common-anchor-header">تحدي البنية التحتية لهندسة السياق<button data-href="#The-Infrastructure-Challenge-of-Context-Engineering" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>لا تكون هندسة السياق فعالة إلا بقدر فعالية البنية التحتية التي تعمل عليها. وتواجه الشركات اليوم عاصفة مثالية من تحديات البيانات:</p>
<h3 id="Scale-Explosion--From-Terabytes-to-Petabytes" class="common-anchor-header">انفجار النطاق - من تيرابايت إلى بيتابايت</h3><p>اليوم، أعاد نمو البيانات تعريف خط الأساس. فأحمال العمل التي كانت تتناسب بشكل مريح مع قاعدة بيانات واحدة أصبحت الآن تمتد إلى بيتابايت، مما يتطلب تخزينًا وحسابًا موزعًا. يمكن أن يتحول تغيير المخطط الذي كان عبارة عن تحديث SQL من سطر واحد إلى جهد تنسيق كامل عبر المجموعات وخطوط الأنابيب والخدمات. لا يتعلق التوسع ببساطة بإضافة الأجهزة - بل يتعلق بالهندسة من أجل التنسيق والمرونة والمرونة على نطاق يتم فيه اختبار كل افتراض على نطاق واسع.</p>
<h3 id="Consumption-Revolution--Systems-That-Speak-AI" class="common-anchor-header">ثورة الاستهلاك - الأنظمة التي تتحدث الذكاء الاصطناعي</h3><p>لا يكتفي وكلاء الذكاء الاصطناعي بالاستعلام عن البيانات فحسب، بل يقومون بتوليدها وتحويلها واستهلاكها بشكل مستمر بسرعة الآلة. لا تستطيع البنية التحتية المصممة فقط للتطبيقات التي تواجه الإنسان مواكبة ذلك. ولدعم الوكلاء، يجب أن توفر الأنظمة استرجاعاً منخفض الكمون وتحديثات متدفقة وأعباء عمل ثقيلة في الكتابة دون تعطل. وبعبارة أخرى، يجب أن يتم بناء حزمة البنية التحتية "للتحدث بالذكاء الاصطناعي" باعتبارها عبء العمل الأصلي، وليس كفكرة لاحقة.</p>
<h3 id="Multimodal-Complexity--Many-Data-Types-One-System" class="common-anchor-header">التعقيد متعدد الوسائط - العديد من أنواع البيانات، نظام واحد</h3><p>تمزج أعباء عمل الذكاء الاصطناعي بين النصوص والصور والصوت والفيديو والتضمينات عالية الأبعاد، وكل منها مرفق ببيانات وصفية غنية. إدارة هذا التغاير هو جوهر هندسة السياق العملي. لا يكمن التحدي في تخزين العناصر المتنوعة فحسب، بل في فهرستها واسترجاعها بكفاءة والحفاظ على الاتساق الدلالي عبر الطرائق. يجب أن تتعامل البنية التحتية الجاهزة حقًا للذكاء الاصطناعي مع تعدد الوسائط كمبدأ تصميم من الدرجة الأولى، وليس كميزة إضافية.</p>
<h2 id="Milvus-+-Loon-Purpose-Built-Data-Infrastructure-for-AI" class="common-anchor-header">ميلفوس + لون: بنية تحتية للبيانات مصممة خصيصاً للذكاء الاصطناعي<button data-href="#Milvus-+-Loon-Purpose-Built-Data-Infrastructure-for-AI" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>لا يمكن حل تحديات الحجم والاستهلاك وتعدد الوسائط بالاعتماد على النظرية وحدها، فهي تتطلب بنية تحتية مصممة خصيصاً للذكاء الاصطناعي. لهذا السبب قمنا في <a href="https://zilliz.com/">Zilliz</a> بتصميم <strong>Milvus</strong> <strong>وLoon</strong> للعمل معاً، لمعالجة جانبي المشكلة: الاسترجاع عالي الأداء في وقت التشغيل ومعالجة البيانات على نطاق واسع في مرحلة ما قبل التشغيل.</p>
<ul>
<li><p><a href="https://milvus.io/"><strong>Milvus</strong></a>: قاعدة البيانات المتجهة مفتوحة المصدر الأكثر اعتماداً على نطاق واسع والمُحسّنة لاسترجاع وتخزين المتجهات عالية الأداء.</p></li>
<li><p><strong>Loon</strong>: خدمة بحيرة البيانات متعددة الوسائط السحابية القادمة المصممة لمعالجة وتنظيم البيانات متعددة الوسائط على نطاق واسع قبل أن تصل إلى قاعدة البيانات. ترقبوا المزيد.</p></li>
</ul>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/multimodal_data_lake_min_ddc3de6ea4.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="Lightning-Fast-Vector-Search" class="common-anchor-header">بحث فائق السرعة في المتجهات</h3><p>تم تصميم<strong>Milvus</strong> من الألف إلى الياء لأعباء عمل المتجهات. وباعتباره طبقة العرض، فإنه يوفر استرجاعًا دون 10 مللي ثانية عبر مئات الملايين - أو حتى المليارات - من المتجهات، سواء كانت مستمدة من النصوص أو الصور أو الصوت أو الفيديو. بالنسبة لتطبيقات الذكاء الاصطناعي، فإن سرعة الاسترجاع ليست "أمراً لطيفاً". بل هي ما يحدد ما إذا كان الوكيل يشعر بالاستجابة أو البطء، وما إذا كانت نتيجة البحث ذات صلة أو غير ملائمة. يظهر الأداء هنا بشكل مباشر في تجربة المستخدم النهائي.</p>
<h3 id="Multimodal-Data-Lake-Service-at-Scale" class="common-anchor-header">خدمة بحيرة البيانات متعددة الوسائط على نطاق واسع</h3><p><strong>Loon</strong> هي خدمة بحيرة البيانات متعددة الوسائط القادمة لدينا، وهي مصممة لمعالجة وتحليلات البيانات غير المهيكلة على نطاق واسع دون اتصال بالإنترنت. وهي تكمل خدمة Milvus على جانب خط الأنابيب، حيث تقوم بإعداد البيانات قبل أن تصل إلى قاعدة البيانات. غالبًا ما تكون مجموعات البيانات متعددة الوسائط في العالم الحقيقي - التي تمتد عبر النصوص والصور والصوت والفيديو - فوضوية في كثير من الأحيان، مع وجود ازدواجية وضوضاء وتنسيقات غير متسقة. تتولى Loon هذا العمل الشاق باستخدام أطر عمل موزعة مثل راي ودافت، حيث تقوم بضغط البيانات وإلغاء تكرارها وتجميعها قبل بثها مباشرةً إلى ميلفوس. والنتيجة بسيطة: لا توجد اختناقات في التدريج، ولا تحويلات تنسيق مؤلمة - فقط بيانات نظيفة ومنظمة يمكن للنماذج استخدامها على الفور.</p>
<h3 id="Cloud-Native-Elasticity" class="common-anchor-header">المرونة السحابية الأصلية</h3><p>كلا النظامين مصممان على السحابة الأصلية، مع توسيع نطاق التخزين والحوسبة بشكل مستقل. وهذا يعني أنه مع نمو أعباء العمل من غيغابايت إلى بيتابايت، يمكنك موازنة الموارد بين العرض في الوقت الفعلي والتدريب دون اتصال بالإنترنت، بدلاً من الإفراط في توفير الموارد لأحدهما أو التقليل من الآخر.</p>
<h3 id="Future-Proof-Architecture" class="common-anchor-header">بنية مقاومة للمستقبل</h3><p>الأهم من ذلك هو أن هذه البنية مصممة للنمو معك. لا تزال هندسة السياق في تطور مستمر. في الوقت الحالي، تركز معظم الفرق على البحث الدلالي وخطوط أنابيب RAG. لكن الموجة التالية ستتطلب المزيد - دمج أنواع متعددة من البيانات، والاستدلال عبرها، وتشغيل تدفقات العمل التي يحركها الوكيل.</p>
<p>مع Milvus و Loon، لا يتطلب هذا الانتقال تمزيق الأساس الخاص بك. يمكن أن تمتد نفس الحزمة التي تدعم حالات استخدام اليوم بشكل طبيعي إلى حالات الغد. يمكنك إضافة قدرات جديدة دون البدء من جديد، مما يعني مخاطر أقل، وتكلفة أقل، ومسار أكثر سلاسة مع زيادة تعقيد أعباء عمل الذكاء الاصطناعي.</p>
<h2 id="Your-Next-Move" class="common-anchor-header">خطوتك التالية<button data-href="#Your-Next-Move" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>هندسة السياق ليست مجرد تخصص تقني آخر - إنها الطريقة التي نطلق بها العنان لإمكانات الذكاء الاصطناعي الإبداعية مع الحفاظ على ثباتها وموثوقيتها. إذا كنت مستعداً لوضع هذه الأفكار موضع التنفيذ، فابدأ من حيث الأهمية القصوى.</p>
<ul>
<li><p><a href="https://milvus.io/docs/overview.md"><strong>جرب مع Milvus</strong></a> لترى كيف يمكن لقواعد البيانات المتجهة أن ترسخ الاسترجاع في عمليات النشر في العالم الحقيقي.</p></li>
<li><p><a href="https://www.linkedin.com/company/the-milvus-project/"><strong>تابع Milvus</strong></a> للحصول على تحديثات حول إصدار Loon ورؤى حول إدارة البيانات متعددة الوسائط على نطاق واسع.</p></li>
<li><p><a href="https://discord.com/invite/8uyFbECzPX"><strong>انضم إلى مجتمع Zilliz على Discord</strong></a> لمشاركة الاستراتيجيات ومقارنة البنى والمساعدة في تشكيل أفضل الممارسات.</p></li>
</ul>
<p>الشركات التي تتقن هندسة السياق اليوم ستشكل مشهد الذكاء الاصطناعي غداً. لا تدع البنية التحتية تكون القيد - قم ببناء الأساس الذي يستحقه إبداع الذكاء الاصطناعي لديك.</p>
