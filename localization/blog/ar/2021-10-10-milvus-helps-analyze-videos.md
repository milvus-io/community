---
id: 2021-10-10-milvus-helps-analyze-videos.md
title: اكتشاف الكائنات
author: Shiyu Chen
date: 2021-10-11T00:00:00.000Z
desc: تعرّف على كيفية قيام Milvus بتشغيل تحليل الذكاء الاصطناعي لمحتويات الفيديو.
cover: assets.zilliz.com/Who_is_it_e9d4510ace.png
tag: Scenarios
canonicalUrl: 'https://zilliz.com/blog/milvus-helps-analyze-videos-intelligently'
---
<custom-h1>بناء نظام تحليل فيديو باستخدام قاعدة بيانات ميلفوس فيكتورز</custom-h1><p><em>شيو تشين، مهندسة بيانات في شركة Zilliz، تخرجت من جامعة زيليز وحصلت على شهادة في علوم الحاسب الآلي. منذ انضمامها إلى Zilliz، عملت على استكشاف حلول لـ Milvus في مجالات مختلفة، مثل تحليل الصوت والفيديو، واسترجاع الصيغ الجزيئية، وما إلى ذلك، مما أثرى سيناريوهات التطبيق في المجتمع بشكل كبير. وهي تستكشف حاليًا المزيد من الحلول المثيرة للاهتمام. في أوقات فراغها، تحب الرياضة والقراءة.</em></p>
<p>عندما كنت أشاهد <em>فيلم Free Guy</em> في عطلة نهاية الأسبوع الماضي، شعرت أنني رأيت الممثل الذي يلعب دور بودي، حارس الأمن، في مكان ما من قبل، ولكنني لم أستطع تذكر أي من أعماله. كان رأسي محشوًا بـ "من هذا الرجل"؟ كنت متأكدًا من أنني رأيت هذا الوجه وكنت أحاول جاهدًا أن أتذكر اسمه. حالة مشابهة هي أنني رأيت ذات مرة الممثل الرئيسي في أحد الفيديوهات وهو يتناول مشروبًا كنت أحبه كثيرًا، ولكنني فشلت في تذكر اسم العلامة التجارية.</p>
<p>كانت الإجابة على طرف لساني، لكن عقلي كان عالقًا تمامًا.</p>
<p>تدفعني ظاهرة طرف اللسان (TOT) إلى الجنون عند مشاهدة الأفلام. لو كان هناك فقط محرك بحث عكسي عن الصور لمقاطع الفيديو يمكّنني من العثور على مقاطع الفيديو وتحليل محتواها. من قبل، قمتُ ببناء محرك <a href="https://github.com/milvus-io/bootcamp/tree/master/solutions/reverse_image_search/quick_deploy">بحث</a> عكسي <a href="https://github.com/milvus-io/bootcamp/tree/master/solutions/reverse_image_search/quick_deploy">عن الصور باستخدام Milvus</a>. وبالنظر إلى أن تحليل محتوى الفيديو يشبه إلى حد ما تحليل الصور، قررت بناء محرك تحليل محتوى الفيديو استنادًا إلى Milvus.</p>
<h2 id="Object-detection" class="common-anchor-header">اكتشاف الكائنات<button data-href="#Object-detection" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Overview" class="common-anchor-header">نظرة عامة</h3><p>قبل التحليل، يجب اكتشاف الأجسام في الفيديو أولاً. يعد اكتشاف الأجسام في الفيديو بفعالية ودقة هو التحدي الرئيسي للمهمة. وهي أيضًا مهمة مهمة مهمة لتطبيقات مثل الطيار الآلي والأجهزة القابلة للارتداء وإنترنت الأشياء.</p>
<p>وقد تم تطويرها من خوارزميات معالجة الصور التقليدية إلى الشبكات العصبية العميقة (DNN)، وتشمل النماذج السائدة اليوم لاكتشاف الأجسام شبكات R-CNN وFRCNN وSSD وYOLO. يمكن لنظام تحليل الفيديو القائم على التعلم العميق المستند إلى Milvus المقدم في هذا الموضوع اكتشاف الأجسام بذكاء وسرعة.</p>
<h3 id="Implementation" class="common-anchor-header">التنفيذ</h3><p>لاكتشاف الأجسام في الفيديو والتعرّف عليها، يجب على النظام أولاً استخراج الإطارات من الفيديو واكتشاف الأجسام في صور الإطارات باستخدام اكتشاف الأجسام، وثانيًا استخراج متجهات السمات من الأجسام المكتشفة، وأخيرًا تحليل الجسم بناءً على متجهات السمات.</p>
<ul>
<li>استخراج الإطار</li>
</ul>
<p>يتم تحويل تحليل الفيديو إلى تحليل الصور باستخدام استخراج الإطارات. حاليًا، تقنية استخراج الإطارات ناضجة جدًا. تدعم برامج مثل FFmpeg و OpenCV استخراج الإطارات على فترات زمنية محددة. تقدم هذه المقالة كيفية استخراج الإطارات من الفيديو كل ثانية باستخدام OpenCV.</p>
<ul>
<li>اكتشاف الكائنات</li>
</ul>
<p>يتعلق باكتشاف الكائنات بالعثور على الكائنات في الإطارات المستخرجة واستخراج لقطات من الكائنات وفقًا لمواضعها. كما هو موضح في الأشكال التالية، تم اكتشاف دراجة وكلب وسيارة. يقدّم هذا الموضوع كيفية اكتشاف الأجسام باستخدام YOLOv3، والذي يُستخدم عادةً لاكتشاف الأجسام.</p>
<ul>
<li>استخراج الميزات</li>
</ul>
<p>يشير استخلاص الميزات إلى تحويل البيانات غير المهيكلة، التي يصعب على الآلات التعرّف عليها، إلى متجهات ميزات. على سبيل المثال، يمكن تحويل الصور إلى متجهات ميزات متعددة الأبعاد باستخدام نماذج التعلم العميق. في الوقت الحالي، تشمل نماذج الذكاء الاصطناعي الأكثر شيوعًا للتعرف على الصور نماذج VGG و GNN و ResNet. يقدم هذا الموضوع كيفية استخراج الميزات من الكائنات المكتشفة باستخدام ResNet-50.</p>
<ul>
<li>تحليل المتجهات</li>
</ul>
<p>تتم مقارنة متجهات السمات المستخرجة مع متجهات المكتبة، ويتم إرجاع المعلومات المقابلة للمتجهات الأكثر تشابهًا. بالنسبة لمجموعات بيانات متجهات السمات واسعة النطاق، يمثل الحساب تحديًا كبيرًا. يقدّم هذا الموضوع كيفية تحليل متجهات السمات باستخدام ميلفوس.</p>
<h2 id="Key-technologies" class="common-anchor-header">التقنيات الرئيسية<button data-href="#Key-technologies" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="OpenCV" class="common-anchor-header">OpenCV</h3><p>مكتبة الرؤية الحاسوبية مفتوحة المصدر (OpenCV) هي مكتبة رؤية حاسوبية مفتوحة المصدر (OpenCV) هي مكتبة رؤية حاسوبية متعددة المنصات، توفر العديد من الخوارزميات العالمية لمعالجة الصور والرؤية الحاسوبية. يشيع استخدام OpenCV في مجال الرؤية الحاسوبية.</p>
<p>يوضح المثال التالي كيفية التقاط إطارات الفيديو على فترات زمنية محددة وحفظها كصور باستخدام OpenCV مع Python.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> cv2 
<span class="hljs-built_in">cap</span> = cv2.VideoCapture(file_path)   
framerate = <span class="hljs-built_in">cap</span>.get(cv2.CAP_PROP_FPS)   
allframes = <span class="hljs-type">int</span>(cv2.VideoCapture.get(<span class="hljs-built_in">cap</span>, <span class="hljs-type">int</span>(cv2.CAP_PROP_FRAME_COUNT)))  
success, image = <span class="hljs-built_in">cap</span>.read() 
cv2.imwrite(file_name, image)
<button class="copy-code-btn"></button></code></pre>
<h3 id="YOLOv3" class="common-anchor-header">YOLOv3</h3><p>You Only Look Only One، الإصدار 3 (YOLOv3 [5]) هي خوارزمية للكشف عن الأجسام على مرحلة واحدة تم اقتراحها في السنوات الأخيرة. بالمقارنة مع خوارزميات اكتشاف الأجسام التقليدية بنفس الدقة، فإن YOLOv3 أسرع بمرتين. YOLOv3 المذكورة في هذا الموضوع هي النسخة المحسّنة من PaddlePaddle [6]. يستخدم طرق تحسين متعددة مع سرعة استدلال أعلى.</p>
<h3 id="ResNet-50" class="common-anchor-header">ResNet-50</h3><p>ResNet [7] هو الفائز في ILSVRC 2015 في تصنيف الصور بسبب بساطته وعمليته. كأساس للعديد من طرق تحليل الصور، أثبت ResNet أنه نموذج شائع متخصص في اكتشاف الصور وتجزئتها والتعرف عليها.</p>
<h3 id="Milvus" class="common-anchor-header">ميلفوس</h3><p><a href="https://milvus.io/">Milvus</a> عبارة عن قاعدة بيانات متجهات سحابية مفتوحة المصدر ومفتوحة المصدر تم إنشاؤها لإدارة متجهات التضمين التي تم إنشاؤها بواسطة نماذج التعلم الآلي والشبكات العصبية. وهي تُستخدم على نطاق واسع في سيناريوهات مثل الرؤية الحاسوبية ومعالجة اللغة الطبيعية والكيمياء الحاسوبية وأنظمة التوصية الشخصية وغيرها.</p>
<p>تصف الإجراءات التالية كيفية عمل ميلفوس.</p>
<ol>
<li>يتم تحويل البيانات غير المهيكلة إلى ناقلات ميزات باستخدام نماذج التعلم العميق ويتم استيرادها إلى ميلفوس.</li>
<li>يخزن ميلفوس متجهات السمات ويفهرسها.</li>
<li>يُرجع ميلفوس المتجهات الأكثر تشابهًا مع المتجهات التي يستعلم عنها المستخدمون.</li>
</ol>
<h2 id="Deployment" class="common-anchor-header">النشر<button data-href="#Deployment" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>الآن لديك بعض الفهم لأنظمة تحليل الفيديو القائمة على ميلفوس. يتكون النظام بشكل أساسي من جزأين، كما هو موضح في الشكل التالي.</p>
<ul>
<li><p>تشير الأسهم الحمراء إلى عملية استيراد البيانات. استخدم ResNet-50 لاستخراج متجهات الملامح من مجموعة بيانات الصورة واستيراد متجهات الملامح إلى ميلفوس.</p></li>
<li><p>تشير الأسهم السوداء إلى عملية تحليل الفيديو. أولاً، استخرج الإطارات من الفيديو واحفظ الإطارات كصور. ثانيًا، اكتشاف واستخراج الأجسام في الصور باستخدام YOLOv3. بعد ذلك، استخدم ResNet-50 لاستخراج متجهات السمات من الصور. أخيرًا، يبحث Milvus عن معلومات الكائنات ويعيد معلومات الكائنات مع متجهات الميزات المقابلة.</p></li>
</ul>
<p>لمزيد من المعلومات، راجع <a href="https://github.com/milvus-io/bootcamp/tree/master/solutions/video_similarity_search/object_detection">معسكر ميلفوس التمهيدي: نظام الكشف عن كائنات الفيديو</a>.</p>
<p><strong>استيراد البيانات</strong></p>
<p>عملية استيراد البيانات بسيطة. قم بتحويل البيانات إلى متجهات ذات 2,048 بُعدًا واستيراد المتجهات إلى ميلفوس.</p>
<pre><code translate="no" class="language-python">vector = image_encoder.execute(filename)
entities = [vector]
collection.insert(data=entities)
<button class="copy-code-btn"></button></code></pre>
<p><strong>تحليل الفيديو</strong></p>
<p>كما هو موضح أعلاه، تتضمن عملية تحليل الفيديو التقاط إطارات الفيديو، واكتشاف الأجسام في كل إطار، واستخراج المتجهات من الأجسام، وحساب تشابه المتجهات باستخدام مقاييس المسافة الإقليدية (L2)، والبحث عن النتائج باستخدام Milvus.</p>
<pre><code translate="no" class="language-python">images = extract_frame(filename, 1, prefix)   
detector = Detector()   
run(detector, DATA_PATH)       
vectors = get_object_vector(image_encoder, DATA_PATH)
search_params = {<span class="hljs-string">&quot;metric_type&quot;</span>: <span class="hljs-string">&quot;L2&quot;</span>, <span class="hljs-string">&quot;params&quot;</span>: {<span class="hljs-string">&quot;nprobe&quot;</span>: 10}}
results = collection.search(vectors, param=search_params, <span class="hljs-built_in">limit</span>=10)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Conclusion" class="common-anchor-header">الخلاصة<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>في الوقت الحالي، أكثر من 80% من البيانات غير منظمة. ومع التطور السريع للذكاء الاصطناعي، تم تطوير عدد متزايد من نماذج التعلم العميق لتحليل البيانات غير المنظمة. حققت تقنيات مثل اكتشاف الأشياء ومعالجة الصور اختراقات كبيرة في كل من الأوساط الأكاديمية والصناعية. وبفضل هذه التقنيات، استوفى المزيد والمزيد من منصات الذكاء الاصطناعي المتطلبات العملية.</p>
<p>تم بناء نظام تحليل الفيديو الذي تمت مناقشته في هذا الموضوع باستخدام برنامج Milvus، والذي يمكنه تحليل محتوى الفيديو بسرعة.</p>
<p>كقاعدة بيانات متجهة مفتوحة المصدر، تدعم Milvus متجهات الميزات المستخرجة باستخدام نماذج مختلفة للتعلم العميق. وبتكامله مع مكتبات مثل Faiss وNMSLIB وAnnoy، يوفر Milvus مجموعة من واجهات برمجة التطبيقات البديهية، التي تدعم تبديل أنواع الفهرس وفقًا للسيناريوهات. بالإضافة إلى ذلك، تدعم Milvus التصفية القياسية، مما يزيد من معدل الاستدعاء ومرونة البحث. وقد تم تطبيق Milvus في العديد من المجالات مثل معالجة الصور، والرؤية الحاسوبية، ومعالجة اللغات الطبيعية، والتعرف على الكلام، ونظام التوصية، واكتشاف الأدوية الجديدة.</p>
<h2 id="References" class="common-anchor-header">المراجع<button data-href="#References" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>[1] A. D. Bagdanov, L. Ballan, M. Bertini, A. Del Bimbo. "مطابقة العلامات التجارية واسترجاعها في قواعد بيانات الفيديو الرياضي." وقائع ورشة العمل الدولية حول ورشة عمل حول استرجاع معلومات الوسائط المتعددة، ACM، 2007. https://www.researchgate.net/publication/210113141_Trademark_matching_and_retrieval_in_sports_video_databases</p>
<p>[2] J. Kleban, X. Xie, W.-Y. Ma. "التنقيب الهرمي المكاني للكشف عن الشعارات في المشاهد الطبيعية". مؤتمر IEEE الدولي، 2008. https://ieeexplore.ieee.org/document/4607625</p>
<p>[3] R. Boia, C. Florea, L. Florea, R. Dogaru. "تحديد موقع الشعار والتعرف عليه في الصور الطبيعية باستخدام الرسوم البيانية للفئات المتجانسة." رؤية الآلة وتطبيقاتها 27 (2), 2016. https://link.springer.com/article/10.1007/s00138-015-0741-7</p>
<p>[4] R. Boia, C. Florea, L. Florea. "التكتل الإهليلجي الإهليلجي في النموذج الأولي للفئة للكشف عن الشعار." BMVC, 2015. http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=5C87F52DE38AB0C90F8340DFEBB841F7?doi=10.1.1.707.9371&amp;rep=rep1&amp;type=pdf</p>
<p>[5] https://arxiv.org/abs/1804.02767</p>
<p>[6] https://paddlepaddle.org.cn/modelbasedetail/yolov3</p>
<p>[7] https://arxiv.org/abs/1512.03385</p>
