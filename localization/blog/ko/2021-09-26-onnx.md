---
id: 2021-09-26-onnx.md
title: ONNX로 모델 처리
date: 2021-09-26T00:00:00.000Z
desc: ONNX 및 Milvus 기반 이미지 검색에 여러 모델을 사용하는 방법
cover: assets.zilliz.com/medium_1_cfb009269a.png
tag: Engineering
canonicalUrl: >-
  https://zilliz.com/blog/combine-ai-models-for-image-search-using-onnx-and-milvus
---
<custom-h1>ONNX와 Milvus를 사용해 이미지 검색을 위한 AI 모델 결합하기</custom-h1><p>오픈 신경망 교환(ONNX)은 머신러닝 모델을 표현하기 위해 만들어진 개방형 형식입니다. 2017년 오픈 소스화된 이후, ONNX는 머신 러닝과 딥 러닝 모델을 위한 빌딩 블록을 제공하는 AI 표준으로 발전해 왔습니다. ONNX는 AI 개발자가 다양한 프레임워크, 도구, 런타임, 컴파일러에서 모델을 사용할 수 있도록 공통 파일 형식을 정의하며, 인공지능 커뮤니티의 혁신 속도를 높이는 데 도움을 줍니다.</p>
<p>Milvus는 유연성과 안정성이 뛰어나고 속도가 매우 빠른 오픈 소스 벡터 데이터베이스입니다. 벡터의 추가, 삭제, 업데이트 및 거의 실시간에 가까운 검색을 지원합니다. Milvus는 포괄적인 직관적인 API 세트와 널리 채택된 여러 인덱스 라이브러리(예: Faiss, NMSLIB, Annoy)를 지원하여 주어진 시나리오에 대한 인덱스 선택을 간소화합니다. Milvus는 사용이 간편하여 이미지, 오디오 및 비디오 검색, 추천, 챗봇, 신약 검색 등 전 세계 수백 개의 조직과 기관에서 사용되고 있습니다.</p>
<p>이 글에서는 ONNX와 Milvus를 기반으로 이미지 검색에 여러 모델을 사용하는 방법을 소개합니다. VGG16과 ResNet50 모델을 예로 들어, ONNX를 사용하여 다양한 AI 모델을 실행하여 특징 벡터를 생성하고 마지막으로 Milvus에서 특징 벡터 검색을 수행하여 유사한 이미지를 반환하는 방법을 설명합니다.</p>
<h2 id="Process-Models-with-ONNX" class="common-anchor-header">ONNX로 모델 처리<button data-href="#Process-Models-with-ONNX" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>ONNX 형식은 AI 모델 간에 쉽게 교환할 수 있습니다. 예를 들어, TensorFlow 모델을 ONNX 형식으로 변환하여 Caffe 환경에서 실행할 수 있습니다. 이 예에서는 Keras 프레임워크에서 사전 학습된 ResNet50 모델을 ONNX 형식으로 변환한 다음, VGG16 모델을 ONNX 형식으로 호출하여 다른 모델을 분석합니다.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> keras.applications.resnet50 <span class="hljs-keyword">import</span> ResNet50
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># load keras-resnet50 model and save as a floder</span>
model_resnet50 = ResNet50(include_top=<span class="hljs-literal">False</span>, pooling=<span class="hljs-string">&#x27;max&#x27;</span>, weights=<span class="hljs-string">&#x27;imagenet&#x27;</span>)
tf.saved_model.save(model_resnet50, <span class="hljs-string">&quot;keras_resnet50_model&quot;</span>)

<span class="hljs-comment"># convert resnet50 model to onnx</span>
! python -m tf2onnx.convert --saved-model <span class="hljs-string">&quot;keras_resnet50_model&quot;</span> --output <span class="hljs-string">&quot;onnx_resnet50.onnx&quot;</span>
<button class="copy-code-btn"></button></code></pre>
<p>참고: <code translate="no">keras2onnx.convert_keras(model, model.name)</code> 인터페이스를 사용하여 모델을 변환하면 <code translate="no">AttributeError:'KerasTensor' object has no attribute'graph'</code> 오류가 반환됩니다. 그런 다음 Python의 Bash 명령을 사용하여 스택 오버플로의 솔루션에 따라 변환할 수 있습니다.</p>
<h2 id="Extract-Feature-Vectors-using-Models" class="common-anchor-header">모델을 사용하여 특징 벡터 추출하기<button data-href="#Extract-Feature-Vectors-using-Models" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>ResNet50 모델을 ONNX 형식으로 변환한 후 추론을 통해 사진의 특징 벡터를 직접 추출할 수 있습니다. 참고: 특징 벡터는 추출 후 정규화해야 합니다.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># get the image vectors with onnx model</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_onnx_vectors</span>(<span class="hljs-params">onnx_model, img_path</span>):
    img = image.load_img(img_path, target_size=(<span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=<span class="hljs-number">0</span>)
    x = preprocess_input(x)
    
    sess = onnxruntime.InferenceSession(onnx_model)
    x = x <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(x, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">else</span> [x]
    feed = <span class="hljs-built_in">dict</span>([(<span class="hljs-built_in">input</span>.name, x[n]) <span class="hljs-keyword">for</span> n, <span class="hljs-built_in">input</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sess.get_inputs())])
    feat = sess.run(<span class="hljs-literal">None</span>, feed)[<span class="hljs-number">0</span>]
    
    norm_feat = feat[<span class="hljs-number">0</span>] / LA.norm(feat[<span class="hljs-number">0</span>])
    norm_feat = [i.item() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> norm_feat]
    <span class="hljs-keyword">return</span> norm_feat
<button class="copy-code-btn"></button></code></pre>
<p>이미지 데이터를 처리하려면 ONNX 형식의 VGG16 모델을 사용합니다:</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># generate vectors with ResNet50 and VGG16 ONNX model</span>
2vec_resnet = get_onnx_vectors(<span class="hljs-string">&quot;onnx_resnet50.onnx&quot;</span>, <span class="hljs-string">&quot;./pic/example.jpg&quot;</span>)
3vec_vgg = get_onnx_vectors(<span class="hljs-string">&quot;onnx_vgg16.onnx&quot;</span>, <span class="hljs-string">&quot;./pic/example.jpg&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Store-Vector-Data" class="common-anchor-header">벡터 데이터 저장<button data-href="#Store-Vector-Data" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>사진과 같은 비정형 데이터는 컴퓨터로 직접 처리할 수 없지만, AI 모델을 통해 벡터로 변환한 후 컴퓨터로 분석할 수 있습니다. 밀버스 벡터 데이터베이스는 대규모 비정형 데이터 분석이 가능하도록 설계되었습니다. 벡터 데이터를 저장하고 실시간에 가까운 분석을 수행할 수 있습니다. 먼저 Milvus에서 해당 모델의 컬렉션을 생성한 다음 이미지 벡터를 삽입합니다.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> milvus <span class="hljs-keyword">import</span> *

<span class="hljs-comment"># create collections in Milvus</span>
milvus.create_collection(resnet_collection_param)
milvus.create_collection(vgg_collection_param)

<span class="hljs-comment"># insert data to Milvus and return ids</span>
status, resnet_ids = milvus.insert(resnet_collection_name, resnet_vectors)
status, vgg_ids = milvus.insert(vgg_collection_name, vgg_vectors)
<button class="copy-code-btn"></button></code></pre>
<p>데이터를 성공적으로 삽입하면 Milvus는 벡터에 해당하는 ID를 반환하고, ID로 사진을 찾을 수 있습니다. 이 경우에 사용된 Milvus 1.1은 스칼라 필터링(현재 Milvus 2.0에서 지원)을 지원하지 않으므로 Redis를 사용하여 벡터 ID와 이미지 경로의 키값을 저장합니다.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> redis
<span class="hljs-keyword">def</span> <span class="hljs-title function_">img_ids_to_redis</span>(<span class="hljs-params">img_directory, res_ids</span>):
  <span class="hljs-keyword">for</span> img, ids <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(images, res_ids):
    redis.<span class="hljs-built_in">set</span>(ids, img)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Search-for-Similar-Images" class="common-anchor-header">유사한 이미지 검색<button data-href="#Search-for-Similar-Images" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>데이터를 저장한 후 벡터를 검색할 수 있습니다. Milvus는 유클리드, 내적 곱, 해밍 거리 등 다양한 거리 계산 방법을 지원합니다. 이 글의 이미지 유사도 검색은 Milvus에서 벡터 간의 유클리드 거리 계산을 채택하여 유사한 벡터 ID를 반환한 다음 Redis에서 해당 ID에 해당하는 이미지를 찾습니다.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># search in Milvus and return the similarly results with ids</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">search_in_milvus</span>(<span class="hljs-params">collection_name, search_vector</span>):
    status, results = milvus.search(collection_name, TOP_K, [search_vector])
    <span class="hljs-built_in">print</span>(status)
    re_ids = [x.<span class="hljs-built_in">id</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
    re_distance = [x.distance <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
    <span class="hljs-keyword">return</span> re_ids, re_distance
    
<span class="hljs-comment"># get the images according the result ids</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_sim_imgs</span>(<span class="hljs-params">collection_name, search_vector</span>):
    ids, distance = search_in_milvus(collection_name, search_vector)
    img = [red.get(i).decode(<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ids]
    <span class="hljs-keyword">return</span> ids, distance, img
<button class="copy-code-btn"></button></code></pre>
<p>이 문서에서는 VGG16과 ResNet50 모델을 예로 들어, ONNX를 통해 여러 모델을 처리하고 유사한 벡터 검색을 위해 여러 모델을 Milvus와 결합하여 유사한 이미지를 얻는 방법을 보여줍니다. 위의 두 모델은 특징 벡터를 빠르게 추출할 수 있는 Keras 프레임워크를 기반으로 합니다. 노트북에서 이 두 모델을 기반으로 Milvus가 COCO 데이터 세트에서 사진을 검색한 결과는 비슷하지만 유클리드 거리는 같지 않다는 것을 알 수 있습니다. 다른 데이터 세트를 사용하여 두 모델의 검색 결과를 비교해 볼 수도 있습니다.</p>
<p>Milvus는 대규모 비정형 데이터에서 생성된 특징 벡터를 처리하는 데 사용할 수 있는 고성능, 고가용성 벡터 데이터베이스입니다. 더 많은 솔루션은 <a href="https://github.com/milvus-io/bootcamp">Milvus 부트캠프를</a> 참조하세요.</p>
<h2 id="References" class="common-anchor-header">참고 자료<button data-href="#References" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ol>
<li>https://github.com/onnx/onnx</li>
<li>https://onnx.ai/</li>
<li>https://milvus.io/cn/</li>
<li>https://github.com/milvus-io/bootcamp</li>
</ol>
<h3 id="About-author" class="common-anchor-header">저자 소개</h3><p>질리즈의 데이터 엔지니어인 시유 첸은 시디안 대학교에서 컴퓨터 공학을 전공했습니다. 질리즈에 입사한 이후 오디오 및 비디오 분석, 분자식 검색 등 다양한 분야에서 밀버스를 위한 솔루션을 모색해 왔으며, 이를 통해 커뮤니티의 응용 시나리오를 크게 풍부하게 만들었습니다. 그녀는 현재 더 흥미로운 솔루션을 모색하고 있습니다. 여가 시간에는 스포츠와 독서를 좋아합니다.</p>
