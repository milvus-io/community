---
id: smarter-retrieval-for-rag-late-chunking-with-jina-embeddings-v2-and-milvus.md
title: 'RAGë¥¼ ìœ„í•œ ë” ìŠ¤ë§ˆíŠ¸í•œ ê²€ìƒ‰: Jina Embedding v2 ë° Milvusë¥¼ ì‚¬ìš©í•œ í›„ê¸° ì²­í‚¹'
author: Wei Zang
date: 2025-10-11T00:00:00.000Z
desc: ë¬¸ë§¥ì„ ì¸ì‹í•˜ëŠ” íš¨ìœ¨ì ì¸ ë¬¸ì„œ ì„ë² ë”©ê³¼ ë” ë¹ ë¥´ê³  ìŠ¤ë§ˆíŠ¸í•œ ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•´ í›„ê¸° ì²­í‚¹ ë° ë°€ë²„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
cover: >-
  assets.zilliz.com/Milvus_Meets_Late_Chunking_Smarter_Retrieval_for_RAG_4f9640fffd.png
tag: Tutorials
tags: 'Milvus, Vector Database, Open Source, Vector Embeddings'
recommend: true
meta_keywords: 'Late Chunking, RAG accuracy, vector database, Milvus, document embeddings'
canonicalUrl: >-
  https://milvus.io/blog/smarter-retrieval-for-rag-late-chunking-with-jina-embeddings-v2-and-milvus.md
---
<p>ê°•ë ¥í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•ì€ ì¼ë°˜ì ìœ¼ë¡œ <strong>ë¬¸ì„œ</strong> <a href="https://zilliz.com/learn/guide-to-chunking-strategies-for-rag#Chunking"><strong>ì²­í¬(</strong></a>í° í…ìŠ¤íŠ¸ë¥¼ ê´€ë¦¬í•˜ê¸° ì‰¬ìš´ ì¡°ê°ìœ¼ë¡œ <a href="https://zilliz.com/learn/guide-to-chunking-strategies-for-rag#Chunking"><strong>ë¶„í• í•˜ì—¬</strong></a>ì„ë² ë”© ë° ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì‘ì—…)ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì „ëµì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:</p>
<ul>
<li><p><strong>ê³ ì • í¬ê¸° ì²­í¬</strong> (ì˜ˆ: 512í† í°ë§ˆë‹¤)</p></li>
<li><p><strong>ê°€ë³€ í¬ê¸° ì²­í¬</strong> (ì˜ˆ: ë‹¨ë½ ë˜ëŠ” ë¬¸ì¥ ê²½ê³„)</p></li>
<li><p><strong>ìŠ¬ë¼ì´ë”© ì°½</strong> (ê²¹ì¹˜ëŠ” ìŠ¤íŒ¬)</p></li>
<li><p>ì¬ê·€ì <strong>ì²­í‚¹</strong> (ê³„ì¸µì  ë¶„í• )</p></li>
<li><p><strong>ì˜ë¯¸ì  ì²­í¬</strong> (ì£¼ì œë³„ ê·¸ë£¹í™”)</p></li>
</ul>
<p>ì´ëŸ¬í•œ ë°©ë²•ì—ëŠ” ì¥ì ì´ ìˆì§€ë§Œ, ì¢…ì¢… ê¸´ ë²”ìœ„ì˜ ë¬¸ë§¥ì´ ë‹¨ì ˆë˜ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Jina AIëŠ” ì „ì²´ ë¬¸ì„œë¥¼ ë¨¼ì € ì„ë² ë“œí•œ ë‹¤ìŒ ì²­í¬ë¥¼ ë¶„í• í•˜ëŠ” í›„ê¸° ì²­í‚¹ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.</p>
<p>ì´ ê¸€ì—ì„œëŠ” í›„ê¸° ì²­í‚¹ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì‚´í´ë³´ê³ , ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ìœ„í•´ êµ¬ì¶•ëœ ê³ ì„±ëŠ¥ ì˜¤í”ˆ ì†ŒìŠ¤ ë²¡í„° <a href="https://milvus.io/">ë°ì´í„°ë² ì´ìŠ¤ì¸ Milvusì™€</a>ê²°í•©í•˜ì—¬ RAG íŒŒì´í”„ë¼ì¸ì„ íšê¸°ì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤. ì—”í„°í”„ë¼ì´ì¦ˆ ì§€ì‹ ë² ì´ìŠ¤, AI ê¸°ë°˜ ê³ ê° ì§€ì›, ê³ ê¸‰ ê²€ìƒ‰ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” ê²½ìš°, ì´ ì›Œí¬ìŠ¤ë£¨ë¥¼ í†µí•´ ëŒ€ê·œëª¨ë¡œ ì„ë² ë”©ì„ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì„¸ìš”.</p>
<h2 id="What-Is-Late-Chunking" class="common-anchor-header">í›„ê¸° ì²­í‚¹ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?<button data-href="#What-Is-Late-Chunking" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>ê¸°ì¡´ì˜ ì²­í‚¹ ë°©ì‹ì€ ì£¼ìš” ì •ë³´ê°€ ì—¬ëŸ¬ ì²­í¬ì— ê±¸ì³ ìˆì„ ë•Œ ì¤‘ìš”í•œ ì—°ê²°ì´ ëŠì–´ì ¸ ê²€ìƒ‰ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p>ì•„ë˜ì™€ ê°™ì´ ë‘ ê°œì˜ ì²­í¬ë¡œ ë‚˜ë‰˜ì–´ì ¸ ìˆëŠ” Milvus 2.4.13ì˜ ë¦´ë¦¬ìŠ¤ ë…¸íŠ¸ë¥¼ ì‚´í´ë³´ì„¸ìš”:</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure1_Chunking_Milvus2_4_13_Release_Note_fe7fbdb833.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>ê·¸ë¦¼ 1. Milvus 2.4.13 ì²­í¬ ë¶„í•  ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸</em></p>
<p>"Milvus 2.4.13ì˜ ìƒˆë¡œìš´ ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"ë¼ê³  ì¿¼ë¦¬í•˜ë©´ í‘œì¤€ ì„ë² ë”© ëª¨ë¸ì—ì„œ "Milvus 2.4.13"(ì²­í¬ 1)ê³¼ í•´ë‹¹ ê¸°ëŠ¥(ì²­í¬ 2)ì„ ì—°ê²°í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ”? ë²¡í„°ê°€ ì•½í•´ì§€ê³  ê²€ìƒ‰ ì •í™•ë„ê°€ ë‚®ì•„ì§‘ë‹ˆë‹¤.</p>
<p>ìŠ¬ë¼ì´ë”© ì°½, ê²¹ì¹˜ëŠ” ì»¨í…ìŠ¤íŠ¸, ë°˜ë³µ ìŠ¤ìº”ê³¼ ê°™ì€ íœ´ë¦¬ìŠ¤í‹± ìˆ˜ì •ì€ ë¶€ë¶„ì ì¸ í•´ê²°ì±…ì„ ì œê³µí•˜ì§€ë§Œ ë³´ì¥ì€ ì—†ìŠµë‹ˆë‹¤.</p>
<p><strong>ê¸°ì¡´ì˜ ì²­í‚¹ì€</strong> ì´ íŒŒì´í”„ë¼ì¸ì„ ë”°ë¦…ë‹ˆë‹¤:</p>
<ol>
<li><p>í…ìŠ¤íŠ¸<strong>ì‚¬ì „ ì²­í¬</strong> (ë¬¸ì¥, ë‹¨ë½ ë˜ëŠ” ìµœëŒ€ í† í° ê¸¸ì´ ê¸°ì¤€).</p></li>
<li><p>ê° ì²­í¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ<strong>ì„ë² ë“œí•©ë‹ˆë‹¤</strong>.</p></li>
<li><p>í‰ê·  í’€ë§ ë“±ì„ í†µí•´ í† í° ì„ë² ë”©ì„ í•˜ë‚˜ì˜ ì²­í¬ ë²¡í„°ë¡œ<strong>ì§‘ê³„í•©ë‹ˆë‹¤</strong>.</p></li>
</ol>
<p><strong>í›„ê¸° ì²­í‚¹ì€</strong> íŒŒì´í”„ë¼ì¸ì„ ë’¤ì§‘ìŠµë‹ˆë‹¤:</p>
<ol>
<li><p><strong>ë¨¼ì € ì„ë² ë“œí•©ë‹ˆë‹¤</strong>: ì „ì²´ ë¬¸ì„œì— ëŒ€í•´ ê¸´ ì»¨í…ìŠ¤íŠ¸ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìº¡ì²˜í•˜ëŠ” í’ë¶€í•œ í† í° ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.</p></li>
<li><p><strong>ë‚˜ì¤‘ì— ì²­í¬</strong>: ì´ëŸ¬í•œ í† í° ì„ë² ë”©ì˜ ì¸ì ‘í•œ ìŠ¤íŒ¬ì„ í‰ê·  í’€ë§í•˜ì—¬ ìµœì¢… ì²­í¬ ë²¡í„°ë¥¼ í˜•ì„±í•©ë‹ˆë‹¤.</p></li>
</ol>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure2_Naive_Chunkingvs_Late_Chunking_a94d30b6ea.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>ê·¸ë¦¼ 2. ì´ˆê¸° ì²­í‚¹ê³¼ í›„ê¸° ì²­í‚¹ ë¹„êµ(</em><a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><em>ì¶œì²˜</em></a><em>)</em></p>
<p>ëª¨ë“  ì²­í¬ì— ì „ì²´ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë³´ì¡´í•¨ìœ¼ë¡œì¨ í›„ê¸° ì²­í‚¹ì€ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤:</p>
<ul>
<li><p><strong>ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ - ê°</strong>ì²­í¬ê°€ ë¬¸ë§¥ì„ ì¸ì‹í•©ë‹ˆë‹¤.</p></li>
<li><p><strong>ì²­í¬ ìˆ˜ ê°ì†Œ -</strong>ë” ì§‘ì¤‘ëœ í…ìŠ¤íŠ¸ë¥¼ LLMì— ì „ì†¡í•˜ì—¬ ë¹„ìš©ê³¼ ì§€ì—° ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p></li>
</ul>
<p>jina-embeddings-v2-base-enê³¼ ê°™ì€ ë§ì€ ê¸´ ë¬¸ë§¥ ëª¨ë¸ì€ ìµœëŒ€ 8,192ê°œì˜ í† í°(ì•½ 20ë¶„ ë¶„ëŸ‰(ì•½ 5,000ë‹¨ì–´)ì— í•´ë‹¹)ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ëŒ€ë¶€ë¶„ì˜ ì‹¤ì œ ë¬¸ì„œì— í›„ê¸° ì²­í‚¹ì´ ì‹¤ìš©ì ì…ë‹ˆë‹¤.</p>
<p>ì´ì œ í›„ê¸° ì²­í‚¹ì˜ 'ë¬´ì—‡'ê³¼ 'ì™œ'ë¥¼ ì´í•´í–ˆìœ¼ë‹ˆ ì´ì œ 'ì–´ë–»ê²Œ'ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì„¹ì…˜ì—ì„œëŠ” í›„ê¸° ì²­í‚¹ íŒŒì´í”„ë¼ì¸ì˜ ì‹¤ì œ êµ¬í˜„ ê³¼ì •ì„ ì•ˆë‚´í•˜ê³ , ê¸°ì¡´ ì²­í‚¹ê³¼ ì„±ëŠ¥ì„ ë²¤ì¹˜ë§ˆí‚¹í•˜ê³ , Milvusë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì˜í–¥ë ¥ì„ ê²€ì¦í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ ì‹¤ìš©ì ì¸ ì›Œí¬ìŠ¤ë£¨ëŠ” ì´ë¡ ê³¼ ì‹¤ë¬´ë¥¼ ì—°ê²°í•˜ì—¬ í›„ê¸° ì²­í‚¹ì„ RAG ì›Œí¬í”Œë¡œì— í†µí•©í•˜ëŠ” ë°©ë²•ì„ ì •í™•í•˜ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.</p>
<h2 id="Testing-Late-Chunking" class="common-anchor-header">í›„ê¸° ì²­í‚¹ í…ŒìŠ¤íŠ¸í•˜ê¸°<button data-href="#Testing-Late-Chunking" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Basic-Implementation" class="common-anchor-header">ê¸°ë³¸ êµ¬í˜„</h3><p>ë‹¤ìŒì€ í›„ê¸° ì²­í‚¹ì˜ í•µì‹¬ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ê° ë‹¨ê³„ë¥¼ ì•ˆë‚´í•˜ê¸° ìœ„í•´ ëª…í™•í•œ ë¬¸ì„œ ì„¤ëª…ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. <code translate="no">sentence_chunker</code> í•¨ìˆ˜ëŠ” ì›ë³¸ ë¬¸ì„œë¥¼ ë‹¨ë½ ê¸°ë°˜ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì²­í¬ ì½˜í…ì¸ ì™€ ì²­í¬ ì£¼ì„ ì •ë³´ <code translate="no">span_annotations</code> (ì¦‰, ê° ì²­í¬ì˜ ì‹œì‘ ë° ë ì¸ë±ìŠ¤)ë¥¼ ëª¨ë‘ ë°˜í™˜í•©ë‹ˆë‹¤.</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sentence_chunker</span>(<span class="hljs-params">document, batch_size=<span class="hljs-number">10000</span></span>):
    nlp = spacy.blank(<span class="hljs-string">&quot;en&quot;</span>)
    nlp.add_pipe(<span class="hljs-string">&quot;sentencizer&quot;</span>, config={<span class="hljs-string">&quot;punct_chars&quot;</span>: <span class="hljs-literal">None</span>})
    doc = nlp(document)

    docs = []
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(document), batch_size):
        batch = document[i : i + batch_size]
        docs.append(nlp(batch))

    doc = Doc.from_docs(docs)

    span_annotations = []
    chunks = []
    <span class="hljs-keyword">for</span> i, sent <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(doc.sents):
        span_annotations.append((sent.start, sent.end))
        chunks.append(sent.text)

    <span class="hljs-keyword">return</span> chunks, span_annotations
<button class="copy-code-btn"></button></code></pre>
<p><code translate="no">document_to_token_embeddings</code> í•¨ìˆ˜ëŠ” ì „ì²´ ë¬¸ì„œì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•˜ê¸° ìœ„í•´ jinaai/jina-embeddings-v2-base-en ëª¨ë¸ê³¼ í•´ë‹¹ í† í°í™” ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">document_to_token_embeddings</span>(<span class="hljs-params">model, tokenizer, document, batch_size=<span class="hljs-number">4096</span></span>):
    tokenized_document = tokenizer(document, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
    tokens = tokenized_document.tokens()

    outputs = []
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(tokens), batch_size):
        
        start = i
        end   = <span class="hljs-built_in">min</span>(i + batch_size, <span class="hljs-built_in">len</span>(tokens))

        batch_inputs = {k: v[:, start:end] <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> tokenized_document.items()}

        <span class="hljs-keyword">with</span> torch.no_grad():
            model_output = model(**batch_inputs)

        outputs.append(model_output.last_hidden_state)

    model_output = torch.cat(outputs, dim=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> model_output
<button class="copy-code-btn"></button></code></pre>
<p><code translate="no">late_chunking</code> í•¨ìˆ˜ëŠ” ë¬¸ì„œì˜ í† í° ì„ë² ë”©ê³¼ ì›ë³¸ ì²­í¬ ì–´ë…¸í…Œì´ì…˜ ì •ë³´ <code translate="no">span_annotations</code> ë¥¼ ê°€ì ¸ì™€ì„œ ìµœì¢… ì²­í¬ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">late_chunking</span>(<span class="hljs-params">token_embeddings, span_annotation, max_length=<span class="hljs-literal">None</span></span>):
    outputs = []
    <span class="hljs-keyword">for</span> embeddings, annotations <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(token_embeddings, span_annotation):
        <span class="hljs-keyword">if</span> (
            max_length <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>
        ):
            annotations = [
                (start, <span class="hljs-built_in">min</span>(end, max_length - <span class="hljs-number">1</span>))
                <span class="hljs-keyword">for</span> (start, end) <span class="hljs-keyword">in</span> annotations
                <span class="hljs-keyword">if</span> start &lt; (max_length - <span class="hljs-number">1</span>)
            ]
        pooled_embeddings = []
        <span class="hljs-keyword">for</span> start, end <span class="hljs-keyword">in</span> annotations:
            <span class="hljs-keyword">if</span> (end - start) &gt;= <span class="hljs-number">1</span>:
                pooled_embeddings.append(
                    embeddings[start:end].<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">0</span>) / (end - start)
                )
                    
        pooled_embeddings = [
            embedding.detach().cpu().numpy() <span class="hljs-keyword">for</span> embedding <span class="hljs-keyword">in</span> pooled_embeddings
        ]
        outputs.append(pooled_embeddings)

    <span class="hljs-keyword">return</span> outputs
<button class="copy-code-btn"></button></code></pre>
<p>ì˜ˆë¥¼ ë“¤ì–´, jinaai/jina-embeddings-v2-base-enìœ¼ë¡œ ì²­í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:</p>
<pre><code translate="no">tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;jinaai/jina-embeddings-v2-base-en&#x27;</span>, trust_remote_code=<span class="hljs-literal">True</span>)
model     = AutoModel.from_pretrained(<span class="hljs-string">&#x27;jinaai/jina-embeddings-v2-base-en&#x27;</span>, trust_remote_code=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># First chunk the text as normal, to obtain the beginning and end points of the chunks.</span>
chunks, span_annotations = sentence_chunker(document)
<span class="hljs-comment"># Then embed the full document.</span>
token_embeddings = document_to_token_embeddings(model, tokenizer, document)
<span class="hljs-comment"># Then perform the late chunking</span>
chunk_embeddings = late_chunking(token_embeddings, [span_annotations])[<span class="hljs-number">0</span>]
<button class="copy-code-btn"></button></code></pre>
<p><em>íŒ:</em> íŒŒì´í”„ë¼ì¸ì„ í•¨ìˆ˜ë¡œ ë˜í•‘í•˜ë©´ ë‹¤ë¥¸ ê¸´ ì»¨í…ìŠ¤íŠ¸ ëª¨ë¸ì´ë‚˜ ì²­í‚¹ ì „ëµìœ¼ë¡œ ì‰½ê²Œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<h3 id="Comparison-with-Traditional-Embedding-Methods" class="common-anchor-header">ê¸°ì¡´ ì„ë² ë”© ë°©ë²•ê³¼ì˜ ë¹„êµ</h3><p>í›„ê¸° ì²­í‚¹ì˜ ì¥ì ì„ ë” ìì„¸íˆ ì„¤ëª…í•˜ê¸° ìœ„í•´ ìƒ˜í”Œ ë¬¸ì„œì™€ ì¿¼ë¦¬ ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ì„ë² ë”© ë°©ì‹ê³¼ë„ ë¹„êµí–ˆìŠµë‹ˆë‹¤.</p>
<p>ê·¸ë¦¬ê³  Milvus 2.4.13 ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ ì˜ˆì‹œë¥¼ ë‹¤ì‹œ ì‚´í´ë´…ì‹œë‹¤:</p>
<pre><code translate="no"><span class="hljs-title class_">Milvus</span> <span class="hljs-number">2.4</span><span class="hljs-number">.13</span> introduces dynamic replica load, allowing users to adjust the number <span class="hljs-keyword">of</span> collection replicas without needing to release and reload the collection. <span class="hljs-title class_">This</span> version also addresses several critical bugs related to bulk importing, expression parsing, load balancing, and failure recovery. <span class="hljs-title class_">Additionally</span>, significant improvements have been made to <span class="hljs-variable constant_">MMAP</span> resource usage and <span class="hljs-keyword">import</span> performance, enhancing overall system efficiency. <span class="hljs-title class_">We</span> highly recommend upgrading to <span class="hljs-variable language_">this</span> release <span class="hljs-keyword">for</span> better performance and stability.
<button class="copy-code-btn"></button></code></pre>
<p>ì¿¼ë¦¬ ì„ë² ë”©("milvus 2.4.13")ê³¼ ê° ì²­í¬ ê°„ì˜ <a href="https://zilliz.com/blog/similarity-metrics-for-vector-search#Cosine-Similarity">ì½”ì‚¬ì¸ ìœ ì‚¬ì„±ì„</a> ì¸¡ì •í•©ë‹ˆë‹¤:</p>
<pre><code translate="no">cos_sim = <span class="hljs-keyword">lambda</span> x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))

milvus_embedding = model.encode(<span class="hljs-string">&#x27;milvus 2.4.13&#x27;</span>)

<span class="hljs-keyword">for</span> chunk, late_chunking_embedding, traditional_embedding <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(chunks, chunk_embeddings, embeddings_traditional_chunking):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;similarity_late_chunking(&quot;milvus 2.4.13&quot;, &quot;<span class="hljs-subst">{chunk}</span>&quot;)&#x27;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;late_chunking: &#x27;</span>, cos_sim(milvus_embedding, late_chunking_embedding))
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;similarity_traditional(&quot;milvus 2.4.13&quot;, &quot;<span class="hljs-subst">{chunk}</span>&quot;)&#x27;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;traditional_chunking: &#x27;</span>, cos_sim(milvus_embedding, traditional_embeddings))
<button class="copy-code-btn"></button></code></pre>
<p>í›„ê¸° ì²­í‚¹ì€ ëª¨ë“  ì²­í¬ì—ì„œ ë” ë†’ì€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚°ì¶œí•˜ì—¬ ê¸°ì¡´ ì²­í‚¹ë³´ë‹¤ ì¼ê´€ë˜ê²Œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ì „ì²´ ë¬¸ì„œë¥¼ ë¨¼ì € ì„ë² ë“œí•˜ëŠ” ê²ƒì´ ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë” íš¨ê³¼ì ìœ¼ë¡œ ë³´ì¡´í•œë‹¤ëŠ” ê²ƒì„ í™•ì¸ì‹œì¼œ ì¤ë‹ˆë‹¤.</p>
<pre><code translate="no"><span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Milvus 2.4.13 introduces dynamic replica load, allowing users to adjust the number of collection replicas without needing to release and reload the collection.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.8785206</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Milvus 2.4.13 introduces dynamic replica load, allowing users to adjust the number of collection replicas without needing to release and reload the collection.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.8354263</span>

<span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;This version also addresses several critical bugs related to bulk importing, expression parsing, load balancing, and failure recovery.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.84828955</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;This version also addresses several critical bugs related to bulk importing, expression parsing, load balancing, and failure recovery.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.7222632</span>

<span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Additionally, significant improvements have been made to MMAP resource usage and import performance, enhancing overall system efficiency.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.84942204</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Additionally, significant improvements have been made to MMAP resource usage and import performance, enhancing overall system efficiency.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.6907381</span>

<span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;We highly recommend upgrading to this release for better performance and stability.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.85431844</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;We highly recommend upgrading to this release for better performance and stability.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.71859795</span>
<button class="copy-code-btn"></button></code></pre>
<p>ì „ì²´ ë‹¨ë½ì„ ë¨¼ì € ì„ë² ë“œí•˜ë©´ ê° ì²­í¬ì— "<code translate="no">Milvus 2.4.13</code>" ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¥¸ ìœ ì‚¬ì„± ì ìˆ˜ì™€ ê²€ìƒ‰ í’ˆì§ˆì´ í–¥ìƒëœë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<h3 id="Testing-Late-Chunking-in-Milvus" class="common-anchor-header"><strong>Milvusì—ì„œ í›„ê¸° ì²­í¬ ì„ë² ë”© í…ŒìŠ¤íŠ¸í•˜ê¸°</strong></h3><p>ì²­í¬ ì„ë² ë”©ì´ ìƒì„±ë˜ë©´ Milvusì— ì €ì¥í•˜ê³  ì¿¼ë¦¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì½”ë“œëŠ” ì²­í¬ ë²¡í„°ë¥¼ ì»¬ë ‰ì…˜ì— ì‚½ì…í•©ë‹ˆë‹¤.</p>
<h4 id="Importing-Embeddings-into-Milvus" class="common-anchor-header"><strong>Milvusë¡œ ì„ë² ë”© ê°€ì ¸ì˜¤ê¸°</strong></h4><pre><code translate="no">batch_data=[]
<span class="hljs-keyword">for</span> i in <span class="hljs-keyword">range</span>(<span class="hljs-built_in">len</span>(chunks)):
    data = {
            <span class="hljs-string">&quot;content&quot;</span>: chunks[i],
            <span class="hljs-string">&quot;embedding&quot;</span>: chunk_embeddings[i].tolist(),
        }

    batch_data.<span class="hljs-built_in">append</span>(data)

res = client.insert(
    collection_name=collection,
    data=batch_data,
)
<button class="copy-code-btn"></button></code></pre>
<h4 id="Querying-and-Validation" class="common-anchor-header">ì¿¼ë¦¬ ë° ìœ íš¨ì„± ê²€ì‚¬</h4><p>Milvus ì¿¼ë¦¬ì˜ ì •í™•ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê³„ì‚°í•œ ë¬´ì°¨ë³„ ì½”ì‚¬ì¸ ìœ ì‚¬ì„± ì ìˆ˜ì™€ ë¹„êµí•©ë‹ˆë‹¤. ë‘ ë°©ë²• ëª¨ë‘ ì¼ê´€ëœ ìƒìœ„ k ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ë©´ Milvusì˜ ê²€ìƒ‰ ì •í™•ë„ê°€ ì‹ ë¢°í•  ìˆ˜ ìˆë‹¤ê³  í™•ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p>Milvusì˜ ê¸°ë³¸ ê²€ìƒ‰ì„ ë¬´ì°¨ë³„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìŠ¤ìº”ê³¼ ë¹„êµí•©ë‹ˆë‹¤:</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">late_chunking_query_by_milvus</span>(<span class="hljs-params">query, top_k = <span class="hljs-number">3</span></span>):
    query_vector = model(**tokenizer(query, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)).last_hidden_state.mean(<span class="hljs-number">1</span>).detach().cpu().numpy().flatten()

    res = client.search(
                collection_name=collection,
                data=[query_vector.tolist()],
                limit=top_k,
                output_fields=[<span class="hljs-string">&quot;id&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>],
            )

    <span class="hljs-keyword">return</span> [item.get(<span class="hljs-string">&quot;entity&quot;</span>).get(<span class="hljs-string">&quot;content&quot;</span>) <span class="hljs-keyword">for</span> items <span class="hljs-keyword">in</span> res <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> items]

<span class="hljs-keyword">def</span> <span class="hljs-title function_">late_chunking_query_by_cosine_sim</span>(<span class="hljs-params">query, k = <span class="hljs-number">3</span></span>):
    cos_sim = <span class="hljs-keyword">lambda</span> x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))
    query_vector = model(**tokenizer(query, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)).last_hidden_state.mean(<span class="hljs-number">1</span>).detach().cpu().numpy().flatten()

    results = np.empty(<span class="hljs-built_in">len</span>(chunk_embeddings))
    <span class="hljs-keyword">for</span> i, (chunk, embedding) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(chunks, chunk_embeddings)):
        results[i] = cos_sim(query_vector, embedding)

    results_order = results.argsort()[::-<span class="hljs-number">1</span>]
    <span class="hljs-keyword">return</span> np.array(chunks)[results_order].tolist()[:k]
<button class="copy-code-btn"></button></code></pre>
<p>ì´ë¥¼ í†µí•´ Milvusê°€ ìˆ˜ë™ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìŠ¤ìº”ê³¼ ë™ì¼í•œ ìƒìœ„ k ì²­í¬ë¥¼ ë°˜í™˜í•œë‹¤ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.</p>
<pre><code translate="no">&gt; late_chunking_query_by_milvus(<span class="hljs-string">&quot;What are new features in milvus 2.4.13&quot;</span>, 3)

[<span class="hljs-string">&#x27;\n\n### Features\n\n- Dynamic replica adjustment for loaded collections ([#36417](https://github.com/milvus-io/milvus/pull/36417))\n- Sparse vector MMAP in growing segment types ([#36565](https://github.com/milvus-io/milvus/pull/36565))...
</span><button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">&gt; late_chunking_query_by_cosine_sim(<span class="hljs-string">&quot;What are new features in milvus 2.4.13&quot;</span>, 3)

[<span class="hljs-string">&#x27;\n\n### Features\n\n- Dynamic replica adjustment for loaded collections ([#36417](https://github.com/milvus-io/milvus/pull/36417))\n- Sparse vector MMAP in growing segment types (#36565)...
</span><button class="copy-code-btn"></button></code></pre>
<p>ë”°ë¼ì„œ ë‘ ë°©ë²• ëª¨ë‘ ë™ì¼í•œ ìƒìœ„ 3ê°œ ì²­í¬ë¥¼ ì‚°ì¶œí•˜ì—¬ Milvusì˜ ì •í™•ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤.</p>
<h2 id="Conclusion" class="common-anchor-header">ê²°ë¡ <button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>ì´ ê¸€ì—ì„œëŠ” í›„ê¸° ì²­í‚¹ì˜ ë©”ì»¤ë‹ˆì¦˜ê³¼ ì´ì ì— ëŒ€í•´ ìì„¸íˆ ì‚´í´ë´¤ìŠµë‹ˆë‹¤. íŠ¹íˆ ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ì´ ì¤‘ìš”í•œ ê¸´ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ë•Œ ê¸°ì¡´ ì²­í‚¹ ì ‘ê·¼ ë°©ì‹ì˜ ë‹¨ì ì„ íŒŒì•…í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ì˜ë¯¸ ìˆëŠ” ë©ì–´ë¦¬ë¡œ ìë¥´ê¸° ì „ì— ì „ì²´ ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ëŠ” í›„ê¸° ì²­í‚¹ì˜ ê°œë…ì„ ì†Œê°œí•˜ê³ , ì´ë¥¼ í†µí•´ ì–´ë–»ê²Œ ì „ì²´ ë¬¸ë§¥ì´ ë³´ì¡´ë˜ì–´ ì˜ë¯¸ì  ìœ ì‚¬ì„±ê³¼ ê²€ìƒ‰ ì •í™•ë„ê°€ í–¥ìƒë˜ëŠ”ì§€ ë³´ì—¬ë“œë ¸ìŠµë‹ˆë‹¤.</p>
<p>ê·¸ëŸ° ë‹¤ìŒ Jina AIì˜ jina-embeddings-v2-base-en ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‹¤ìŠµ êµ¬í˜„ì„ ì‚´í´ë³´ê³  ê¸°ì¡´ ë°©ì‹ê³¼ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥í•˜ê³  ì •í™•í•œ ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•´ ì²­í¬ ì„ë² ë”©ì„ Milvusì— í†µí•©í•˜ëŠ” ë°©ë²•ì„ ì‹œì—°í–ˆìŠµë‹ˆë‹¤.</p>
<p>í›„ê¸° ì²­í‚¹ì€ ë¬¸ë§¥ì´ ê°€ì¥ ì¤‘ìš”í•œ ê¸¸ê³  ë³µì¡í•œ ë¬¸ì„œì— ì í•©í•œ ë¬¸ë§¥ <strong>ìš°ì„ </strong> ì„ë² ë”© ì ‘ê·¼ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤. ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë¯¸ë¦¬ ì„ë² ë”©í•˜ê³  ë‚˜ì¤‘ì— ìŠ¬ë¼ì´ì‹±í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì´ì ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>
<ul>
<li><p><strong>Ô ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ</strong></p></li>
<li><p>âš¡ <strong>ê°„ê²°í•˜ê³  ì§‘ì¤‘ì ì¸ LLM í”„ë¡¬í”„íŠ¸</strong></p></li>
<li><p>ğŸ› ï¸ ëª¨ë“  ê¸´ ì»¨í…ìŠ¤íŠ¸ ëª¨ë¸ê³¼ì˜ <strong>ê°„ë‹¨í•œ í†µí•©</strong> </p></li>
</ul>
