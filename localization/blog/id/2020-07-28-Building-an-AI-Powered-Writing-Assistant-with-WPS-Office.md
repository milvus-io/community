---
id: Building-an-AI-Powered-Writing-Assistant-with-WPS-Office.md
title: Membangun Asisten Penulisan Bertenaga AI untuk Kantor WPS
author: milvus
date: 2020-07-28T03:35:40.105Z
desc: >-
  Pelajari bagaimana Kingsoft memanfaatkan Milvus, mesin pencari kemiripan
  sumber terbuka, untuk membangun mesin rekomendasi bagi asisten penulisan
  bertenaga AI WPS Office.
cover: assets.zilliz.com/wps_thumbnail_6cb7876963.jpg
tag: Scenarios
canonicalUrl: >-
  https://zilliz.com/blog/Building-an-AI-Powered-Writing-Assistant-with-WPS-Office
---
<custom-h1>Membangun Asisten Penulisan Bertenaga AI untuk WPS Office</custom-h1><p>WPS Office adalah alat produktivitas yang dikembangkan oleh Kingsoft dengan lebih dari 150 juta pengguna di seluruh dunia. Departemen kecerdasan buatan (AI) perusahaan ini membangun asisten penulisan cerdas dari awal menggunakan algoritma pencocokan semantik seperti pengenalan maksud dan pengelompokan teks. Alat ini tersedia dalam bentuk aplikasi web dan <a href="https://walkthechat.com/wechat-mini-programs-simple-introduction/">program mini WeChat</a> yang membantu pengguna dengan cepat membuat garis besar, paragraf individual, dan seluruh dokumen hanya dengan memasukkan judul dan memilih hingga lima kata kunci.</p>
<p>Mesin rekomendasi asisten penulis menggunakan Milvus, sebuah mesin pencari kemiripan sumber terbuka, untuk menggerakkan modul pemrosesan vektor intinya. Di bawah ini kita akan menjelajahi proses pembuatan asisten penulisan pintar WPS Offices, termasuk bagaimana fitur diekstraksi dari data yang tidak terstruktur serta peran yang dimainkan Milvus dalam menyimpan data dan memberi daya pada mesin rekomendasi alat ini.</p>
<p>Langsung ke:</p>
<ul>
<li><a href="#building-an-ai-powered-writing-assistant-for-wps-office">Membangun Asisten Penulisan Bertenaga AI untuk WPS Office</a><ul>
<li><a href="#making-sense-of-unstructured-textual-data">Memahami data tekstual yang tidak terstruktur</a></li>
<li><a href="#using-the-tfidf-model-to-maximize-feature-extraction">Menggunakan model TFIDF untuk memaksimalkan ekstraksi fitur</a></li>
<li><a href="#extracting-features-with-the-bi-directional-lstm-cnns-crf-deep-learning-model">Mengekstraksi fitur dengan model pembelajaran mendalam LSTM-CNNs-CRF dua arah</a></li>
<li><a href="#creating-sentence-embeddings-using-infersent">Membuat sematan kalimat menggunakan Infersent</a></li>
<li><a href="#storing-and-querying-vectors-with-milvus">Menyimpan dan menanyakan vektor dengan Milvus</a></li>
<li><a href="#ai-isnt-replacing-writers-its-helping-them-write">AI tidak menggantikan penulis, tetapi membantu mereka menulis</a></li>
</ul></li>
</ul>
<h3 id="Making-sense-of-unstructured-textual-data" class="common-anchor-header">Memahami data tekstual yang tidak terstruktur</h3><p>Sama seperti masalah modern lainnya yang perlu dipecahkan, membangun asisten penulisan WPS dimulai dengan data yang berantakan. Puluhan juta dokumen teks yang padat yang darinya fitur-fitur yang bermakna harus diekstraksi, untuk lebih tepatnya. Untuk memahami kompleksitas masalah ini, pertimbangkan bagaimana dua jurnalis dari outlet berita yang berbeda dapat melaporkan topik yang sama.</p>
<p>Meskipun keduanya akan mematuhi aturan, prinsip, dan proses yang mengatur struktur kalimat, mereka akan membuat pilihan kata yang berbeda, membuat kalimat dengan panjang yang berbeda-beda, dan menggunakan struktur artikel mereka sendiri untuk menceritakan kisah yang serupa (atau mungkin berbeda). Tidak seperti kumpulan data terstruktur dengan jumlah dimensi yang tetap, badan teks pada dasarnya tidak memiliki struktur karena sintaksis yang mengaturnya sangat mudah dibentuk. Untuk menemukan makna, fitur yang dapat dibaca oleh mesin harus diekstraksi dari kumpulan dokumen yang tidak terstruktur. Namun pertama-tama, data harus dibersihkan.</p>
<p>Ada berbagai cara untuk membersihkan data tekstual, yang tidak akan dibahas dalam artikel ini secara mendalam. Meskipun demikian, ini adalah langkah penting yang mendahului pemrosesan data, dan dapat mencakup menghapus tag, menghapus karakter beraksen, memperluas kontraksi, menghapus karakter khusus, menghapus kata henti, dan banyak lagi. Penjelasan rinci tentang metode untuk pra-pemrosesan dan pembersihan data teks dapat ditemukan <a href="https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41">di sini</a>.</p>
<h3 id="Using-the-TFIDF-model-to-maximize-feature-extraction" class="common-anchor-header">Menggunakan model TFIDF untuk memaksimalkan ekstraksi fitur</h3><p>Untuk mulai memahami data tekstual yang tidak terstruktur, model frekuensi dokumen terbalik (TFIDF) diterapkan pada korpus yang diambil oleh asisten penulisan WPS. Model ini menggunakan kombinasi dari dua metrik, yaitu term frequency dan inverse document frequency, untuk memberikan nilai TFIDF pada setiap kata di dalam dokumen. Term frequency (TF) mewakili jumlah mentah sebuah istilah dalam dokumen dibagi dengan jumlah total istilah dalam dokumen, sedangkan inverse document frequency (IDF) adalah jumlah dokumen dalam korpus dibagi dengan jumlah dokumen di mana sebuah istilah muncul.</p>
<p>Hasil perkalian antara TF dan IDF memberikan ukuran seberapa sering sebuah istilah muncul dalam dokumen dikalikan dengan seberapa unik kata tersebut di dalam korpus. Pada akhirnya, nilai TFIDF adalah ukuran seberapa relevan sebuah kata dengan sebuah dokumen dalam kumpulan dokumen. Istilah diurutkan berdasarkan nilai TFIDF, dan istilah yang memiliki nilai rendah (misalnya kata-kata umum) dapat diberi bobot yang lebih rendah ketika menggunakan deep learning untuk mengekstrak fitur dari korpus.</p>
<h3 id="Extracting-features-with-the-bi-directional-LSTM-CNNs-CRF-deep-learning-model" class="common-anchor-header">Mengekstrak fitur dengan model pembelajaran mendalam LSTM-CNNs-CRF dua arah</h3><p>Dengan menggunakan kombinasi memori jangka pendek dua arah (BLSTM), jaringan syaraf tiruan (CNN), dan medan acak bersyarat (CRF), representasi tingkat kata dan karakter dapat diekstraksi dari korpus. <a href="https://arxiv.org/pdf/1603.01354.pdf">Model BLSTM-CNNs-CRF</a> yang digunakan untuk membangun asisten penulisan WPS Office adalah sebagai berikut:</p>
<ol>
<li><strong>CNN:</strong> Penyematan karakter digunakan sebagai input ke CNN, kemudian struktur kata yang relevan secara semantik (yaitu awalan atau akhiran) diekstraksi dan dikodekan ke dalam vektor representasi tingkat karakter.</li>
<li><strong>BLSTM:</strong> Vektor tingkat karakter digabungkan dengan vektor penyisipan kata, kemudian dimasukkan ke dalam jaringan BLSTM. Setiap urutan disajikan maju dan mundur ke dua keadaan tersembunyi yang terpisah untuk menangkap informasi masa lalu dan masa depan.</li>
<li><strong>CRF:</strong> Vektor keluaran dari BLSTM dimasukkan ke lapisan CRF untuk bersama-sama memecahkan kode urutan label terbaik.</li>
</ol>
<p>Jaringan syaraf sekarang mampu mengekstraksi dan mengklasifikasikan entitas bernama dari teks yang tidak terstruktur. Proses ini disebut <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">pengenalan entitas bernama (NER)</a> dan melibatkan pencarian dan klasifikasi kategori seperti nama orang, institusi, lokasi geografis, dan banyak lagi. Entitas-entitas ini memainkan peran penting dalam menyortir dan mengingat data. Dari sini, kalimat-kalimat kunci, paragraf, dan ringkasan dapat diekstraksi dari korpus.</p>
<h3 id="Creating-sentence-embeddings-using-Infersent" class="common-anchor-header">Membuat sematan kalimat menggunakan Infersent</h3><p><a href="https://github.com/facebookresearch/InferSent">Infersent</a>, sebuah metode penyematan kalimat terawasi yang dirancang oleh Facebook yang menyematkan kalimat lengkap ke dalam ruang vektor, digunakan untuk membuat vektor yang akan dimasukkan ke dalam basis data Milvus. Infersent dilatih menggunakan korpus Stanford Natural Language Inference (SNLI), yang berisi 570 ribu pasangan kalimat yang ditulis dan dilabeli oleh manusia. Informasi tambahan tentang cara kerja Infersent dapat ditemukan <a href="https://medium.com/analytics-vidhya/sentence-embeddings-facebooks-infersent-6ac4a9fc2001">di sini</a>.</p>
<h3 id="Storing-and-querying-vectors-with-Milvus" class="common-anchor-header">Menyimpan dan menanyakan vektor dengan Milvus</h3><p><a href="https://www.milvus.io/">Milvus</a> adalah mesin pencari kemiripan sumber terbuka yang mendukung penambahan, penghapusan, pembaruan, dan pencarian sematan hampir seketika dalam skala triliunan byte. Untuk meningkatkan kinerja kueri, Milvus memungkinkan jenis indeks ditentukan untuk setiap bidang vektor. Asisten pintar WPS Office menggunakan indeks IVF_FLAT, jenis indeks Inverted File (IVF) yang paling dasar di mana "flat" berarti vektor disimpan tanpa kompresi atau kuantisasi. Pengelompokan didasarkan pada IndexFlat2, yang menggunakan pencarian yang tepat untuk jarak L2.</p>
<p>Meskipun IVF_FLAT memiliki tingkat penarikan kueri 100%, kurangnya kompresi menghasilkan kecepatan kueri yang relatif lambat. <a href="https://milvus.io/docs/manage-partitions.md">Fungsi partisi</a> Milvus digunakan untuk membagi data ke dalam beberapa bagian penyimpanan fisik berdasarkan aturan yang telah ditetapkan, membuat kueri lebih cepat dan lebih akurat. Ketika vektor ditambahkan ke Milvus, tag menentukan ke partisi mana data harus ditambahkan. Kueri data vektor menggunakan tag untuk menentukan pada partisi mana kueri harus dijalankan. Data dapat dipecah lebih lanjut menjadi beberapa segmen di dalam setiap partisi untuk lebih meningkatkan kecepatan.</p>
<p>Asisten penulis cerdas juga menggunakan cluster Kubernetes, yang memungkinkan kontainer aplikasi berjalan di berbagai mesin dan lingkungan, serta MySQL untuk manajemen metadata.</p>
<h3 id="AI-isn’t-replacing-writers-it’s-helping-them-write" class="common-anchor-header">AI tidak menggantikan penulis, melainkan membantu mereka menulis</h3><p>Asisten penulisan Kingsoft untuk WPS Office mengandalkan Milvus untuk mengelola dan meminta database lebih dari 2 juta dokumen. Sistem ini sangat fleksibel, mampu menjalankan pencarian hampir seketika pada kumpulan data berskala triliunan. Kueri selesai dalam rata-rata 0,2 detik, yang berarti seluruh dokumen dapat dihasilkan hampir seketika hanya dengan menggunakan judul atau beberapa kata kunci. Meskipun AI tidak menggantikan penulis profesional, teknologi yang ada saat ini mampu meningkatkan proses penulisan dengan cara yang baru dan menarik. Masa depan memang tidak diketahui, tetapi setidaknya penulis dapat menantikan metode yang lebih produktif, dan untuk beberapa metode yang tidak terlalu sulit dalam "menuangkan pena ke atas kertas."</p>
<p>Sumber-sumber berikut ini digunakan untuk artikel ini:</p>
<ul>
<li>"<a href="https://arxiv.org/pdf/1603.01354.pdf">Pelabelan Urutan End-to-end melalui LSTM-CNNs-CRF dua arah</a>," Xuezhe Ma dan Eduard Hovy.</li>
<li>"<a href="https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41">Metode Tradisional untuk Data Teks</a>," Dipanjan (DJ) Sarkar.</li>
<li>"<a href="https://ieeexplore.ieee.org/document/8780663">Ekstraksi Fitur Teks berdasarkan TF-IDF Associating Semantic</a>," Qing Liu, Jing Wang, Dehai Zhang, Yun Yang, NaiYao Wang.</li>
<li>"<a href="https://medium.com/analytics-vidhya/sentence-embeddings-facebooks-infersent-6ac4a9fc2001">Memahami Penyisipan Kalimat menggunakan Infersent Facebook</a>," Rehan Ahmad</li>
<li>"<a href="https://arxiv.org/pdf/1705.02364.pdf">Pembelajaran Terawasi Representasi Kalimat Universal dari Data Inferensi Bahasa Alami</a>," Alexis Conneau, Douwe Kiela, Holger Schwenk, LoÏc Barrault, Antoine Bordes.V1</li>
</ul>
<p>Baca <a href="https://zilliz.com/user-stories">cerita pengguna</a> lain untuk mempelajari lebih lanjut tentang membuat sesuatu dengan Milvus.</p>
