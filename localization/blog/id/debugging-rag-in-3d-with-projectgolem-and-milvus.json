{"codeList":["Download docker-compose.yml\nwget https://github.com/milvus-io/milvus/releases/download/v2.6.8/milvus-standalone-docker-compose.yml -O docker-compose.yml\nStart MilvusÔºàverify port mappingÔºö19530:19530Ôºâ\ndocker-compose up -d\nVerify that the services are running\ndocker ps | grep milvus\nYou should see three containersÔºömilvus-standalone, milvus-etcd, milvus-minio\n","from pymilvus import MilvusClient\nfrom pymilvus.milvus_client.index import IndexParams\nfrom openai import OpenAI\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nimport umap\nfrom sklearn.neighbors import NearestNeighbors\nimport json\nimport numpy as np\nimport os\nimport glob\n--- CONFIG ---\nMILVUS_URI = \"http://localhost:19530\"\nCOLLECTION_NAME = \"golem_memories\"\nJSON_OUTPUT_PATH = \"./golem_cortex.json\"\nData directory (users place .md files in this folder)\nDATA_DIR = \"./data\"\nOpenAI Embedding Config\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nOPENAI_BASE_URL = \"https://api.openai.com/v1\"  #\nOPENAI_EMBEDDING_MODEL = \"text-embedding-3-small\"\n1536 dimensions\nEMBEDDING_DIM = 1536\nColor mapping: colors are assigned automatically and reused in a round-robin manner\nCOLORS = [\n[0.29, 0.87, 0.50],\nGreen\n[0.22, 0.74, 0.97],\nBlue\n[0.60, 0.20, 0.80],\nPurple\n[0.94, 0.94, 0.20],\nGold\n[0.98, 0.55, 0.00],\nOrange\n[0.90, 0.30, 0.40],\nRed\n[0.40, 0.90, 0.90],\nCyan\n[0.95, 0.50, 0.90],\nMagenta\n]\ndef get_embeddings(texts):\n\"\"\"Batch embedding using OpenAI API\"\"\"\nclient = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)\nembeddings = []\nbatch_size = 100\nOpenAI allows multiple texts per request\nfor i in range(0, len(texts), batch_size):\nbatch = texts[i:i + batch_size]\nresponse = client.embeddings.create(\nmodel=OPENAI_EMBEDDING_MODEL,\ninput=batch\n)\nembeddings.extend([item.embedding for item in response.data])\nprint(f\"   ‚Ü≥ Embedded {min(i + batch_size, len(texts))}/{len(texts)}...\")\nreturn np.array(embeddings)\ndef load_markdown_files(data_dir):\n\"\"\"Load all markdown files from the data directory\"\"\"\nmd_files = glob.glob(os.path.join(data_dir, \"**/*.md\"), recursive=True)\nif not md_files:\nprint(f\"   ‚ùå ERROR: No .md files found in '{data_dir}'\")\nprint(f\"   üëâ Create a '{data_dir}' folder and put your markdown files there.\")\nprint(f\"   üëâ Example: {data_dir}/doc1.md, {data_dir}/docs/doc2.md\")\nreturn None\ndocs = []\nprint(f\"\\nüìö FOUND {len(md_files)} MARKDOWN FILES:\")\nfor i, file_path in enumerate(md_files):\nfilename = os.path.basename(file_path)\nCategories are derived from the file‚Äôs path relative to data_dir\nrel_path = os.path.relpath(file_path, data_dir)\ncategory = os.path.dirname(rel_path) if os.path.dirname(rel_path) else \"default\"\nwith open(file_path, 'r', encoding='utf-8') as f:\ncontent = f.read()\ndocs.append({\n\"title\": filename,\n\"text\": content,\n\"cat\": category,\n\"path\": file_path\n})\nprint(f\"   {i+1}. [{category}] {filename}\")\nreturn docs\ndef ingest_dense():\nprint(f\"üß† PROJECT GOLEM - NEURAL MEMORY BUILDER\")\nprint(f\"=\" * 50)\nif not OPENAI_API_KEY:\nprint(\"   ‚ùå ERROR: OPENAI_API_KEY environment variable not set!\")\nprint(\"   üëâ Run: export OPENAI_API_KEY='your-key-here'\")\nreturn\nprint(f\"   ‚Ü≥ Using OpenAI Embedding: {OPENAI_EMBEDDING_MODEL}\")\nprint(f\"   ‚Ü≥ Embedding Dimension: {EMBEDDING_DIM}\")\nprint(f\"   ‚Ü≥ Data Directory: {DATA_DIR}\")\n1. Load local markdown files\ndocs = load_markdown_files(DATA_DIR)\nif docs is None:\nreturn\n2. Split documents into chunks\nprint(f\"\\nüì¶ PROCESSING DOCUMENTS...\")\nsplitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)\nchunks = []\nraw_texts = []\ncolors = []\nchunk_titles = []\ncategories = []\nfor doc in docs:\ndoc_chunks = splitter.create_documents([doc['text']])\ncat_index = hash(doc['cat']) % len(COLORS)\nfor i, chunk in enumerate(doc_chunks):\nchunks.append({\n\"text\": chunk.page_content,\n\"title\": doc['title'],\n\"cat\": doc['cat']\n})\nraw_texts.append(chunk.page_content)\ncolors.append(COLORS[cat_index])\nchunk_titles.append(f\"{doc['title']} (chunk {i+1})\")\ncategories.append(doc['cat'])\nprint(f\"   ‚Ü≥ Created {len(chunks)} text chunks from {len(docs)} documents\")\n3. Generate embeddings\nprint(f\"\\nüîÆ GENERATING EMBEDDINGS...\")\nvectors = get_embeddings(raw_texts)\n4. 3D Projection (UMAP)\nprint(\"\\nüé® CALCULATING 3D MANIFOLD...\")\nreducer = umap.UMAP(n_components=3, n_neighbors=30, min_dist=0.1, metric='cosine')\nembeddings_3d = reducer.fit_transform(vectors)\n5. Wiring (KNN)\nprint(\"   ‚Ü≥ Wiring Synapses (finding connections)...\")\nnbrs = NearestNeighbors(n_neighbors=8, metric='cosine').fit(vectors)\ndistances, indices = nbrs.kneighbors(vectors)\n6. Prepare output data\ncortex_data = []\nmilvus_data = []\nfor i in range(len(chunks)):\ncortex_data.append({\n\"id\": i,\n\"title\": chunk_titles[i],\n\"cat\": categories[i],\n\"pos\": embeddings_3d[i].tolist(),\n\"col\": colors[i],\n\"nbs\": indices[i][1:].tolist()\n})\nmilvus_data.append({\n\"id\": i,\n\"text\": chunks[i]['text'],\n\"title\": chunk_titles[i],\n\"category\": categories[i],\n\"vector\": vectors[i].tolist()\n})\nwith open(JSON_OUTPUT_PATH, 'w') as f:\njson.dump(cortex_data, f)\n7. Store vectors in Milvus\nprint(\"\\nüíæ STORING IN MILVUS...\")\nclient = MilvusClient(uri=MILVUS_URI)\nDrop existing collection if it exists\nif client.has_collection(COLLECTION_NAME):\nprint(f\"   ‚Ü≥ Dropping existing collection '{COLLECTION_NAME}'...\")\nclient.drop_collection(COLLECTION_NAME)\nCreate new collection\nprint(f\"   ‚Ü≥ Creating collection '{COLLECTION_NAME}' (dim={EMBEDDING_DIM})...\")\nclient.create_collection(\ncollection_name=COLLECTION_NAME,\ndimension=EMBEDDING_DIM\n)\nInsert data\nprint(f\"   ‚Ü≥ Inserting {len(milvus_data)} vectors...\")\nclient.insert(\ncollection_name=COLLECTION_NAME,\ndata=milvus_data\n)\nCreate index for faster search\nprint(\"   ‚Ü≥ Creating index...\")\nindex_params = IndexParams()\nindex_params.add_index(\nfield_name=\"vector\",\nindex_type=\"AUTOINDEX\",\nmetric_type=\"COSINE\"\n)\nclient.create_index(\ncollection_name=COLLECTION_NAME,\nindex_params=index_params\n)\nprint(f\"\\n‚úÖ CORTEX GENERATED SUCCESSFULLY!\")\nprint(f\"   üìä {len(chunks)} memory nodes stored in Milvus\")\nprint(f\"   üìÅ Cortex data saved to: {JSON_OUTPUT_PATH}\")\nprint(f\"   üöÄ Run 'python GolemServer.py' to start the server\")\nif __name__ == \"__main__\":\ningest_dense()\n","from flask import Flask, request, jsonify, send_from_directory\nfrom openai import OpenAI\nfrom pymilvus import MilvusClient\nimport json\nimport os\nimport sys\n--- CONFIG ---\nExplicitly set the folder to where this script is located\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nOpenAI Embedding Config\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nOPENAI_BASE_URL = \"https://api.openai.com/v1\"\nOPENAI_EMBEDDING_MODEL = \"text-embedding-3-small\"\nMilvus Config\nMILVUS_URI = \"http://localhost:19530\"\nCOLLECTION_NAME = \"golem_memories\"\nThese match the files generated by ingest.py\nJSON_FILE = \"golem_cortex.json\"\nUPDATED: Matches your new repo filename\nHTML_FILE = \"index.html\"\napp = Flask(__name__, static_folder=BASE_DIR)\nprint(f\"\\nüß† PROJECT GOLEM SERVER\")\nprint(f\"   üìÇ Serving from: {BASE_DIR}\")\n--- DIAGNOSTICS ---\nCheck if files exist before starting\nmissing_files = []\nif not os.path.exists(os.path.join(BASE_DIR, JSON_FILE)):\nmissing_files.append(JSON_FILE)\nif not os.path.exists(os.path.join(BASE_DIR, HTML_FILE)):\nmissing_files.append(HTML_FILE)\nif missing_files:\nprint(f\"   ‚ùå CRITICAL ERROR: Missing files in this folder:\")\nfor f in missing_files:\nprint(f\"      - {f}\")\nprint(\"   üëâ Did you run 'python ingest.py' successfully?\")\nsys.exit(1)\nelse:\nprint(f\"   ‚úÖ Files Verified: Cortex Map found.\")\nCheck API Key\nif not OPENAI_API_KEY:\nprint(f\"   ‚ùå CRITICAL ERROR: OPENAI_API_KEY environment variable not set!\")\nprint(\"   üëâ Run: export OPENAI_API_KEY='your-key-here'\")\nsys.exit(1)\nprint(f\"   ‚Ü≥ Using OpenAI Embedding: {OPENAI_EMBEDDING_MODEL}\")\nprint(\"   ‚Ü≥ Connecting to Milvus...\")\nmilvus_client = MilvusClient(uri=MILVUS_URI)\nVerify collection exists\nif not milvus_client.has_collection(COLLECTION_NAME):\nprint(f\"   ‚ùå CRITICAL ERROR: Collection '{COLLECTION_NAME}' not found in Milvus.\")\nprint(\"   üëâ Did you run 'python ingest.py' successfully?\")\nsys.exit(1)\nInitialize OpenAI client\nopenai_client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)\n--- ROUTES ---\n@app.route('/')\ndef root():\nForce serve the specific HTML file\nreturn send_from_directory(BASE_DIR, HTML_FILE)\n@app.route('/')\ndef serve_static(filename):\nreturn send_from_directory(BASE_DIR, filename)\n@app.route('/query', methods=['POST'])\ndef query_brain():\ndata = request.json\ntext = data.get('query', '')\nif not text: return jsonify({\"indices\": []})\nprint(f\"üîé Query: {text}\")\nGet query embedding from OpenAI\nresponse = openai_client.embeddings.create(\nmodel=OPENAI_EMBEDDING_MODEL,\ninput=text\n)\nquery_vec = response.data[0].embedding\nSearch in Milvus\nresults = milvus_client.search(\ncollection_name=COLLECTION_NAME,\ndata=[query_vec],\nlimit=50,\noutput_fields=[\"id\"]\n)\nExtract indices and scores\nindices = [r['id'] for r in results[0]]\nscores = [r['distance'] for r in results[0]]\nreturn jsonify({\n\"indices\": indices,\n\"scores\": scores\n})\nif __name__ == '__main__':\nprint(\"   ‚úÖ SYSTEM ONLINE: http://localhost:8000\")\napp.run(port=8000)\n","https://github.com/milvus-io/milvus-docs/tree/v2.6.x/site/en\n","python ingest.py\n","python GolemServer.py\n"],"headingContent":"","anchorList":[{"label":"Apa itu Project_Golem?","href":"What-Is-ProjectGolem","type":2,"isActive":false},{"label":"Mengapa Project_Golem Tidak Siap Produksi","href":"Why-ProjectGolem-Isnt-Production-Ready","type":2,"isActive":false},{"label":"Bagaimana Milvus Memberdayakan Lapisan Retrieval Project_Golem","href":"How-Milvus-Powers-ProjectGolem‚Äôs-Retrieval-Layer","type":2,"isActive":false},{"label":"Cara Menerapkan dan Menjelajahi Project_Golem dengan Milvus","href":"How-to-Deploy-and-Explore-ProjectGolem-with-Milvus","type":2,"isActive":false},{"label":"Kesimpulan","href":"Conclusion","type":2,"isActive":false}]}