{"codeList":["pip install vectordb-bench\n","pip install vectordb-bench[all]\n","pip install vectordb-bench[elastic]\n","init_bench\n","id,emb,label\n1,\"[0.12,0.56,0.89,...]\",A\n2,\"[0.33,0.48,0.90,...]\",B\n","import numpy as np\nvectors = np.random.rand(10000, 768).astype('float32')\nnp.save(\"vectors.npy\", vectors)\n","pip install numpy pandas faiss-cpu\n","python convert_to_vdb_format.py \\\n  --train data/train.csv \\\n  --test data/test.csv \\\n  --out datasets/custom \\\n  --topk 10\n","datasets/custom/\nâ”œâ”€â”€ train.parquet        # Training vectors\nâ”œâ”€â”€ test.parquet         # Query vectors  \nâ”œâ”€â”€ neighbors.parquet    # Ground Truth\nâ””â”€â”€ scalar_labels.parquet # Optional scalar labels\n","import os\nimport argparse\nimport numpy as np\nimport pandas as pd\nimport faiss\nfrom ast import literal_eval\nfrom typing import Optional\ndef load_csv(path: str):\n    df = pd.read_csv(path)\n    if 'emb' not in df.columns:\n        raise ValueError(f\"CSV file missing 'emb' column: {path}\")\n   df['emb'] = df['emb'].apply(literal_eval)\n    if 'id' not in df.columns:\n        df.insert(0, 'id', range(len(df)))\n    return df\ndef load_npy(path: str):\n    arr = np.load(path)\n    df = pd.DataFrame({\n        'id': range(arr.shape[0]),\n        'emb': arr.tolist()\n    })\n    return df\ndef load_vectors(path: str) -> pd.DataFrame:\n    if path.endswith('.csv'):\n        return load_csv(path)\n    elif path.endswith('.npy'):\n        return load_npy(path)\n    else:\n        raise ValueError(f\"Unsupported file format: {path}\")\ndef compute_ground_truth(train_vectors: np.ndarray, test_vectors: np.ndarray, top_k: int = 10):\n    dim = train_vectors.shape[1]\n    index = faiss.IndexFlatL2(dim)\n    index.add(train_vectors)\n    _, indices = index.search(test_vectors, top_k)\n    return indices\ndef save_ground_truth(df_path: str, indices: np.ndarray):\n    df = pd.DataFrame({\n        \"id\": np.arange(indices.shape[0]),\n        \"neighbors_id\": indices.tolist()\n    })\n    df.to_parquet(df_path, index=False)\n    print(f\"âœ… Ground truth saved successfully: {df_path}\")\ndef main(train_path: str, test_path: str, output_dir: str,\n         label_path: Optional[str] = None, top_k: int = 10):\n    os.makedirs(output_dir, exist_ok=True)\n    # Load training and query data\n    print(\"ğŸ“¥ Loading training data...\")\n    train_df = load_vectors(train_path)\n    print(\"ğŸ“¥ Loading query data...\")\n    test_df = load_vectors(test_path)\n    # Extract vectors and convert to numpy\n    train_vectors = np.array(train_df['emb'].to_list(), dtype='float32')\n    test_vectors = np.array(test_df['emb'].to_list(), dtype='float32')\n    # Save parquet files retaining all fields\n    train_df.to_parquet(os.path.join(output_dir, 'train.parquet'), index=False)\n    print(f\"âœ… train.parquet saved successfully, {len(train_df)} records total\")\n    test_df.to_parquet(os.path.join(output_dir, 'test.parquet'), index=False)\n    print(f\"âœ… test.parquet saved successfully, {len(test_df)} records total\")\n    # Compute ground truth\n    print(\"ğŸ” Computing Ground Truth (nearest neighbors)...\")\n    gt_indices = compute_ground_truth(train_vectors, test_vectors, top_k=top_k)\n    save_ground_truth(os.path.join(output_dir, 'neighbors.parquet'), gt_indices)\n    # Load and save label file (if provided)\n    if label_path:\n        print(\"ğŸ“¥ Loading label file...\")\n        label_df = pd.read_csv(label_path)\n        if 'labels' not in label_df.columns:\n            raise ValueError(\"Label file must contain 'labels' column\")\n        label_df['labels'] = label_df['labels'].apply(literal_eval)\n        label_df.to_parquet(os.path.join(output_dir, 'scalar_labels.parquet'), index=False)\n        print(\"âœ… Label file saved as scalar_labels.parquet\")\n\nif \nname\n == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Convert CSV/NPY vectors to VectorDBBench data format (retaining all columns)\")\n    parser.add_argument(\"--train\", required=True, help=\"Training data path (CSV or NPY)\")\n    parser.add_argument(\"--test\", required=True, help=\"Query data path (CSV or NPY)\")\n    parser.add_argument(\"--out\", required=True, help=\"Output directory\")\n    parser.add_argument(\"--labels\", help=\"Label CSV path (optional)\")\n    parser.add_argument(\"--topk\", type=int, default=10, help=\"Ground truth\")\n    args = parser.parse_args()\n    main(args.train, args.test, args.out, args.labels, args.topk)\n","import pandas as pd\nimport numpy as np\ndef generate_csv(num_records: int, dim: int, filename: str):\n    ids = range(num_records)\n    vectors = np.random.rand(num_records, dim).round(6) \n    emb_str = [str(list(vec)) for vec in vectors]\n    df = pd.DataFrame({\n        'id': ids,\n        'emb': emb_str\n    })\n    df.to_csv(filename, index=False)\n    print(f\"Generated file {filename}, {num_records} records total, vector dimension {dim}\")\nif\nname\n == \"__main__\":\n    num_records = 3000  # Number of records to generate\n    dim = 768  # Vector dimension\n\n    generate_csv(num_records, dim, \"train.csv\")\n    generate_csv(num_records, dim, \"test.csv\")\n"],"headingContent":"","anchorList":[{"label":"è§£å†³ä¹‹é“ï¼šç”¨ä½ çš„æ•°æ®æµ‹è¯•ï¼Œè€Œä¸æ˜¯ç…§æœ¬å®£ç§‘çš„åŸºå‡†æµ‹è¯•","href":"The-Fix-Test-with-Your-Data-Not-Canned-Benchmarks","type":2,"isActive":false},{"label":"å¦‚ä½•ä½¿ç”¨VDBBenchç”¨è‡ªå®šä¹‰æ•°æ®é›†è¯„ä¼°VectorDB","href":"How-to-Evaluate-VectorDBs-with-Your-Custom-Datasets-with-VDBBench","type":2,"isActive":false},{"label":"ç»“æœåˆ†æå’Œæ€§èƒ½è¯„ä¼°","href":"Results-Analysis-and-Performance-Evaluation","type":2,"isActive":false},{"label":"è¡¥å……å·¥å…·ï¼šæµ‹è¯•æ•°æ®ç”Ÿæˆ","href":"Supplemental-Tools-Test-Data-Generation","type":2,"isActive":false},{"label":"ç»“è®º","href":"Conclusion","type":2,"isActive":false}]}