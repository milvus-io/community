---
id: >-
  when-context-engineering-is-done-right-hallucinations-can-spark-ai-creativity.md
title: >-
  При правильном подходе к созданию контекста галлюцинации могут стать искрой
  творчества ИИ
author: James Luan
date: 2025-09-30T00:00:00.000Z
desc: >-
  Узнайте, почему галлюцинации ИИ - это не просто ошибки, а искры творчества, и
  как контекстная инженерия превращает их в надежные, реальные результаты.
cover: assets.zilliz.com/Chat_GPT_Image_Oct_1_2025_10_42_15_AM_101639b3bf.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database, AI Agents, Context Engineering'
meta_keywords: 'Milvus, vector database, AI Agents, Context Engineering'
meta_title: |
  If Context Engineering Done Right, Hallucinations Can Spark AI Creativity
origin: >-
  https://milvus.io/blog/when-context-engineering-is-done-right-hallucinations-can-spark-ai-creativity.md
---
<p>Долгое время многие из нас - и я в том числе - относились к галлюцинациям LLM не более чем к дефектам. Для их устранения была построена целая цепочка инструментов: системы поиска, ограждения, тонкая настройка и многое другое. Эти средства защиты по-прежнему ценны. Но чем больше я изучаю, как модели на самом деле генерируют ответы - и как системы вроде <a href="https://milvus.io/"><strong>Milvus</strong></a> вписываются в более широкие конвейеры ИИ, - тем меньше я верю, что галлюцинации - это просто неудачи. На самом деле, они могут быть искрой творчества ИИ.</p>
<p>Если мы посмотрим на человеческое творчество, то обнаружим ту же самую картину. Каждый прорыв основывается на скачках воображения. Но эти скачки никогда не возникают из ниоткуда. Поэты сначала осваивают ритм и метр, прежде чем нарушить правила. Ученые опираются на устоявшиеся теории, прежде чем отправиться на непроверенную территорию. Прогресс зависит от этих скачков, если они опираются на прочные знания и понимание.</p>
<p>LLM действуют примерно так же. Их так называемые "галлюцинации" или "скачки" - аналогии, ассоциации и экстраполяции - возникают в результате того же генеративного процесса, который позволяет моделям устанавливать связи, расширять знания и выводить идеи за пределы того, чему их явно обучали. Не каждый скачок оказывается успешным, но когда он происходит, результаты могут быть впечатляющими.</p>
<p>Именно поэтому я рассматриваю <strong>контекстную инженерию</strong> как важнейший следующий шаг. Вместо того чтобы пытаться устранить все галлюцинации, мы должны сосредоточиться на их <em>управлении</em>. Создавая правильный контекст, мы можем найти баланс, сохраняя модели достаточно изобретательными, чтобы исследовать новую почву, и в то же время гарантируя, что они остаются достаточно надежными, чтобы им можно было доверять.</p>
<h2 id="What-is-Context-Engineering" class="common-anchor-header">Что такое контекстная инженерия?<button data-href="#What-is-Context-Engineering" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Что же именно мы подразумеваем под <em>контекстной инженерией</em>? Термин может быть новым, но практика развивается уже много лет. Такие техники, как RAG, подсказки, вызов функций и MCP, являются ранними попытками решить одну и ту же проблему: предоставить моделям подходящее окружение для получения полезных результатов. Контекстная инженерия - это объединение этих подходов в целостную структуру.</p>
<h2 id="The-Three-Pillars-of-Context-Engineering" class="common-anchor-header">Три столпа контекстной инженерии<button data-href="#The-Three-Pillars-of-Context-Engineering" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Эффективный контекстный инжиниринг опирается на три взаимосвязанных слоя:</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/context_engineering_1_8f2b39c5e7.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="1-The-Instructions-Layer--Defining-Direction" class="common-anchor-header">1. Слой инструкций - определение направления</h3><p>Этот слой включает в себя подсказки, небольшие примеры и демонстрации. Это навигационная система модели: не просто расплывчатое "идите на север", а четкий маршрут с путевыми точками. Хорошо структурированные инструкции устанавливают границы, определяют цели и уменьшают двусмысленность поведения модели.</p>
<h3 id="2-The-Knowledge-Layer--Supplying-Ground-Truth" class="common-anchor-header">2. Слой знаний - обеспечение базовой истины</h3><p>Здесь мы размещаем факты, код, документы и данные, которые необходимы модели для эффективного рассуждения. Без этого слоя система импровизирует на основе неполной памяти. С ним модель может основывать свои выводы на данных, специфичных для конкретной области. Чем точнее и релевантнее знания, тем надежнее рассуждения.</p>
<h3 id="3-The-Tools-Layer--Enabling-Action-and-Feedback" class="common-anchor-header">3. Слой инструментов - обеспечение действий и обратной связи</h3><p>Этот слой охватывает API, вызовы функций и внешние интеграции. Именно он позволяет системе перейти от рассуждений к действиям - получению данных, выполнению вычислений или запуску рабочих процессов. Не менее важно, что эти инструменты обеспечивают обратную связь в режиме реального времени, которая может быть включена в рассуждения модели. Такая обратная связь позволяет корректировать, адаптировать и постоянно совершенствовать модель. На практике это то, что превращает LLM из пассивных респондентов в активных участников системы.</p>
<p>Эти слои не являются изолированными - они усиливают друг друга. Инструкции определяют цель, знания предоставляют информацию для работы, а инструменты превращают решения в действия и возвращают результаты в цикл. При правильной организации они создают среду, в которой модели могут быть как творческими, так и надежными.</p>
<h2 id="The-Long-Context-Challenges-When-More-Becomes-Less" class="common-anchor-header">Длинные контекстные вызовы: Когда больше становится меньше<button data-href="#The-Long-Context-Challenges-When-More-Becomes-Less" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Многие модели искусственного интеллекта сейчас рекламируют окна с миллионным контекстом - достаточно для ~75 000 строк кода или документа из 750 000 слов. Однако большее количество контекста не дает автоматически лучших результатов. На практике очень длинные контексты приводят к появлению различных режимов сбоя, которые могут ухудшить качество рассуждений и надежность.</p>
<h3 id="Context-Poisoning--When-Bad-Information-Spreads" class="common-anchor-header">Отравление контекста - когда распространяется плохая информация</h3><p>Как только ложная информация попадает в рабочий контекст - будь то цели, резюме или промежуточное состояние - это может свести на нет весь процесс рассуждения. Яркий пример - <a href="https://arxiv.org/pdf/2507.06261">отчет DeepMind Gemini 2.5</a>. Агент LLM, играющий в Pokémon, неправильно прочитал состояние игры и решил, что его задача - "поймать непойманного легендарного". Эта неверная цель была записана как факт, что привело агента к созданию сложных, но невозможных стратегий.</p>
<p>Как показано в приведенном ниже отрывке, отравленный контекст завел модель в петлю - она повторяла ошибки, игнорировала здравый смысл и усиливала одну и ту же ошибку, пока весь процесс рассуждений не разрушился.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_1_Excerpt_from_Gemini_2_5_Tech_Paper_e89adf9eed.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Рисунок 1: Отрывок из <a href="https://arxiv.org/pdf/2507.06261">технической документации Gemini 2.5</a></p>
<h3 id="Context-Distraction--Lost-in-the-Details" class="common-anchor-header">Отвлечение контекста - потеря в деталях</h3><p>По мере расширения контекстных окон модели могут начать отвлекаться на транскрипт и недоиспользовать то, что они узнали во время обучения. Например, модель Gemini 2.5 Pro от DeepMind поддерживает окно в миллион токов, но <a href="https://arxiv.org/pdf/2507.06261">начинает дрейфовать в районе ~100 000 токов, перерабатывая</a>прошлые действия вместо того, чтобы генерировать новые стратегии. <a href="https://www.databricks.com/blog/long-context-rag-performance-llms">Исследование Databricks</a> показывает, что более мелкие модели, такие как Llama 3.1-405B, достигают этого предела гораздо раньше, примерно на ~32 000 жетонов. Это знакомый человеческий эффект: слишком много фонового чтения, и вы теряете сюжет.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_2_Excerpt_from_Gemini_2_5_Tech_Paper_56d775c59d.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Рисунок 2: Выдержка из <a href="https://arxiv.org/pdf/2507.06261">технической документации Gemini 2.5</a></p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_3_Long_context_performance_of_GPT_Claude_Llama_Mistral_and_DBRX_models_on_4_curated_RAG_datasets_Databricks_Docs_QA_Finance_Bench_Hot_Pot_QA_and_Natural_Questions_Source_Databricks_99086246b9.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Рисунок 3: Производительность моделей GPT, Claude, Llama, Mistral и DBRX в длинном контексте на 4 курируемых наборах данных RAG (Databricks DocsQA, FinanceBench, HotPotQA и Natural Questions) [Источник:</em> <a href="https://www.databricks.com/blog/long-context-rag-performance-llms"><em>Databricks</em></a><em>]</em>.</p>
<h3 id="Context-Confusion--Too-Many-Tools-in-the-Kitchen" class="common-anchor-header">Контекстная путаница - слишком много инструментов на кухне</h3><p>Добавление дополнительных инструментов не всегда помогает. <a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Berkeley Function-Calling Leaderboard</a> показывает, что когда контекст отображает обширные меню инструментов - часто с множеством нерелевантных опций - надежность модели снижается, и инструменты вызываются даже тогда, когда в них нет необходимости. Один из ярких примеров: квантованная Llama 3.1-8B потерпела неудачу с 46 доступными инструментами, но преуспела, когда набор был сокращен до 19. Это парадокс выбора для систем ИИ - слишком много вариантов, худшие решения.</p>
<h3 id="Context-Clash--When-Information-Conflicts" class="common-anchor-header">Столкновение контекстов - когда информация противоречит друг другу</h3><p>Многооборотные взаимодействия добавляют особый режим сбоя: раннее недопонимание усугубляется по мере разветвления диалога. В <a href="https://arxiv.org/pdf/2505.06120v1">экспериментах Microsoft и Salesforce</a> LLM с открытым и закрытым весом показали заметно худшие результаты в многооборотном взаимодействии по сравнению с однооборотным - в среднем на 39 % по шести задачам генерации. Как только неверное предположение переходит в состояние разговора, последующие повороты наследуют его и усиливают ошибку.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_4_LL_Ms_get_lost_in_multi_turn_conversations_in_experiments_21f194b02d.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Рисунок 4: LLM теряются в многооборотных разговорах в экспериментах</em></p>
<p>Эффект проявляется даже в пограничных моделях. Когда эталонные задачи были распределены между поворотами, оценка производительности модели OpenAI o3 упала с <strong>98,1</strong> до <strong>64,1</strong>. Первоначальное неверное прочтение эффективно "задает" модель мира; каждый ответ строится на ее основе, превращая небольшое противоречие в закоренелую слепую зону, если его явно не исправить.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_4_The_performance_scores_in_LLM_multi_turn_conversation_experiments_414d3a0b3f.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Рисунок 4: Оценка производительности в экспериментах LLM с многооборотным разговором</em></p>
<h2 id="Six-Strategies-to-Tame-Long-Context" class="common-anchor-header">Шесть стратегий по борьбе с длинным контекстом<button data-href="#Six-Strategies-to-Tame-Long-Context" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Ответ на проблемы длинного контекста заключается не в том, чтобы отказаться от этой возможности, а в том, чтобы дисциплинированно ее использовать. Вот шесть стратегий, которые, как мы убедились, работают на практике:</p>
<h3 id="Context-Isolation" class="common-anchor-header">Изоляция контекста</h3><p>Разбейте сложные рабочие процессы на специализированные агенты с изолированными контекстами. Каждый агент сосредоточен на своей области без вмешательства, что снижает риск распространения ошибок. Это не только повышает точность, но и позволяет выполнять работу параллельно, подобно хорошо структурированной команде инженеров.</p>
<h3 id="Context-Pruning" class="common-anchor-header">Обрезка контекста</h3><p>Регулярно проверяйте и обрезайте контекст. Удаляйте лишние детали, устаревшую информацию и неактуальные следы. Думайте об этом как о рефакторинге: вычищайте мертвый код и зависимости, оставляя только самое необходимое. Эффективная обрезка требует четких критериев того, что относится к контексту, а что нет.</p>
<h3 id="Context-Summarization" class="common-anchor-header">Суммирование контекста</h3><p>Длинные истории не нужно носить с собой в полном объеме. Вместо этого сократите их до кратких резюме, в которых отражено только то, что необходимо для следующего шага. Хорошее обобщение сохраняет важнейшие факты, решения и ограничения, исключая повторы и ненужные детали. Это все равно что заменить 200-страничную спецификацию одностраничным дизайн-брифом, который все равно даст вам все необходимое для продвижения вперед.</p>
<h3 id="Context-Offloading" class="common-anchor-header">Разгрузка контекста</h3><p>Не все детали должны быть частью живого контекста. Сохраняйте некритичные данные во внешних системах - базах знаний, хранилищах документов или векторных базах данных, таких как Milvus, - и получайте их только при необходимости. Это снижает когнитивную нагрузку на модель, сохраняя доступ к фоновой информации.</p>
<h3 id="Strategic-RAG" class="common-anchor-header">Стратегический RAG</h3><p>Поиск информации эффективен только в том случае, если он избирателен. Внедряйте внешние знания с помощью строгой фильтрации и контроля качества, чтобы модель потребляла релевантные и точные данные. Как и в случае с любой системой обработки данных: мусор входит, мусор выходит - но при качественном извлечении контекст становится активом, а не пассивом.</p>
<h3 id="Optimized-Tool-Loading" class="common-anchor-header">Оптимизированная загрузка инструментов</h3><p>Большее количество инструментов не равно лучшей производительности. Исследования показывают, что надежность резко падает после ~30 доступных инструментов. Загружайте только те функции, которые необходимы для конкретной задачи, а к остальным закрывайте доступ. Бережливый набор инструментов способствует точности и уменьшает шум, который может подавлять процесс принятия решений.</p>
<h2 id="The-Infrastructure-Challenge-of-Context-Engineering" class="common-anchor-header">Инфраструктурная проблема контекстной инженерии<button data-href="#The-Infrastructure-Challenge-of-Context-Engineering" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Контекстная инженерия эффективна лишь в той мере, в какой эффективна инфраструктура, на которой она работает. А современные предприятия сталкиваются с идеальным штормом проблем, связанных с данными:</p>
<h3 id="Scale-Explosion--From-Terabytes-to-Petabytes" class="common-anchor-header">Взрыв масштаба - от терабайтов к петабайтам</h3><p>Сегодня рост объема данных изменил базовые показатели. Рабочие нагрузки, которые раньше легко умещались в одной базе данных, теперь охватывают петабайты, требуя распределенного хранения и вычислений. Изменение схемы, которое раньше сводилось к однострочному обновлению SQL, может превратиться в полноценную работу по оркестровке кластеров, конвейеров и сервисов. Масштабирование - это не просто добавление оборудования, а разработка координации, устойчивости и эластичности в масштабах, где каждое предположение подвергается стресс-тестированию.</p>
<h3 id="Consumption-Revolution--Systems-That-Speak-AI" class="common-anchor-header">Революция в потреблении - системы, говорящие на языке ИИ</h3><p>Агенты искусственного интеллекта не просто запрашивают данные - они непрерывно генерируют, преобразуют и потребляют их с машинной скоростью. Инфраструктура, созданная только для приложений, ориентированных на человека, не может за этим угнаться. Чтобы поддерживать агентов, системы должны обеспечивать поиск данных с низкой задержкой, потоковое обновление и высокую нагрузку на запись без сбоев. Другими словами, инфраструктурный стек должен быть построен таким образом, чтобы "говорить на языке ИИ" как его родная рабочая нагрузка, а не как нечто вторичное.</p>
<h3 id="Multimodal-Complexity--Many-Data-Types-One-System" class="common-anchor-header">Мультимодальная сложность - много типов данных, одна система</h3><p>В рабочих нагрузках ИИ смешиваются текст, изображения, аудио, видео и высокоразмерные вкрапления, к каждому из которых прилагаются богатые метаданные. Управление этой гетерогенностью - суть практического контекстного проектирования. Проблема заключается не только в хранении разнообразных объектов, но и в их индексировании, эффективном извлечении и обеспечении семантической согласованности между модальностями. По-настоящему готовая к ИИ инфраструктура должна относиться к мультимодальности как к первоклассному принципу проектирования, а не как к дополнительной функции.</p>
<h2 id="Milvus-+-Loon-Purpose-Built-Data-Infrastructure-for-AI" class="common-anchor-header">Milvus + Loon: Целевая инфраструктура данных для ИИ<button data-href="#Milvus-+-Loon-Purpose-Built-Data-Infrastructure-for-AI" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Проблемы масштабирования, потребления и мультимодальности не могут быть решены только теорией - они требуют инфраструктуры, специально созданной для ИИ. Именно поэтому мы в <a href="https://zilliz.com/">Zilliz</a> разработали <strong>Milvus</strong> и <strong>Loon</strong>, чтобы они работали вместе, решая обе стороны проблемы: высокопроизводительный поиск во время выполнения и крупномасштабную обработку данных в процессе выполнения.</p>
<ul>
<li><p><a href="https://milvus.io/"><strong>Milvus</strong></a>: наиболее широко распространенная векторная база данных с открытым исходным кодом, оптимизированная для высокопроизводительного поиска и хранения векторов.</p></li>
<li><p><strong>Loon</strong>: наш готовящийся облачный нативный сервис мультимодального озера данных, предназначенный для обработки и организации масштабных мультимодальных данных еще до того, как они попадут в базу данных. Следите за новостями.</p></li>
</ul>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/multimodal_data_lake_min_ddc3de6ea4.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="Lightning-Fast-Vector-Search" class="common-anchor-header">Молниеносный векторный поиск</h3><p><strong>Milvus</strong> с нуля создан для векторных рабочих нагрузок. В качестве обслуживающего слоя он обеспечивает поиск в течение 10 мс среди сотен миллионов или даже миллиардов векторов, полученных из текста, изображений, аудио или видео. Для приложений ИИ скорость поиска - это не просто "приятно иметь". Именно от нее зависит, будет ли агент работать быстро или вяло, будет ли результат поиска релевантным или неактуальным. Производительность здесь напрямую отражается на опыте конечного пользователя.</p>
<h3 id="Multimodal-Data-Lake-Service-at-Scale" class="common-anchor-header">Мультимодальная служба озера данных в масштабе</h3><p><strong>Loon</strong> - это наш новый сервис мультимодального озера данных, предназначенный для масштабной автономной обработки и анализа неструктурированных данных. Он дополняет Milvus со стороны конвейера, подготавливая данные еще до того, как они попадут в базу данных. Реальные наборы мультимодальных данных, включающие текст, изображения, аудио и видео, часто бывают беспорядочными, с дублированием, шумами и несогласованными форматами. Loon берет на себя эту тяжелую работу, используя распределенные фреймворки, такие как Ray и Daft, сжимая, дедуплицируя и кластеризуя данные перед их передачей непосредственно в Milvus. Результат прост: никаких узких мест на этапе обработки, никаких мучительных преобразований форматов - только чистые, структурированные данные, которые модели могут использовать немедленно.</p>
<h3 id="Cloud-Native-Elasticity" class="common-anchor-header">Эластичность на основе облачных вычислений</h3><p>Обе системы построены по принципу "облако-натива", а хранилища и вычисления масштабируются независимо друг от друга. Это означает, что по мере роста рабочих нагрузок от гигабайтов до петабайтов вы сможете распределять ресурсы между обслуживанием в реальном времени и автономным обучением, а не перераспределять их в пользу одного и не сокращать другого.</p>
<h3 id="Future-Proof-Architecture" class="common-anchor-header">Перспективная архитектура</h3><p>Самое главное, что эта архитектура создана для того, чтобы расти вместе с вами. Контекстная инженерия продолжает развиваться. Сейчас большинство команд сосредоточены на семантическом поиске и конвейерах RAG. Но следующая волна потребует большего - интеграции нескольких типов данных, рассуждений на их основе и управления рабочими процессами с помощью агентов.</p>
<p>С Milvus и Loon этот переход не требует разрушения фундамента. Тот же стек, который поддерживает сегодняшние сценарии использования, может естественным образом распространяться на завтрашние. Вы добавляете новые возможности без необходимости начинать все сначала, что означает меньший риск, меньшие затраты и более плавный переход по мере усложнения рабочих нагрузок ИИ.</p>
<h2 id="Your-Next-Move" class="common-anchor-header">Ваш следующий шаг<button data-href="#Your-Next-Move" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Контекстная инженерия - это не просто еще одна техническая дисциплина, это то, как мы раскрываем творческий потенциал ИИ, сохраняя его обоснованность и надежность. Если вы готовы применить эти идеи на практике, начните с самого важного.</p>
<ul>
<li><p><a href="https://milvus.io/docs/overview.md"><strong>Поэкспериментируйте с Milvus</strong></a> и узнайте, как векторные базы данных могут способствовать поиску информации в реальных условиях.</p></li>
<li><p><a href="https://www.linkedin.com/company/the-milvus-project/"><strong>Следите за Milvus</strong></a>, чтобы узнать о выходе Loon и получить информацию об управлении крупномасштабными мультимодальными данными.</p></li>
<li><p><a href="https://discord.com/invite/8uyFbECzPX"><strong>Присоединяйтесь к сообществу Zilliz на Discord</strong></a>, чтобы поделиться стратегиями, сравнить архитектуры и помочь сформировать лучшие практики.</p></li>
</ul>
<p>Компании, которые освоят контекстную инженерию сегодня, будут определять ландшафт ИИ завтра. Не позволяйте инфраструктуре быть ограничителем - создайте фундамент, которого заслуживает ваш творческий потенциал ИИ.</p>
