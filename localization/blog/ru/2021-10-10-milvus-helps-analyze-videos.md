---
id: 2021-10-10-milvus-helps-analyze-videos.md
title: Обнаружение объектов
author: Shiyu Chen
date: 2021-10-11T00:00:00.000Z
desc: >-
  Узнайте, как Milvus обеспечивает искусственный интеллект для анализа
  видеоматериалов.
cover: assets.zilliz.com/Who_is_it_e9d4510ace.png
tag: Scenarios
canonicalUrl: 'https://zilliz.com/blog/milvus-helps-analyze-videos-intelligently'
---
<custom-h1>Создание системы анализа видео с помощью векторной базы данных Milvus</custom-h1><p><em>Шиюй Чен, инженер по обработке данных в Zilliz, окончила Университет Сидянь по специальности "Компьютерные науки". С момента прихода в Zilliz она занимается поиском решений для Milvus в различных областях, таких как анализ аудио и видео, поиск формул молекул и т. д., что значительно обогатило сценарии применения сообщества. В настоящее время она занимается поиском новых интересных решений. В свободное время она любит спорт и чтение.</em></p>
<p>Когда я смотрела фильм <em>"Свободный парень"</em> в прошлые выходные, мне показалось, что я уже где-то видела актера, который играет охранника Бадди, но не могла вспомнить ни одной его работы. Моя голова была забита вопросами "кто этот парень?". Я был уверен, что видел это лицо, и изо всех сил пытался вспомнить его имя. Похожий случай: однажды я увидел, как ведущий актер в видеоролике пьет напиток, который мне раньше очень нравился, но так и не смог вспомнить название бренда.</p>
<p>Ответ был на кончике моего языка, но мой мозг чувствовал себя полностью застрявшим.</p>
<p>Феномен кончика языка (TOT) сводит меня с ума при просмотре фильмов. Если бы только существовала система обратного поиска изображений для видео, которая позволила бы мне находить видео и анализировать его содержание. Раньше я создал <a href="https://github.com/milvus-io/bootcamp/tree/master/solutions/reverse_image_search/quick_deploy">систему обратного поиска изображений с помощью Milvus</a>. Учитывая, что анализ видеоконтента чем-то похож на анализ изображений, я решил создать механизм анализа видеоконтента на основе Milvus.</p>
<h2 id="Object-detection" class="common-anchor-header">Обнаружение объектов<button data-href="#Object-detection" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Overview" class="common-anchor-header">Обзор</h3><p>Прежде чем приступить к анализу, необходимо обнаружить объекты на видео. Эффективное и точное обнаружение объектов на видео является основной задачей. Это также важная задача для таких приложений, как автопилот, носимые устройства и IoT.</p>
<p>Сегодня основные модели для обнаружения объектов развиваются от традиционных алгоритмов обработки изображений до глубоких нейронных сетей (DNN), включая R-CNN, FRCNN, SSD и YOLO. Система анализа видео на основе глубокого обучения Milvus, представленная в этой теме, может быстро и интеллектуально обнаруживать объекты.</p>
<h3 id="Implementation" class="common-anchor-header">Реализация</h3><p>Чтобы обнаружить и распознать объекты на видео, система должна сначала извлечь кадры из видео и обнаружить объекты на изображениях кадров с помощью функции обнаружения объектов, во-вторых, извлечь векторы признаков из обнаруженных объектов и, наконец, проанализировать объект на основе векторов признаков.</p>
<ul>
<li>Извлечение кадров</li>
</ul>
<p>Анализ видео преобразуется в анализ изображений с помощью извлечения кадров. В настоящее время технология извлечения кадров очень развита. Такие программы, как FFmpeg и OpenCV, поддерживают извлечение кадров через заданные интервалы времени. В этой статье рассказывается о том, как извлекать кадры из видео каждую секунду с помощью OpenCV.</p>
<ul>
<li>Обнаружение объектов</li>
</ul>
<p>Обнаружение объектов - это поиск объектов в извлеченных кадрах и извлечение скриншотов объектов в соответствии с их положением. Как показано на следующих рисунках, были обнаружены велосипед, собака и автомобиль. В этой теме рассказывается о том, как обнаружить объекты с помощью YOLOv3, который обычно используется для обнаружения объектов.</p>
<ul>
<li>Извлечение признаков</li>
</ul>
<p>Извлечение признаков - это преобразование неструктурированных данных, которые трудно распознать машинам, в векторы признаков. Например, изображения могут быть преобразованы в многомерные векторы признаков с помощью моделей глубокого обучения. В настоящее время наиболее популярными моделями ИИ для распознавания изображений являются VGG, GNN и ResNet. В этой теме рассказывается о том, как извлекать признаки из обнаруженных объектов с помощью ResNet-50.</p>
<ul>
<li>Векторный анализ</li>
</ul>
<p>Извлеченные векторы признаков сравниваются с библиотечными векторами, и возвращается информация, соответствующая наиболее похожим векторам. Для больших наборов данных векторов признаков вычисление представляет собой огромную проблему. В этой теме рассказывается о том, как анализировать векторы признаков с помощью Milvus.</p>
<h2 id="Key-technologies" class="common-anchor-header">Ключевые технологии<button data-href="#Key-technologies" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="OpenCV" class="common-anchor-header">OpenCV</h3><p>Open Source Computer Vision Library (OpenCV) - это кроссплатформенная библиотека компьютерного зрения, которая предоставляет множество универсальных алгоритмов для обработки изображений и компьютерного зрения. OpenCV широко используется в области компьютерного зрения.</p>
<p>В следующем примере показано, как с помощью OpenCV и Python захватить видеокадры через заданные промежутки времени и сохранить их как изображения.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> cv2 
<span class="hljs-built_in">cap</span> = cv2.VideoCapture(file_path)   
framerate = <span class="hljs-built_in">cap</span>.get(cv2.CAP_PROP_FPS)   
allframes = <span class="hljs-type">int</span>(cv2.VideoCapture.get(<span class="hljs-built_in">cap</span>, <span class="hljs-type">int</span>(cv2.CAP_PROP_FRAME_COUNT)))  
success, image = <span class="hljs-built_in">cap</span>.read() 
cv2.imwrite(file_name, image)
<button class="copy-code-btn"></button></code></pre>
<h3 id="YOLOv3" class="common-anchor-header">YOLOv3</h3><p>You Only Look Once, Version 3 (YOLOv3 [5]) - это одноэтапный алгоритм обнаружения объектов, предложенный в последние годы. По сравнению с традиционными алгоритмами обнаружения объектов с той же точностью, YOLOv3 работает в два раза быстрее. YOLOv3, упоминаемый в данной теме, является улучшенной версией PaddlePaddle [6]. Она использует несколько методов оптимизации и отличается более высокой скоростью вывода.</p>
<h3 id="ResNet-50" class="common-anchor-header">ResNet-50</h3><p>ResNet [7] - победитель ILSVRC 2015 в области классификации изображений благодаря своей простоте и практичности. Являясь основой многих методов анализа изображений, ResNet оказывается популярной моделью, специализирующейся на обнаружении, сегментации и распознавании изображений.</p>
<h3 id="Milvus" class="common-anchor-header">Milvus</h3><p><a href="https://milvus.io/">Milvus</a> - это облачная база данных векторов с открытым исходным кодом, созданная для управления векторами встраивания, генерируемыми моделями машинного обучения и нейронными сетями. Она широко используется в таких областях, как компьютерное зрение, обработка естественного языка, вычислительная химия, персонализированные рекомендательные системы и т. д.</p>
<p>Ниже описаны процедуры работы Milvus.</p>
<ol>
<li>Неструктурированные данные преобразуются в векторы признаков с помощью моделей глубокого обучения и импортируются в Milvus.</li>
<li>Milvus хранит и индексирует векторы признаков.</li>
<li>Milvus возвращает векторы, наиболее похожие на вектор, запрашиваемый пользователем.</li>
</ol>
<h2 id="Deployment" class="common-anchor-header">Развертывание<button data-href="#Deployment" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Теперь вы имеете некоторое представление о системах видеоанализа на базе Milvus. Система состоит в основном из двух частей, как показано на следующем рисунке.</p>
<ul>
<li><p>Красные стрелки указывают на процесс импорта данных. Используйте ResNet-50 для извлечения векторов признаков из набора данных изображений и импортируйте векторы признаков в Milvus.</p></li>
<li><p>Черные стрелки указывают на процесс анализа видео. Во-первых, извлеките кадры из видео и сохраните их как изображения. Во-вторых, обнаруживаем и извлекаем объекты на изображениях с помощью YOLOv3. Затем с помощью ResNet-50 извлекаются векторы признаков из изображений. И наконец, Milvus ищет и возвращает информацию об объектах с соответствующими векторами признаков.</p></li>
</ul>
<p>Для получения дополнительной информации см. раздел <a href="https://github.com/milvus-io/bootcamp/tree/master/solutions/video_similarity_search/object_detection">Milvus Bootcamp: Система обнаружения видеообъектов</a>.</p>
<p><strong>Импорт данных</strong></p>
<p>Процесс импорта данных прост. Преобразуйте данные в 2 048-мерные векторы и импортируйте векторы в Milvus.</p>
<pre><code translate="no" class="language-python">vector = image_encoder.execute(filename)
entities = [vector]
collection.insert(data=entities)
<button class="copy-code-btn"></button></code></pre>
<p><strong>Анализ видео</strong></p>
<p>Как было сказано выше, процесс анализа видео включает в себя захват видеокадров, обнаружение объектов в каждом кадре, извлечение векторов из объектов, вычисление сходства векторов с помощью метрики евклидова расстояния (L2) и поиск результатов с помощью Milvus.</p>
<pre><code translate="no" class="language-python">images = extract_frame(filename, 1, prefix)   
detector = Detector()   
run(detector, DATA_PATH)       
vectors = get_object_vector(image_encoder, DATA_PATH)
search_params = {<span class="hljs-string">&quot;metric_type&quot;</span>: <span class="hljs-string">&quot;L2&quot;</span>, <span class="hljs-string">&quot;params&quot;</span>: {<span class="hljs-string">&quot;nprobe&quot;</span>: 10}}
results = collection.search(vectors, param=search_params, <span class="hljs-built_in">limit</span>=10)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Conclusion" class="common-anchor-header">Заключение<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>В настоящее время более 80 % данных являются неструктурированными. С быстрым развитием ИИ появляется все больше моделей глубокого обучения для анализа неструктурированных данных. Такие технологии, как обнаружение объектов и обработка изображений, достигли больших успехов как в научных кругах, так и в промышленности. Благодаря этим технологиям все больше и больше платформ ИИ отвечают практическим требованиям.</p>
<p>Система видеоанализа, рассматриваемая в этой теме, построена на базе Milvus, которая может быстро анализировать видеоконтент.</p>
<p>Являясь векторной базой данных с открытым исходным кодом, Milvus поддерживает векторы признаков, извлеченные с помощью различных моделей глубокого обучения. Интегрированный с такими библиотеками, как Faiss, NMSLIB и Annoy, Milvus предоставляет набор интуитивно понятных API, поддерживающих переключение типов индексов в зависимости от сценария. Кроме того, Milvus поддерживает скалярную фильтрацию, что повышает скорость запоминания и гибкость поиска. Milvus применяется во многих областях, таких как обработка изображений, компьютерное зрение, обработка естественного языка, распознавание речи, рекомендательные системы и поиск новых лекарств.</p>
<h2 id="References" class="common-anchor-header">Ссылки<button data-href="#References" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>[1] А. Д. Багданов, Л. Баллан, М. Бертини, А. Дель Бимбо. "Сопоставление и поиск товарных знаков в базах данных спортивного видео". Труды международного семинара по мультимедийному информационному поиску, ACM, 2007. https://www.researchgate.net/publication/210113141_Trademark_matching_and_retrieval_in_sports_video_databases</p>
<p>[2] J. Kleban, X. Xie, W.-Y. Ma. "Пространственная пирамида для обнаружения логотипов в естественных сценах". Международная конференция IEEE, 2008. https://ieeexplore.ieee.org/document/4607625</p>
<p>[3] Р. Бойя, К. Флореа, Л. Флореа, Р. Догару. "Локализация и распознавание логотипов на естественных изображениях с помощью графов гомографических классов". Machine Vision and Applications 27 (2), 2016. https://link.springer.com/article/10.1007/s00138-015-0741-7</p>
<p>[4] R. Boia, C. Florea, L. Florea. "Агломерация эллиптических асифтов в прототипе класса для обнаружения логотипов". BMVC, 2015. http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=5C87F52DE38AB0C90F8340DFEBB841F7?doi=10.1.1.707.9371&amp;rep=rep1&amp;type=pdf</p>
<p>[5] https://arxiv.org/abs/1804.02767</p>
<p>[6] https://paddlepaddle.org.cn/modelbasedetail/yolov3</p>
<p>[7] https://arxiv.org/abs/1512.03385</p>
