---
id: faster-index-builds-and-scalable-queries-with-gpu-cagra-in-milvus.md
title: >-
  Оптимизация NVIDIA CAGRA в Milvus: гибридный подход GPU-CPU к ускоренному
  индексированию и более дешевым запросам
author: Marcelo Chen
date: 2025-12-10T00:00:00.000Z
cover: assets.zilliz.com/CAGRA_cover_7b9675965f.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database'
meta_keywords: 'Milvus2.6, CAGRA, GPU, CPU, graph-based index'
meta_title: |
  Optimizing CAGRA in Milvus: A Hybrid GPU–CPU Approach
desc: >-
  Узнайте, как GPU_CAGRA в Milvus 2.6 использует GPU для быстрого построения
  графов и CPU для масштабируемого обслуживания запросов.
origin: >-
  https://milvus.io/blog/faster-index-builds-and-scalable-queries-with-gpu-cagra-in-milvus.md
---
<p>По мере того как системы искусственного интеллекта переходят от экспериментов к производственной инфраструктуре, векторные базы данных перестают справляться с миллионами вкраплений. <strong>Миллиарды стали обычным делом, а десятки миллиардов - все более распространенным.</strong> При таких масштабах выбор алгоритма влияет не только на производительность и запоминание, но и непосредственно на стоимость инфраструктуры.</p>
<p>В связи с этим возникает основной вопрос для крупномасштабных развертываний: <strong>как выбрать правильный индекс, который обеспечит приемлемую отзывчивость и задержку и при этом не выведет использование вычислительных ресурсов из-под контроля?</strong></p>
<p>Наиболее распространенным ответом стали индексы на основе графиков, такие как <strong>NSW, HNSW, CAGRA и Vamana</strong>. Благодаря навигации по заранее построенным графам соседей эти индексы обеспечивают быстрый поиск ближайших соседей в миллиардных масштабах, позволяя избежать грубого сканирования и сравнения каждого вектора с запросом.</p>
<p>Однако стоимость такого подхода неравномерна. <strong>Запрос графа относительно дешев, а его построение - нет.</strong> Построение высококачественного графа требует масштабных вычислений расстояний и итеративного уточнения по всему набору данных - нагрузка, с которой традиционные CPU не справляются по мере роста данных.</p>
<p>NVIDIA CAGRA решает эту проблему, используя GPU для ускорения построения графов за счет массивного параллелизма. Хотя это значительно сокращает время сборки, использование GPU для построения индексов и обслуживания запросов приводит к увеличению стоимости и ограничений масштабируемости в производственных средах.</p>
<p>Чтобы сбалансировать эти компромиссы, в <a href="https://milvus.io/docs/release_notes.md#v261">Milvus 2.6.1</a> <strong>используется гибридный дизайн для</strong> <strong>индексов</strong> <a href="https://milvus.io/docs/gpu-cagra.md">GPU_CAGRA</a>: <strong>GPU используются только для построения графов, а выполнение запросов происходит на CPU.</strong> Это позволяет сохранить качественные преимущества графов, построенных на GPU, а также масштабируемость и экономическую эффективность обслуживания запросов, что особенно хорошо подходит для рабочих нагрузок с нечастыми обновлениями данных, большими объемами запросов и строгой чувствительностью к стоимости.</p>
<h2 id="What-Is-CAGRA-and-How-Does-It-Work" class="common-anchor-header">Что такое CAGRA и как она работает?<button data-href="#What-Is-CAGRA-and-How-Does-It-Work" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Векторные индексы на основе графов обычно делятся на две основные категории:</p>
<ul>
<li><p><strong>Итеративное построение графов</strong>, представленное <strong>CAGRA</strong> (уже поддерживается в Milvus).</p></li>
<li><p><strong>Построение графов на основе вставки</strong>, представленное <strong>Vamana</strong> (в настоящее время разрабатывается в Milvus).</p></li>
</ul>
<p>Эти два подхода значительно отличаются по своим целям и техническим основам, что делает каждый из них подходящим для различных масштабов данных и моделей рабочей нагрузки.</p>
<p><strong>NVIDIA CAGRA (CUDA ANN Graph-based)</strong> - это нативный GPU-алгоритм для приблизительного поиска ближайших соседей (ANN), предназначенный для эффективного построения и запроса крупномасштабных графов близости. Используя параллелизм GPU, CAGRA значительно ускоряет построение графов и обеспечивает высокую производительность запросов по сравнению с подходами на базе CPU, такими как HNSW.</p>
<p>CAGRA построен на алгоритме <strong>NN-Descent (Nearest Neighbor Descent)</strong>, который строит граф k-nearest-neighbor (kNN) путем итеративного уточнения. На каждой итерации оцениваются и обновляются соседи-кандидаты, постепенно сходясь к более качественным отношениям между соседями по всему набору данных.</p>
<p>После каждого раунда уточнения CAGRA применяет дополнительные методы обрезки графа - например, <strong>обрезку 2-ходовых обходов - для</strong>удаления лишних ребер при сохранении качества поиска. Такое сочетание итеративного уточнения и обрезки приводит к созданию <strong>компактного, но хорошо связанного графа</strong>, который эффективно обходится во время запроса.</p>
<p>Благодаря многократному уточнению и обрезке CAGRA создает структуру графа, поддерживающую <strong>высокий отзыв и поиск ближайших соседей с низкой задержкой в больших масштабах</strong>, что делает ее особенно подходящей для статичных или редко обновляемых наборов данных.</p>
<h3 id="Step-1-Building-the-Initial-Graph-with-NN-Descent" class="common-anchor-header">Шаг 1: Построение исходного графа с помощью NN-Descent</h3><p>NN-Descent основан на простом, но действенном наблюдении: если узел <em>u</em> является соседом <em>v</em>, а узел <em>w</em> - соседом <em>u</em>, то с большой вероятностью <em>w</em> также является соседом <em>v</em>. Это переходное свойство позволяет алгоритму эффективно находить истинных ближайших соседей без исчерпывающего сравнения каждой пары векторов.</p>
<p>В качестве основного алгоритма построения графов CAGRA использует NN-Descent. Процесс происходит следующим образом:</p>
<p><strong>1. Случайная инициализация:</strong> Каждый узел начинает работу с небольшим набором случайно выбранных соседей, формируя грубый начальный граф.</p>
<p><strong>2. Расширение круга соседей:</strong> На каждой итерации узел собирает своих текущих соседей и их соседей, чтобы сформировать список кандидатов. Алгоритм вычисляет сходство между узлом и всеми кандидатами. Поскольку список кандидатов каждого узла независим, эти вычисления могут быть назначены отдельным блокам потоков GPU и выполняться параллельно в огромных масштабах.</p>
<p><strong>3. Обновление списка кандидатов:</strong> если алгоритм находит кандидатов, которые ближе, чем текущие соседи узла, он меняет местами более удаленных соседей и обновляет список kNN узла. За несколько итераций этот процесс позволяет получить приблизительный kNN-граф гораздо более высокого качества.</p>
<p><strong>4. Проверка сходимости:</strong> По мере выполнения итераций происходит все меньше обновлений соседей. Как только количество обновленных связей опускается ниже заданного порога, алгоритм останавливается, указывая на то, что граф фактически стабилизировался.</p>
<p>Поскольку расширение соседей и вычисление сходства для разных узлов полностью независимы, CAGRA передает рабочую нагрузку NN-Descent для каждого узла в выделенный блок потоков GPU. Такая конструкция обеспечивает массивный параллелизм и позволяет строить графы на порядки быстрее, чем традиционные методы на базе CPU.</p>
<h3 id="Step-2-Pruning-the-Graph-with-2-Hop-Detours" class="common-anchor-header">Шаг 2: обрезка графа с помощью 2-ходовых обходов</h3><p>После завершения работы NN-Descent полученный граф является точным, но слишком плотным. NN-Descent намеренно сохраняет лишних соседей-кандидатов, а случайная фаза инициализации вносит множество слабых или неактуальных ребер. В результате каждый узел часто оказывается со степенью, в два раза или даже в несколько раз превышающей целевую степень.</p>
<p>Чтобы получить компактный и эффективный граф, CAGRA применяет обрезку 2-ходовых обходов.</p>
<p>Идея проста: если узел <em>A</em> может косвенно достичь узла <em>B</em> через общего соседа <em>C</em> (образуя путь A → C → B), и расстояние этого косвенного пути сравнимо с прямым расстоянием между <em>A</em> и <em>B</em>, то прямое ребро A → B считается избыточным и может быть удалено.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/2_hop_detours_d15eae8702.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Ключевое преимущество этой стратегии обрезки заключается в том, что проверка избыточности каждого ребра зависит только от локальной информации - расстояния между двумя конечными точками и их общими соседями. Поскольку каждое ребро может быть оценено независимо, шаг обрезки хорошо распараллеливается и естественно вписывается в пакетное выполнение на GPU.</p>
<p>В результате CAGRA может эффективно обрезать граф на GPU, сокращая накладные расходы на хранение на <strong>40-50 %</strong>, сохраняя при этом точность поиска и повышая скорость обхода во время выполнения запроса.</p>
<h2 id="GPUCAGRA-in-Milvus-What’s-Different" class="common-anchor-header">GPU_CAGRA в Milvus: в чем разница?<button data-href="#GPUCAGRA-in-Milvus-What’s-Different" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Хотя GPU обеспечивают значительные преимущества в производительности при построении графов, производственные среды сталкиваются с практической проблемой: Ресурсы GPU гораздо дороже и ограниченнее, чем у CPU. Если построение индексов и выполнение запросов зависят исключительно от GPU, быстро возникает несколько эксплуатационных проблем:</p>
<ul>
<li><p><strong>Низкий уровень использования ресурсов:</strong> Трафик запросов часто нерегулярен и скачкообразен, в результате чего GPU простаивают длительное время и расходуют дорогостоящие вычислительные мощности.</p></li>
<li><p><strong>Высокая стоимость развертывания:</strong> Назначение GPU каждому экземпляру, обслуживающему запросы, приводит к увеличению стоимости оборудования, даже если большинство запросов не используют производительность GPU в полной мере.</p></li>
<li><p><strong>Ограниченная масштабируемость:</strong> Количество доступных GPU напрямую влияет на количество копий сервисов, которые вы можете запустить, что ограничивает ваши возможности по масштабированию в зависимости от спроса.</p></li>
<li><p><strong>Снижение гибкости:</strong> Когда построение индексов и формирование запросов зависят от GPU, система становится привязанной к доступности GPU и не может легко перенести рабочую нагрузку на CPU.</p></li>
</ul>
<p>Чтобы устранить эти ограничения, в Milvus 2.6.1 появился режим гибкого развертывания индекса GPU_CAGRA с помощью параметра <code translate="no">adapt_for_cpu</code>. Этот режим обеспечивает гибридный рабочий процесс: CAGRA использует GPU для построения высококачественного индекса графов, а выполнение запросов происходит на CPU - как правило, с использованием HNSW в качестве алгоритма поиска.</p>
<p>При таком подходе GPU используются там, где они приносят наибольшую пользу - быстрое и высокоточное построение индексов, в то время как CPU справляются с крупномасштабными запросами гораздо более экономичным и масштабируемым способом.</p>
<p>В результате этот гибридный подход особенно хорошо подходит для таких рабочих нагрузок, в которых:</p>
<ul>
<li><p><strong>Обновление данных происходит нечасто</strong>, поэтому перестройка индексов происходит редко</p></li>
<li><p><strong>Объем запросов высок</strong> и требует большого количества недорогих реплик</p></li>
<li><p><strong>Высокая чувствительность к затратам</strong>, и использование GPU должно жестко контролироваться.</p></li>
</ul>
<h3 id="Understanding-adaptforcpu" class="common-anchor-header">Понимание <code translate="no">adapt_for_cpu</code></h3><p>В Milvus параметр <code translate="no">adapt_for_cpu</code> управляет тем, как индекс CAGRA сериализуется на диск во время построения индекса и как он десериализуется в память во время загрузки. Изменяя этот параметр во время сборки и во время загрузки, Milvus может гибко переключаться между построением индекса на базе GPU и выполнением запроса на базе CPU.</p>
<p>Различные комбинации <code translate="no">adapt_for_cpu</code> во время сборки и во время загрузки приводят к четырем режимам выполнения, каждый из которых предназначен для определенного сценария работы.</p>
<table>
<thead>
<tr><th style="text-align:center"><strong>Время построения (<code translate="no">adapt_for_cpu</code>)</strong></th><th style="text-align:center"><strong>Время загрузки (<code translate="no">adapt_for_cpu</code>)</strong></th><th style="text-align:center"><strong>Логика выполнения</strong></th><th style="text-align:center"><strong>Рекомендуемый сценарий</strong></th></tr>
</thead>
<tbody>
<tr><td style="text-align:center"><strong>истинный</strong></td><td style="text-align:center"><strong>верно</strong></td><td style="text-align:center">Сборка на GPU_CAGRA → сериализация в HNSW → десериализация в HNSW → <strong>обработка запросов на CPU</strong></td><td style="text-align:center">Рабочие нагрузки, чувствительные к затратам; крупномасштабное обслуживание запросов</td></tr>
<tr><td style="text-align:center"><strong>true</strong></td><td style="text-align:center"><strong>ложь</strong></td><td style="text-align:center">Сборка с GPU_CAGRA → сериализация как HNSW → десериализация как HNSW → <strong>обработка запросов на CPU</strong></td><td style="text-align:center">Последующие запросы возвращаются на CPU при несовпадении параметров</td></tr>
<tr><td style="text-align:center"><strong>false</strong></td><td style="text-align:center"><strong>true</strong></td><td style="text-align:center">Построение с помощью GPU_CAGRA → сериализация как CAGRA → десериализация как HNSW → <strong>запросы к CPU</strong></td><td style="text-align:center">Сохранение исходного индекса CAGRA для хранения, обеспечивая временный поиск на CPU</td></tr>
<tr><td style="text-align:center"><strong>false</strong></td><td style="text-align:center"><strong>false</strong></td><td style="text-align:center">Построение с помощью GPU_CAGRA → сериализация как CAGRA → десериализация как CAGRA → <strong>запросы на GPU</strong></td><td style="text-align:center">Критичные по производительности рабочие нагрузки, где стоимость имеет второстепенное значение</td></tr>
</tbody>
</table>
<p><strong>Примечание:</strong> Механизм <code translate="no">adapt_for_cpu</code> поддерживает только одностороннее преобразование. Индекс CAGRA может быть преобразован в HNSW, поскольку структура графа CAGRA сохраняет все отношения между соседями, необходимые HNSW. Однако индекс HNSW не может быть преобразован обратно в CAGRA, поскольку в нем отсутствует дополнительная структурная информация, необходимая для запросов на основе GPU. Поэтому настройки времени сборки следует выбирать тщательно, с учетом долгосрочного развертывания и требований к запросам.</p>
<h2 id="Putting-GPUCAGRA-to-the-Test" class="common-anchor-header">Испытание GPU_CAGRA на прочность<button data-href="#Putting-GPUCAGRA-to-the-Test" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Чтобы оценить эффективность гибридной модели выполнения - использование GPU для построения индексов и CPU для выполнения запросов - мы провели серию контролируемых экспериментов в стандартной среде. Оценка сосредоточена на трех параметрах: <strong>производительности построения индекса</strong>, <strong>производительности запросов</strong> и <strong>точности запоминания</strong>.</p>
<p><strong>Экспериментальная установка</strong></p>
<p>Эксперименты проводились на широко распространенном, стандартном для отрасли оборудовании, чтобы обеспечить надежность и широкую применимость результатов.</p>
<ul>
<li><p>ПРОЦЕССОР: Процессор MD EPYC 7R13 (16 процессоров)</p></li>
<li><p>GPU: NVIDIA L4</p></li>
</ul>
<h3 id="1-Index-Build-Performance" class="common-anchor-header">1. Производительность построения индекса</h3><p>Мы сравниваем CAGRA, построенный на GPU, с HNSW, построенным на CPU, при одинаковой целевой степени графа 64.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/cp1_a177200ab2.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><strong>Основные результаты</strong></p>
<ul>
<li><p><strong>GPU CAGRA строит индексы на 12-15× быстрее, чем CPU HNSW.</strong> Как на Cohere1M, так и на Gist1M, CAGRA на базе GPU значительно превосходит HNSW на базе CPU, что подчеркивает эффективность параллелизма GPU при построении графов.</p></li>
<li><p><strong>Время построения линейно увеличивается с количеством итераций NN-Descent.</strong> По мере увеличения числа итераций время построения растет почти линейно, что отражает итерационную природу NN-Descent и обеспечивает предсказуемый компромисс между стоимостью построения и качеством графа.</p></li>
</ul>
<h3 id="2-Query-performance" class="common-anchor-header">2. Производительность запросов</h3><p>В этом эксперименте граф CAGRA строится один раз на GPU, а затем запрашивается с использованием двух различных путей выполнения:</p>
<ul>
<li><p><strong>Запрос на CPU</strong>: индекс десериализуется в формат HNSW и поиск выполняется на CPU.</p></li>
<li><p><strong>Запрос на GPU</strong>: поиск выполняется непосредственно в графе CAGRA с использованием обхода на базе GPU.</p></li>
</ul>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/cp2_bd00e60553.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><strong>Основные результаты</strong></p>
<ul>
<li><p><strong>Пропускная способность поиска на GPU в 5-6 раз выше, чем на CPU.</strong> Как в Cohere1M, так и в Gist1M, обход графа на основе GPU обеспечивает значительно более высокий QPS, что подчеркивает эффективность параллельной навигации по графу на GPU.</p></li>
<li><p><strong>Recall увеличивается с числом итераций NN-Descent, а затем достигает плато.</strong> По мере роста числа итераций построения запоминание улучшается как для запросов на CPU, так и на GPU. Однако после определенного момента дополнительные итерации дают все меньший выигрыш, указывая на то, что качество графа в основном сходится.</p></li>
</ul>
<h3 id="3-Recall-accuracy" class="common-anchor-header">3. Точность запоминания</h3><p>В этом эксперименте оба графа - CAGRA и HNSW - запрашиваются на CPU, чтобы сравнить точность запоминания при одинаковых условиях запроса.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/cp3_1a46a7bdda.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><strong>Основные результаты</strong></p>
<p><strong>CAGRA достигает более высокой точности запоминания, чем HNSW, на обоих наборах данных</strong>, показывая, что даже когда индекс CAGRA создается на GPU и десериализуется для поиска на CPU, качество графа хорошо сохраняется.</p>
<h2 id="What’s-Next-Scaling-Index-Construction-with-Vamana" class="common-anchor-header">Что дальше: Масштабирование построения индексов с помощью Vamana<button data-href="#What’s-Next-Scaling-Index-Construction-with-Vamana" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Гибридный GPU-CPU подход Milvus предлагает практичное и экономически эффективное решение для современных крупномасштабных рабочих нагрузок векторного поиска. Построение высококачественных графов CAGRA на GPU и обслуживание запросов на CPU позволяет сочетать быстрое построение индексов с масштабируемым и доступным выполнением запросов, что особенно<strong>хорошо подходит для рабочих нагрузок с нечастыми обновлениями, большими объемами запросов и жесткими ограничениями по стоимости.</strong></p>
<p>При еще больших масштабах - десятки<strong>или сотни миллиардов векторов -</strong>построение<strong>индекса</strong>само по себе становится узким местом. Когда полный набор данных уже не помещается в память GPU, индустрия обычно обращается к методам <strong>построения графов на основе вставок</strong>, таким как <strong>Vamana</strong>. Вместо того чтобы строить граф сразу, Vamana обрабатывает данные партиями, постепенно вставляя новые векторы, сохраняя при этом глобальную связность.</p>
<p>Конвейер построения графа состоит из трех ключевых этапов:</p>
<p><strong>1. Геометрическое наращивание партий</strong> - начиная с небольших партий для формирования скелета графа, затем увеличивая размер партии, чтобы максимизировать параллелизм, и, наконец, используя большие партии для уточнения деталей.</p>
<p><strong>2. Жадная вставка</strong> - каждый новый узел вставляется путем навигации от центральной точки входа, итеративно уточняя набор своих соседей.</p>
<p><strong>3. Обновление обратных ребер</strong> - добавление обратных связей для сохранения симметрии и обеспечения эффективной навигации по графу.</p>
<p>Обрезка интегрирована непосредственно в процесс построения с помощью критерия α-RNG: если сосед-кандидат <em>v</em> уже покрыт существующим соседом <em>p′</em> (т. е. <em>d(p′, v) &lt; α × d(p, v)</em>), то <em>v</em> обрезается. Параметр α позволяет точно контролировать разреженность и точность. Ускорение на GPU достигается за счет внутрипакетного параллелизма и геометрического масштабирования пакетов, что позволяет найти баланс между качеством индекса и пропускной способностью.</p>
<p>Вместе эти методы позволяют командам справляться с быстрым ростом данных и масштабными обновлениями индексов, не сталкиваясь с ограничениями памяти GPU.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/One_more_thing_b458360e25.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>Команда Milvus активно разрабатывает поддержку Vamana и планирует выпустить ее в первой половине 2026 года. Следите за новостями.</p>
<p>У вас есть вопросы или вы хотите получить подробную информацию о любой функции последней версии Milvus? Присоединяйтесь к нашему<a href="https://discord.com/invite/8uyFbECzPX"> каналу Discord</a> или создавайте проблемы на<a href="https://github.com/milvus-io/milvus"> GitHub</a>. Вы также можете записаться на 20-минутную индивидуальную сессию, чтобы получить знания, рекомендации и ответы на свои вопросы в<a href="https://milvus.io/blog/join-milvus-office-hours-to-get-support-from-vectordb-experts.md"> Milvus Office Hours</a>.</p>
<h2 id="Learn-More-about-Milvus-26-Features" class="common-anchor-header">Подробнее о возможностях Milvus 2.6<button data-href="#Learn-More-about-Milvus-26-Features" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ul>
<li><p><a href="https://milvus.io/blog/introduce-milvus-2-6-built-for-scale-designed-to-reduce-costs.md">Представляем Milvus 2.6: доступный векторный поиск в миллиардных масштабах</a></p></li>
<li><p><a href="https://milvus.io/blog/data-in-and-data-out-in-milvus-2-6.md">Представляем функцию встраивания: Как Milvus 2.6 оптимизирует векторизацию и семантический поиск</a></p></li>
<li><p><a href="https://milvus.io/blog/json-shredding-in-milvus-faster-json-filtering-with-flexibility.md">Измельчение JSON в Milvus: 88,9-кратное ускорение фильтрации JSON с гибкостью</a></p></li>
<li><p><a href="https://milvus.io/blog/unlocking-true-entity-level-retrieval-new-array-of-structs-and-max-sim-capabilities-in-milvus.md">Разблокирование истинного поиска на уровне сущностей: Новые возможности Array-of-Structs и MAX_SIM в Milvus</a></p></li>
<li><p><a href="https://milvus.io/blog/minhash-lsh-in-milvus-the-secret-weapon-for-fighting-duplicates-in-llm-training-data.md">MinHash LSH в Milvus: секретное оружие для борьбы с дубликатами в обучающих данных LLM </a></p></li>
<li><p><a href="https://milvus.io/blog/bring-vector-compression-to-the-extreme-how-milvus-serves-3%C3%97-more-queries-with-rabitq.md">Доведите векторное сжатие до крайности: как Milvus обслуживает в 3 раза больше запросов с помощью RaBitQ</a></p></li>
<li><p><a href="https://milvus.io/blog/benchmarks-lie-vector-dbs-deserve-a-real-test.md">Бенчмарки лгут - векторные БД заслуживают реальной проверки </a></p></li>
<li><p><a href="https://milvus.io/blog/we-replaced-kafka-pulsar-with-a-woodpecker-for-milvus.md">Мы заменили Kafka/Pulsar на Woodpecker для Milvus</a></p></li>
</ul>
