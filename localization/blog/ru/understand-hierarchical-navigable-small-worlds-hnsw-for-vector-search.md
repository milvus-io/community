---
id: understand-hierarchical-navigable-small-worlds-hnsw-for-vector-search.md
title: Понимание иерархических перемещаемых малых миров (HNSW) для векторного поиска
author: Stefan Webb
date: 2025-05-21T00:00:00.000Z
desc: >-
  HNSW (Hierarchical Navigable Small World) - это эффективный алгоритм
  приближенного поиска ближайших соседей с использованием многослойной структуры
  графов.
cover: assets.zilliz.com/Chat_GPT_Image_May_26_2025_11_56_17_AM_1a84d31090.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database, vector search'
meta_keywords: 'Milvus, HNSW, Hierarchical Navigable Small Worlds, RAG, vector search'
meta_title: |
  Understand HNSW for Vector Search
origin: >-
  https://milvus.io/blog/understand-hierarchical-navigable-small-worlds-hnsw-for-vector-search.md
---
<p>Ключевой операцией <a href="https://milvus.io/blog/what-is-a-vector-database.md">векторных баз данных</a> является <em>поиск сходства</em>, который заключается в нахождении ближайших соседей в базе данных по вектору запроса, например, по евклидову расстоянию. Наивный метод вычисляет расстояние от вектора запроса до каждого вектора, хранящегося в базе данных, и берет топ-K ближайших. Однако такой способ явно не подходит при увеличении размера базы данных. На практике наивный поиск по сходству применим только для баз данных, содержащих менее 1 миллиона векторов. Как мы можем масштабировать поиск до 10 и 100 миллионов или даже до миллиардов векторов?</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_Descending_a_hierarchy_of_vector_search_indices_cf9fb8060a.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Рисунок: Нисходящая иерархия индексов векторного поиска</em></p>
<p>Было разработано множество алгоритмов и структур данных для масштабирования поиска сходства в высокоразмерных векторных пространствах до сублинейной временной сложности. В этой статье мы объясним и реализуем популярный и эффективный метод под названием Hierarchical Navigable Small Worlds (HNSW), который часто выбирается по умолчанию для векторных наборов данных среднего размера. Он относится к семейству методов поиска, которые строят граф над векторами, где вершины обозначают векторы, а ребра - сходство между ними. Поиск осуществляется путем навигации по графу, в простейшем случае - жадным переходом к ближайшему к запросу соседу текущей вершины и повторяется до тех пор, пока не будет достигнут локальный минимум.</p>
<p>Мы расскажем подробнее, как строится граф поиска, как граф обеспечивает поиск, а в конце дадим ссылку на реализацию HNSW, выполненную вами на простом языке Python.</p>
<h2 id="Navigable-Small-Worlds" class="common-anchor-header">Малые миры с навигацией<button data-href="#Navigable-Small-Worlds" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure_NSW_graph_created_from_100_randomly_located_2_D_points_3ffccbd6a7.jpg" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Рисунок: Граф НСВ, созданный из 100 случайно расположенных двумерных точек.</em></p>
<p>Как уже говорилось, HNSW строит поисковый граф в автономном режиме, прежде чем мы сможем выполнить запрос. Алгоритм построен на основе предыдущей работы, метода под названием Navigable Small Worlds (NSW). Сначала мы расскажем о NSW, а затем перейдем к <em>иерархическому</em> NSW. На иллюстрации выше показан построенный граф поиска для NSW над двумерными векторами. Во всех приведенных ниже примерах мы ограничиваемся двумерными векторами, чтобы иметь возможность их визуализировать.</p>
<h2 id="Constructing-the-Graph" class="common-anchor-header">Построение графа<button data-href="#Constructing-the-Graph" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>НСВ - это граф, в котором вершины представляют векторы, а ребра строятся эвристически на основе сходства между векторами таким образом, чтобы большинство векторов были доступны из любой точки через небольшое количество переходов. Это так называемое свойство "маленького мира", которое позволяет быстро перемещаться. Смотрите рисунок выше.</p>
<p>Граф инициализируется как пустой. Мы перебираем векторы, добавляя каждый из них в граф по очереди. Для каждого вектора, начиная со случайного начального узла, мы жадно находим ближайшие R узлов, достижимых из начальной точки <em>в построенном на данный момент графе</em>. Эти R узлов затем соединяются с новым узлом, представляющим вставляемый вектор, при необходимости обрезая все соседние узлы, которые теперь имеют более R соседей. Повторение этого процесса для всех векторов приведет к получению графа NSW. Смотрите иллюстрацию выше, визуализирующую алгоритм, а теоретический анализ свойств графа, построенного подобным образом, см. в ресурсах в конце статьи.</p>
<h2 id="Searching-the-Graph" class="common-anchor-header">Поиск в графе<button data-href="#Searching-the-Graph" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Мы уже познакомились с алгоритмом поиска на примере его использования при построении графа. Однако в данном случае узел запроса предоставляется пользователем, а не вставляется в граф. Начиная со случайной записи, мы жадно переходим к ее ближайшему к запросу соседу, сохраняя динамический набор ближайших векторов, встреченных на данный момент. См. иллюстрацию выше. Обратите внимание, что мы можем повысить точность поиска, начав поиск с нескольких случайных точек входа и агрегируя результаты, а также рассматривая несколько соседей на каждом шаге. Однако эти улучшения достигаются за счет увеличения времени ожидания.</p>
<custom-h1>Добавление иерархии</custom-h1><p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/adding_hierarchy_0101234812.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p>До сих пор мы описывали алгоритм NSW и структуру данных, которые могут помочь нам увеличить масштаб поиска в высокоразмерном пространстве. Тем не менее, метод имеет серьезные недостатки, включая неудачу в низких размерностях, медленную сходимость поиска и тенденцию к застреванию в локальных минимумах.</p>
<p>Авторы HNSW устраняют эти недостатки с помощью трех модификаций NSW:</p>
<ul>
<li><p>Явный выбор входных узлов при построении и поиске;</p></li>
<li><p>Разделение ребер по различным масштабам; и,</p></li>
<li><p>Использование продвинутой эвристики для выбора соседей.</p></li>
</ul>
<p>Первые два пункта реализуются с помощью простой идеи: построения <em>иерархии поисковых графов</em>. Вместо одного графа, как в NSW, HNSW строит иерархию графов. В каждом графе, или слое, выполняется индивидуальный поиск так же, как и в NSW. Верхний слой, который ищется первым, содержит очень мало узлов, а более глубокие слои постепенно включают все больше и больше узлов, а нижний слой включает все узлы. Это означает, что верхние слои содержат более длинные переходы по векторному пространству, что позволяет осуществлять своего рода поиск от курса к точке. Иллюстрацию см. выше.</p>
<h2 id="Constructing-the-Graph" class="common-anchor-header">Построение графа<button data-href="#Constructing-the-Graph" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Алгоритм построения работает следующим образом: мы заранее фиксируем количество слоев, <em>L</em>. Значение l=1 будет соответствовать самому грубому слою, с которого начинается поиск, а l=L - самому плотному слою, на котором поиск заканчивается. Мы перебираем каждый вектор, который нужно вставить, и выбираем слой вставки, следуя усеченному <a href="https://en.wikipedia.org/wiki/Geometric_distribution">геометрическому распределению</a> (либо отвергая <em>l &gt; L</em>, либо задавая <em>l' =</em> min_(l, L)_). Допустим, для текущего вектора мы делаем выборку <em>1 &lt; l &lt; L</em>. Мы выполняем жадный поиск на верхнем слое, L, пока не достигнем его локального минимума. Затем мы следуем по ребру от локального минимума в _L_-м слое к соответствующему вектору в _(L-1)_-м слое и используем его как точку входа для жадного поиска в _(L-1)_-м слое.</p>
<p>Этот процесс повторяется до тех пор, пока мы не достигнем _l_-го слоя. Затем мы начинаем создавать узлы для вставляемого вектора, соединяя его с ближайшими соседями, найденными в результате жадного поиска в _l_-м слое, который был построен до сих пор, переходим на _(l-1)_-й слой и повторяем, пока не вставим вектор в _1_-й слой. Анимация выше наглядно демонстрирует это.</p>
<p>Мы видим, что этот метод построения иерархического графа использует умный явный выбор узла вставки для каждого вектора. Мы перебираем слои над слоем вставки, построенным до сих пор, осуществляя эффективный поиск от расстояния от курса до точки. Кроме того, метод разделяет связи по разным масштабам в каждом слое: верхний слой позволяет совершать длинные прыжки по пространству поиска, а масштаб уменьшается к нижнему слою. Обе эти модификации помогают избежать ловушек в субоптимальных минимумах и ускоряют сходимость поиска за счет дополнительной памяти.</p>
<h2 id="Searching-the-Graph" class="common-anchor-header">Поиск на графе<button data-href="#Searching-the-Graph" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Процедура поиска работает аналогично шагу построения внутреннего графа. Начиная с верхнего слоя, мы жадно переходим к узлу или узлам, наиболее близким к запросу. Затем мы следуем за этим узлом (узлами) вниз на следующий слой и повторяем процесс. Ответ мы получаем из списка <em>R</em> ближайших соседей в нижнем слое, как показано на анимации выше.</p>
<h2 id="Conclusion" class="common-anchor-header">Заключение<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Векторные базы данных, такие как Milvus, обеспечивают высоко оптимизированную и настроенную реализацию HNSW, и часто это лучший поисковый индекс по умолчанию для наборов данных, которые умещаются в памяти.</p>
<p>Мы набросали высокоуровневый обзор того, как и почему работает HNSW, отдавая предпочтение визуализации и интуиции, а не теории и математике. Поэтому мы опустили точное описание алгоритмов построения и поиска<a href="https://arxiv.org/abs/1603.09320">[Malkov and Yashushin, 2016</a>; Alg 1-3], анализ сложности поиска и построения<a href="https://arxiv.org/abs/1603.09320">[Malkov and Yashushin, 2016</a>; §4.2] и менее существенные детали, такие как эвристика для более эффективного выбора соседних узлов при построении<a href="https://arxiv.org/abs/1603.09320">[Malkov and Yashushin, 2016</a>; Alg 5]. Кроме того, мы опустили обсуждение гиперпараметров алгоритма, их значения и того, как они влияют на компромисс между задержкой/скоростью/памятью<a href="https://arxiv.org/abs/1603.09320">[Malkov and Yashushin, 2016</a>; §4.1]. Понимание этого важно для использования HNSW на практике.</p>
<p>Нижеприведенные ресурсы содержат дополнительную литературу по этим темам и полную педагогическую реализацию на Python (написанную мной) для NSW и HNSW, включая код для создания анимации в этой статье.</p>
<custom-h1>Ресурсы</custom-h1><ul>
<li><p>GitHub: "<a href="https://github.com/stefanwebb/hnsw-illustrated">HNSW-Illustrated: Небольшая реализация Hierarchical Navigable Small Worlds (HNSW), алгоритма векторного поиска, для целей обучения</a>".</p></li>
<li><p><a href="https://milvus.io/docs/hnsw.md#HNSW">Документация по HNSW | Milvus</a></p></li>
<li><p><a href="https://zilliz.com/learn/hierarchical-navigable-small-worlds-HNSW">Понимание иерархических перемещаемых малых миров (HNSW) - Zilliz Learn</a></p></li>
<li><p>Документ HNSW: "<a href="https://arxiv.org/abs/1603.09320">Эффективный и надежный приближенный поиск ближайших соседей с использованием иерархических графов Hierarchical Navigable Small World</a>"</p></li>
<li><p>Работа NSW: "<a href="https://publications.hse.ru/pubs/share/folder/x5p6h7thif/128296059.pdf">Алгоритм приближенного поиска ближайших соседей на основе навигационных графов малого мира</a>"</p></li>
</ul>
