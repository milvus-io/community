---
id: building-an-intelligent-news-recommendation-system-inside-sohu-news-app.md
title: Рекомендация контента с помощью семантического векторного поиска
author: milvus
date: 2021-06-08T01:42:53.489Z
desc: >-
  Узнайте, как с помощью Milvus была создана интеллектуальная система
  рекомендаций новостей в приложении.
cover: assets.zilliz.com/blog_Sohu_News_dec53d0814.jpg
tag: Scenarios
canonicalUrl: >-
  https://zilliz.com/blog/building-an-intelligent-news-recommendation-system-inside-sohu-news-app
---
<custom-h1>Создание интеллектуальной системы рекомендаций новостей в приложении Sohu News</custom-h1><p>Поскольку <a href="https://www.socialmediatoday.com/news/new-research-shows-that-71-of-americans-now-get-news-content-via-social-pl/593255/">71% американцев</a> получают рекомендации по новостям с социальных платформ, персонализированный контент быстро стал способом обнаружения новых медиа. Независимо от того, ищут ли люди конкретные темы или взаимодействуют с рекомендованным контентом, все, что видят пользователи, оптимизируется алгоритмами для повышения коэффициента кликов (CTR), вовлеченности и релевантности. Sohu - это китайская группа онлайн-медиа, видео, поиска и игр, зарегистрированная на бирже NASDAQ. Она использовала <a href="https://milvus.io/">Milvus</a>, векторную базу данных с открытым исходным кодом, созданную компанией <a href="https://zilliz.com/">Zilliz</a>, для создания семантической векторной поисковой системы в своем новостном приложении. В этой статье рассказывается о том, как компания использовала профили пользователей для точной настройки персонализированных рекомендаций контента с течением времени, улучшая пользовательский опыт и вовлеченность.</p>
<h2 id="Recommending-content-using-semantic-vector-search" class="common-anchor-header">Рекомендация контента с помощью семантического векторного поиска<button data-href="#Recommending-content-using-semantic-vector-search" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Профили пользователей Sohu News создаются на основе истории посещений и корректируются по мере того, как пользователи ищут и взаимодействуют с новостным контентом. Рекомендательная система Sohu использует семантический векторный поиск для поиска релевантных новостных статей. Система определяет набор тегов, которые, как ожидается, будут интересны каждому пользователю на основе истории просмотров. Затем она быстро ищет релевантные статьи и сортирует результаты по популярности (измеряемой средним CTR), а затем предлагает их пользователям.</p>
<p>Только New York Times публикует <a href="https://www.theatlantic.com/technology/archive/2016/05/how-many-stories-do-newspapers-publish-per-day/483845/">230 статей</a> в день, что дает представление о масштабах нового контента, который должна уметь обрабатывать эффективная рекомендательная система. Для обработки больших объемов новостей требуется миллисекундный поиск по сходству и ежечасное сопоставление тегов с новым контентом. Sohu выбрала Milvus, потому что он эффективно и точно обрабатывает огромные массивы данных, сокращает потребление памяти при поиске и поддерживает высокопроизводительные развертывания.</p>
<h2 id="Understanding-a-news-recommendation-system-workflow" class="common-anchor-header">Понимание рабочего процесса системы рекомендаций новостей<button data-href="#Understanding-a-news-recommendation-system-workflow" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Рекомендация контента на основе семантического векторного поиска в Sohu основана на глубокой структурированной семантической модели (DSSM), которая использует две нейронные сети для представления пользовательских запросов и новостных статей в виде векторов. Модель вычисляет косинусоидальное сходство двух семантических векторов, после чего наиболее похожая партия новостей отправляется в пул кандидатов на рекомендацию. Далее новостные статьи ранжируются на основе их предполагаемого CTR, и те из них, которые имеют самый высокий прогнозируемый показатель кликов, отображаются пользователям.</p>
<h3 id="Encoding-news-articles-into-semantic-vectors-with-BERT-as-service" class="common-anchor-header">Кодирование новостных статей в семантические векторы с помощью BERT-as-service</h3><p>Для кодирования новостных статей в семантические векторы система использует инструмент <a href="https://github.com/hanxiao/bert-as-service.git">BERT-as-service</a>. Если при использовании этой модели количество слов в любом фрагменте контента превышает 512, в процессе встраивания происходит потеря информации. Чтобы помочь преодолеть эту проблему, система сначала извлекает резюме и кодирует его в 768-мерный семантический вектор. Затем из каждой новостной статьи извлекаются две наиболее релевантные темы, и на основе идентификатора темы определяются соответствующие предварительно обученные векторы тем (200 измерений). Затем векторы тем объединяются с 768-мерным семантическим вектором, извлеченным из резюме статьи, образуя 968-мерный семантический вектор.</p>
<p>Новый контент постоянно поступает через Kafta и преобразуется в семантические векторы перед вставкой в базу данных Milvus.</p>
<h3 id="Extracting-semantically-similar-tags-from-user-profiles-with-BERT-as-service" class="common-anchor-header">Извлечение семантически схожих тегов из профилей пользователей с помощью BERT-as-service</h3><p>Другая нейронная сеть модели - это семантический вектор пользователя. Семантически схожие теги (например, коронавирус, ковид, COVID-19, пандемия, новый штамм, пневмония) извлекаются из профилей пользователей на основе интересов, поисковых запросов и истории посещений. Список полученных тегов сортируется по весу, а 200 лучших делятся на различные семантические группы. Перестановки тегов в каждой семантической группе используются для генерации новых фраз тегов, которые затем кодируются в семантические векторы с помощью BERT-сервиса.</p>
<p>Для каждого пользовательского профиля наборы фраз-тегов имеют <a href="https://github.com/baidu/Familia">соответствующий набор тем</a>, которые помечаются весом, указывающим на уровень заинтересованности пользователя. Две лучшие темы из всех релевантных тем выбираются и кодируются моделью машинного обучения (ML) для встраивания в соответствующий семантический вектор тега, формируя 968-мерный семантический вектор пользователя. Даже если система генерирует одинаковые теги для разных пользователей, различные веса для тегов и соответствующих им тем, а также явная дисперсия между векторами тем каждого пользователя обеспечивают уникальность рекомендаций.</p>
<p>Система способна создавать персонализированные новостные рекомендации, вычисляя косинусное сходство семантических векторов, извлеченных как из профилей пользователей, так и из новостных статей.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/Sohu01_1e466fe0c3.jpg" alt="Sohu01.jpg" class="doc-image" id="sohu01.jpg" />
   </span> <span class="img-wrapper"> <span>Sohu01.jpg</span> </span></p>
<h3 id="Computing-new-semantic-user-profile-vectors-and-inserting-them-to-Milvus" class="common-anchor-header">Вычисление новых семантических векторов профилей пользователей и вставка их в Milvus</h3><p>Векторы семантических профилей пользователей вычисляются ежедневно, причем данные за предыдущий 24-часовой период обрабатываются вечером следующего дня. Векторы вставляются в Milvus по отдельности и проходят через процесс запроса, чтобы предоставить пользователям релевантные результаты новостей. Новостной контент по своей сути является актуальным, поэтому вычисления необходимо выполнять ежечасно, чтобы сформировать текущую ленту новостей, содержащую контент с высоким прогнозируемым коэффициентом кликов и релевантный для пользователей. Новостной контент также сортируется в разделы по дате, а старые новости удаляются ежедневно.</p>
<h3 id="Decreasing-semantic-vector-extraction-time-from-days-to-hours" class="common-anchor-header">Сокращение времени извлечения семантических векторов с нескольких дней до нескольких часов</h3><p>Поиск контента с использованием семантических векторов требует ежедневного преобразования десятков миллионов фраз тегов в семантические векторы. Это трудоемкий процесс, требующий нескольких дней, даже при работе с графическими процессорами (GPU), которые ускоряют подобные вычисления. Чтобы преодолеть эту техническую проблему, необходимо оптимизировать семантические векторы, полученные в результате предыдущего встраивания, чтобы при появлении похожих фраз тегов соответствующие семантические векторы извлекались напрямую.</p>
<p>Семантический вектор существующего набора фраз-тегов сохраняется, а новый набор фраз-тегов, который генерируется ежедневно, кодируется в векторы MinHash. <a href="https://milvus.io/docs/v1.1.1/metric.md">Расстояние Жаккара</a> используется для вычисления сходства между вектором MinHash новой фразы тега и сохраненным вектором фразы тега. Если расстояние Жаккара превышает заданный порог, два набора считаются похожими. Если порог сходства соблюден, новые фразы могут использовать семантическую информацию из предыдущих вкраплений. Тесты показывают, что расстояние выше 0,8 гарантирует достаточную точность для большинства ситуаций.</p>
<p>Благодаря этому процессу ежедневное преобразование десятков миллионов векторов, о которых говорилось выше, сокращается с нескольких дней до примерно двух часов. Хотя другие методы хранения семантических векторов могут быть более подходящими в зависимости от конкретных требований проекта, вычисление сходства между двумя фразами тегов с помощью расстояния Жаккара в базе данных Milvus остается эффективным и точным методом в самых разных сценариях.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/Sohu02_d50fccc538.jpg" alt="Sohu02.jpg" class="doc-image" id="sohu02.jpg" />
   </span> <span class="img-wrapper"> <span>Sohu02.jpg</span> </span></p>
<h2 id="Overcoming-bad-cases-of-short-text-classification" class="common-anchor-header">Преодоление "плохих случаев" классификации коротких текстов<button data-href="#Overcoming-bad-cases-of-short-text-classification" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>При классификации новостных текстов короткие новостные статьи имеют меньше признаков для извлечения, чем длинные. Из-за этого алгоритмы классификации терпят неудачу, когда контент разной длины пропускается через один и тот же классификатор. Milvus помогает решить эту проблему путем поиска нескольких фрагментов информации о классификации длинных текстов с похожей семантикой и надежными оценками, а затем использует механизм голосования для изменения классификации коротких текстов.</p>
<h3 id="Identifying-and-resolving-misclassified-short-text" class="common-anchor-header">Выявление и устранение ошибок в классификации короткого текста</h3><p>Точная классификация каждой новостной статьи имеет решающее значение для предоставления полезных рекомендаций по содержанию. Поскольку короткие новостные статьи содержат меньше признаков, применение одного и того же классификатора для новостей разной длины приводит к увеличению числа ошибок при классификации коротких текстов. Человеческая маркировка слишком медленная и неточная для этой задачи, поэтому BERT-as-service и Milvus используются для быстрого выявления неправильно классифицированных коротких текстов в партиях, их правильной переклассификации, а затем использования партий данных в качестве корпуса для обучения против этой проблемы.</p>
<p>BERT-as-service используется для кодирования пяти миллионов длинных новостных статей с оценкой классификатора более 0,9 в семантические векторы. После вставки длинных текстовых статей в Milvus, короткие текстовые новости кодируются в семантические векторы. Каждый семантический вектор коротких новостей используется для запроса к базе данных Milvus и получения 20 лучших длинных новостных статей с наибольшим косинусным сходством с целевой короткой новостью. Если 18 из 20 наиболее похожих по семантике длинных новостей оказываются в одной и той же классификации, но она отличается от классификации запрошенной короткой новости, то классификация коротких новостей считается неверной и должна быть скорректирована, чтобы соответствовать 18 длинным новостным статьям.</p>
<p>Этот процесс быстро выявляет и исправляет неточные классификации коротких текстов. Статистика случайной выборки показывает, что после исправления классификаций коротких текстов общая точность классификации текста превышает 95 %. Используя классификацию длинных текстов с высокой степенью достоверности для исправления классификации коротких текстов, можно за короткий промежуток времени исправить большинство неудачных классификаций. Кроме того, это хороший корпус для обучения классификатора коротких текстов.</p>
<p>![Sohu03.jpg](https://assets.zilliz.com/Sohu03_a43074cf5f.jpg "Блок-схема обнаружения "плохих случаев" классификации коротких текстов").</p>
<h2 id="Milvus-can-power-real-time-news-content-recommendation-and-more" class="common-anchor-header">Milvus может обеспечить рекомендации новостного контента в режиме реального времени и многое другое<button data-href="#Milvus-can-power-real-time-news-content-recommendation-and-more" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Milvus значительно улучшил производительность системы рекомендаций новостей Sohu в реальном времени, а также повысил эффективность выявления неправильно классифицированных коротких текстов. Если вам интересно узнать больше о Milvus и его различных применениях:</p>
<ul>
<li>Читайте наш <a href="https://zilliz.com/blog">блог</a>.</li>
<li>Общайтесь с нашим сообществом разработчиков с открытым исходным кодом в <a href="https://join.slack.com/t/milvusio/shared_invite/zt-e0u4qu3k-bI2GDNys3ZqX1YCJ9OM~GQ">Slack</a>.</li>
<li>Используйте самую популярную в мире векторную базу данных на <a href="https://github.com/milvus-io/milvus/">GitHub</a> или вносите в нее свой вклад.</li>
<li>Быстро тестируйте и внедряйте приложения для ИИ с помощью нашего нового <a href="https://github.com/milvus-io/bootcamp">буткемпа</a>.</li>
</ul>
