---
id: 2021-09-26-onnx.md
title: Обработка моделей с помощью ONNX
date: 2021-09-26T00:00:00.000Z
desc: >-
  как использовать несколько моделей для поиска изображений на основе ONNX и
  Milvus
cover: assets.zilliz.com/medium_1_cfb009269a.png
tag: Engineering
canonicalUrl: >-
  https://zilliz.com/blog/combine-ai-models-for-image-search-using-onnx-and-milvus
---
<custom-h1>Объединение моделей ИИ для поиска изображений с помощью ONNX и Milvus</custom-h1><p>Open Neural Network Exchange (ONNX) - это открытый формат, созданный для представления моделей машинного обучения. С момента своего появления в открытом доступе в 2017 году ONNX превратился в стандарт для ИИ, предоставляя строительные блоки для моделей машинного обучения и глубокого обучения. ONNX определяет общий формат файлов, позволяющий разработчикам ИИ использовать модели в различных фреймворках, инструментах, средах выполнения и компиляторах, и помогает увеличить скорость инноваций в сообществе искусственного интеллекта.</p>
<p>Milvus - это векторная база данных с открытым исходным кодом, которая отличается высокой гибкостью, надежностью и молниеносной скоростью. Она поддерживает добавление, удаление, обновление и поиск векторов практически в режиме реального времени. Milvus имеет обширный набор интуитивно понятных API и поддерживает множество широко распространенных библиотек индексов (например, Faiss, NMSLIB и Annoy), что упрощает выбор индекса для конкретного сценария. Milvus прост в использовании и применяется в сотнях организаций и учреждений по всему миру, включая поиск изображений, аудио и видео, рекомендации, чатботы, поиск новых лекарств и т. д.</p>
<p>В этой статье мы расскажем вам, как использовать несколько моделей для поиска изображений на основе ONNX и Milvus. В качестве примера взяты модели VGG16 и ResNet50, с помощью ONNX запущены различные модели искусственного интеллекта для создания векторов признаков, а затем в Milvus выполнен поиск по векторам признаков для возврата похожих изображений.</p>
<h2 id="Process-Models-with-ONNX" class="common-anchor-header">Обработка моделей с помощью ONNX<button data-href="#Process-Models-with-ONNX" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Формат ONNX позволяет легко обмениваться данными между моделями ИИ. Например, модель TensorFlow можно преобразовать в формат ONNX и запустить в среде Caffe. В этом примере мы конвертируем предварительно обученную модель ResNet50 во фреймворке Keras в формат ONNX, а затем вызываем модель VGG16 в формате ONNX для анализа различных моделей.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> keras.applications.resnet50 <span class="hljs-keyword">import</span> ResNet50
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># load keras-resnet50 model and save as a floder</span>
model_resnet50 = ResNet50(include_top=<span class="hljs-literal">False</span>, pooling=<span class="hljs-string">&#x27;max&#x27;</span>, weights=<span class="hljs-string">&#x27;imagenet&#x27;</span>)
tf.saved_model.save(model_resnet50, <span class="hljs-string">&quot;keras_resnet50_model&quot;</span>)

<span class="hljs-comment"># convert resnet50 model to onnx</span>
! python -m tf2onnx.convert --saved-model <span class="hljs-string">&quot;keras_resnet50_model&quot;</span> --output <span class="hljs-string">&quot;onnx_resnet50.onnx&quot;</span>
<button class="copy-code-btn"></button></code></pre>
<p>Примечание: Когда мы использовали интерфейс <code translate="no">keras2onnx.convert_keras(model, model.name)</code> для преобразования модели, он вернет ошибку <code translate="no">AttributeError:'KerasTensor' object has no attribute'graph'</code>. Тогда мы можем использовать команду Bash в Python для конвертации в соответствии с решением на Stack Overflow.</p>
<h2 id="Extract-Feature-Vectors-using-Models" class="common-anchor-header">Извлечение векторов признаков с помощью моделей<button data-href="#Extract-Feature-Vectors-using-Models" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>После преобразования модели ResNet50 в формат ONNX можно извлечь вектор признаков изображения непосредственно через вывод. Примечание: Векторы признаков необходимо нормализовать после извлечения.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># get the image vectors with onnx model</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_onnx_vectors</span>(<span class="hljs-params">onnx_model, img_path</span>):
    img = image.load_img(img_path, target_size=(<span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=<span class="hljs-number">0</span>)
    x = preprocess_input(x)
    
    sess = onnxruntime.InferenceSession(onnx_model)
    x = x <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(x, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">else</span> [x]
    feed = <span class="hljs-built_in">dict</span>([(<span class="hljs-built_in">input</span>.name, x[n]) <span class="hljs-keyword">for</span> n, <span class="hljs-built_in">input</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sess.get_inputs())])
    feat = sess.run(<span class="hljs-literal">None</span>, feed)[<span class="hljs-number">0</span>]
    
    norm_feat = feat[<span class="hljs-number">0</span>] / LA.norm(feat[<span class="hljs-number">0</span>])
    norm_feat = [i.item() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> norm_feat]
    <span class="hljs-keyword">return</span> norm_feat
<button class="copy-code-btn"></button></code></pre>
<p>Для обработки данных изображений используйте модель VGG16 в формате ONNX:</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># generate vectors with ResNet50 and VGG16 ONNX model</span>
2vec_resnet = get_onnx_vectors(<span class="hljs-string">&quot;onnx_resnet50.onnx&quot;</span>, <span class="hljs-string">&quot;./pic/example.jpg&quot;</span>)
3vec_vgg = get_onnx_vectors(<span class="hljs-string">&quot;onnx_vgg16.onnx&quot;</span>, <span class="hljs-string">&quot;./pic/example.jpg&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Store-Vector-Data" class="common-anchor-header">Хранение векторных данных<button data-href="#Store-Vector-Data" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Неструктурированные данные, такие как изображения, не могут быть напрямую обработаны компьютером, но они могут быть преобразованы в векторы с помощью модели искусственного интеллекта и затем проанализированы компьютером. Векторная база данных Milvus предназначена для массового анализа неструктурированных данных. Она может хранить векторные данные и выполнять анализ практически в режиме реального времени. Сначала создайте коллекцию соответствующей модели в Milvus, а затем вставьте в нее векторы изображений.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> milvus <span class="hljs-keyword">import</span> *

<span class="hljs-comment"># create collections in Milvus</span>
milvus.create_collection(resnet_collection_param)
milvus.create_collection(vgg_collection_param)

<span class="hljs-comment"># insert data to Milvus and return ids</span>
status, resnet_ids = milvus.insert(resnet_collection_name, resnet_vectors)
status, vgg_ids = milvus.insert(vgg_collection_name, vgg_vectors)
<button class="copy-code-btn"></button></code></pre>
<p>После успешной вставки данных Milvus вернет ID, соответствующий вектору, и мы сможем найти изображение по ID. Поскольку используемый в данном случае Milvus 1.1 не поддерживает скалярную фильтрацию (которую теперь поддерживает Milvus 2.0), для хранения идентификатора вектора и ключа-значения пути к изображению используется Redis.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> redis
<span class="hljs-keyword">def</span> <span class="hljs-title function_">img_ids_to_redis</span>(<span class="hljs-params">img_directory, res_ids</span>):
  <span class="hljs-keyword">for</span> img, ids <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(images, res_ids):
    redis.<span class="hljs-built_in">set</span>(ids, img)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Search-for-Similar-Images" class="common-anchor-header">Поиск похожих изображений<button data-href="#Search-for-Similar-Images" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>После хранения данных мы можем извлечь вектор. Milvus поддерживает несколько методов расчета расстояния, включая евклидово, внутреннее произведение и расстояние Хэмминга. При поиске сходства изображений в этой статье используется вычисление евклидова расстояния между векторами в Milvus, возвращается идентификатор похожего вектора, а затем находится изображение, соответствующее этому идентификатору в Redis.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># search in Milvus and return the similarly results with ids</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">search_in_milvus</span>(<span class="hljs-params">collection_name, search_vector</span>):
    status, results = milvus.search(collection_name, TOP_K, [search_vector])
    <span class="hljs-built_in">print</span>(status)
    re_ids = [x.<span class="hljs-built_in">id</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
    re_distance = [x.distance <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
    <span class="hljs-keyword">return</span> re_ids, re_distance
    
<span class="hljs-comment"># get the images according the result ids</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_sim_imgs</span>(<span class="hljs-params">collection_name, search_vector</span>):
    ids, distance = search_in_milvus(collection_name, search_vector)
    img = [red.get(i).decode(<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ids]
    <span class="hljs-keyword">return</span> ids, distance, img
<button class="copy-code-btn"></button></code></pre>
<p>На примере моделей VGG16 и ResNet50 в этой статье показана обработка нескольких моделей с помощью ONNX и объединение нескольких моделей с Milvus для поиска похожих векторов с целью получения похожих изображений. Две вышеупомянутые модели основаны на фреймворке Keras, который позволяет быстро извлекать векторы признаков. Из блокнота видно, что, хотя результаты поиска Milvus изображений в наборе данных COCO на основе этих двух моделей похожи, их евклидовы расстояния не одинаковы. Вы также можете попробовать сравнить результаты поиска этих двух моделей с помощью других наборов данных.</p>
<p>Milvus - это высокопроизводительная и доступная база данных векторов, которую можно использовать для обработки векторов признаков, полученных из массивных неструктурированных данных. Для получения более подробных решений вы можете обратиться к <a href="https://github.com/milvus-io/bootcamp">Milvus bootcamp</a>.</p>
<h2 id="References" class="common-anchor-header">Ссылки<button data-href="#References" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ol>
<li>https://github.com/onnx/onnx</li>
<li>https://onnx.ai/</li>
<li>https://milvus.io/cn/</li>
<li>https://github.com/milvus-io/bootcamp</li>
</ol>
<h3 id="About-author" class="common-anchor-header">Об авторе</h3><p>Шиюй Чен, инженер по обработке данных в Zilliz, окончила Сидяньский университет по специальности "Компьютерные науки". С момента прихода в Zilliz она занималась поиском решений для Milvus в различных областях, таких как анализ аудио и видео, поиск формул молекул и т. д., что значительно обогатило сценарии применения сообщества. В настоящее время она занимается поиском новых интересных решений. В свободное время она любит спорт и чтение.</p>
