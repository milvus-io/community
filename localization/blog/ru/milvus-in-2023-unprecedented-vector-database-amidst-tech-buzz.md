---
id: milvus-in-2023-unprecedented-vector-database-amidst-tech-buzz.md
title: '2023 год: год ИИ'
author: James Luan
date: 2024-01-05T00:00:00.000Z
desc: >-
  Размышления о всей индустрии векторных баз данных с особым акцентом на Milvus
  - выдающемся продукте в этом ландшафте.
cover: >-
  assets.zilliz.com/Milvus_in_2023_An_Atypical_Vector_DB_Amidst_Tech_Buzz_1_1151400765.png
tags: 'Milvus, Vector Database, LLM, RAG, Open Source, Artificial Intelligence'
recommend: true
canonicalUrl: >-
  https://thenewstack.io/milvus-in-2023-open-source-vector-database-year-in-review/
---
<p>
 <span class="img-wrapper">
   <img translate="no" src="https://assets.zilliz.com/image_7_1c3b05e71c.jpg" alt="This image is generated by AI. " class="doc-image" id="this-image-is-generated-by-ai.-" />
   <span>Это изображение создано искусственным интеллектом. </span> </span>
  
</p>
<custom-h1>Милвус в 2023 году: Беспрецедентная база данных векторов на фоне технологической шумихи</custom-h1><p><em>Этот пост был написан Джеймсом Луаном при помощи ChatGPT. Джеймс в основном писал подсказки, а также просматривал и полировал контент, сгенерированный ИИ.</em></p>
<h2 id="2023-the-year-of-AI" class="common-anchor-header">2023 год: год ИИ<button data-href="#2023-the-year-of-AI" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>2023 год станет поворотным пунктом в развитии искусственного интеллекта (ИИ). <a href="https://zilliz.com/glossary/large-language-models-(llms)">Большие языковые модели (LLM)</a> заняли центральное место, получив широкое признание благодаря своим исключительным возможностям обработки естественного языка. Этот всплеск популярности существенно расширил возможности приложений машинного обучения, позволив разработчикам создавать более интеллектуальные и интерактивные приложения.</p>
<p>На фоне этой революции <a href="https://zilliz.com/learn/what-is-vector-database">векторные базы данных</a> стали важнейшим компонентом, выступающим в роли долговременной памяти для LLM. Появление моделей <a href="https://zilliz.com/use-cases/llm-retrieval-augmented-generation">Retrieval-Augmented Generation (RAG)</a>, интеллектуальных агентов и приложений для мультимодального поиска продемонстрировало огромный потенциал векторных баз данных в повышении эффективности мультимодального поиска данных, уменьшении галлюцинаций в LLM и дополнении знаний о домене.</p>
<p>Эволюция LLM также послужила катализатором значительного прогресса в технологиях встраивания. Согласно <a href="https://huggingface.co/spaces/mteb/leaderboard">таблице лидеров Massive Text Embedding Benchmark (MTEB)</a> на HuggingFace, ведущие модели встраивания, такие как UAE, VoyageAI, CohereV3 и Bge, были выпущены в 2023 году. Эти достижения повысили эффективность векторного поиска в различных технологиях векторного поиска, таких как Milvus, обеспечив более точные и эффективные возможности обработки данных для приложений ИИ.</p>
<p>Однако с ростом популярности векторных баз данных возникли споры о необходимости специализированных решений. На арену векторных баз данных вышли десятки стартапов. Многие традиционные реляционные и NoSQL-базы данных стали рассматривать векторы как важный тип данных, а многие утверждают, что способны заменить специализированные векторные базы данных в любой ситуации.</p>
<p>Сейчас, когда мы вступаем в 2024 год, самое время задуматься о всей индустрии векторных баз данных, уделив особое внимание Milvus - продукту, выделяющемуся на этом фоне.</p>
<h2 id="Milvus-in-2023-numbers-dont-lie" class="common-anchor-header">Milvus в 2023 году: цифры не лгут<button data-href="#Milvus-in-2023-numbers-dont-lie" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Впервые запущенный в 2019 году, <a href="https://zilliz.com/what-is-milvus">Milvus</a> стал пионером в области векторных баз данных и неизменно сохраняет репутацию надежного, масштабируемого, качественного и производительного продукта. В 2023 году Milvus добился впечатляющих результатов и претерпел значительные изменения, в первую очередь благодаря быстрому продвижению LLM и буму заявок на AIGC. Вот несколько ключевых показателей, которые лучше всего отражают прогресс Milvus в 2023 году.</p>
<h3 id="ZERO-downtime-during-rolling-upgrades" class="common-anchor-header">Нулевое время простоя во время скользящих обновлений</h3><p>Для тех, кто только начинает работать с векторными базами данных, основное внимание уделяется функциональности, а не оперативному обслуживанию. Многие разработчики приложений также уделяют меньше внимания стабильности векторных баз данных, чем транзакционных, поскольку их приложения часто находятся на ранних стадиях разработки. Однако стабильность становится незаменимой, если вы планируете развернуть свое приложение AIGC в производственной среде и добиться наилучшего пользовательского опыта.</p>
<p>Milvus отличает то, что приоритетом является не только функциональность, но и стабильность работы. Начиная с версии 2.2.3 мы добавили в Milvus функцию скользящих обновлений. После постоянных доработок эта функция обеспечивает нулевое время простоя во время обновлений без прерывания бизнес-процессов.</p>
<h3 id="3x-performance-improvement-in-production-environments" class="common-anchor-header">3-кратное повышение производительности в производственных средах</h3><p>Повышение производительности векторного поиска должно быть главной целью для векторных баз данных. Многие решения для векторного поиска предпочли основываться на адаптации алгоритма <a href="https://zilliz.com/learn/hierarchical-navigable-small-worlds-HNSW">HNSW</a>, чтобы быстро выйти на рынок; к сожалению, это привело к тому, что они столкнулись с серьезными проблемами в реальных производственных средах, особенно при поиске с высокой фильтрацией (более 90 %) и частом удалении данных. Milvus учитывает производительность с самого начала и отлично справляется с оптимизацией производительности на любом этапе разработки, особенно в производственных средах, добиваясь трехкратного улучшения производительности поиска, особенно в ситуациях с фильтрованным поиском и потоковой вставкой/поиском.</p>
<p>Чтобы помочь сообществу разработчиков векторных баз данных, в прошлом году мы представили <a href="https://github.com/zilliztech/VectorDBBench">VectorDBBench</a>, инструмент бенчмаркинга с открытым исходным кодом. Этот инструмент необходим для ранней оценки векторных баз данных в различных условиях. В отличие от традиционных методов оценки, VectorDBBench оценивает базы данных, используя реальные данные, в том числе сверхбольшие наборы данных или те, которые близко напоминают данные реальных моделей встраивания, предоставляя пользователям более глубокую информацию для принятия обоснованных решений.</p>
<h3 id="5-recall-improvement-on-the-Beir-dataset" class="common-anchor-header">Улучшение запоминания на 5 % на наборе данных Beir</h3><p>Хотя <a href="https://zilliz.com/learn/sparse-and-dense-embeddings">плотные вкрапления</a> доказали свою эффективность в векторном поиске, они должны наверстать упущенное при поиске имен, объектов, аббревиатур и коротких контекстов запросов. В ответ на их недостатки Milvus представила гибридный подход к запросам, который объединяет плотные вкрапления с <a href="https://zilliz.com/learn/sparse-and-dense-embeddings">разреженными вкраплениями</a> для повышения качества результатов поиска. Синергия этого гибридного решения с моделью ранжирования привела к значительному 5-процентному улучшению показателя отзыва на наборе данных Beir, что было подтверждено нашими тестами.</p>
<p>Не ограничиваясь улучшением качества поиска, Milvus также представила решение для поиска на основе графов, адаптированное для разреженных вкраплений и превосходящее по производительности обычные поисковые алгоритмы, такие как WAND.</p>
<p>На конкурсе NeurIPS BigANN 2023 года Зихао Ванг, талантливый инженер из Zilliz, представил <a href="https://big-ann-benchmarks.com/neurips23.html#winners">Pyanns</a>, поисковый алгоритм, который продемонстрировал значительное превосходство над другими участниками в треке поиска по разреженным вкраплениям. Это прорывное решение является предшественником наших алгоритмов поиска с разреженными вкраплениями для производственных сред.</p>
<h3 id="10x-memory-saving-on-large-datasets" class="common-anchor-header">10-кратная экономия памяти на больших массивах данных</h3><p>В 2023 году наиболее популярным вариантом использования векторных баз данных будет<a href="https://zilliz.com/use-cases/llm-retrieval-augmented-generation">поиск с расширением (Retrieval Augmented Generation</a>, RAG). Однако увеличение объемов векторных данных в приложениях RAG создает проблему хранения данных для этих приложений. Эта проблема особенно актуальна, когда объем преобразованных векторов превышает объем исходных фрагментов документов, что потенциально увеличивает затраты на использование памяти. Например, после разделения документов на чанки размер 1536-мерного вектора float32 (около 3 кб), преобразованного из чанка в 500 токенов (около 1 кб), превышает размер чанка в 500 токенов.</p>
<p>Milvus - первая векторная база данных с открытым исходным кодом, поддерживающая индексирование на диске, что позволяет добиться заметной 5-кратной экономии памяти. К концу 2023 года мы представили <a href="https://milvus.io/docs/release_notes.md#v234">Milvus 2.3.4</a>, в которой появилась возможность загружать скалярные и векторные данные/индексы на диск с помощью файлов с отображением памяти<a href="https://zilliz.com/blog/milvus-introduced-mmap-for-redefined-data-management-increased-storage-capability">(MMap</a>). Это достижение обеспечивает более чем 10-кратное сокращение использования памяти по сравнению с традиционным индексированием в памяти.</p>
<h3 id="20-Milvus-releases" class="common-anchor-header">20 выпусков Milvus</h3><p>В 2023 году Milvus прошел путь трансформации, отмеченный значительными вехами. За год мы выпустили 20 релизов, что стало свидетельством преданности более 300 разработчиков сообщества и реализации нашей приверженности подходу к разработке, ориентированному на пользователя.</p>
<p>В частности, в Milvus 2.2.9 была представлена <a href="https://zilliz.com/blog/what-is-dynamic-schema">динамическая схема</a>, что ознаменовало важный переход от приоритета производительности к повышению удобства использования. Основываясь на этом, в <a href="https://milvus.io/blog/unveiling-milvus-2-3-milestone-release-offering-support-for-gpu-arm64-cdc-and-other-features.md">Milvus 2.3</a> появились такие важные функции, как Upsert, <a href="https://zilliz.com/blog/unlock-advanced-recommendation-engines-with-milvus-new-range-search">Range Search</a>, Cosine metrics и другие. Все они были разработаны с учетом конкретных потребностей и отзывов наших пользователей. Этот итеративный процесс разработки подчеркивает наше стремление постоянно приводить Milvus в соответствие с меняющимися требованиями наших пользователей.</p>
<h3 id="1000000-tenants-in-a-Single-Custer" class="common-anchor-header">1 000 000 арендаторов в одном Кастере</h3><p>Реализация многопользовательской аренды имеет решающее значение для разработки систем RAG, агентов искусственного интеллекта и других приложений LLM, отвечающих повышенным требованиям пользователей к изоляции данных. Для B2C-компаний количество арендаторов может исчисляться миллионами, что делает физическую изоляцию пользовательских данных непрактичной (например, вряд ли кто-то будет создавать миллионы таблиц в реляционной базе данных). Milvus представил функцию Partition Key, позволяющую эффективно логически изолировать и фильтровать данные на основе ключей разделов, что очень удобно в больших масштабах.</p>
<p>И наоборот, предприятиям B2B, привыкшим работать с десятками тысяч арендаторов, выгоднее использовать более тонкую стратегию, предполагающую изоляцию физических ресурсов. В последней версии Milvus 2.3.4 улучшено управление памятью, работа с корутинами и оптимизация процессора, что упрощает создание десятков тысяч таблиц в рамках одного кластера. Это усовершенствование также отвечает потребностям B2B-компаний, повышая эффективность и контроль.</p>
<h3 id="10000000-Docker-image-pulls" class="common-anchor-header">10 000 000 извлечений образов Docker</h3><p>На исходе 2023 года Milvus достиг впечатляющего рубежа - <a href="https://hub.docker.com/r/milvusdb/milvus">10 миллионов</a> загрузок <a href="https://hub.docker.com/r/milvusdb/milvus">образов Docker</a>. Это достижение свидетельствует о растущем интересе сообщества разработчиков к Milvus и подчеркивает его растущее значение в области векторных баз данных.</p>
<p>Будучи первой в мире облачной нативной векторной базой данных, Milvus может похвастаться бесшовной интеграцией с Kubernetes и более широкой контейнерной экосистемой. Заглядывая в будущее, нельзя не задуматься о следующей точке фокуса в постоянно развивающемся ландшафте векторных баз данных. Может быть, это будет подъем бессерверных сервисов?</p>
<h3 id="10-billion-entities-in-a-single-collection" class="common-anchor-header">10 миллиардов сущностей в одной коллекции</h3><p>Хотя масштабируемость, возможно, и не занимает сейчас центральное место в феномене ИИ, она, безусловно, играет ключевую роль, а не просто является побочным явлением. Векторная база данных Milvus может легко масштабироваться и вмещать миллиарды векторных данных, не испытывая затруднений. Посмотрите, например, на одного из наших клиентов LLM. Milvus без труда помог этому клиенту хранить, обрабатывать и извлекать поразительные 10 миллиардов точек данных. Но как найти баланс между стоимостью и производительностью при работе с таким огромным объемом данных? Будьте уверены, у Mivus есть различные возможности, чтобы помочь вам решить эту проблему и повысить качество работы.</p>
<h2 id="Beyond-the-numbers-the-new-insights-into-vector-databases" class="common-anchor-header">За цифрами: новое понимание векторных баз данных<button data-href="#Beyond-the-numbers-the-new-insights-into-vector-databases" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Помимо числовых показателей, 2023 год обогатил нас ценными сведениями. Мы погрузились в тонкости ландшафта векторных баз данных, выйдя за рамки простой статистики, чтобы понять тонкие нюансы и развивающуюся динамику технологии векторного поиска.</p>
<h3 id="LLM-apps-are-still-in-the-early-stages" class="common-anchor-header">Приложения LLM все еще находятся на ранних стадиях.</h3><p>Вспоминая первые дни бума мобильного интернета, многие разработчики создавали простые приложения вроде фонариков или прогнозов погоды, которые со временем интегрировались в операционные системы смартфонов. В прошлом году большинство приложений AI Native, таких как AutoGPT, которое быстро набрало 100 000 звезд на GitHub, не приносили практической пользы, а представляли собой лишь осмысленные эксперименты. Для приложений векторных баз данных текущие сценарии использования могут быть лишь первой волной преобразований AI Native, и я с нетерпением жду появления новых убийственных сценариев использования.</p>
<h3 id="Vector-databases-go-toward-diversification" class="common-anchor-header">Векторные базы данных идут по пути диверсификации.</h3><p>Подобно эволюции баз данных на такие категории, как OLTP, OLAP и NoSQL, векторные базы данных демонстрируют явную тенденцию к диверсификации. Отходя от традиционной ориентации на онлайн-сервисы, значительное распространение получил оффлайн-анализ. Еще одним ярким примером этого сдвига является появление <a href="https://zilliz.com/blog/building-llm-apps-100x-faster-responses-drastic-cost-reduction-using-gptcache">GPTCache</a>, семантического кэша с открытым исходным кодом, выпущенного в 2023 году. Он повышает эффективность и скорость работы приложений на базе GPT, сохраняя и извлекая ответы, сгенерированные языковыми моделями.</p>
<p>Мы надеемся, что в следующем году векторные базы данных получат еще большее разнообразие приложений и системных конструкций.</p>
<h3 id="Vector-operations-are-becoming-more-complicated" class="common-anchor-header">Векторные операции становятся все сложнее.</h3><p>Хотя поддержка поиска по <a href="https://zilliz.com/glossary/anns">приближенным ближайшим соседям (ANN)</a> является определяющей особенностью векторных баз данных, она не является единственной. Распространенное мнение о том, что достаточно поддерживать поиск ближайших соседей, чтобы классифицировать базу данных как векторную или базу данных с поддержкой ИИ, слишком упрощает тонкости векторных операций. Помимо базовых возможностей гибридной скалярной фильтрации и векторного поиска, базы данных, предназначенные для "родных" приложений ИИ, должны поддерживать более сложные семантические возможности, такие как NN-фильтрация, KNN Join и кластерные запросы.</p>
<h3 id="Elastic-scalability-is-essential-for-AI-native-applications" class="common-anchor-header">Эластичная масштабируемость необходима для приложений, основанных на искусственном интеллекте.</h3><p>Экспоненциальный рост приложений с искусственным интеллектом, примером которого может служить ChatGPT, набравший за два месяца более 100 миллионов ежемесячных активных пользователей, превосходит все предыдущие бизнес-траектории. Быстрое масштабирование с 1 миллиона до 1 миллиарда точек данных приобретает первостепенное значение, как только компании достигают своего пика роста. Разработчики приложений для искусственного интеллекта выигрывают от модели обслуживания "оплата по факту", которую устанавливают поставщики LLM, что приводит к значительному сокращению операционных расходов. Аналогичным образом, хранение данных, соответствующее этой модели ценообразования, оказывается выгодным для разработчиков, позволяя им уделять больше внимания основной деятельности.</p>
<p>В отличие от языковых моделей (LLM) и различных других технологических систем, векторные базы данных работают в режиме состояния, требуя постоянного хранения данных для своей функциональности. Следовательно, при выборе векторных баз данных необходимо уделять первостепенное внимание эластичности и масштабируемости. Такая расстановка приоритетов обеспечивает соответствие динамическим требованиям развивающихся приложений ИИ, подчеркивая необходимость плавной адаптации к изменяющимся рабочим нагрузкам.</p>
<h3 id="Leveraging-machine-learning-in-vector-databases-can-yield-extraordinary-results" class="common-anchor-header">Использование машинного обучения в векторных базах данных может дать необыкновенные результаты.</h3><p>В 2023 году наши значительные инвестиции в проекты AI4DB (AI for Database) принесли замечательные результаты. В рамках наших усилий мы внедрили две важнейшие возможности в <a href="https://zilliz.com/cloud">Zilliz Cloud</a>, полностью управляемое решение Milvus: 1) AutoIndex, индекс с автоматической настройкой параметров, основанный на машинном обучении, и 2) стратегию разделения данных, основанную на кластеризации данных. Обе инновации сыграли решающую роль в значительном повышении производительности поиска в Zilliz Cloud.</p>
<h3 id="Open-source-vs-closed-source" class="common-anchor-header">Открытый исходный код против закрытого исходного кода</h3><p>В настоящее время лидируют закрытые LLM, такие как серия GPT от OpenAI и Claude, что ставит сообщество open-source в невыгодное положение из-за отсутствия сопоставимых вычислительных и информационных ресурсов.</p>
<p>Однако в рамках векторных баз данных открытый исходный код в конечном итоге станет предпочтительным выбором для пользователей. Выбор в пользу открытого исходного кода дает множество преимуществ, включая более разнообразные сценарии использования, ускоренную итерацию и создание более надежной экосистемы. Кроме того, системы баз данных настолько сложны, что они не могут позволить себе непрозрачность, часто ассоциирующуюся с LLM. Пользователи должны досконально разобраться в базе данных, прежде чем выбрать наиболее разумный подход к ее использованию. Более того, прозрачность, заложенная в открытом исходном коде, дает пользователям свободу и возможность настраивать базу данных в соответствии со своими потребностями.</p>
<h2 id="Epilogue---And-a-new-beginning" class="common-anchor-header">Эпилог - И новое начало!<button data-href="#Epilogue---And-a-new-beginning" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>2023 год стремительно проносится мимо трансформационных изменений, а история векторных баз данных только начинается. Наше путешествие с векторной базой данных Milvus - это не просто потеряться в шумихе AIGC. Вместо этого мы сосредоточились на тщательной разработке нашего продукта, выявлении и развитии прикладных задач, которые соответствуют нашим сильным сторонам, и неустанном служении нашим пользователям. Наша приверженность открытому исходному коду призвана устранить разрыв между нами и нашими пользователями, позволяя им чувствовать нашу преданность и мастерство даже на расстоянии".</p>
<p>В 2023 году также было основано множество стартапов в области ИИ и получены первые раунды финансирования. Очень интересно наблюдать за инновациями этих разработчиков, и это напоминает мне о том, почему я изначально занялся разработкой VectorDB. 2024 год станет годом, когда все эти инновационные приложения получат реальное развитие, привлекая не только финансирование, но и реальных платящих клиентов. Доход от клиентов будет предъявлять к разработчикам другие требования, поскольку создание полностью масштабируемого решения с минимальным временем простоя имеет первостепенное значение.</p>
<p>Давайте сделаем необычные вещи в 2024 году!</p>
