---
id: 2021-12-21-milvus-2.0.md
title: Эволюция облачной масштабируемой векторной базы данных Milvus
author: Jun Gu
date: 2021-12-21T00:00:00.000Z
desc: Процесс разработки новой архитектуры кластера баз данных Milvus.
cover: assets.zilliz.com/Evolution_dd677ce3be.png
tag: Engineering
---
<blockquote>
<p>В этой статье мы расскажем о том, как мы разрабатывали новую архитектуру кластера баз данных Milvus.</p>
</blockquote>
<h2 id="Objectives-of-Milvus-vector-database" class="common-anchor-header">Цели векторной базы данных Milvus<button data-href="#Objectives-of-Milvus-vector-database" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Когда идея создания <a href="https://github.com/milvus-io/milvus">векторной базы данных Milvus</a> впервые пришла нам в голову, мы хотели создать инфраструктуру данных, которая помогла бы людям ускорить внедрение ИИ в их организациях.</p>
<p>Для выполнения этой задачи мы поставили перед проектом Milvus две важнейшие цели.</p>
<h3 id="Ease-of-use" class="common-anchor-header">Простота использования</h3><p>AI/ML - это развивающаяся область, в которой постоянно появляются новые технологии. Большинство разработчиков не совсем знакомы с быстро развивающимися технологиями и инструментами ИИ. Разработчики уже потратили большую часть своей энергии на поиск, обучение и настройку моделей. Им трудно тратить дополнительные усилия на обработку большого количества векторов встраивания, генерируемых моделями. Не говоря уже о том, что работа с большим объемом данных - это всегда очень сложная задача.</p>
<p>Поэтому мы придаем "простоте использования" очень высокий приоритет, так как это может значительно снизить стоимость разработки.</p>
<h3 id="Low-running-costs" class="common-anchor-header">Низкие эксплуатационные расходы</h3><p>Одним из главных препятствий на пути внедрения ИИ в производство является обоснование возврата инвестиций. У нас будет больше возможностей внедрить наши приложения ИИ в производство с более низкими эксплуатационными расходами. А это будет способствовать увеличению потенциальной выгоды.</p>
<h3 id="Design-principles-of-Milvus-20" class="common-anchor-header">Принципы проектирования Milvus 2.0</h3><p>В Milvus 1.0 мы уже начали двигаться к этим целям. Но этого далеко не достаточно, особенно в плане масштабируемости и доступности. Тогда мы начали разработку Milvus 2.0, чтобы улучшить эти показатели. Принципы, которые мы заложили в эту новую версию, включают:</p>
<ul>
<li>Стремление к высокой масштабируемости и доступности</li>
<li>Опора на развитую облачную инфраструктуру и практику</li>
<li>Минимальный компромисс производительности в облаке</li>
</ul>
<p>Другими словами, мы хотим сделать кластер баз данных Milvus "облачным".</p>
<h2 id="The-evolution-of-database-clusters" class="common-anchor-header">Эволюция кластеров баз данных<button data-href="#The-evolution-of-database-clusters" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Векторная база данных - это новый вид баз данных, поскольку она работает с новыми типами данных (векторами). Однако перед ней стоят те же задачи, что и перед другими базами данных, с некоторыми собственными требованиями. В оставшейся части этой статьи я расскажу о том, что мы узнали из существующих реализаций кластеров баз данных, и о том, как мы разрабатывали новую архитектуру группы Milvus.</p>
<p>Если вас интересуют детали реализации групповых компонентов Milvus, пожалуйста, следите за документацией Milvus. Мы будем постоянно публиковать технические статьи в репозитории Milvus GitHub, на сайте Milvus и в блоге Milvus.</p>
<h3 id="The-ideal-database-cluster" class="common-anchor-header">Идеальный кластер баз данных</h3><blockquote>
<p>"Целься в малое, промахнись в малое".</p>
</blockquote>
<p>Давайте сначала перечислим важнейшие возможности, которыми должен обладать <strong>идеальный</strong> кластер баз данных.</p>
<ol>
<li>Взаимодействие и отсутствие единой точки отказа: пользователи, подключенные к разным членам группы, могут одновременно иметь доступ на чтение/запись к одному и тому же фрагменту данных.</li>
<li>Согласованность: разные члены группы должны видеть одни и те же данные.</li>
<li>Масштабируемость: мы можем добавлять или удалять членов группы на ходу.</li>
</ol>
<p>Честно говоря, все эти возможности трудно получить вместе. В современных реализациях кластеров баз данных людям приходится идти на компромисс с некоторыми из этих возможностей. Люди не ожидают идеального кластера баз данных, пока он может вписаться в пользовательские сценарии. Однако кластер "разделяй все" когда-то был очень близок к идеальному кластеру баз данных. Если мы хотим чему-то научиться, нам следует начать именно с этого.</p>
<h3 id="The-key-considerations-of-a-database-cluster" class="common-anchor-header">Ключевые аспекты кластера баз данных</h3><p>Кластер shared-everything имеет более длинную историю по сравнению с другими современными реализациями. Db2 data sharing group и Oracle RAC являются типичными кластерами shared-everything. Многие думают, что shared-everything означает совместное использование дисков. Это гораздо больше.</p>
<p>В кластере shared-everything есть только один вид базы данных, входящий в группу. Пользователи могут подключаться к любому из этих симметричных членов для доступа к любым данным. Что же такое "все", которое должно быть общим для того, чтобы это работало?</p>
<h4 id="The-sequence-of-events-in-the-group" class="common-anchor-header">Последовательность событий в группе</h4><p>Во-первых, последовательность событий в группе очень важна для разрешения потенциальных конфликтов, вызванных одновременным доступом разных членов группы. Для обозначения последовательности событий мы обычно используем порядковый номер записи журнала базы данных. В то же время порядковый номер записи журнала обычно генерируется из временной метки.</p>
<p>Таким образом, потребность в последовательности групповых событий равна потребности в глобальном таймере. Если бы мы могли иметь атомные часы для группы, это было бы просто замечательно. Однако Milvus - это проект программного обеспечения с открытым исходным кодом, а значит, мы должны полагаться на общедоступные ресурсы. На сегодняшний день атомные часы - это все еще опция премиум-класса для крупных компаний.</p>
<p>Мы реализовали компонент синхронизации времени в кластере баз данных Milvus 2.0. Ссылку на него вы можете найти в приложении.</p>
<h4 id="Global-locking" class="common-anchor-header">Глобальная блокировка</h4><p>В базе данных есть механизм блокировки для разрешения конфликтов одновременного доступа, будь то оптимистическая или пессимистическая блокировка. Аналогично, нам нужна глобальная блокировка для разрешения конфликтов одновременного доступа между разными членами группы.</p>
<p>Глобальная блокировка означает, что разные члены группы должны общаться друг с другом для согласования запросов на блокировку. На эффективность процесса согласования глобальной блокировки влияет несколько важных факторов:</p>
<ul>
<li>Скорость межсистемных соединений</li>
<li>Количество членов группы, которые должны участвовать в процессе переговоров</li>
<li>Частота конфликтов в группе.</li>
</ul>
<p>Типичный размер группы не превышает 100 человек. Например, Db2 DSG - 32, Oracle RAC - 100. Члены группы размещаются в одной серверной комнате, соединенной оптическим волокном для минимизации задержки передачи данных. Поэтому такой кластер иногда называют централизованным. Из-за ограничения размера группы для кластеров с общим доступом выбирают серверы высокого класса (мейнфреймы или миникомпьютеры, которые имеют гораздо большую емкость процессора, памяти, каналов ввода-вывода и т. д.).</p>
<p>В современной облачной среде это предположение об аппаратном обеспечении кардинально изменилось. Сегодня облачные центры обработки данных представляют собой высокоплотные серверные комнаты, заполненные тысячами (тысячами) товарных X86-серверов с TCP/IP-соединениями. Если мы будем опираться на эти серверы X86 для построения кластера баз данных, размер группы должен увеличиться до сотен (даже тысяч) машин. И в некоторых бизнес-сценариях мы захотим, чтобы эти сотни машин X86 были разбросаны по разным регионам. Таким образом, внедрение глобальной блокировки может оказаться нецелесообразным, поскольку производительность глобальной блокировки будет недостаточно высокой.</p>
<p>В Milvus 2.0 мы не будем реализовывать глобальную блокировку. С одной стороны, не будет обновления векторных данных. (Люди предпочитают удалять-вставлять вместо обновления.) Поэтому нам не нужно беспокоиться о конфликтах нескольких писателей на одном и том же фрагменте данных в группе Milvus с чередованием. В то же время мы можем использовать MVCC (multi-version concurrency control, метод управления параллелизмом, предотвращающий блокировку) для разрешения конфликтов между читателями и писателями.</p>
<p>С другой стороны, обработка векторных данных занимает гораздо больше памяти, чем обработка структурированных данных. Поэтому векторные базы данных требуют более высокой масштабируемости.</p>
<h4 id="Shared-in-memory-data-cache" class="common-anchor-header">Общий кэш данных в памяти</h4><p>Вкратце можно разделить механизм базы данных на две части: механизм хранения и механизм вычислений. Механизм хранения отвечает за две важнейшие задачи:</p>
<ul>
<li>Запись данных в постоянное хранилище для обеспечения их долговечности.</li>
<li>Загрузка данных из постоянного хранилища в кэш данных in-memory (он же буферный пул); это единственное место, где вычислительный механизм получает доступ к данным.</li>
</ul>
<p>В сценарии кластера баз данных что, если участник A обновил данные, кэшированные в участнике B? Как участник B может узнать, что срок хранения данных в памяти истек? Для решения этой проблемы в классическом кластере с общим доступом предусмотрен механизм аннулирования перекрестных буферов. Механизм перекрестного аннулирования буферов будет работать аналогично глобальной блокировке, если мы поддерживаем сильную согласованность между членами группы. Как уже говорилось, в современной облачной среде это нецелесообразно. <strong>Поэтому мы решили снизить уровень согласованности в группе Milvus, масштабируемой в облаке, до уровня возможной согласованности.</strong> Таким образом, механизм аннулирования перекрестных буферов в Milvus 2.0 может стать асинхронным процессом.</p>
<h4 id="Shared-storage" class="common-anchor-header">Совместное хранение</h4><p>Совместное хранение данных - это, вероятно, первое, о чем думают при обсуждении кластера баз данных.</p>
<p>За последние годы развития облачных хранилищ варианты хранения данных также значительно изменились. Сеть хранения данных (SAN) была (и остается) основой хранения данных в группе "все общее". Но в облачной среде SAN не существует. Базе данных приходится использовать локальный диск, подключенный к виртуальным машинам облака. Использование локального диска создает проблему согласованности данных между членами группы. Кроме того, нам приходится беспокоиться о высокой доступности членов группы.</p>
<p>Затем Snowflake стал отличной ролевой моделью для облачных баз данных, использующих облачное хранилище общего доступа (S3 storage). Это вдохновляет и Milvus 2.0. Как уже говорилось, мы намерены опираться на развитую облачную инфраструктуру. Но прежде чем мы сможем использовать облачное хранилище, нам нужно подумать о нескольких вещах.</p>
<p>Во-первых, хранилище S3 дешево и надежно, но оно не предназначено для мгновенного доступа к данным, как в сценариях с базами данных. Нам нужно создать компоненты данных (которые мы называем узлами данных в Milvus 2.0), чтобы соединить локальную память/диск и хранилище S3. Есть несколько примеров (например, Alluxio, JuiceFS и т. д.), которые мы можем изучить. Причина, по которой мы не можем интегрировать эти проекты напрямую, заключается в том, что мы ориентируемся на разную гранулярность данных. Alluxio и JuiceFS предназначены для наборов данных или POSIX-файлов, в то время как мы ориентируемся на уровень записей данных (векторов).</p>
<p>Когда векторные данные будут размещены в хранилище S3, ответ для метаданных будет прост: хранить их в ETCD. А как быть с данными журнала? В классических реализациях хранилище журналов также основано на SAN. Файлы журнала одного члена группы баз данных совместно используются в кластере баз данных для восстановления после сбоев. Поэтому это не было проблемой до тех пор, пока мы не перешли в облачную среду.</p>
<p>В статье Spanner компания Google показала, как она реализовала глобально распределенную базу данных (группу) с алгоритмом консенсуса Paxos. Вам нужно запрограммировать кластер базы данных как группу репликации машины состояний. Редо-журнал обычно является "состоянием", которое будет реплицироваться по всей группе.</p>
<p>Репликация redo-log с помощью алгоритмов консенсуса - мощный инструмент, и в некоторых бизнес-сценариях он имеет существенные преимущества. Но для векторной базы данных Milvus мы не нашли достаточных стимулов для создания группы репликации машины состояний в целом. Мы решили использовать облачную очередь/платформу обмена сообщениями (Apache Pulsar, Apache Kafka и т. д.) в качестве альтернативного облачного хранилища журналов. Делегировав хранение журналов платформе обмена сообщениями, мы получили следующие преимущества.</p>
<ul>
<li>Группа в большей степени ориентирована на события, а значит, многие процессы могут быть асинхронными. Это улучшает масштабируемость.</li>
<li>Компоненты более слабо связаны друг с другом, что значительно упрощает выполнение скользящих обновлений в режиме онлайн. Повышается доступность и работоспособность.</li>
</ul>
<p>Мы вернемся к этой теме в следующем разделе.</p>
<p>Итак, мы рассмотрели важнейшие аспекты кластера баз данных. Прежде чем мы перейдем к обсуждению архитектуры Milvus 2.0, позвольте мне сначала объяснить, как мы управляем векторами в Milvus.</p>
<h3 id="Data-management-and-performance-predictability" class="common-anchor-header">Управление данными и предсказуемость производительности</h3><p>В Milvus векторы хранятся в коллекциях. Коллекция" - это логическая концепция, эквивалентная "таблице" в базах данных SQL. В "коллекции" может быть несколько физических файлов для хранения векторов. Физический файл - это &quot;сегмент&quot;. Сегмент" - это физическое понятие, подобное файлу табличного пространства в базах данных SQL. Когда объем данных невелик, мы можем сохранить все в одном сегменте/физическом файле. Но сегодня мы постоянно сталкиваемся с большими данными. Когда имеется несколько сегментов/физических файлов, как распределить данные по разным разделам данных?</p>
<p>Хотя на первом месте стоят данные, а не индексы, мы должны хранить данные так, как предпочитает алгоритм индексации, чтобы в большинстве случаев обеспечить эффективный доступ к данным. Часто используемой стратегией в базах данных SQL является разделение по диапазону значений ключа разделения. Обычно люди создают кластеризованный индекс для применения ключа разделения. В целом, это достойный подход для баз данных SQL. Данные хранятся в хорошем виде, оптимизированы для ввода-вывода (prefetch). Но недостатки все же есть.</p>
<ul>
<li>Перекос данных. В некоторых разделах может быть гораздо больше данных, чем в других. Распределение реальных данных не так просто, как числовой диапазон.</li>
<li>Горячие точки доступа. На некоторые разделы данных может приходиться больше нагрузки.</li>
</ul>
<p>Представьте, что больше нагрузки приходится на разделы с большим количеством данных. При возникновении таких ситуаций нам необходимо перераспределить данные между разделами. (Это утомительная повседневная жизнь DBA).</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/clustered_index_f4a3322668.png" alt="The Clustered index for vectors" class="doc-image" id="the-clustered-index-for-vectors" />
   </span> <span class="img-wrapper"> <span>Кластеризованный индекс для векторов</span> </span></p>
<p>Мы также можем создать кластеризованный индекс для векторов (индекс инвертированного списка). Но это не тот же случай, что и в базах данных SQL. Если в базах данных SQL индекс построен, то доступ к данным через него будет очень эффективным, с меньшими вычислениями и операциями ввода-вывода. Но для векторных данных даже при наличии индекса потребуется гораздо больше вычислений и операций ввода-вывода. Поэтому упомянутые выше недостатки будут иметь более серьезное влияние на кластеры векторных баз данных. Кроме того, стоимость ребалансировки векторов в разных сегментах очень высока из-за объема данных и сложности вычислений.</p>
<p>В Milvus мы используем стратегию разделения по росту. Когда мы вносим данные в коллекцию векторов, Milvus добавляет новые векторы в последний сегмент коллекции. Milvus закроет сегмент, как только его размер станет достаточно большим (порог настраивается), и построит индекс для закрытого сегмента. Тем временем будет создан новый сегмент для хранения новых данных. Эта простая стратегия более сбалансирована для векторной обработки.</p>
<p>Векторный запрос - это процесс поиска наиболее похожих кандидатов в коллекции векторов. Это типичная процедура MapReduce. Например, мы хотим найти 20 наиболее похожих результатов из коллекции векторов с десятью сегментами. Мы можем найти 20 лучших результатов в каждом из сегментов, а затем объединить результаты 20 * 10 в итоговые 20 результатов. Поскольку в каждом сегменте одинаковое количество векторов и одинаковый индекс, время обработки каждого сегмента практически одинаково. Это дает нам преимущество предсказуемости производительности, что очень важно при планировании масштаба кластеров баз данных.</p>
<h3 id="New-paradigms-in-Milvus-20" class="common-anchor-header">Новые парадигмы в Milvus 2.0</h3><p>В Milvus 1.0 мы реализовали шардинг с разделением на чтение и запись, как в большинстве баз данных SQL. Это была хорошая попытка масштабирования кластера баз данных Milvus. Но проблемы тоже вполне очевидны.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/milvus_1_0_9b7441a58f.png" alt="Milvus database 1.0" class="doc-image" id="milvus-database-1.0" />
   </span> <span class="img-wrapper"> <span>База данных Milvus 1.0</span> </span></p>
<p>В Milvus 1.0 узел R/W должен полностью заботиться о последнем сегменте, включая векторное добавление, поиск в этом неиндексированном сегменте, построение индекса и т. д. Поскольку у каждой коллекции есть только один писатель, он очень занят, если данные непрерывно поступают в систему. Также проблемой является производительность обмена данными между узлом R/W и узлами чтения. Кроме того, для совместного хранения данных мы должны полагаться либо на NFS (нестабильно), либо на премиальные облачные хранилища (слишком дорого).</p>
<p>Эти существующие проблемы трудно решить в архитектуре Milvus 1.0. Поэтому мы внедрили новые парадигмы в дизайн Milvus 2.0, чтобы решить эти проблемы.</p>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/Milvus_architecture_feaccc489d.png" alt="Milvus architecture" class="doc-image" id="milvus-architecture" />
   </span> <span class="img-wrapper"> <span>Архитектура Milvus</span> </span></p>
<h4 id="Actor-model" class="common-anchor-header">Акторная модель</h4><p>Существует две модели программирования параллельных вычислительных систем.</p>
<ul>
<li>Общая память, которая подразумевает контроль параллелизма (блокировку) и синхронную обработку.</li>
<li>Модель акторов (она же модель передачи сообщений) означает управление сообщениями и асинхронную обработку.</li>
</ul>
<p>Эти две модели мы можем применить и в кластерах распределенных баз данных.</p>
<p>Как уже говорилось, большинство известных распределенных баз данных используют один и тот же метод: репликацию redo-log по алгоритмам консенсуса. Это синхронная обработка с использованием алгоритмов консенсуса для создания распределенной общей памяти для записей redo-log. Различные компании и венчурные капиталы вложили в эту технологию миллиарды долларов. Я не хотел комментировать это, пока мы не начали работать над Milvus 2.0. Многие считают эту технологию единственным способом реализации распределенных систем баз данных. Это раздражает. Если я промолчу, люди могут понять, что мы были безрассудны в проектировании распределенных баз данных.</p>
<p>В последние годы репликация Redo-log с помощью алгоритмов консенсуса была самой переоцененной технологией баз данных. Здесь есть две ключевые проблемы.</p>
<ul>
<li>Предположение о том, что репликация redo-log лучше, является хрупким.</li>
<li>Поставщики вводят людей в заблуждение относительно возможностей алгоритмов консенсуса.</li>
</ul>
<p>Допустим, у нас есть два узла базы данных, исходный и целевой. В самом начале у них есть точные копии данных. Мы выполняем некоторые операции изменения (I/U/D SQL-операторы) на узле-источнике и хотим, чтобы целевой узел обновлялся. Что мы должны сделать? Самый простой способ - воспроизвести операции на целевом узле. Но это не самый эффективный способ.</p>
<p>Размышляя о стоимости выполнения оператора I/U/D, мы можем разделить ее на подготовку к выполнению и физическую работу. Подготовка к выполнению включает в себя работу SQL-парсера, SQL-оптимизатора и т. д. Независимо от того, сколько записей данных будет затронуто, это фиксированная стоимость. Стоимость физической части работы зависит от того, сколько записей данных будет затронуто; это плавающая стоимость. Идея репликации redo-log заключается в экономии фиксированных затрат на целевом узле; на целевом узле мы воспроизводим только redo-log (физическую работу).</p>
<p>Процент экономии зависит от количества записей redo-log. Если одна операция затрагивает только одну запись, я должен увидеть значительную экономию от репликации redo-log. А если речь идет о 10 000 записей? Тогда стоит задуматься о надежности сети. Что надежнее - отправка одной операции или 10 000 записей redo-log? А как насчет миллиона записей? Репликация redo-log - это супер в таких сценариях, как платежные системы, системы метаданных и т. д. В этих сценариях каждая операция ввода/вывода из базы данных затрагивает лишь небольшое количество записей (1 или 2). Но с интенсивными нагрузками ввода-вывода, такими как пакетные задания, работать сложно.</p>
<p>Поставщики всегда утверждают, что алгоритмы консенсуса могут обеспечить сильную согласованность в кластерах баз данных. Но люди используют алгоритмы консенсуса только для репликации записей redo-log. Записи redo-log согласованы на разных узлах, но это не означает, что представления данных на других узлах тоже согласованы. Мы должны объединить записи redo-log в реальные записи таблицы. Поэтому даже при такой синхронной обработке мы все равно можем получить только конечную согласованность представлений данных.</p>
<p>Мы должны использовать репликацию redo-log по алгоритмам консенсуса в соответствующих местах. В системе метаданных (ETCD) и платформе обмена сообщениями (например, Apache Pulsar), используемых в Milvus 2.0, реализованы алгоритмы консенсуса. Но, как я уже говорил, "для векторной базы данных Milvus мы не находим достаточных стимулов для того, чтобы быть группой репликации государственной машины в целом".</p>
<p>В Milvus 2.0 мы используем модель акторов для организации рабочих узлов. Рабочие узлы одиноки. Они общаются только с платформой обмена сообщениями, получая команды и отправляя результаты. Это звучит скучно.</p>
<blockquote>
<p>&quot;Каков наш девиз?&quot; - &quot;Скука всегда лучше&quot; - The Hitman's Bodyguard (2017).</p>
</blockquote>
<p>Акторная модель является асинхронной. Она подходит для масштабируемости и доступности. Поскольку рабочие узлы не знают друг друга, присоединение или удаление некоторых рабочих узлов не оказывает влияния на другие рабочие узлы.</p>
<h4 id="Separation-of-availability-and-durability" class="common-anchor-header">Разделение доступности и долговечности</h4><p>В Milvus 2.0 мы делаем повтор операций, а не повтор журналов, потому что в векторной базе данных нет большой разницы между повтором операций и повтором журналов. У нас нет ни функции Update, ни функции Insert with Select. Кроме того, воспроизведение операций гораздо проще осуществлять с помощью модели акторов.</p>
<p>Таким образом, несколько рабочих узлов могут выполнять одну и ту же операцию из платформы обмена сообщениями в соответствии со своими обязанностями. Я уже упоминал, что мы решили использовать облачное хранилище S3 в качестве общего уровня хранения кластера баз данных Milvus. Хранилище S3 очень надежно. Тогда есть ли необходимость в том, чтобы разные рабочие узлы записывали одни и те же данные в общее хранилище?</p>
<p>Поэтому мы разработали три роли для рабочих узлов.</p>
<ul>
<li>Узел запросов поддерживает представление данных в памяти в соответствии с заданием. Работа узла запроса включает в себя выполнение векторного поиска и поддержание данных в памяти в актуальном состоянии. При этом ему не нужно ничего записывать в хранилище S3. Это самый чувствительный к памяти узел в группе.</li>
<li>Узел данных отвечает за запись новых данных в хранилище S3. Узлу данных не нужно поддерживать представление данных в памяти, поэтому аппаратная конфигурация узла данных существенно отличается от узла запросов.</li>
<li>Индексный узел строит индексы для сегментов, закрытых узлом данных, когда размер сегментов достигает порогового значения. Это самая ресурсоемкая работа в группе.</li>
</ul>
<p>Эти три типа узлов представляют различные виды рабочей нагрузки. Они могут масштабироваться независимо друг от друга. Мы называем это разделением доступности и долговечности, о котором узнали из облачной базы данных Microsoft Socrates.</p>
<h2 id="The-end-also-the-beginning" class="common-anchor-header">Конец, но и начало<button data-href="#The-end-also-the-beginning" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>В этой статье мы рассмотрели несколько проектных решений векторной базы данных Milvus 2.0.  Давайте быстро подведем итоги.</p>
<ul>
<li>Мы выбрали конечную согласованность для кластера Milvus 2.0.</li>
<li>Мы интегрировали зрелые облачные компоненты в Milvus 2.0 настолько, насколько это было возможно. Мы контролировали внедрение новых компонентов Milvus 2.0 в производственные среды пользователей.</li>
<li>Благодаря модели акторов и разделению доступности и долговечности Milvus 2.0 легко масштабируется в облачной среде.</li>
</ul>
<p>На данный момент мы сформировали основу базы данных Milvus 2.0, масштабируемой в облаке, но в нашем бэклоге есть множество требований от сообщества Milvus, которые необходимо удовлетворить. Если вы придерживаетесь той же миссии ("Создавать больше инфраструктурного программного обеспечения с открытым исходным кодом для ускорения трансформации ИИ"), добро пожаловать в сообщество Milvus.</p>
<p>Milvus - это выпускной проект фонда LF AI &amp; Data. Вам НЕ нужно подписывать никаких CLA для Milvus!</p>
<h2 id="Appendix" class="common-anchor-header">Приложение<button data-href="#Appendix" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Milvus-design-doc" class="common-anchor-header">Дизайн-документ Milvus</h3><p><a href="https://github.com/milvus-io/milvus/tree/master/docs/design_docs">https://github.com/milvus-io/milvus/tree/master/docs/design_docs</a></p>
<ul>
<li><a href="https://github.com/milvus-io/milvus/blob/master/docs/design_docs/20211215-milvus_timesync.md">Синхронизация времени в Milvus</a></li>
</ul>
<h3 id="Raft-implementation-in-C++" class="common-anchor-header">Реализация Raft на C++</h3><p>Если вас все еще интересует алгоритм консенсуса, я предлагаю вам ознакомиться с <a href="https://github.com/eBay/Gringofts">проектом с открытым исходным кодом Gringofts от eBay</a>. Это реализация на C++ алгоритма консенсуса Raft (вариант семейства Paxos). Мои друзья Джеки и Элвис (мои бывшие коллеги по Morgan Stanley) создали его для системы онлайн-платежей eBay, которая как раз является одним из наиболее подходящих сценариев для этой технологии.</p>
