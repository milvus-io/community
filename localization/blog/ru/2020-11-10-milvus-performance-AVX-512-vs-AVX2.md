---
id: milvus-performance-AVX-512-vs-AVX2.md
title: Что такое расширенные векторные расширения?
author: milvus
date: 2020-11-10T22:15:39.156Z
desc: >-
  Узнайте, как Milvus работает на AVX-512 по сравнению с AVX2, используя
  различные векторные индексы.
cover: assets.zilliz.com/header_milvus_performance_avx_512_vs_avx2_2c9f14ef96.png
tag: Engineering
canonicalUrl: 'https://zilliz.com/blog/milvus-performance-AVX-512-vs-AVX2'
---
<custom-h1>Производительность Milvus на AVX-512 в сравнении с AVX2</custom-h1><p>Сознательные разумные машины, желающие захватить мир, - постоянный атрибут научной фантастики, но в реальности современные компьютеры очень послушны. Без подсказки они редко знают, что им делать. Компьютеры выполняют задачи, основываясь на инструкциях, или приказах, передаваемых из программы в процессор. На самом низком уровне каждая инструкция - это последовательность единиц и нулей, описывающая операцию, которую должен выполнить компьютер. Как правило, в компьютерных языках ассемблера каждый оператор машинного языка соответствует инструкции процессора. Центральный процессор (ЦП) опирается на инструкции для выполнения вычислений и управления системами. Кроме того, производительность процессора часто измеряется в терминах возможности выполнения инструкций (например, время выполнения).</p>
<h2 id="What-are-Advanced-Vector-Extensions" class="common-anchor-header">Что такое расширенные векторные расширения?<button data-href="#What-are-Advanced-Vector-Extensions" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Расширенные векторные расширения (AVX) - это набор инструкций для микропроцессоров, основанных на архитектуре набора инструкций семейства x86. Впервые предложенный Intel в марте 2008 года, AVX получил широкую поддержку три года спустя с выходом Sandy Bridge - микроархитектуры, используемой во втором поколении процессоров Intel Core (например, Core i7, i5, i3) - и конкурирующей микроархитектуры AMD, также выпущенной в 2011 году, Bulldozer.</p>
<p>AVX представила новую схему кодирования, новые возможности и новые инструкции. AVX2 расширяет большинство целочисленных операций до 256 бит и вводит операции умножения и накопления (FMA). AVX-512 расширяет AVX до 512-битных операций, используя новую кодировку префикса расширенного вектора (EVEX).</p>
<p><a href="https://milvus.io/docs">Milvus</a> - это векторная база данных с открытым исходным кодом, предназначенная для поиска сходств и приложений искусственного интеллекта (ИИ). Платформа поддерживает набор инструкций AVX-512, то есть может использоваться со всеми процессорами, в которых есть инструкции AVX-512. Milvus имеет широкое применение, охватывая системы рекомендаций, компьютерное зрение, обработку естественного языка (NLP) и многое другое. В этой статье представлены результаты производительности и анализ векторной базы данных Milvus на AVX-512 и AVX2.</p>
<h2 id="Milvus-performance-on-AVX-512-vs-AVX2" class="common-anchor-header">Производительность Milvus на AVX-512 по сравнению с AVX2<button data-href="#Milvus-performance-on-AVX-512-vs-AVX2" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="System-configuration" class="common-anchor-header">Конфигурация системы</h3><ul>
<li>ПРОЦЕССОР: Процессор Intel® Platinum 8163 @ 2,50 ГГц24 ядра 48 потоков</li>
<li>Количество процессоров: 2</li>
<li>Видеокарта, GeForce RTX 2080Ti 11GB 4 карты</li>
<li>Память: 768 ГБ</li>
<li>Диск: 2 ТБ SSD</li>
</ul>
<h3 id="Milvus-parameters" class="common-anchor-header">Параметры Milvus</h3><ul>
<li>cahce.cahe_size: 25, Размер памяти процессора, используемой для кэширования данных для ускорения запросов.</li>
<li>nlist: 4096</li>
<li>nprobe: 128</li>
</ul>
<p>Примечание: <code translate="no">nlist</code> - это параметр индексирования, создаваемый клиентом; <code translate="no">nprobe</code> - параметр поиска. И IVF_FLAT, и IVF_SQ8 используют алгоритм кластеризации для разбиения большого количества векторов на ведра, <code translate="no">nlist</code> - общее количество ведер для разбиения при кластеризации. Первый шаг в запросе - найти количество ведер, которые ближе всего к целевому вектору, а второй шаг - найти топ-к векторов в этих ведрах, сравнивая расстояние между векторами. <code translate="no">nprobe</code> означает количество ведер на первом шаге.</p>
<h3 id="Dataset-SIFT10M-dataset" class="common-anchor-header">Набор данных: Набор данных SIFT10M</h3><p>В этих тестах используется <a href="https://archive.ics.uci.edu/ml/datasets/SIFT10M">набор данных SIFT10M</a>, который содержит один миллион 128-мерных векторов и часто используется для анализа производительности соответствующих методов поиска ближайших соседей. Сравнивается время поиска top-1 для nq = [1, 10, 100, 500, 1000] между двумя наборами инструкций.</p>
<h3 id="Results-by-vector-index-type" class="common-anchor-header">Результаты по типу векторных индексов</h3><p><a href="https://zilliz.com/blog/Accelerating-Similarity-Search-on-Really-Big-Data-with-Vector-Indexing">Векторные индексы</a> - это экономичные по времени и пространству структуры данных, построенные на векторном поле коллекции с использованием различных математических моделей. Векторная индексация позволяет эффективно искать в больших массивах данных векторы, схожие с входным вектором. Из-за того, что точный поиск занимает много времени, большинство типов индексов <a href="https://milvus.io/docs/v2.0.x/index.md#CPU">, поддерживаемых Milvus</a>, используют приближенный поиск ближайших соседей (ANN).</p>
<p>Для этих тестов с AVX-512 и AVX2 использовались три индекса: IVF_FLAT, IVF_SQ8 и HNSW.</p>
<h3 id="IVFFLAT" class="common-anchor-header">IVF_FLAT</h3><p>Инвертированный файл (IVF_FLAT) - это тип индекса, основанный на квантовании. Это самый базовый IVF-индекс, и закодированные данные, хранящиеся в каждой единице, соответствуют исходным данным. Индекс делит векторные данные на некоторое количество кластеров (nlist), а затем сравнивает расстояния между целевым входным вектором и центром каждого кластера. В зависимости от количества кластеров, к которым система настроена на запрос (nprobe), результаты поиска сходства возвращаются на основе сравнений между целевым входным вектором и векторами только в наиболее похожих кластерах, что значительно сокращает время запроса. Настраивая nprobe, можно найти идеальный баланс между точностью и скоростью для конкретного сценария.</p>
<p><strong>Результаты работы</strong> <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/IVF_FLAT_3688377fc8.png" alt="IVF_FLAT.png" class="doc-image" id="ivf_flat.png" /><span>IVF_FLAT.png</span> </span></p>
<h3 id="IVFSQ8" class="common-anchor-header">IVF_SQ8</h3><p>IVF_FLAT не выполняет никакого сжатия, поэтому создаваемые им индексные файлы примерно того же размера, что и исходные, сырые неиндексированные векторные данные. Если ресурсы памяти диска, CPU или GPU ограничены, IVF_SQ8 - лучший вариант, чем IVF_FLAT. Этот тип индекса может преобразовать каждое измерение исходного вектора из четырехбайтового числа с плавающей точкой в однобайтовое целое без знака, выполнив скалярное квантование. Это позволяет сократить потребление памяти на диске, CPU и GPU на 70-75 %.</p>
<p><strong>Результаты производительности</strong> <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/IVF_SQ_8_bed28307f7.png" alt="IVF_SQ8.png" class="doc-image" id="ivf_sq8.png" /><span>IVF_SQ8.png</span> </span></p>
<h3 id="HNSW" class="common-anchor-header">HNSW</h3><p>Hierarchical Small World Graph (HNSW) - это алгоритм индексирования на основе графов. Запросы начинаются на самом верхнем уровне с поиска узла, ближайшего к цели, а затем переходят на следующий уровень для очередного раунда поиска. После нескольких итераций он может быстро приблизиться к целевой позиции.</p>
<p><strong>Результаты работы</strong> <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/HNSW_52aba39214.png" alt="HNSW.png" class="doc-image" id="hnsw.png" /><span>HNSW.png</span> </span></p>
<h2 id="Comparing-vector-indexes" class="common-anchor-header">Сравнение векторных индексов<button data-href="#Comparing-vector-indexes" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Векторный поиск на наборе инструкций AVX-512 стабильно быстрее, чем на AVX2. Это объясняется тем, что AVX-512 поддерживает 512-битные вычисления, в то время как AVX2 поддерживает только 256-битные вычисления. Теоретически AVX-512 должен быть вдвое быстрее AVX2, однако Milvus выполняет и другие трудоемкие задачи, помимо вычислений векторного сходства. В реальных условиях общее время поиска AVX-512 вряд ли будет вдвое меньше, чем AVX2. <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/comparison_a64b92f1dd.png" alt="comparison.png" class="doc-image" id="comparison.png" /><span>comparison.png</span> </span></p>
<p>Поиск по индексу HNSW значительно быстрее, чем по двум другим индексам, а поиск по IVF_SQ8 немного быстрее, чем по IVF_FLAT на обоих наборах инструкций. Вероятно, это связано с тем, что IVF_SQ8 требует всего 25 % памяти от объема, необходимого IVF_FLAT. IVF_SQ8 загружает 1 байт для каждой размерности вектора, в то время как IVF_FLAT загружает 4 байта для каждой размерности вектора. Время, необходимое для вычисления, скорее всего, ограничено пропускной способностью памяти. В результате IVF_SQ8 не только занимает меньше места, но и требует меньше времени для извлечения векторов.</p>
<h2 id="Milvus-is-a-versatile-high-performance-vector-database" class="common-anchor-header">Milvus - универсальная, высокопроизводительная база данных векторов<button data-href="#Milvus-is-a-versatile-high-performance-vector-database" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Тесты, представленные в этой статье, показывают, что Milvus обеспечивает отличную производительность на наборах инструкций AVX-512 и AVX2 при использовании различных индексов. Независимо от типа индекса, Milvus лучше работает на AVX-512.</p>
<p>Milvus совместим с различными платформами глубокого обучения и используется в различных приложениях ИИ. <a href="https://zilliz.com/news/lfaidata-launches-milvus-2.0-an-advanced-cloud-native-vector-database-built-for-ai">Milvus 2.0</a>, переосмысленная версия самой популярной в мире векторной базы данных, была выпущена под лицензией с открытым исходным кодом в июле 2021 года. Более подробную информацию о проекте можно найти на следующих ресурсах:</p>
<ul>
<li>Найдите Milvus на <a href="https://github.com/milvus-io/milvus/">GitHub</a> или внесите в него свой вклад.</li>
<li>Общайтесь с сообществом через <a href="https://join.slack.com/t/milvusio/shared_invite/zt-e0u4qu3k-bI2GDNys3ZqX1YCJ9OM~GQ">Slack</a>.</li>
<li>Общайтесь с нами в <a href="https://twitter.com/milvusio">Twitter</a>.</li>
</ul>
