---
id: optimizing-billion-scale-image-search-milvus-part-2.md
title: Система поиска по изображениям второго поколения
author: Rife Wang
date: 2020-08-11T22:20:27.855Z
desc: >-
  Пример использования Milvus для создания системы поиска по сходству
  изображений для реального бизнеса.
cover: assets.zilliz.com/header_c73631b1e7.png
tag: Scenarios
canonicalUrl: 'https://zilliz.com/blog/optimizing-billion-scale-image-search-milvus-part-2'
---
<custom-h1>Путешествие к оптимизации поиска изображений в миллиардных масштабах (2/2)</custom-h1><p>Эта статья - вторая часть статьи <strong>"Путешествие к оптимизации поиска изображений в миллиардных масштабах" от UPYUN</strong>. Если вы пропустили первую часть, нажмите <a href="https://zilliz.com/blog/optimizing-billion-scale-image-search-milvus-part-1">здесь</a>.</p>
<h2 id="The-second-generation-search-by-image-system" class="common-anchor-header">Система поиска по изображениям второго поколения<button data-href="#The-second-generation-search-by-image-system" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Система поиска по изображениям второго поколения технически выбирает решение CNN + Milvus. Эта система основана на векторах признаков и обеспечивает лучшую техническую поддержку.</p>
<h2 id="Feature-extraction" class="common-anchor-header">Извлечение признаков<button data-href="#Feature-extraction" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>В области компьютерного зрения использование искусственного интеллекта стало мейнстримом. Так и в системе поиска по изображениям второго поколения для извлечения признаков используется конволюционная нейронная сеть (CNN).</p>
<p>Термин CNN сложен для понимания. Здесь мы сосредоточимся на ответах на два вопроса:</p>
<ul>
<li>Что может делать CNN?</li>
<li>Почему я могу использовать CNN для поиска изображений?</li>
</ul>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/1_meme_649be6dfe8.jpg" alt="1-meme.jpg" class="doc-image" id="1-meme.jpg" />
   </span> <span class="img-wrapper"> <span>1-meme.jpg</span> </span></p>
<p>В области искусственного интеллекта проводится множество соревнований, и классификация изображений - одно из самых важных. Задача классификации изображений - определить, о чем идет речь: о кошке, собаке, яблоке, груше или других типах объектов.</p>
<p>Что может делать CNN? Он может извлекать признаки и распознавать объекты. Он извлекает признаки из нескольких измерений и измеряет, насколько близки признаки изображения к признакам кошек или собак. Мы можем выбрать наиболее близкие из них в качестве результата идентификации, который показывает, о чем идет речь на конкретном изображении - о кошке, собаке или о чем-то еще.</p>
<p>Какая связь между функцией идентификации объектов в CNN и поиском по изображению? Нам нужен не конечный результат идентификации, а вектор признаков, извлеченный из множества измерений. Векторы признаков двух изображений с похожим содержанием должны быть близки.</p>
<h3 id="Which-CNN-model-should-I-use" class="common-anchor-header">Какую модель CNN следует использовать?</h3><p>Ответ - VGG16. Почему стоит выбрать именно ее? Во-первых, VGG16 обладает хорошей способностью к обобщению, то есть она очень универсальна. Во-вторых, векторы признаков, извлекаемые VGG16, имеют 512 измерений. Если измерений очень мало, это может повлиять на точность. Если измерений слишком много, стоимость хранения и вычисления этих векторов признаков будет относительно высокой.</p>
<p>Использование CNN для извлечения признаков изображения является наиболее распространенным решением. В качестве модели мы можем использовать VGG16, а для технической реализации - Keras + TensorFlow. Вот официальный пример Keras:</p>
<pre><code translate="no">from keras.applications.vgg16 import VGG16
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input
import numpy as np
model = VGG16(weights=’imagenet’, include_top=False)
img_path = ‘elephant.jpg’
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
features = model.predict(x)
</code></pre>
<p>Извлеченные здесь признаки - это векторы признаков.</p>
<h3 id="1-Normalization" class="common-anchor-header">1. Нормализация</h3><p>Чтобы облегчить последующие операции, мы часто нормализуем признаки:</p>
<p>То, что используется в дальнейшем, также является нормализованным <code translate="no">norm_feat</code>.</p>
<h3 id="2-Image-description" class="common-anchor-header">2. Описание изображения</h3><p>Изображение загружается с помощью метода <code translate="no">image.load_img</code> из <code translate="no">keras.preprocessing</code>:</p>
<pre><code translate="no">from keras.preprocessing import image
img_path = 'elephant.jpg'
img = image.load_img(img_path, target_size=(224, 224))
</code></pre>
<p>Фактически, это метод TensorFlow, вызываемый Keras. Подробнее см. документацию по TensorFlow. Конечный объект изображения на самом деле является экземпляром PIL Image (PIL, используемый TensorFlow).</p>
<h3 id="3-Bytes-conversion" class="common-anchor-header">3. Преобразование байтов</h3><p>На практике содержимое изображений часто передается по сети. Поэтому вместо загрузки изображений из пути мы предпочитаем преобразовывать байтовые данные непосредственно в объекты изображений, то есть PIL Images:</p>
<pre><code translate="no">import io
from PIL import Image

# img_bytes: 图片内容 bytes
img = Image.open(io.BytesIO(img_bytes))
img = img.convert('RGB')

img = img.resize((224, 224), Image.NEAREST)
</code></pre>
<p>Приведенное выше изображение img совпадает с результатом, полученным методом image.load_img. Следует обратить внимание на два момента:</p>
<ul>
<li>Вы должны выполнить преобразование RGB.</li>
<li>Необходимо изменить размер (resize - второй параметр <code translate="no">load_img method</code>).</li>
</ul>
<h3 id="4-Black-border-processing" class="common-anchor-header">4. Обработка черной границы</h3><p>Изображения, например скриншоты, иногда могут иметь довольно много черных границ. Эти черные границы не имеют практической ценности и создают много помех. По этой причине удаление черных границ также является распространенной практикой.</p>
<p>Черная граница - это, по сути, строка или столбец пикселей, где все пиксели имеют значения (0, 0, 0) (RGB-изображение). Чтобы удалить черную границу, нужно найти эти строки или столбцы и удалить их. На самом деле это трехмерное умножение матрицы в NumPy.</p>
<p>Пример удаления горизонтальных черных границ:</p>
<pre><code translate="no"># -*- coding: utf-8 -*-
import numpy as np
from keras.preprocessing import image
def RemoveBlackEdge(img):
Args:
       img: PIL image instance
Returns:
       PIL image instance
&quot;&quot;&quot;
   width = img.width
   img = image.img_to_array(img)
   img_without_black = img[~np.all(img == np.zeros((1, width, 3), np.uint8), axis=(1, 2))]
   img = image.array_to_img(img_without_black)
return img
</code></pre>
<p>Это практически все, о чем я хочу рассказать, используя CNN для извлечения особенностей изображений и других способов их обработки. Теперь давайте посмотрим на векторные поисковые системы.</p>
<h2 id="Vector-search-engine" class="common-anchor-header">Векторная поисковая система<button data-href="#Vector-search-engine" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Проблема извлечения векторов признаков из изображений решена. Остались следующие проблемы:</p>
<ul>
<li>Как хранить векторы признаков?</li>
<li>Как вычислять сходство векторов признаков, то есть как искать? Векторная поисковая система Milvus с открытым исходным кодом может решить эти две проблемы. Пока что он хорошо работает в нашей производственной среде.</li>
</ul>
<p>
  
   <span class="img-wrapper"> <img translate="no" src="https://assets.zilliz.com/3_milvus_logo_3a7411f2c8.png" alt="3-milvus-logo.png" class="doc-image" id="3-milvus-logo.png" />
   </span> <span class="img-wrapper"> <span>3-milvus-logo.png</span> </span></p>
<h2 id="Milvus-the-vector-search-engine" class="common-anchor-header">Milvus, векторная поисковая система<button data-href="#Milvus-the-vector-search-engine" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Извлечь векторы признаков из изображения далеко не достаточно. Нам также необходимо динамически управлять этими векторами признаков (добавлять, удалять и обновлять), вычислять сходство векторов и возвращать данные векторов в диапазоне ближайших соседей. Векторный поисковик с открытым исходным кодом Milvus неплохо справляется с этими задачами.</p>
<p>В остальной части статьи будут описаны конкретные практики и моменты, на которые следует обратить внимание.</p>
<h3 id="1-Requirements-for-CPU" class="common-anchor-header">1. Требования к процессору</h3><p>Чтобы использовать Milvus, ваш процессор должен поддерживать набор инструкций avx2. Для систем Linux используйте следующую команду, чтобы проверить, какие наборы инструкций поддерживает ваш процессор:</p>
<p><code translate="no">cat /proc/cpuinfo | grep flags</code></p>
<p>В результате вы получите что-то вроде:</p>
<pre><code translate="no">flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb         rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2     ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm abm cpuid_fault epb invpcid_single pti intel_ppin tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts
</code></pre>
<p>За флагами следуют наборы инструкций, поддерживаемые вашим процессором. Конечно, это гораздо больше, чем мне нужно. Я просто хочу узнать, поддерживается ли определенный набор инструкций, например avx2. Просто добавьте grep для фильтрации:</p>
<pre><code translate="no">cat /proc/cpuinfo | grep flags | grep avx2
</code></pre>
<p>Если результат не возвращается, значит, этот конкретный набор инструкций не поддерживается. Тогда вам нужно сменить машину.</p>
<h3 id="2-Capacity-planning" class="common-anchor-header">2. Планирование мощностей</h3><p>Планирование емкости - это первое, на что мы обращаем внимание при проектировании системы. Сколько данных нам нужно хранить? Сколько памяти и дискового пространства требуется для этих данных?</p>
<p>Давайте сделаем несколько быстрых математических вычислений. Каждое измерение вектора - float32. Тип float32 занимает 4 байта. Значит, вектор из 512 измерений требует 2 КБ памяти. Аналогично:</p>
<ul>
<li>Тысяча 512-мерных векторов требуют 2 МБ памяти.</li>
<li>Один миллион 512-мерных векторов требует 2 ГБ памяти.</li>
<li>10 миллионов 512-мерных векторов требуют 20 ГБ памяти.</li>
<li>100 миллионов 512-мерных векторов требуют 200 ГБ памяти.</li>
<li>Один миллиард 512-мерных векторов требует 2 ТБ памяти.</li>
</ul>
<p>Если мы хотим хранить все данные в памяти, то системе нужен как минимум соответствующий объем памяти.</p>
<p>Рекомендуется использовать официальный инструмент для расчета размера: Milvus sizing tool.</p>
<p>На самом деле наша память может быть не такой уж и большой (это не имеет значения, если у вас недостаточно памяти. Milvus автоматически сбрасывает данные на диск). Помимо исходных векторных данных, нам также необходимо учитывать хранение других данных, таких как журналы.</p>
<h3 id="3-System-configuration" class="common-anchor-header">3. Конфигурация системы</h3><p>Более подробную информацию о конфигурации системы можно найти в документации по Milvus:</p>
<ul>
<li>Milvus server configuration: https://milvus.io/docs/v0.10.1/milvus_config.md.</li>
</ul>
<h3 id="4-Database-design" class="common-anchor-header">4. Проектирование базы данных</h3><p><strong>Коллекция и раздел</strong></p>
<ul>
<li>Коллекция также известна как таблица.</li>
<li>Под разделом понимаются разделы внутри коллекции.</li>
</ul>
<p>Базовая реализация раздела фактически совпадает с реализацией коллекции, за исключением того, что раздел находится под коллекцией. Но с помощью разделов организация данных становится более гибкой. Мы также можем запрашивать конкретный раздел в коллекции, чтобы добиться лучших результатов запроса.</p>
<p>Сколько у нас может быть коллекций и разделов? Основная информация о коллекциях и разделах находится в метаданных. Для управления внутренними метаданными Milvus использует либо SQLite (внутренняя интеграция Milvus), либо MySQL (требуется внешнее подключение). Если вы используете SQLite по умолчанию для управления метаданными, то при слишком большом количестве коллекций и разделов производительность будет сильно снижена. Поэтому общее число коллекций и разделов не должно превышать 50 000 (в Milvus 0.8.0 это число ограничено 4 096). Если вам необходимо задать большее число, рекомендуется использовать MySQL через внешнее соединение.</p>
<p>Структура данных, поддерживаемая коллекцией и разделом Milvus, очень проста, а именно <code translate="no">ID + vector</code>. Другими словами, в таблице всего два столбца: ID и векторные данные.</p>
<p><strong>Примечание:</strong></p>
<ul>
<li>ID должны быть целыми числами.</li>
<li>Нам нужно убедиться, что ID уникален в пределах коллекции, а не раздела.</li>
</ul>
<p><strong>Условная фильтрация</strong></p>
<p>Когда мы используем традиционные базы данных, мы можем указывать значения полей в качестве условий фильтрации. Хотя Milvus не фильтрует точно так же, мы можем реализовать простую условную фильтрацию с помощью коллекций и разделов. Например, у нас есть большой объем данных об изображениях, и эти данные принадлежат определенным пользователям. Тогда мы можем разделить данные на разделы по пользователям. Таким образом, использование пользователя в качестве условия фильтрации фактически является указанием раздела.</p>
<p><strong>Структурированные данные и векторное отображение</strong></p>
<p>Milvus поддерживает только структуру данных ID + вектор. Но в бизнес-сценариях нам нужны структурированные данные, несущие бизнес-смысл. Другими словами, нам нужно найти структурированные данные через векторы. Соответственно, нам нужно поддерживать отношения отображения между структурированными данными и векторами через ID.</p>
<pre><code translate="no">structured data ID &lt;--&gt; mapping table &lt;--&gt; Milvus ID
</code></pre>
<p><strong>Выбор индекса</strong></p>
<p>Вы можете обратиться к следующим статьям:</p>
<ul>
<li>Типы индексов: https://www.milvus.io/docs/v0.10.1/index.md</li>
<li>Как выбрать индекс: https://medium.com/@milvusio/how-to-choose-an-index-in-milvus-4f3d15259212</li>
</ul>
<h3 id="5-Processing-search-results" class="common-anchor-header">5. Обработка результатов поиска</h3><p>Результаты поиска в Milvus представляют собой коллекцию ID + расстояние:</p>
<ul>
<li>ID: ID в коллекции.</li>
<li>Расстояние: значение расстояния 0 ~ 1 указывает на уровень сходства; чем меньше значение, тем более похожи два вектора.</li>
</ul>
<p><strong>Фильтрация данных, чей ID равен -1</strong></p>
<p>Когда количество коллекций слишком мало, в результатах поиска могут оказаться данные, чей ID равен -1. Мы должны отфильтровать их самостоятельно.</p>
<p><strong>Пагинация</strong></p>
<p>Поиск по векторам осуществляется совершенно иначе. Результаты запроса сортируются в порядке убывания сходства, и выбираются наиболее похожие (topK) результаты (topK задается пользователем во время запроса).</p>
<p>Milvus не поддерживает пагинацию. Если нам нужна функция пагинации, мы должны реализовать ее самостоятельно. Например, если у нас есть десять результатов на каждой странице, а мы хотим отобразить только третью страницу, нам нужно указать topK = 30 и вернуть только последние десять результатов.</p>
<p><strong>Порог сходства для бизнеса</strong></p>
<p>Расстояние между векторами двух изображений находится в диапазоне от 0 до 1. Если мы хотим решить, похожи ли два изображения в конкретном бизнес-сценарии, нам нужно указать порог в этом диапазоне. Два изображения похожи, если расстояние меньше порога, или они сильно отличаются друг от друга, если расстояние больше порога. Вам необходимо настроить порог в соответствии с вашими потребностями.</p>
<blockquote>
<p>Эта статья написана rifewang, пользователем Milvus и инженером-программистом UPYUN. Если вам понравилась эта статья, заходите поздороваться с нами на https://github.com/rifewang.</p>
</blockquote>
