---
id: understanding-ivf-vector-index-how-It-works-and-when-to-choose-it-over-hnsw.md
title: IVFベクターインデックスを理解する：その仕組みとHNSWより選ぶべき場合
author: Jack Li
date: 2025-10-27T00:00:00.000Z
cover: assets.zilliz.com/ivf_1bbe0e9f85.png
tag: Tutorials
recommend: false
publishToMedium: true
tags: 'Milvus, vector database'
meta_keywords: 'IVF, ANN, HNSW, vector index, vector database'
meta_title: How to Choose Between IVF and HNSW for ANN Vector Search
desc: >-
  IVFベクトルインデックスがどのように機能するのか、どのようにANN検索を高速化するのか、そしてどのような場合に速度、メモリ、フィルタリング効率においてHNSWを上回るのかを学ぶ。
origin: >-
  https://milvus.io/blog/understanding-ivf-vector-index-how-It-works-and-when-to-choose-it-over-hnsw.md
---
<p>ベクトルデータベースでは、画像特徴、テキスト埋め込み、音声表現など、膨大な高次元ベクトルのコレクションから最も類似した結果を素早く見つける必要があります。インデックスがない場合、唯一の選択肢はクエリベクトルをデータセット内のすべてのベクトルと比較することです。この<strong>総当たり検索は</strong>、数千のベクトルであればうまくいくかもしれませんが、数千万、数億のベクトルを扱うようになると、耐えられないほど時間がかかり、計算コストが高くなります。</p>
<p>そこで登場するのが<strong>近似最近傍（ANN）</strong>検索だ。巨大な図書館で特定の本を探すようなものだと考えてほしい。すべての本を一冊ずつチェックするのではなく、その本がある可能性が最も高いセクションを閲覧することから始める。完全な検索と<em>まったく</em>同じ結果は得られないかもしれないが、非常に近い結果を、しかもほんのわずかな時間で得ることができる。要するに、ANNはわずかな精度の低下と引き換えに、スピードとスケーラビリティを大幅に向上させているのだ。</p>
<p>ANN検索を実装する多くの方法の中で、<strong>IVF（Inverted File</strong>）と<strong>HNSW（Hierarchical Navigable Small World）の</strong>2つが最も広く使われている。しかし、IVFは大規模なベクトル検索において、その効率性と適応性の高さで際立っている。この記事では、IVFがどのように機能し、HNSWとどのように比較するかを説明します。</p>
<h2 id="What-is-an-IVF-Vector-Index" class="common-anchor-header">IVFベクトルインデックスとは？<button data-href="#What-is-an-IVF-Vector-Index" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p><strong>IVF（Inverted File</strong>）は、ANNのアルゴリズムとして最も広く使われているものの1つです。IVFは、テキスト検索システムで使用される「転置インデックス」からその核となるアイデアを拝借していますが、今回は単語や文書の代わりに、高次元空間のベクトルを扱っています。</p>
<p>巨大な図書館を整理するようなものだ。すべての本（ベクトル）を巨大な山に捨てたら、必要なものを見つけるのに永遠に時間がかかるだろう。IVFは、まずすべてのベクトルをグループ（<em>バケツ</em>）に<strong>クラスタリングする</strong>ことでこれを解決します。各バケツは似たようなベクトルの「カテゴリー」を表し、<strong>重心によって</strong>定義される。</p>
<p>クエリーが来ると、検索は2つのステップで行われる：</p>
<p><strong>1.最も近いクラスターを見つける。</strong>システムは、セントロイドがクエリーベクトルに最も近いいくつかのバケットを探します。ちょうど、図書館で最も本がありそうな2つか3つのセクションにまっすぐ向かうようなものです。</p>
<p><strong>2.それらのクラスター内を検索する。</strong>一度正しいセクションに入れば、図書館全体ではなく、小さな本のセットに目を通すだけで済む。</p>
<p>この方法は、計算量を桁違いに減らすことができる。精度の高い結果が得られることに変わりはないが、そのスピードははるかに速い。</p>
<h2 id="How-to-Build-an-IVF-Vector-Index" class="common-anchor-header">IVFベクトル指数の構築方法<button data-href="#How-to-Build-an-IVF-Vector-Index" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>IVFベクトル・インデックスを構築するプロセスには、主に3つのステップがあります：K-meansクラスタリング、ベクトル割り当て、圧縮符号化（オプション）です。全プロセスは以下のようになります：</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/ivf_building_process_90c2966975.webp" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="Step-1-K-means-Clustering" class="common-anchor-header">ステップ 1: K-平均クラスタリング</h3><p>まず、データセットXに対してk-meansクラスタリングを実行し、高次元ベクトル空間をnlistクラスタに分割する。セントロイドの数nlistは、クラスタリングの細かさを決定する重要なハイパーパラメータである。</p>
<p>k-meansがどのように機能するかを説明しよう：</p>
<ul>
<li><p><strong>初期化：</strong> <em>nlist個の</em>ベクトルを初期セントロイドとしてランダムに選択する。</p></li>
<li><p><strong>割り当て：</strong>各ベクトルについて、すべてのセントロイドとの距離を計算し、最も近いものに割り当てる。</p></li>
<li><p><strong>更新：</strong>各クラスタについて、そのベクトルの平均を計算し、それを新しいセントロイドとして設定する。</p></li>
<li><p><strong>反復と収束：</strong>セントロイドが大きく変化しなくなるか、最大反復回数に達するまで、割り当てと更新を繰り返す。</p></li>
</ul>
<p>k-meansが収束すると、得られたnリストのセントロイドがIVFの「インデックス・ディレクトリ」を形成する。インデックス・ディレクトリは、データセットがどのように粗く分割されるかを定義し、クエリーが後で検索空間を素早く絞り込むことを可能にする。</p>
<p>図書館の例えを思い出してほしい。セントロイドを訓練することは、トピックごとに本をグループ分けする方法を決めるようなものだ：</p>
<ul>
<li><p>nlistが大きければセクションが増え、それぞれのセクションにはより少ない、より具体的な本が並ぶ。</p></li>
<li><p>nlistが小さければ、セクションは少なくなり、それぞれがより広範なトピックをカバーすることになります。</p></li>
</ul>
<h3 id="Step-2-Vector-Assignment" class="common-anchor-header">ステップ2：ベクトルの割り当て</h3><p>次に、各ベクトルは、そのセントロイドが最も近いクラスタに割り当てられ、転置リスト（List_i）が形成されます。各転置リストには、そのクラスタに属するすべてのベクトルのIDと格納情報が格納されます。</p>
<p>このステップは、本をそれぞれのセクションに棚分けするようなものだと考えることができます。後でタイトルを探すとき、図書館全体を歩き回るのではなく、そのタイトルがある可能性が高いいくつかのセクションをチェックするだけでよい。</p>
<h3 id="Step-3-Compression-Encoding-Optional" class="common-anchor-header">ステップ3：圧縮エンコーディング（オプション）</h3><p>メモリを節約し、計算を高速化するために、各クラスタ内のベクトルは圧縮エンコーディングを通過することができます。一般的なアプローチは2つある：</p>
<ul>
<li><p><strong>SQ8（スカラー量子化）：</strong>この方法は、ベクトルの各次元を8ビットに量子化します。標準的な<code translate="no">float32</code> ベクトルの場合、各次元は通常4バイトを占める。SQ8では、各次元はわずか1バイトに縮小され、ベクトルのジオメトリはほぼそのままに、4:1の圧縮率を達成します。</p></li>
<li><p><strong>PQ（積量子化）：</strong>高次元のベクトルをいくつかの部分空間に分割します。例えば、128次元のベクトルは、それぞれ16次元の8つの部分ベクトルに分割することができます。各サブスペースでは、小さなコードブック（通常256エントリ）が事前に訓練され、各サブベクトルは、最も近いコードブックエントリを指す8ビットのインデックスで表されます。つまり、元の128次元<code translate="no">float32</code> ベクトル（512バイト必要）は、わずか8バイト（8つの部分空間×各1バイト）で表現でき、64:1の圧縮率を達成できる。</p></li>
</ul>
<h2 id="How-to-Use-the-IVF-Vector-Index-for-Search" class="common-anchor-header">検索にIVFベクトルインデックスを使用する方法<button data-href="#How-to-Use-the-IVF-Vector-Index-for-Search" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>セントロイドテーブル、転置リスト、圧縮エンコーダとコードブック（オプション）が構築されると、IVFインデックスを使用して類似検索を高速化することができます。このプロセスには通常、以下のような3つの主要ステップがある：</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/ivf_search_process_025d3f444f.webp" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<h3 id="Step-1-Calculate-distances-from-the-query-vector-to-all-centroids" class="common-anchor-header">ステップ1：クエリーベクトルからすべてのセントロイドまでの距離を計算する。</h3><p>クエリベクトルqが到着すると、システムはまずそれがどのクラスタに属する可能性が高いかを決定する。次に、qとセントロイドテーブルCのすべてのセントロイドとの距離を計算する。通常、ユークリッド距離か内積を類似度メトリックとして使用する。次にセントロイドはクエリーベクトルとの距離でソートされ、最も近いものから遠いものまで順番に並べられる。</p>
<p>例えば、図に示すように、順序は次のようになる：C4 &lt; C2 &lt; C1 &lt; C3 &lt; C5。</p>
<h3 id="Step-2-Select-the-nearest-nprobe-clusters" class="common-anchor-header">ステップ2：最も近いnprobeクラスタを選択する</h3><p>データセット全体のスキャンを避けるため、IVFはクエリーベクトルに最も近い上位<em>nprobe</em>クラスター内のみを検索します。</p>
<p>パラメータnprobeは検索範囲を定義し、速度と想起のバランスに直接影響する：</p>
<ul>
<li><p>nprobeを小さくするとクエリーは速くなるが、リコールは低下する。</p></li>
<li><p>nprobeを小さくすると、クエリーは速くなるが、リコールは低下する。nprobeを大きくすると、リコールは向上するが、待ち時間が長くなる。</p></li>
</ul>
<p>実際のシステムでは、nprobeはレイテンシーバジェットや精度要件に基づいて動的に調整することができます。 上記の例では、nprobe = 2の場合、システムはクラスタ2とクラスタ4（2つの最近傍クラスタ）内のみを検索します。</p>
<h3 id="Step-3-Search-the-nearest-neighbor-in-the-selected-clusters" class="common-anchor-header">ステップ3: 選択されたクラスター内の最近傍を検索する</h3><p>候補クラスタが選択されると、システムはクエリベクトルqとその中に格納されているベクトルを比較します。 比較には主に2つのモードがあります：</p>
<ul>
<li><p><strong>厳密比較（IVF_FLAT）</strong>：選択されたクラスタから元のベクトルを取り出し、qとの距離を直接計算します。</p></li>
<li><p><strong>近似比較（IVF_PQ / IVF_SQ8）</strong>：PQまたはSQ8圧縮が使用されている場合、システムは距離計算を高速化するために<strong>ルックアップテーブル法を</strong>採用する。検索を開始する前に、クエリーベクトルと各コードブックエントリ間の距離を事前に計算する。そして、各ベクトルについて、これらの事前計算された距離を「ルックアップして合計」するだけで、類似度を推定することができる。</p></li>
</ul>
<p>最後に、検索されたすべてのクラスタからの候補結果がマージされ、再ランク付けされ、最終出力としてTop-kの最も類似したベクトルが生成されます。</p>
<h2 id="IVF-In-Practice" class="common-anchor-header">IVF の実際<button data-href="#IVF-In-Practice" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>IVFベクトルインデックスがどのように<strong>構築さ</strong>れ、<strong>検索されるかを</strong>理解したら、次のステップは実際のワークロードに適用することです。実際の作業では、<strong>性能</strong>、<strong>精度</strong>、<strong>メモリ使用量の</strong>バランスを取る必要があります。以下は、エンジニアの経験から導き出された実践的なガイドラインです。</p>
<h3 id="How-to-Choose-the-Right-nlist" class="common-anchor-header">正しいnlistの選び方</h3><p>前述したように、パラメータnlistは、IVFインデックスを構築する際にデータセットを分割するクラスタ数を決定します。</p>
<ul>
<li><p><strong>nlistを大きくする</strong>：より細かいクラスターを作成し、各クラスターに含まれるベクトル数が少なくなります。これにより、検索時にスキャンされるベクトル数が減り、一般的にクエリが高速になります。しかし、インデックスの構築には時間がかかり、セントロイド・テーブルはより多くのメモリを消費します。</p></li>
<li><p><strong>より小さな nlist</strong>：インデックスの構築を高速化し、メモリ使用量を減らしますが、各クラスタはより "混雑" します。各クエリはクラスタ内でより多くのベクトルをスキャンする必要があり、パフォーマンスのボトルネックになる可能性があります。</p></li>
</ul>
<p>これらのトレードオフに基づく、実用的な経験則を以下に示す：</p>
<p><strong>100万人規模の</strong>データセットの場合、<strong>nlist ≈ √n</strong>（nはインデックスを作成するデータシャード内のベクトル数）が良い出発点となります。</p>
<p>例えば、100万個のベクトルがある場合、nlist = 1,000とする。数千万から数億という大きなデータセットの場合、ほとんどのベクトル・データベースは各シャードが100万程度のベクトルを含むようにデータをシャード化し、このルールを実用的なものにしています。</p>
<p>nlistはインデックス作成時に固定されるため、後で変更するとインデックス全体を再構築することになります。ですから、早めに実験するのが一番です。いくつかの値（理想的には2の累乗（例えば1024、2048））をテストして、ワークロードの速度、精度、メモリのバランスをとるスイートスポットを見つける。</p>
<h3 id="How-to-Tune-nprobe" class="common-anchor-header">nprobeの調整方法</h3><p>nprobeパラメータは、クエリ時に検索されるクラスタ数を制御します。リコールとレイテンシのトレードオフに直接影響します。</p>
<ul>
<li><p><strong>nprobeを大きくする</strong>：より多くのクラスターをカバーし、リコールが高くなりますが、レイテンシも高くなります。一般的に遅延は検索されるクラスタ数とともに直線的に増加する。</p></li>
<li><p><strong>nprobeが小さい</strong>：より少ないクラスターを検索し、より低い遅延とより速いクエリーをもたらします。しかし、いくつかの真の最近傍を見逃す可能性があり、再現率と結果の精度が若干下がります。</p></li>
</ul>
<p>アプリケーションがレイテンシに極端に敏感でない場合、nprobeを動的に実験するのは良いアイデアです。例えば、1から16までの値をテストし、リコールとレイテンシがどのように変化するかを観察します。目標は、リコールが許容でき、レイテンシが目標範囲内に収まるスイートスポットを見つけることである。</p>
<p>nprobeは実行時の検索パラメーターであるため、インデックスを再構築することなく、その場で調整することができる。このため、異なるワークロードやクエリーシナリオに対して、高速、低コスト、かつ柔軟性の高いチューニングが可能です。</p>
<h3 id="Common-Variants-of-the-IVF-Index" class="common-anchor-header">IVFインデックスの一般的なバリエーション</h3><p>IVFインデックスを構築する際には、各クラスタのベクトルに対して圧縮エンコーディングを使用するかどうか、使用する場合はどの方法を使用するかを決定する必要があります。</p>
<p>その結果、IVFインデックスには3つの一般的なバリエーションがあります：</p>
<table>
<thead>
<tr><th><strong>IVF バリアント</strong></th><th><strong>主な機能</strong></th><th><strong>使用例</strong></th></tr>
</thead>
<tbody>
<tr><td><strong>IVF_FLAT</strong></td><td>各クラスタ内の生のベクトルを圧縮せずに格納。最も精度が高いが、最もメモリを消費する。</td><td>高い再現性（95%以上）が求められる中規模データセット（数億ベクトルまで）に最適です。</td></tr>
<tr><td><strong>IVF_PQ</strong></td><td>クラスタ内のベクトルを圧縮するために積量子化（PQ）を適用します。圧縮率を調整することで、メモリ使用量を大幅に削減できる。</td><td>多少の精度低下が許容される大規模なベクトル探索（数億以上）に適しています。64:1の圧縮比の場合、リコールは通常70%程度ですが、圧縮比を下げることで90%以上に達することもあります。</td></tr>
<tr><td><strong>IVF_SQ8</strong></td><td>スカラー量子化（SQ8）を使用してベクトルを量子化します。メモリ使用量は IVF_FLAT と IVF_PQ の中間に位置します。</td><td>比較的高い再現率（90%以上）を維持しながら効率を向上させる必要がある大規模ベクトル検索に最適です。</td></tr>
</tbody>
</table>
<h2 id="IVF-vs-HNSW-Pick-What-Fits" class="common-anchor-header">IVFとHNSWの比較：適合するものを選ぶ<button data-href="#IVF-vs-HNSW-Pick-What-Fits" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>IVFの他に、<strong>HNSW（Hierarchical Navigable Small World</strong>）も広く使われているインメモリ・ベクトルインデックスです。下の表は、両者の主な違いを示しています。</p>
<table>
<thead>
<tr><th></th><th><strong>IVF</strong></th><th><strong>HNSW</strong></th></tr>
</thead>
<tbody>
<tr><td><strong>アルゴリズム概念</strong></td><td>クラスタリングとバケッティング</td><td>多層グラフ・ナビゲーション</td></tr>
<tr><td><strong>メモリ使用量</strong></td><td>比較的低い</td><td>比較的高い</td></tr>
<tr><td><strong>インデックス構築速度</strong></td><td>速い（クラスタリングのみ必要）</td><td>遅い（多層グラフ構築が必要）</td></tr>
<tr><td><strong>クエリー速度（フィルタリングなし）</strong></td><td>高速、<em>nprobeに</em>依存</td><td>非常に速いが、対数の複雑さを伴う</td></tr>
<tr><td><strong>クエリー速度（フィルタリングあり）</strong></td><td>安定 - 候補を絞り込むためにセントロイドレベルで粗いフィルタリングを行う。</td><td>不安定 - 特にフィルタリングの比率が高い場合（90%以上）、グラフが断片化し、フルグラフトラバーサルに近くなり、ブルートフォースサーチよりも遅くなる可能性がある。</td></tr>
<tr><td><strong>回収率</strong></td><td>圧縮の有無による; 量子化なしでも、再現率は<strong>95%</strong>以上に達する。</td><td>通常は<strong>98%</strong>以上</td></tr>
<tr><td><strong>主要パラメータ</strong></td><td><em>nlist</em>,<em>nprobe</em></td><td><em>m</em>,<em>ef_construction</em>,<em>ef_search</em></td></tr>
<tr><td><strong>使用例</strong></td><td>メモリは限られているが、高いクエリーパフォーマンスとリコールが必要な場合。</td><td>メモリは十分で、極めて高いリコールとクエリー性能が目標だが、フィルタリングは必要ないか、フィルタリング比率が低い場合。</td></tr>
</tbody>
</table>
<p>実世界のアプリケーションでは、フィルタリング条件を含めることは非常に一般的です。例えば、"特定のユーザーからのベクトルだけを検索する"、"結果を特定の時間範囲に制限する "などです。基本的なアルゴリズムの違いにより、一般的にIVFはHNSWよりもフィルタリングされた検索を効率的に処理します。</p>
<p>IVFの強みは2段階のフィルタリング処理にある。まずセントロイド（クラスター）レベルで粗視化フィルタを実行し、候補セットを素早く絞り込み、次に選択されたクラスター内で細かい距離計算を行うことができる。これにより、データの大部分がフィルタリングされた場合でも、安定した予測可能な性能が維持される。</p>
<p>対照的に、HNSWはグラフ・トラバーサルに基づいている。その構造上、トラバーサル中にフィルタリング条件を直接利用することはできない。フィルタリングの比率が低い場合、これは大きな問題にはならない。しかし、フィルタリングの比率が高い場合（例えば、90％以上のデータがフィルタリングされる）、残りのグラフはしばしば断片化され、多くの "孤立ノード "が形成される。このような場合、検索はフルグラフトラバーサルに近くなり、時には総当り検索よりも悪くなることがある。</p>
<p>実際には、IVF インデックスは既に様々なドメインで多くのインパクトのあるユースケースを支えている：</p>
<ul>
<li><p><strong>Eコマース検索：</strong>Eコマース検索：ユーザーが商品画像をアップロードすると、何百万ものリストから視覚的に類似した商品を即座に見つけることができる。</p></li>
<li><p><strong>特許検索：</strong>従来のキーワード検索よりもはるかに効率的です。</p></li>
<li><p><strong>RAG知識ベース：</strong>IVFは、何百万ものテナント文書から最も関連性の高いコンテキストを検索し、AIモデルがより正確で根拠のある応答を生成することを保証します。</p></li>
</ul>
<h2 id="Conclusion" class="common-anchor-header">結論<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>適切なインデックスを選択するには、特定のユースケースによります。大規模なデータセットを扱う場合や、フィルタリングされた検索をサポートする必要がある場合は、IVFの方が適している可能性があります。HNSWのようなグラフベースのインデックスに比べ、IVFはインデックス構築の高速化、メモリ使用量の削減、速度と精度の強力なバランスを実現します。</p>
<p>オープンソースのベクトルデータベースとして最も有名な<a href="https://milvus.io/">Milvusは</a>、IVF_FLAT、IVF_PQ、IVF_SQ8を含むIVFファミリー全体をフルサポートしています。これらのインデックスタイプを簡単に試すことができ、パフォーマンスとメモリのニーズに最も適したセットアップを見つけることができます。Milvusがサポートしているインデックスの完全なリストについては、この<a href="https://milvus.io/docs/index-explained.md">Milvus Index docページを</a>ご覧ください。</p>
<p>画像検索、推薦システム、またはRAG知識ベースを構築している方は、MilvusのIVFインデックスを試してみてください。</p>
