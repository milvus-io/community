---
id: smarter-retrieval-for-rag-late-chunking-with-jina-embeddings-v2-and-milvus.md
title: RAGã®ã‚ˆã‚Šã‚¹ãƒãƒ¼ãƒˆãªæ¤œç´¢ï¼šJina Embeddings v2ã¨milvusã«ã‚ˆã‚‹å¾ŒæœŸãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°
author: Wei Zang
date: 2025-10-11T00:00:00.000Z
desc: åŠ¹ç‡çš„ã§æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸæ–‡æ›¸åŸ‹ã‚è¾¼ã¿ã¨ã€ã‚ˆã‚Šé«˜é€Ÿã§ã‚¹ãƒãƒ¼ãƒˆãªãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ãŸã‚ã«ã€å¾ŒæœŸãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨milvusã‚’ä½¿ç”¨ã—ã¦RAGã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚
cover: >-
  assets.zilliz.com/Milvus_Meets_Late_Chunking_Smarter_Retrieval_for_RAG_4f9640fffd.png
tag: Tutorials
tags: 'Milvus, Vector Database, Open Source, Vector Embeddings'
recommend: true
meta_keywords: 'Late Chunking, RAG accuracy, vector database, Milvus, document embeddings'
canonicalUrl: >-
  https://milvus.io/blog/smarter-retrieval-for-rag-late-chunking-with-jina-embeddings-v2-and-milvus.md
---
<p>å …ç‰¢ãªRAGã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã¯é€šå¸¸ã€<strong>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®</strong> <a href="https://zilliz.com/learn/guide-to-chunking-strategies-for-rag#Chunking"><strong>ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã‹ã‚‰</strong></a>å§‹ã¾ã‚‹<a href="https://zilliz.com/learn/guide-to-chunking-strategies-for-rag#Chunking"><strong>ã€‚</strong></a>ä¸€èˆ¬çš„ãªæˆ¦ç•¥ã¯ä»¥ä¸‹ã®é€šã‚Šï¼š</p>
<ul>
<li><p><strong>å›ºå®šã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯</strong>ï¼ˆä¾‹ï¼š512ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ï¼‰</p></li>
<li><p><strong>å¯å¤‰ã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯</strong>ï¼ˆæ®µè½ã‚„æ–‡ã®å¢ƒç•Œãªã©ï¼‰</p></li>
<li><p><strong>ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦</strong>ï¼ˆã‚¹ãƒ‘ãƒ³ã®é‡è¤‡ï¼‰</p></li>
<li><p><strong>å†å¸°çš„ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°</strong>ï¼ˆéšå±¤çš„åˆ†å‰²ï¼‰</p></li>
<li><p><strong>æ„å‘³çš„ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°</strong>ï¼ˆãƒˆãƒ”ãƒƒã‚¯ã«ã‚ˆã‚‹ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰</p></li>
</ul>
<p>ã“ã‚Œã‚‰ã®æ–¹æ³•ã«ã¯åˆ©ç‚¹ãŒã‚ã‚‹ä¸€æ–¹ã§ã€ã—ã°ã—ã°é•·æœŸçš„ãªæ–‡è„ˆã‚’ç ´å£Šã—ã¦ã—ã¾ã†ã€‚ã“ã®èª²é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€Jina AIã¯å¾ŒæœŸãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä½œæˆã—ã¾ã™ï¼šæœ€åˆã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¨ä½“ã‚’åŸ‹ã‚è¾¼ã¿ã€æ¬¡ã«ãƒãƒ£ãƒ³ã‚¯ã‚’åˆ‡ã‚Šå‡ºã—ã¾ã™ã€‚</p>
<p>ã“ã®è¨˜äº‹ã§ã¯ã€Late ChunkingãŒã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã™ã‚‹ã‹ã‚’æ¢ã‚Šã€<a href="https://milvus.io/">Milvusï¼ˆ</a>é¡ä¼¼æ¤œç´¢ç”¨ã«æ§‹ç¯‰ã•ã‚ŒãŸé«˜æ€§èƒ½ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åŠ‡çš„ã«æ”¹å–„ã§ãã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã¾ã™ã€‚ã‚ãªãŸãŒã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã€AIä¸»å°ã®ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã€ã¾ãŸã¯é«˜åº¦ãªæ¤œç´¢ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã«é–¢ã‚ã‚‰ãšã€ã“ã®ã‚¦ã‚©ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã§ã¯ã€ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’ã‚ˆã‚ŠåŠ¹æœçš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ç®¡ç†ã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚</p>
<h2 id="What-Is-Late-Chunking" class="common-anchor-header">å¾ŒæœŸãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨ã¯ï¼Ÿ<button data-href="#What-Is-Late-Chunking" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>å¾“æ¥ã®ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æ‰‹æ³•ã§ã¯ã€é‡è¦ãªæƒ…å ±ãŒè¤‡æ•°ã®ãƒãƒ£ãƒ³ã‚¯ã«ã¾ãŸãŒã‚‹å ´åˆã€é‡è¦ãªã¤ãªãŒã‚Šã‚’æ–­ã¡åˆ‡ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</p>
<p>Milvus 2.4.13ã®ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‚’2ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†ã‘ã¦è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure1_Chunking_Milvus2_4_13_Release_Note_fe7fbdb833.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>å›³1.Milvus 2.4.13ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã®ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°</em></p>
<p>ã‚‚ã—ã€"Milvus 2.4.13ã®æ–°æ©Ÿèƒ½ã¯ä½•ã§ã™ã‹ï¼Ÿ"ã¨å•ã„åˆã‚ã›ãŸå ´åˆã€æ¨™æº–çš„ãªåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€"Milvus 2.4.13"ï¼ˆãƒãƒ£ãƒ³ã‚¯1ï¼‰ã¨ãã®æ©Ÿèƒ½ï¼ˆãƒãƒ£ãƒ³ã‚¯2ï¼‰ã‚’çµã³ã¤ã‘ã‚‹ã“ã¨ãŒã§ããªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚çµæœã¯ï¼Ÿãƒ™ã‚¯ãƒˆãƒ«ãŒå¼±ããªã‚Šã€æ¤œç´¢ç²¾åº¦ãŒä½ä¸‹ã—ã¾ã™ã€‚</p>
<p>ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€ç¹°ã‚Šè¿”ã—ã‚¹ã‚­ãƒ£ãƒ³ãªã©ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªä¿®æ­£ã¯ã€éƒ¨åˆ†çš„ãªæ•‘æ¸ˆã‚’æä¾›ã—ã¾ã™ãŒã€ä¿è¨¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</p>
<p><strong>ä¼çµ±çš„ãªãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¯</strong>ã€ã“ã®ã‚ˆã†ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«å¾“ã£ã¦ã„ã‚‹ï¼š</p>
<ol>
<li><p>ãƒ†ã‚­ã‚¹ãƒˆã‚’<strong>äº‹å‰ã«ãƒãƒ£ãƒ³ã‚¯ã™ã‚‹</strong>ï¼ˆã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã€ãƒ‘ãƒ©ã‚°ãƒ©ãƒ•ã€ã¾ãŸã¯æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³é•·ã§ï¼‰ã€‚</p></li>
<li><p>å„ãƒãƒ£ãƒ³ã‚¯ã‚’åˆ¥ã€…ã«<strong>åŸ‹ã‚è¾¼ã‚€</strong>ã€‚</p></li>
<li><p>ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ã‚’ï¼ˆå¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãªã©ã§ï¼‰1ã¤ã®ãƒãƒ£ãƒ³ã‚¯ãƒ™ã‚¯ãƒˆãƒ«ã«<strong>é›†ç´„ã™ã‚‹</strong>ã€‚</p></li>
</ol>
<p><strong>ãƒ¬ã‚¤ãƒˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¯</strong>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åè»¢ã•ã›ã‚‹ï¼š</p>
<ol>
<li><p><strong>æœ€åˆã«åŸ‹ã‚è¾¼ã‚€</strong>ï¼šæœ€åˆã«åŸ‹ã‚è¾¼ã‚€ï¼šæ–‡æ›¸å…¨ä½“ã«å¯¾ã—ã¦ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆå¤‰æ›ã‚’å®Ÿè¡Œã—ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆã‚’æ‰ãˆãŸãƒªãƒƒãƒãªãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã™ã‚‹ã€‚</p></li>
<li><p><strong>å¾Œã§ãƒãƒ£ãƒ³ã‚¯ã™ã‚‹</strong>ï¼šãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã‚’å¹³å‡åŒ–ã—ã€ãƒãƒ£ãƒ³ã‚¯ãƒ™ã‚¯ãƒˆãƒ«ã‚’å½¢æˆã—ã¾ã™ã€‚</p></li>
</ol>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure2_Naive_Chunkingvs_Late_Chunking_a94d30b6ea.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>å›³2.ãƒŠã‚¤ãƒ¼ãƒ–ãƒ»ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨ãƒ¬ã‚¤ãƒˆãƒ»ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã®æ¯”è¼ƒ</em><em>ï¼ˆ</em><a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><em>ã‚½ãƒ¼ã‚¹ï¼‰</em></a></p>
<p>ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã«å®Œå…¨ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿æŒã™ã‚‹ã“ã¨ã§ã€Late Chunking ã¯æ¬¡ã®ã‚ˆã†ãªåŠ¹æœã‚’ã‚‚ãŸã‚‰ã—ã¾ã™ï¼š</p>
<ul>
<li><p><strong>æ¤œç´¢ç²¾åº¦ã®å‘ä¸Š-å„ãƒãƒ£ãƒ³ã‚¯ã¯</strong>æ–‡è„ˆã‚’æ„è­˜ã—ã¦ã„ã‚‹ã€‚</p></li>
<li><p><strong>ã‚ˆã‚Šå°‘ãªã„ãƒãƒ£ãƒ³ã‚¯-ã‚ˆã‚Š</strong>ç„¦ç‚¹ã‚’çµã£ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’LLMã«é€ã‚‹ã“ã¨ãŒã§ãã€ã‚³ã‚¹ãƒˆã¨å¾…ã¡æ™‚é–“ã‚’å‰Šæ¸›ã§ãã¾ã™ã€‚</p></li>
</ul>
<p>jina-embeddings-v2-base-enã®ã‚ˆã†ãªå¤šãã®ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã¯ã€æœ€å¤§8,192ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</p>
<p>ã•ã¦ã€ãƒ¬ã‚¤ãƒˆãƒ»ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã®èƒŒæ™¯ã«ã‚ã‚‹ã€Œä½•ã€ã¨ã€Œãªãœã€ã‚’ç†è§£ã—ãŸã¨ã“ã‚ã§ã€ã€Œã©ã®ã‚ˆã†ã«ã€ã«é£›ã³è¾¼ã‚“ã§ã¿ã‚ˆã†ã€‚æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€Late Chunkingãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè·µçš„ãªå®Ÿè£…ã€å¾“æ¥ã®ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã«å¯¾ã™ã‚‹æ€§èƒ½ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€Milvusã‚’ä½¿ç”¨ã—ãŸå®Ÿä¸–ç•Œã¸ã®å½±éŸ¿ã®æ¤œè¨¼ã‚’ã”æ¡ˆå†…ã—ã¾ã™ã€‚ã“ã®å®Ÿè·µçš„ãªã‚¦ã‚©ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã¯ã€ç†è«–ã¨å®Ÿè·µã®æ¶ã‘æ©‹ã¨ãªã‚Šã€Late Chunkingã‚’RAGãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«çµ±åˆã™ã‚‹æ–¹æ³•ã‚’æ­£ç¢ºã«ç¤ºã—ã¾ã™ã€‚</p>
<h2 id="Testing-Late-Chunking" class="common-anchor-header">ãƒ¬ã‚¤ãƒˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ<button data-href="#Testing-Late-Chunking" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Basic-Implementation" class="common-anchor-header">åŸºæœ¬çš„ãªå®Ÿè£…</h3><p>ä»¥ä¸‹ã¯ãƒ¬ã‚¤ãƒˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã®ã‚³ã‚¢æ©Ÿèƒ½ã§ã™ã€‚å„ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¬ã‚¤ãƒ‰ã¨ã—ã¦ã€åˆ†ã‹ã‚Šã‚„ã™ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚é–¢æ•°<code translate="no">sentence_chunker</code> ã¯ã€å…ƒã®æ–‡æ›¸ã‚’æ®µè½ãƒ™ãƒ¼ã‚¹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã€ãƒãƒ£ãƒ³ã‚¯ã®å†…å®¹ã¨ãƒãƒ£ãƒ³ã‚¯ã®æ³¨é‡ˆæƒ…å ±<code translate="no">span_annotations</code> ï¼ˆã™ãªã‚ã¡ã€å„ãƒãƒ£ãƒ³ã‚¯ã®é–‹å§‹ã¨çµ‚äº†ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰ã®ä¸¡æ–¹ã‚’è¿”ã—ã¾ã™ã€‚</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sentence_chunker</span>(<span class="hljs-params">document, batch_size=<span class="hljs-number">10000</span></span>):
    nlp = spacy.blank(<span class="hljs-string">&quot;en&quot;</span>)
    nlp.add_pipe(<span class="hljs-string">&quot;sentencizer&quot;</span>, config={<span class="hljs-string">&quot;punct_chars&quot;</span>: <span class="hljs-literal">None</span>})
    doc = nlp(document)

    docs = []
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(document), batch_size):
        batch = document[i : i + batch_size]
        docs.append(nlp(batch))

    doc = Doc.from_docs(docs)

    span_annotations = []
    chunks = []
    <span class="hljs-keyword">for</span> i, sent <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(doc.sents):
        span_annotations.append((sent.start, sent.end))
        chunks.append(sent.text)

    <span class="hljs-keyword">return</span> chunks, span_annotations
<button class="copy-code-btn"></button></code></pre>
<p>é–¢æ•°<code translate="no">document_to_token_embeddings</code> ã¯ã€jinaai/jina-embeddings-v2-base-en ãƒ¢ãƒ‡ãƒ«ã¨ãã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ä½¿ã£ã¦ã€æ–‡æ›¸å…¨ä½“ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">document_to_token_embeddings</span>(<span class="hljs-params">model, tokenizer, document, batch_size=<span class="hljs-number">4096</span></span>):
    tokenized_document = tokenizer(document, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
    tokens = tokenized_document.tokens()

    outputs = []
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(tokens), batch_size):
        
        start = i
        end   = <span class="hljs-built_in">min</span>(i + batch_size, <span class="hljs-built_in">len</span>(tokens))

        batch_inputs = {k: v[:, start:end] <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> tokenized_document.items()}

        <span class="hljs-keyword">with</span> torch.no_grad():
            model_output = model(**batch_inputs)

        outputs.append(model_output.last_hidden_state)

    model_output = torch.cat(outputs, dim=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> model_output
<button class="copy-code-btn"></button></code></pre>
<p>é–¢æ•°<code translate="no">late_chunking</code> ã¯ã€æ–‡æ›¸ã®ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã¨å…ƒã®ãƒãƒ£ãƒ³ã‚¯ã®æ³¨é‡ˆæƒ…å ±<code translate="no">span_annotations</code> ã‚’å—ã‘å–ã‚Šã€æœ€çµ‚çš„ãªãƒãƒ£ãƒ³ã‚¯ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">late_chunking</span>(<span class="hljs-params">token_embeddings, span_annotation, max_length=<span class="hljs-literal">None</span></span>):
    outputs = []
    <span class="hljs-keyword">for</span> embeddings, annotations <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(token_embeddings, span_annotation):
        <span class="hljs-keyword">if</span> (
            max_length <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>
        ):
            annotations = [
                (start, <span class="hljs-built_in">min</span>(end, max_length - <span class="hljs-number">1</span>))
                <span class="hljs-keyword">for</span> (start, end) <span class="hljs-keyword">in</span> annotations
                <span class="hljs-keyword">if</span> start &lt; (max_length - <span class="hljs-number">1</span>)
            ]
        pooled_embeddings = []
        <span class="hljs-keyword">for</span> start, end <span class="hljs-keyword">in</span> annotations:
            <span class="hljs-keyword">if</span> (end - start) &gt;= <span class="hljs-number">1</span>:
                pooled_embeddings.append(
                    embeddings[start:end].<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">0</span>) / (end - start)
                )
                    
        pooled_embeddings = [
            embedding.detach().cpu().numpy() <span class="hljs-keyword">for</span> embedding <span class="hljs-keyword">in</span> pooled_embeddings
        ]
        outputs.append(pooled_embeddings)

    <span class="hljs-keyword">return</span> outputs
<button class="copy-code-btn"></button></code></pre>
<p>ä¾‹ãˆã°ã€jinaai/jina-embeddings-v2-base-enã‚’ä½¿ã£ãŸãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ï¼š</p>
<pre><code translate="no">tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;jinaai/jina-embeddings-v2-base-en&#x27;</span>, trust_remote_code=<span class="hljs-literal">True</span>)
model     = AutoModel.from_pretrained(<span class="hljs-string">&#x27;jinaai/jina-embeddings-v2-base-en&#x27;</span>, trust_remote_code=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># First chunk the text as normal, to obtain the beginning and end points of the chunks.</span>
chunks, span_annotations = sentence_chunker(document)
<span class="hljs-comment"># Then embed the full document.</span>
token_embeddings = document_to_token_embeddings(model, tokenizer, document)
<span class="hljs-comment"># Then perform the late chunking</span>
chunk_embeddings = late_chunking(token_embeddings, [span_annotations])[<span class="hljs-number">0</span>]
<button class="copy-code-btn"></button></code></pre>
<p><em>ãƒ’ãƒ³ãƒˆï¼š</em>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–¢æ•°ã§ãƒ©ãƒƒãƒ—ã™ã‚‹ã“ã¨ã§ã€ä»–ã®ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚„ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ã‚’ç°¡å˜ã«å…¥ã‚Œæ›¿ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</p>
<h3 id="Comparison-with-Traditional-Embedding-Methods" class="common-anchor-header">å¾“æ¥ã®åŸ‹ã‚è¾¼ã¿æ‰‹æ³•ã¨ã®æ¯”è¼ƒ</h3><p>Late Chunkingã®å„ªä½æ€§ã‚’ã•ã‚‰ã«ç¤ºã™ãŸã‚ã«ã€ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸ã¨ã‚¯ã‚¨ãƒªã‚’ç”¨ã„ã¦ã€å¾“æ¥ã®åŸ‹ã‚è¾¼ã¿æ‰‹æ³•ã¨ã‚‚æ¯”è¼ƒã—ã¾ã—ãŸã€‚</p>
<p>Milvus 2.4.13ã®ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã®ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š</p>
<pre><code translate="no"><span class="hljs-title class_">Milvus</span> <span class="hljs-number">2.4</span><span class="hljs-number">.13</span> introduces dynamic replica load, allowing users to adjust the number <span class="hljs-keyword">of</span> collection replicas without needing to release and reload the collection. <span class="hljs-title class_">This</span> version also addresses several critical bugs related to bulk importing, expression parsing, load balancing, and failure recovery. <span class="hljs-title class_">Additionally</span>, significant improvements have been made to <span class="hljs-variable constant_">MMAP</span> resource usage and <span class="hljs-keyword">import</span> performance, enhancing overall system efficiency. <span class="hljs-title class_">We</span> highly recommend upgrading to <span class="hljs-variable language_">this</span> release <span class="hljs-keyword">for</span> better performance and stability.
<button class="copy-code-btn"></button></code></pre>
<p>ã‚¯ã‚¨ãƒªãƒ¼åŸ‹ã‚è¾¼ã¿ï¼ˆ"milvus 2.4.13"ï¼‰ã¨å„ãƒãƒ£ãƒ³ã‚¯é–“ã®<a href="https://zilliz.com/blog/similarity-metrics-for-vector-search#Cosine-Similarity">ä½™å¼¦é¡ä¼¼åº¦ã‚’</a>æ¸¬å®šã—ã¾ã™ï¼š</p>
<pre><code translate="no">cos_sim = <span class="hljs-keyword">lambda</span> x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))

milvus_embedding = model.encode(<span class="hljs-string">&#x27;milvus 2.4.13&#x27;</span>)

<span class="hljs-keyword">for</span> chunk, late_chunking_embedding, traditional_embedding <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(chunks, chunk_embeddings, embeddings_traditional_chunking):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;similarity_late_chunking(&quot;milvus 2.4.13&quot;, &quot;<span class="hljs-subst">{chunk}</span>&quot;)&#x27;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;late_chunking: &#x27;</span>, cos_sim(milvus_embedding, late_chunking_embedding))
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;similarity_traditional(&quot;milvus 2.4.13&quot;, &quot;<span class="hljs-subst">{chunk}</span>&quot;)&#x27;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;traditional_chunking: &#x27;</span>, cos_sim(milvus_embedding, traditional_embeddings))
<button class="copy-code-btn"></button></code></pre>
<p>ãƒ¬ã‚¤ãƒˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¯ä¸€è²«ã—ã¦å¾“æ¥ã®ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã‚’å‡Œé§•ã—ã€ã™ã¹ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã§ã‚ˆã‚Šé«˜ã„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã¯ã€æœ€åˆã«å®Œå…¨ãªæ–‡æ›¸ã‚’åŸ‹ã‚è¾¼ã‚€ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹æœçš„ã«ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªæ–‡è„ˆã‚’ä¿æŒã§ãã‚‹ã“ã¨ã‚’è£ä»˜ã‘ã¦ã„ã‚‹ã€‚</p>
<pre><code translate="no"><span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Milvus 2.4.13 introduces dynamic replica load, allowing users to adjust the number of collection replicas without needing to release and reload the collection.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.8785206</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Milvus 2.4.13 introduces dynamic replica load, allowing users to adjust the number of collection replicas without needing to release and reload the collection.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.8354263</span>

<span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;This version also addresses several critical bugs related to bulk importing, expression parsing, load balancing, and failure recovery.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.84828955</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;This version also addresses several critical bugs related to bulk importing, expression parsing, load balancing, and failure recovery.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.7222632</span>

<span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Additionally, significant improvements have been made to MMAP resource usage and import performance, enhancing overall system efficiency.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.84942204</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Additionally, significant improvements have been made to MMAP resource usage and import performance, enhancing overall system efficiency.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.6907381</span>

<span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;We highly recommend upgrading to this release for better performance and stability.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.85431844</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;We highly recommend upgrading to this release for better performance and stability.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.71859795</span>
<button class="copy-code-btn"></button></code></pre>
<p>æ®µè½å…¨ä½“ã‚’æœ€åˆã«åŸ‹ã‚è¾¼ã‚€ã“ã¨ã§ã€å„ãƒãƒ£ãƒ³ã‚¯ã«"<code translate="no">Milvus 2.4.13</code>"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºå®Ÿã«ä¼ãˆã‚‹ã“ã¨ãŒã§ãã€é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã¨æ¤œç´¢å“è³ªãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚</p>
<h3 id="Testing-Late-Chunking-in-Milvus" class="common-anchor-header"><strong>Milvusã§ã®å¾ŒæœŸãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ</strong></h3><p>ãƒãƒ£ãƒ³ã‚¯ã®åŸ‹ã‚è¾¼ã¿ãŒç”Ÿæˆã•ã‚ŒãŸã‚‰ã€Milvusã«æ ¼ç´ã—ã€ã‚¯ã‚¨ãƒªãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ãƒãƒ£ãƒ³ã‚¯ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«æŒ¿å…¥ã™ã‚‹ã€‚</p>
<h4 id="Importing-Embeddings-into-Milvus" class="common-anchor-header"><strong>Milvusã«åŸ‹ã‚è¾¼ã¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã€‚</strong></h4><pre><code translate="no">batch_data=[]
<span class="hljs-keyword">for</span> i in <span class="hljs-keyword">range</span>(<span class="hljs-built_in">len</span>(chunks)):
    data = {
            <span class="hljs-string">&quot;content&quot;</span>: chunks[i],
            <span class="hljs-string">&quot;embedding&quot;</span>: chunk_embeddings[i].tolist(),
        }

    batch_data.<span class="hljs-built_in">append</span>(data)

res = client.insert(
    collection_name=collection,
    data=batch_data,
)
<button class="copy-code-btn"></button></code></pre>
<h4 id="Querying-and-Validation" class="common-anchor-header">ã‚¯ã‚¨ãƒªã¨æ¤œè¨¼</h4><p>Milvusã®ã‚¯ã‚¨ãƒªã®ç²¾åº¦ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ã€Milvusã®æ¤œç´¢çµæœã‚’æ‰‹å‹•ã§è¨ˆç®—ã—ãŸã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã¨æ¯”è¼ƒã—ã¾ã™ã€‚ä¸¡æ–¹ã®æ–¹æ³•ãŒä¸€è²«ã—ãŸãƒˆãƒƒãƒ—kã®çµæœã‚’è¿”ã™å ´åˆã€Milvusã®æ¤œç´¢ç²¾åº¦ã¯ä¿¡é ¼ã§ãã‚‹ã¨ç¢ºä¿¡ã§ãã¾ã™ã€‚</p>
<p>Milvusã®ãƒã‚¤ãƒ†ã‚£ãƒ–æ¤œç´¢ã¨ãƒ–ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ã‚¹ãƒ»ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚¹ã‚­ãƒ£ãƒ³ã‚’æ¯”è¼ƒã™ã‚‹ï¼š</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">late_chunking_query_by_milvus</span>(<span class="hljs-params">query, top_k = <span class="hljs-number">3</span></span>):
    query_vector = model(**tokenizer(query, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)).last_hidden_state.mean(<span class="hljs-number">1</span>).detach().cpu().numpy().flatten()

    res = client.search(
                collection_name=collection,
                data=[query_vector.tolist()],
                limit=top_k,
                output_fields=[<span class="hljs-string">&quot;id&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>],
            )

    <span class="hljs-keyword">return</span> [item.get(<span class="hljs-string">&quot;entity&quot;</span>).get(<span class="hljs-string">&quot;content&quot;</span>) <span class="hljs-keyword">for</span> items <span class="hljs-keyword">in</span> res <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> items]

<span class="hljs-keyword">def</span> <span class="hljs-title function_">late_chunking_query_by_cosine_sim</span>(<span class="hljs-params">query, k = <span class="hljs-number">3</span></span>):
    cos_sim = <span class="hljs-keyword">lambda</span> x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))
    query_vector = model(**tokenizer(query, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)).last_hidden_state.mean(<span class="hljs-number">1</span>).detach().cpu().numpy().flatten()

    results = np.empty(<span class="hljs-built_in">len</span>(chunk_embeddings))
    <span class="hljs-keyword">for</span> i, (chunk, embedding) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(chunks, chunk_embeddings)):
        results[i] = cos_sim(query_vector, embedding)

    results_order = results.argsort()[::-<span class="hljs-number">1</span>]
    <span class="hljs-keyword">return</span> np.array(chunks)[results_order].tolist()[:k]
<button class="copy-code-btn"></button></code></pre>
<p>ã“ã‚Œã¯MilvusãŒæ‰‹ä½œæ¥­ã«ã‚ˆã‚‹cosine-simã‚¹ã‚­ãƒ£ãƒ³ã¨åŒã˜top-kãƒãƒ£ãƒ³ã‚¯ã‚’è¿”ã™ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚</p>
<pre><code translate="no">&gt; late_chunking_query_by_milvus(<span class="hljs-string">&quot;What are new features in milvus 2.4.13&quot;</span>, 3)

[<span class="hljs-string">&#x27;\n\n### Features\n\n- Dynamic replica adjustment for loaded collections ([#36417](https://github.com/milvus-io/milvus/pull/36417))\n- Sparse vector MMAP in growing segment types ([#36565](https://github.com/milvus-io/milvus/pull/36565))...
</span><button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">&gt; late_chunking_query_by_cosine_sim(<span class="hljs-string">&quot;What are new features in milvus 2.4.13&quot;</span>, 3)

[<span class="hljs-string">&#x27;\n\n### Features\n\n- Dynamic replica adjustment for loaded collections ([#36417](https://github.com/milvus-io/milvus/pull/36417))\n- Sparse vector MMAP in growing segment types (#36565)...
</span><button class="copy-code-btn"></button></code></pre>
<p>ã¤ã¾ã‚Šã€ã©ã¡ã‚‰ã®æ–¹æ³•ã§ã‚‚åŒã˜ãƒˆãƒƒãƒ—3ã®ãƒãƒ£ãƒ³ã‚¯ãŒå¾—ã‚‰ã‚Œã€Milvusã®ç²¾åº¦ãŒç¢ºèªã§ãã‚‹ã€‚</p>
<h2 id="Conclusion" class="common-anchor-header">çµè«–<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>ã“ã®è¨˜äº‹ã§ã¯ã€ãƒ¬ã‚¤ãƒˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã®ä»•çµ„ã¿ã¨åˆ©ç‚¹ã«ã¤ã„ã¦æ·±ãæ˜ã‚Šä¸‹ã’ã¦ã¿ãŸã€‚ã¾ãšã€å¾“æ¥ã®ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ¬ ç‚¹ã€ç‰¹ã«æ–‡è„ˆã®ä¿æŒãŒé‡è¦ãªé•·ã„æ–‡æ›¸ã‚’æ‰±ã†å ´åˆã®æ¬ ç‚¹ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚æ„å‘³ã®ã‚ã‚‹ãƒãƒ£ãƒ³ã‚¯ã«ã‚¹ãƒ©ã‚¤ã‚¹ã™ã‚‹å‰ã«æ–‡æ›¸å…¨ä½“ã‚’åŸ‹ã‚è¾¼ã‚€ã¨ã„ã†ãƒ¬ã‚¤ãƒˆãƒ»ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’ç´¹ä»‹ã—ã€ã“ã‚Œã«ã‚ˆã‚Šã‚°ãƒ­ãƒ¼ãƒãƒ«ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒä¿æŒã•ã‚Œã€æ„å‘³çš„é¡ä¼¼æ€§ã¨æ¤œç´¢ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚</p>
<p>ãã®å¾Œã€Jina AIã®jina-embeddings-v2-base-enãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸå®Ÿè·µçš„ãªå®Ÿè£…ã‚’è¡Œã„ã€å¾“æ¥ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ãŸã€‚æœ€å¾Œã«ã€ãƒãƒ£ãƒ³ã‚¯åŸ‹ã‚è¾¼ã¿ã‚’Milvusã«çµ±åˆã—ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§é«˜ç²¾åº¦ãªãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ãŸã€‚</p>
<p>ãƒ¬ã‚¤ãƒˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¯ã€<strong>æ–‡è„ˆãŒ</strong>æœ€ã‚‚é‡è¦ãªé•·ãã¦è¤‡é›‘ãªæ–‡æ›¸ã«æœ€é©ãªã€<strong>æ–‡è„ˆå„ªå…ˆã®</strong>åŸ‹ã‚è¾¼ã¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æä¾›ã—ã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’å…ˆã«åŸ‹ã‚è¾¼ã¿ã€å¾Œã§ã‚¹ãƒ©ã‚¤ã‚¹ã™ã‚‹ã“ã¨ã§ã€æ¬¡ã®ã‚ˆã†ãªåˆ©ç‚¹ãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š</p>
<ul>
<li><p><strong>æ¤œç´¢ç²¾åº¦ãŒ</strong>å‘ä¸Šã—ã¾ã™ã€‚</p></li>
<li><p>âš¡<strong>ç„¡é§„ã®ãªã„ç„¦ç‚¹åŒ–ã•ã‚ŒãŸLLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ</strong></p></li>
<li><p>ğŸ› ï¸ ã‚ã‚‰ã‚†ã‚‹ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã¨ã®<strong>ç°¡å˜ãªçµ±åˆ</strong></p></li>
</ul>
