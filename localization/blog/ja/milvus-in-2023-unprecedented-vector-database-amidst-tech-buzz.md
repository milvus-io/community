---
id: milvus-in-2023-unprecedented-vector-database-amidst-tech-buzz.md
title: 2023年：AIの年
author: James Luan
date: 2024-01-05T00:00:00.000Z
desc: ベクターデータベース業界全体を振り返り、その中でも特にMilvusに注目。
cover: >-
  assets.zilliz.com/Milvus_in_2023_An_Atypical_Vector_DB_Amidst_Tech_Buzz_1_1151400765.png
tags: 'Milvus, Vector Database, LLM, RAG, Open Source, Artificial Intelligence'
recommend: true
canonicalUrl: >-
  https://thenewstack.io/milvus-in-2023-open-source-vector-database-year-in-review/
---
<p>
 <span class="img-wrapper">
   <img translate="no" src="https://assets.zilliz.com/image_7_1c3b05e71c.jpg" alt="This image is generated by AI. " class="doc-image" id="this-image-is-generated-by-ai.-" />
   <span>この画像はAIによって生成されたものです。 </span> </span>
  
</p>
<custom-h1>2023年のmilvus：技術的な話題の中、前例のないベクターデータベース</custom-h1><p><em>この記事は、ChatGPTの協力を得てジェームス・ルアンが執筆した。ジェームズは主にプロンプトを書き、AIが生成したコンテンツをレビューして推敲した。</em></p>
<h2 id="2023-the-year-of-AI" class="common-anchor-header">2023年：AIの年<button data-href="#2023-the-year-of-AI" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>2023年は、人工知能（AI）において極めて重要なターニングポイントを迎えます。<a href="https://zilliz.com/glossary/large-language-models-(llms)">大規模言語モデル（LLM）が</a>中心的な役割を果たし、その卓越した自然言語処理能力が広く認知されるようになりました。この人気急上昇により、機械学習アプリケーションの可能性が大幅に広がり、開発者はよりインテリジェントでインタラクティブなアプリケーションを構築できるようになった。</p>
<p>この革命の中で、<a href="https://zilliz.com/learn/what-is-vector-database">ベクターデータベースは</a>LLMの長期記憶として機能する重要なコンポーネントとして登場した。<a href="https://zilliz.com/use-cases/llm-retrieval-augmented-generation">検索拡張世代（RAG）</a>モデル、インテリジェントエージェント、マルチモーダル検索アプリの台頭は、マルチモーダルデータの検索効率を高め、LLMの幻覚を減らし、ドメイン知識を補完するベクトルデータベースの大きな可能性を示している。</p>
<p>LLMの進化は、埋め込み技術の著しい進歩にもつながっている。HuggingFaceの<a href="https://huggingface.co/spaces/mteb/leaderboard">Massive Text Embedding Benchmark (MTEB) Leaderboardに</a>よると、UAE、VoyageAI、CohereV3、Bgeといった主要なエンベッディングモデルが2023年にリリースされている。これらの進歩は、Milvusのような様々なベクトル検索技術のベクトル検索効果を強化し、AIアプリケーションにより正確で効率的なデータ処理能力を提供している。</p>
<p>しかし、ベクターデータベースの普及に伴い、専門的なソリューションの必要性について議論が起こった。数十社の新興企業がベクトル・データベースの分野に参入した。伝統的なリレーショナル・データベースやNoSQLデータベースの多くが、ベクトルを重要なデータ型として扱い始め、あらゆる状況で専用のベクトル・データベースを代替できると主張するものも少なくない。</p>
<p>2024年を迎えるにあたり、ベクターデータベース業界全体を振り返り、その中でも特に傑出した製品であるMilvusに注目するのは賢明な機会だろう。</p>
<h2 id="Milvus-in-2023-numbers-dont-lie" class="common-anchor-header">2023年のMilvus：数字は嘘をつかない<button data-href="#Milvus-in-2023-numbers-dont-lie" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>2019年に初めて発売された<a href="https://zilliz.com/what-is-milvus">Milvusは</a>、ベクターデータベースの概念を開拓し、高い信頼性、拡張性、検索品質、パフォーマンスで一貫して高い評価を維持してきた。2023年、Milvusは目覚ましい業績を達成し、主にLLMの急速な進歩とAIGCアプリケーションのブームによって大きな変化を遂げた。以下は、2023年のMilvusの躍進を象徴する主な数字である。</p>
<h3 id="ZERO-downtime-during-rolling-upgrades" class="common-anchor-header">ローリングアップグレード中のダウンタイムゼロ</h3><p>ベクターデータベースを初めて導入する場合、運用保守よりも機能性を重視する。また、多くのアプリケーション開発者は、トランザクションデータベースよりもベクターデータベースの安定性に注意を払っていません。しかし、AIGCアプリケーションを本番環境に導入し、最高のユーザーエクスペリエンスを実現することを目指すのであれば、安定性は不可欠となります。</p>
<p>Milvusは、機能性だけでなく、運用の安定性を優先することで、他社との差別化を図っています。Milvusは、バージョン2.2.3からローリングアップグレードに対応しました。継続的な改良を経て、この機能により、ビジネスプロセスを中断することなく、アップグレード中のダウンタイムをゼロにすることができます。</p>
<h3 id="3x-performance-improvement-in-production-environments" class="common-anchor-header">本番環境で3倍のパフォーマンス向上</h3><p>ベクトル検索のパフォーマンスを向上させることは、ベクトルデータベースにとって第一の目標でなければなりません。多くのベクトル検索ソリューションは、迅速に市場に投入するために、<a href="https://zilliz.com/learn/hierarchical-navigable-small-worlds-HNSW">HNSW</a>アルゴリズムの適応をソリューションのベースとすることを選択しました。残念ながら、このことは、特に高度にフィルタリングされた検索（90％以上）や頻繁なデータ削除など、実運用環境において大きな課題に直面することにつながります。Milvusは最初からパフォーマンスを考慮し、開発のどの段階においてもパフォーマンスを最適化することに優れており、特に本番環境においては、フィルタリング検索やストリーミング挿入/検索の状況において、検索パフォーマンスを3倍向上させることに成功しています。</p>
<p>ベクトルデータベースコミュニティをさらに支援するために、昨年、オープンソースのベンチマークツールである<a href="https://github.com/zilliztech/VectorDBBench">VectorDBBenchを</a>導入しました。このツールは、様々な条件下でのベクトルデータベースの早期評価に不可欠です。従来の評価方法とは異なり、VectorDBBenchは、超大規模データセットや実際の埋め込みモデルからのデータに近いものを含む実世界のデータを用いてデータベースを評価し、十分な情報に基づいた意思決定のためのより洞察力のある情報をユーザーに提供します。</p>
<h3 id="5-recall-improvement-on-the-Beir-dataset" class="common-anchor-header">Beirデータセットで5%のリコール改善</h3><p><a href="https://zilliz.com/learn/sparse-and-dense-embeddings">密な埋め込みは</a>ベクトル検索において効果的であることが証明されていますが、名前、オブジェクト、略語、短いクエリコンテキストを検索する際には追いつく必要があります。Milvusはその限界に対応するため、密な埋め込みと<a href="https://zilliz.com/learn/sparse-and-dense-embeddings">疎な埋め込みを</a>統合し、検索結果の質を高めるハイブリッドクエリアプローチを導入した。このハイブリッド・ソリューションとリランキング・モデルの相乗効果により、Beirデータセットにおいて、我々のテストにより検証されたように、想起率が5%大幅に改善された。</p>
<p>Milvusは検索品質の向上にとどまらず、WANDのような従来の検索アルゴリズムを凌駕する、スパース埋め込みに特化したグラフベースの検索ソリューションを発表した。</p>
<p>2023年のNeurIPS BigANNコンペティションでは、Zilliz社の優秀なエンジニアであるZihao Wang氏が、スパース埋め込み検索トラックで他のエントリーを大きく凌駕する検索アルゴリズム「<a href="https://big-ann-benchmarks.com/neurips23.html#winners">Pyanns</a>」を発表した。この画期的なソリューションは、当社の本番環境向けスパース埋め込み検索アルゴリズムの先駆けとなるものです。</p>
<h3 id="10x-memory-saving-on-large-datasets" class="common-anchor-header">大規模データセットで10倍のメモリ節約</h3><p>2023年のベクトル・データベースのユースケースで最も人気があったのは、<a href="https://zilliz.com/use-cases/llm-retrieval-augmented-generation">RAG</a>（<a href="https://zilliz.com/use-cases/llm-retrieval-augmented-generation">Retrieval Augmented Generation</a>）であった。しかし、RAGアプリケーションによるベクトルデータ量の増加は、これらのアプリケーションにストレージの課題をもたらします。この課題は、変換されたベクトルの量が元のドキュメントチャンクの量を超える場合に特に当てはまり、潜在的にメモリ使用コストをエスカレートさせます。例えば、ドキュメントをチャンクに分割した後、500トークンのチャンク（約1kb）から変換された1536次元のfloat32ベクトル（約3kb）のサイズは、500トークンのチャンクよりも大きくなります。</p>
<p>Milvusは、ディスクベースのインデックスをサポートする最初のオープンソースのベクトル・データベースであり、5倍という驚くべきメモリ節約をもたらす。2023年末までに<a href="https://milvus.io/docs/release_notes.md#v234">Milvus 2.3.</a>4を導入し、メモリマップファイル<a href="https://zilliz.com/blog/milvus-introduced-mmap-for-redefined-data-management-increased-storage-capability">（MMap</a>）を使用してスカラーおよびベクトルデータ/インデックスをディスクにロードする機能を実現しました。この進化により、従来のインメモリインデキシングと比較して、メモリ使用量を10倍以上削減することができる。</p>
<h3 id="20-Milvus-releases" class="common-anchor-header">20のMilvusリリース</h3><p>2023年、Milvusは重要なマイルストーンに彩られた変革の旅に出ました。これは、300名を超えるコミュニティ開発者の献身と、ユーザー主導の開発アプローチを実現した証です。</p>
<p>その一例として、Milvus 2.2.9では<a href="https://zilliz.com/blog/what-is-dynamic-schema">ダイナミックスキーマを</a>導入し、パフォーマンス優先からユーザビリティ向上への重要な転換を図りました。これに基づき、<a href="https://milvus.io/blog/unveiling-milvus-2-3-milestone-release-offering-support-for-gpu-arm64-cdc-and-other-features.md">Milvus 2.3では</a>、Upsert、<a href="https://zilliz.com/blog/unlock-advanced-recommendation-engines-with-milvus-new-range-search">Range Search</a>、Cosineメトリクスなどの重要な機能が導入されました。このような反復的な開発プロセスは、Milvusをユーザーの進化する要件に合わせ続けるという我々のコミットメントを強調するものです。</p>
<h3 id="1000000-tenants-in-a-Single-Custer" class="common-anchor-header">シングルカスターで1,000,000テナント</h3><p>マルチテナントの実装は、RAGシステム、AIエージェント、その他のLLMアプリケーションを開発し、データの分離に対するユーザーの高い要求に応えるために非常に重要です。B2Cビジネスの場合、テナント数は数百万に急増する可能性があり、ユーザーデータの物理的な分離は現実的ではありません（例として、リレーショナル・データベースに数百万のテーブルを作成する人はまずいません）。Milvusはパーティション・キー機能を導入し、効率的で論理的な分離とパーティション・キーに基づくデータのフィルタリングを可能にしました。</p>
<p>逆に、何万ものテナントを扱うことに慣れているB2B企業では、物理的なリソースの分離を含むより微妙な戦略の恩恵を受けることができます。最新のMilvus 2.3.4では、メモリ管理、コルーチン処理、CPU最適化が強化され、単一クラスタ内での数万テーブルの作成が容易になった。この機能強化により、B2Bビジネスのニーズにも対応し、効率性と制御性が強化されました。</p>
<h3 id="10000000-Docker-image-pulls" class="common-anchor-header">10,000,000回のDockerイメージプル</h3><p>2023年が終わりに近づくにつれ、Milvusは<a href="https://hub.docker.com/r/milvusdb/milvus">1000万Dockerプルダウンロードという</a>素晴らしいマイルストーンに到達しました。この快挙は、Milvusに対する開発者コミュニティの魅力の高まりを示すものであり、ベクトルデータベース領域におけるMilvusの重要性の高まりを強調するものです。</p>
<p>世界初のクラウドネイティブなベクターデータベースとして、MilvusはKubernetesや広範なコンテナエコシステムとのシームレスな統合を誇っている。将来を見据えて、進化し続けるベクターデータベースの状況における次の焦点について考えずにはいられない。それはサーバーレス・サービスの台頭だろうか？</p>
<h3 id="10-billion-entities-in-a-single-collection" class="common-anchor-header">ひとつのコレクションに100億エンティティ</h3><p>現在のところ、スケーラビリティがAI現象のスポットライトを浴びることはないかもしれないが、単なる余興ではなく、極めて重要な役割を果たしていることは確かだ。Milvusのベクトル・データベースは、汗をかくことなく、何十億ものベクトル・データをシームレスにスケールアウトすることができる。例えば、LLMの顧客の一例を見てみよう。Milvusは、この顧客が100億という驚異的なデータポイントを保存、処理、取得するのを難なく支援しました。しかし、このような大量のデータを扱う場合、コストとパフォーマンスのバランスをどのように取ればよいのでしょうか？ご安心ください、Mivusにはその課題に対処し、お客様の体験を向上させるための様々な機能があります。</p>
<h2 id="Beyond-the-numbers-the-new-insights-into-vector-databases" class="common-anchor-header">数字を超えて：ベクターデータベースの新たな洞察<button data-href="#Beyond-the-numbers-the-new-insights-into-vector-databases" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>数値的なマイルストーンを超えて、2023年は貴重な洞察で私たちを豊かにしてくれました。単なる統計にとどまらず、ベクター検索技術の微妙なニュアンスと進化するダイナミクスを把握するために、ベクターデータベースの複雑な状況を掘り下げてきました。</p>
<h3 id="LLM-apps-are-still-in-the-early-stages" class="common-anchor-header">LLMアプリはまだ初期段階にある。</h3><p>モバイル・インターネット・ブームの初期を振り返ると、多くの開発者が懐中電灯や天気予報のようなシンプルなアプリを作り、やがてスマートフォンのOSに統合された。昨年、GitHubで急速に10万スターを達成したAutoGPTのように、ほとんどのAIネイティブ・アプリケーションは実用的な価値を提供せず、有意義な実験に過ぎなかった。ベクトルデータベースアプリケーションにとって、現在のユースケースはAIネイティブの変革の第一波に過ぎないかもしれず、私はより多くのキラーユースケースが出現することを切望している。</p>
<h3 id="Vector-databases-go-toward-diversification" class="common-anchor-header">ベクトル・データベースは多様化へ</h3><p>データベースがOLTP、OLAP、NoSQLのようなカテゴリーに進化したのと同様に、ベクトル・データベースも多様化への明確な傾向を示している。従来のオンラインサービス中心から脱却し、オフライン分析が大きな支持を得ている。このシフトのもう一つの顕著な例は、2023年にリリースされたオープンソースのセマンティックキャッシュである<a href="https://zilliz.com/blog/building-llm-apps-100x-faster-responses-drastic-cost-reduction-using-gptcache">GPTCacheの</a>導入である。GPTCacheは、言語モデルによって生成された応答を保存・検索することで、GPTベースのアプリケーションの効率と速度を向上させる。</p>
<p>来年、ベクトルデータベースにおけるアプリケーションやシステム設計がさらに多様化することを目の当たりにし、期待と興奮を感じている。</p>
<h3 id="Vector-operations-are-becoming-more-complicated" class="common-anchor-header">ベクトル演算は複雑化している。</h3><p><a href="https://zilliz.com/glossary/anns">近似最近傍（ANN）</a>検索への対応はベクトルデータベースの特徴ですが、それだけではありません。データベースをベクトルまたはAIネイティブ・データベースとして分類するには、単に最近傍探索を維持すれば十分だという通説は、ベクトル演算の複雑さを単純化しすぎている。ハイブリッドスカラーフィルタリングとベクトル検索という基本的な機能だけでなく、AIネイティブアプリケーション向けにカスタマイズされたデータベースは、NNフィルタリング、KNNジョイン、クラスタークエリなど、より洗練されたセマンティック機能をサポートする必要がある。</p>
<h3 id="Elastic-scalability-is-essential-for-AI-native-applications" class="common-anchor-header">AIネイティブ・アプリケーションには、弾力的なスケーラビリティが不可欠です。</h3><p>ChatGPTが2ヶ月で1億人以上の月間アクティブユーザーを獲得したことに代表されるように、AIアプリケーションの指数関数的な成長は、それまでのビジネスの軌跡を凌駕しています。ビジネスが成長軌道に乗ると、100万から10億のデータ・ポイントへの迅速なスケーリングが最も重要になります。AIアプリケーションの開発者は、LLMプロバイダーが設定した従量課金のサービスモデルから恩恵を受け、運用コストの大幅な削減につながる。同様に、この価格設定モデルに沿ったデータの保存は開発者にとって有利であり、コア・ビジネスにより多くの注意を向けることができる。</p>
<p>言語モデル（LLM）やその他のさまざまな技術システムとは異なり、ベクターデータベースはステートフルな方法で動作するため、その機能には永続的なデータストレージが必要です。そのため、ベクターデータベースを選択する際には、弾力性と拡張性を優先することが極めて重要です。この優先順位付けにより、進化するAIアプリケーションの動的な要求との整合性が確保され、変化するワークロードへのシームレスな適応性の必要性が強調されます。</p>
<h3 id="Leveraging-machine-learning-in-vector-databases-can-yield-extraordinary-results" class="common-anchor-header">ベクトル・データベースで機械学習を活用することで、並外れた結果を得ることができます。</h3><p>2023年、AI4DB（データベースのためのAI）プロジェクトに対する当社の多額の投資は、目覚ましい成果をもたらしました。私たちの努力の一環として、フルマネージドMilvusソリューションである<a href="https://zilliz.com/cloud">Zilliz Cloudに</a>2つの極めて重要な機能を導入しました：1）機械学習に根ざした自動パラメータ調整インデックスであるAutoIndexと、2）データのクラスタリングに基づくデータ分割戦略です。この2つのイノベーションは、Zilliz Cloudの検索パフォーマンスを大幅に向上させる上で重要な役割を果たした。</p>
<h3 id="Open-source-vs-closed-source" class="common-anchor-header">オープンソースとクローズドソースの比較</h3><p>現在、OpenAIのGPTシリーズやClaudeのようなクローズドソースのLLMがリードしており、同等の計算資源やデータ資源がないため、オープンソースコミュニティは不利な立場に置かれている。</p>
<p>しかし、ベクトル・データベースにおいては、オープンソースが最終的にはユーザーに支持される選択肢となるだろう。オープンソースを選択することで、より多様なユースケース、迅速な反復、より強固なエコシステムの構築など、多くの利点がもたらされる。さらに、データベースシステムは非常に複雑であるため、LLMにありがちな不透明さは許されない。ユーザーは、データベースを利用するための最も合理的なアプローチを選択する前に、データベースを徹底的に理解しなければならない。さらに、オープンソースに組み込まれた透明性は、ユーザーが自分のニーズに応じてデータベースをカスタマイズする自由とコントロールを持つことを可能にする。</p>
<h2 id="Epilogue---And-a-new-beginning" class="common-anchor-header">エピローグ - そして新たな始まり<button data-href="#Epilogue---And-a-new-beginning" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>変革の中で2023年が過ぎようとしている今、ベクターデータベースの物語は始まったばかりである。Milvusベクターデータベースの旅は、AIGCの誇大広告に惑わされることではありません。その代わりに、私たちは細心の注意を払って製品を開発し、私たちの強みに合致するアプリケーションのユースケースを特定して育成し、揺るぎなくユーザーに貢献することに注力しています。オープンソースへのコミットメントは、私たちとユーザーとの間のギャップを埋め、遠く離れていても私たちの献身と職人技を感じてもらうことを目的としています。</p>
<p>2023年には、多くのAIスタートアップが設立され、最初の資金調達を行いました。このような開発者のイノベーションを見るのはエキサイティングであり、そもそもなぜVectorDBの開発に携わるようになったのかを思い出させてくれる。2024年は、これらの革新的なアプリケーションが本格的な牽引力を獲得し、資金だけでなく実際の有料顧客を引き付ける年になるだろう。ダウンタイムがほとんどなく、完全にスケーラブルなソリューションを構築することが最重要であるため、顧客からの収益は開発者にさまざまな要求をもたらすだろう。</p>
<p>2024年、驚異的なことを実現しよう！</p>
