---
id: smarter-retrieval-for-rag-late-chunking-with-jina-embeddings-v2-and-milvus.md
title: ç‚º RAG æä¾›æ›´è°æ˜çš„æ“·å–åŠŸèƒ½ï¼šä½¿ç”¨ Jina Embeddings v2 å’Œ Milvus çš„å¾ŒæœŸåˆ†å¡ŠåŠŸèƒ½
author: Wei Zang
date: 2025-10-11T00:00:00.000Z
desc: ä½¿ç”¨ Late Chunking å’Œ Milvus ä¾†æå‡ RAG çš„æº–ç¢ºåº¦ï¼Œä»¥é”åˆ°é«˜æ•ˆã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ–‡ä»¶åµŒå…¥ï¼Œä»¥åŠæ›´å¿«ã€æ›´æ™ºæ…§çš„å‘é‡æœå°‹ã€‚
cover: assets.zilliz.com/Milvus_Meets_Late_Chunking_eaff956df1.png
tag: Tutorials
tags: 'Milvus, Vector Database, Open Source, Vector Embeddings'
recommend: false
meta_keywords: 'Late Chunking, RAG accuracy, vector database, Milvus, document embeddings'
canonicalUrl: >-
  https://milvus.io/blog/smarter-retrieval-for-rag-late-chunking-with-jina-embeddings-v2-and-milvus.md
---
<p>å»ºç«‹å¼·å¤§çš„ RAG ç³»çµ±é€šå¸¸å¾<strong>æ–‡ä»¶</strong> <a href="https://zilliz.com/learn/guide-to-chunking-strategies-for-rag#Chunking"><strong>åˆ†å¡Š</strong></a>é–‹å§‹<a href="https://zilliz.com/learn/guide-to-chunking-strategies-for-rag#Chunking"><strong>- å°‡</strong></a>å¤§å‹æ–‡å­—<a href="https://zilliz.com/learn/guide-to-chunking-strategies-for-rag#Chunking"><strong>åˆ†å‰²</strong></a>æˆæ˜“æ–¼ç®¡ç†çš„ç‰‡æ®µï¼Œä»¥ä¾¿åµŒå…¥å’Œæª¢ç´¢ã€‚å¸¸è¦‹çš„ç­–ç•¥åŒ…æ‹¬</p>
<ul>
<li><p><strong>å›ºå®šå¤§å°çš„åˆ†å¡Š</strong>(ä¾‹å¦‚ï¼Œæ¯ 512 å€‹è¨˜äº‹å–®ä½)</p></li>
<li><p><strong>å¯è®Šå¤§å°çš„åˆ†å¡Š</strong>(ä¾‹å¦‚ï¼šæ®µè½æˆ–å¥å­é‚Šç•Œ)</p></li>
<li><p><strong>æ»‘å‹•è¦–çª—</strong>(é‡ç–Šè·¨åº¦)</p></li>
<li><p><strong>éæ­¸åˆ†å¡Š</strong>ï¼ˆåˆ†å±¤åˆ†å‰²ï¼‰</p></li>
<li><p><strong>èªæ„åˆ†å¡Š</strong>ï¼ˆä¾ä¸»é¡Œåˆ†é¡ï¼‰</p></li>
</ul>
<p>é›–ç„¶é€™äº›æ–¹æ³•éƒ½æœ‰å…¶å„ªé»ï¼Œä½†å®ƒå€‘å¾€å¾€æœƒç ´å£é•·è·é›¢çš„ä¸Šä¸‹æ–‡ã€‚ç‚ºäº†è§£æ±ºé€™å€‹é›£é¡Œï¼ŒJina AI å‰µé€ äº†ä¸€ç¨® Late Chunking æ–¹æ³•ï¼šå…ˆåµŒå…¥æ•´å€‹æ–‡ä»¶ï¼Œç„¶å¾Œå†åˆ†å‰²å‡ºæ‚¨çš„åˆ†å¡Šã€‚</p>
<p>åœ¨é€™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å€‘å°‡æ¢è¨ Late Chunking å¦‚ä½•é‹ä½œï¼Œä¸¦ç¤ºç¯„å¦‚ä½•å°‡å®ƒèˆ‡<a href="https://milvus.io/">Milvus</a>çµåˆ<a href="https://milvus.io/">ï¼ˆMilvus æ˜¯</a>å°ˆç‚ºç›¸ä¼¼æ€§æœå°‹å»ºç«‹çš„é«˜æ•ˆèƒ½é–‹æ”¾åŸå§‹ç¢¼å‘é‡è³‡æ–™åº«ï¼‰ï¼Œä»¥å¤§å¹…æ”¹å–„æ‚¨çš„ RAG ç®¡é“ã€‚ç„¡è«–æ‚¨æ˜¯è¦å»ºç«‹ä¼æ¥­çŸ¥è­˜åº«ã€AI é©…å‹•çš„å®¢æˆ¶æ”¯æ´ï¼Œæˆ–æ˜¯é€²éšçš„æœå°‹æ‡‰ç”¨ç¨‹å¼ï¼Œé€™ç¯‡æ¼”ç·´éƒ½æœƒå‘Šè¨´æ‚¨å¦‚ä½•æ›´æœ‰æ•ˆåœ°ç®¡ç†åµŒå…¥å¼è¦æ¨¡ã€‚</p>
<h2 id="What-Is-Late-Chunking" class="common-anchor-header">ä»€éº¼æ˜¯å¾ŒæœŸåˆ†å¡Šï¼Ÿ<button data-href="#What-Is-Late-Chunking" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>ç•¶é—œéµè³‡è¨Šè·¨è¶Šå¤šå€‹åˆ†å¡Šæ™‚ï¼Œå‚³çµ±çš„åˆ†å¡Šæ–¹æ³•å¯èƒ½æœƒç ´å£é‡è¦çš„é€£çµï¼Œå°è‡´æ“·å–æ•ˆèƒ½ä¸ä½³ã€‚</p>
<p>è«‹åƒè€ƒ Milvus 2.4.13 çš„ç™¼ä½ˆèªªæ˜ï¼Œå¦‚ä¸‹åœ–æ‰€ç¤ºåˆ†æˆå…©å¤§å¡Šï¼š</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure1_Chunking_Milvus2_4_13_Release_Note_fe7fbdb833.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>åœ– 1.Milvus 2.4.13 ç™¼è¡Œèªªæ˜çš„åˆ†å¡Š</em></p>
<p>å¦‚æœæ‚¨æŸ¥è©¢ã€ŒMilvus 2.4.13 æœ‰å“ªäº›æ–°åŠŸèƒ½ï¼Ÿã€ï¼Œæ¨™æº–çš„åµŒå…¥æ¨¡å‹å¯èƒ½ç„¡æ³•å°‡ã€ŒMilvus 2.4.13ã€ï¼ˆåœ¨ Chunk 1 ä¸­ï¼‰èˆ‡å…¶åŠŸèƒ½ï¼ˆåœ¨ Chunk 2 ä¸­ï¼‰é€£çµèµ·ä¾†ã€‚çµæœå‘¢ï¼Ÿè¼ƒå¼±çš„å‘é‡å’Œè¼ƒä½çš„æª¢ç´¢æº–ç¢ºåº¦ã€‚</p>
<p>å•Ÿç™¼å¼çš„ä¿®å¾©æ–¹æ³•ï¼Œä¾‹å¦‚æ»‘å‹•è¦–çª—ã€é‡ç–Šä¸Šä¸‹æ–‡å’Œé‡è¤‡æƒæï¼Œå¯ä»¥æä¾›éƒ¨åˆ†ç·©è§£ï¼Œä½†ç„¡æ³•ä¿è­‰ã€‚</p>
<p><strong>å‚³çµ±çš„åˆ†å¡ŠæŠ€è¡“</strong>éµå¾ªæ­¤ç®¡é“ï¼š</p>
<ol>
<li><p><strong>é å…ˆå°‡</strong>æ–‡å­—<strong>åˆ†å¡Š</strong>ï¼ˆä¾æ“šå¥å­ã€æ®µè½æˆ–æœ€å¤§ç¬¦è™Ÿé•·åº¦ï¼‰ã€‚</p></li>
<li><p>å–®ç¨<strong>åµŒå…¥</strong>æ¯å€‹åˆ†å¡Šã€‚</p></li>
<li><p><strong>å°‡è¨˜è™Ÿ</strong>åµŒå…¥<strong>èšåˆ</strong>(ä¾‹å¦‚ï¼Œé€éå¹³å‡<strong>åŒ¯é›†</strong>) æˆç‚ºå–®ä¸€çš„åˆ†å¡Šå‘é‡ã€‚</p></li>
</ol>
<p><strong>Late Chunking</strong>ç¿»è½‰ç®¡é“ï¼š</p>
<ol>
<li><p><strong>å…ˆåµŒå…¥</strong>ï¼šåœ¨æ•´å€‹æ–‡ä»¶ä¸ŠåŸ·è¡Œé•·ä¸Šä¸‹æ–‡è½‰æ›å™¨ï¼Œç”¢ç”Ÿè±å¯Œçš„æ¨™è¨˜åµŒå…¥ï¼Œæ•æ‰å…¨å±€ä¸Šä¸‹æ–‡ã€‚</p></li>
<li><p><strong>ä¹‹å¾Œå†åˆ†å¡Š</strong>ï¼šå¹³å‡æ± åŒ–é€™äº›æ¨™è¨˜åµŒå…¥çš„é€£çºŒè·¨åº¦ï¼Œä»¥å½¢æˆæœ€çµ‚çš„åˆ†å¡Šå‘é‡ã€‚</p></li>
</ol>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Figure2_Naive_Chunkingvs_Late_Chunking_a94d30b6ea.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>åœ– 2.åŸå§‹åˆ†å¡Šèˆ‡å¾ŒæœŸåˆ†å¡Š (</em><a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/"><em>åŸå§‹</em></a><em>ç¢¼</em><em>)</em></p>
<p>é€šéåœ¨æ¯å€‹åˆ†å¡Šä¸­ä¿ç•™å®Œæ•´çš„æ–‡æª”ä¸Šä¸‹æ–‡ï¼Œå¾ŒæœŸåˆ†å¡ŠæŠ€è¡“å¯ä»¥ç”¢ç”Ÿä»¥ä¸‹æ•ˆæœï¼š</p>
<ul>
<li><p><strong>æ›´é«˜çš„æª¢ç´¢æº–ç¢ºåº¦ - æ¯å€‹</strong>åˆ†å¡Šéƒ½èƒ½æ„ŸçŸ¥ä¸Šä¸‹æ–‡ã€‚</p></li>
<li><p><strong>æ›´å°‘çš„åˆ†å¡Š - æ‚¨å¯ä»¥</strong>å‚³é€æ›´é›†ä¸­çš„æ–‡å­—åˆ° LLMï¼Œæ¸›å°‘æˆæœ¬èˆ‡å»¶é²ã€‚</p></li>
</ul>
<p>è¨±å¤šé•·ä¸Šä¸‹æ–‡æ¨¡å‹ï¼ˆä¾‹å¦‚ jina-embeddings-v2-base-enï¼‰æœ€å¤šå¯è™•ç† 8,192 å€‹å­—å…ƒï¼Œç›¸ç•¶æ–¼ 20 åˆ†é˜çš„é–±è®€æ™‚é–“ï¼ˆå¤§ç´„ 5,000 å€‹å­—ï¼‰ï¼Œå› æ­¤ Late Chunking é©ç”¨æ–¼å¤§å¤šæ•¸çš„å¯¦éš›æ–‡ä»¶ã€‚</p>
<p>ç¾åœ¨æˆ‘å€‘ç­è§£äº† Late Chunking èƒŒå¾Œçš„ ã€Œæ˜¯ä»€éº¼ ã€å’Œ ã€Œç‚ºä»€éº¼ã€ï¼Œè®“æˆ‘å€‘æ·±å…¥ç­è§£ ã€Œæ€éº¼åšã€ã€‚åœ¨ä¸‹ä¸€ç¯€ä¸­ï¼Œæˆ‘å€‘å°‡å¼•å°æ‚¨å¯¦è¸ Late Chunking ç®¡é“ï¼Œå°‡å…¶æ€§èƒ½èˆ‡å‚³çµ±çš„åˆ†å¡ŠæŠ€è¡“é€²è¡Œæ¯”è¼ƒï¼Œä¸¦ä½¿ç”¨ Milvus å°å…¶å¯¦éš›å½±éŸ¿é€²è¡Œé©—è­‰ã€‚é€™å€‹å¯¦å‹™æ¼”ç·´å°‡éŠœæ¥ç†è«–èˆ‡å¯¦å‹™ï¼Œæº–ç¢ºå±•ç¤ºå¦‚ä½•å°‡å¾ŒæœŸåˆ†å¡ŠæŠ€è¡“æ•´åˆåˆ°æ‚¨çš„ RAG å·¥ä½œæµç¨‹ä¸­ã€‚</p>
<h2 id="Testing-Late-Chunking" class="common-anchor-header">æ¸¬è©¦å¾ŒæœŸåˆ†å¡Š<button data-href="#Testing-Late-Chunking" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Basic-Implementation" class="common-anchor-header">åŸºæœ¬å¯¦ä½œ</h3><p>ä»¥ä¸‹æ˜¯ Late Chunking çš„æ ¸å¿ƒåŠŸèƒ½ã€‚æˆ‘å€‘å·²åŠ å…¥æ¸…æ™°çš„èªªæ˜æ–‡ä»¶ï¼Œå¼•å°æ‚¨å®Œæˆæ¯å€‹æ­¥é©Ÿã€‚å‡½å¼<code translate="no">sentence_chunker</code> æœƒå°‡åŸå§‹æ–‡ä»¶åˆ†å‰²æˆä»¥æ®µè½ç‚ºåŸºç¤çš„åˆ†å¡Šï¼Œä¸¦å‚³å›åˆ†å¡Šå…§å®¹å’Œåˆ†å¡Šè¨»è§£è³‡è¨Š<code translate="no">span_annotations</code> (å³æ¯å€‹åˆ†å¡Šçš„é–‹å§‹å’ŒçµæŸç´¢å¼•)ã€‚</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sentence_chunker</span>(<span class="hljs-params">document, batch_size=<span class="hljs-number">10000</span></span>):
    nlp = spacy.blank(<span class="hljs-string">&quot;en&quot;</span>)
    nlp.add_pipe(<span class="hljs-string">&quot;sentencizer&quot;</span>, config={<span class="hljs-string">&quot;punct_chars&quot;</span>: <span class="hljs-literal">None</span>})
    doc = nlp(document)

    docs = []
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(document), batch_size):
        batch = document[i : i + batch_size]
        docs.append(nlp(batch))

    doc = Doc.from_docs(docs)

    span_annotations = []
    chunks = []
    <span class="hljs-keyword">for</span> i, sent <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(doc.sents):
        span_annotations.append((sent.start, sent.end))
        chunks.append(sent.text)

    <span class="hljs-keyword">return</span> chunks, span_annotations
<button class="copy-code-btn"></button></code></pre>
<p>å‡½å¼<code translate="no">document_to_token_embeddings</code> ä½¿ç”¨ jinaai/jina-embeddings-v2-base-en æ¨¡å‹åŠå…¶ tokenizer ä¾†ç”¢ç”Ÿæ•´å€‹æ–‡ä»¶çš„ embeddingsã€‚</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">document_to_token_embeddings</span>(<span class="hljs-params">model, tokenizer, document, batch_size=<span class="hljs-number">4096</span></span>):
    tokenized_document = tokenizer(document, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
    tokens = tokenized_document.tokens()

    outputs = []
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(tokens), batch_size):
        
        start = i
        end   = <span class="hljs-built_in">min</span>(i + batch_size, <span class="hljs-built_in">len</span>(tokens))

        batch_inputs = {k: v[:, start:end] <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> tokenized_document.items()}

        <span class="hljs-keyword">with</span> torch.no_grad():
            model_output = model(**batch_inputs)

        outputs.append(model_output.last_hidden_state)

    model_output = torch.cat(outputs, dim=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> model_output
<button class="copy-code-btn"></button></code></pre>
<p>å‡½å¼<code translate="no">late_chunking</code> æ¥æ”¶æ–‡ä»¶çš„ token embeddings å’ŒåŸå§‹çš„ chunk è¨»è§£è³‡è¨Š<code translate="no">span_annotations</code> ï¼Œç„¶å¾Œç”¢ç”Ÿæœ€å¾Œçš„ chunk embeddingsã€‚</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">late_chunking</span>(<span class="hljs-params">token_embeddings, span_annotation, max_length=<span class="hljs-literal">None</span></span>):
    outputs = []
    <span class="hljs-keyword">for</span> embeddings, annotations <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(token_embeddings, span_annotation):
        <span class="hljs-keyword">if</span> (
            max_length <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>
        ):
            annotations = [
                (start, <span class="hljs-built_in">min</span>(end, max_length - <span class="hljs-number">1</span>))
                <span class="hljs-keyword">for</span> (start, end) <span class="hljs-keyword">in</span> annotations
                <span class="hljs-keyword">if</span> start &lt; (max_length - <span class="hljs-number">1</span>)
            ]
        pooled_embeddings = []
        <span class="hljs-keyword">for</span> start, end <span class="hljs-keyword">in</span> annotations:
            <span class="hljs-keyword">if</span> (end - start) &gt;= <span class="hljs-number">1</span>:
                pooled_embeddings.append(
                    embeddings[start:end].<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">0</span>) / (end - start)
                )
                    
        pooled_embeddings = [
            embedding.detach().cpu().numpy() <span class="hljs-keyword">for</span> embedding <span class="hljs-keyword">in</span> pooled_embeddings
        ]
        outputs.append(pooled_embeddings)

    <span class="hljs-keyword">return</span> outputs
<button class="copy-code-btn"></button></code></pre>
<p>ä¾‹å¦‚ï¼Œä½¿ç”¨ jinaai/jina-embeddings-v2-base-en é€²è¡Œåˆ†å¡Šï¼š</p>
<pre><code translate="no">tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;jinaai/jina-embeddings-v2-base-en&#x27;</span>, trust_remote_code=<span class="hljs-literal">True</span>)
model     = AutoModel.from_pretrained(<span class="hljs-string">&#x27;jinaai/jina-embeddings-v2-base-en&#x27;</span>, trust_remote_code=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># First chunk the text as normal, to obtain the beginning and end points of the chunks.</span>
chunks, span_annotations = sentence_chunker(document)
<span class="hljs-comment"># Then embed the full document.</span>
token_embeddings = document_to_token_embeddings(model, tokenizer, document)
<span class="hljs-comment"># Then perform the late chunking</span>
chunk_embeddings = late_chunking(token_embeddings, [span_annotations])[<span class="hljs-number">0</span>]
<button class="copy-code-btn"></button></code></pre>
<p><em>æç¤ºï¼š</em>å°‡æ‚¨çš„ç®¡é“åŒ…è£åœ¨å‡½æ•¸ä¸­ï¼Œå¯ä»¥è¼•é¬†åœ°æ›ç”¨å…¶ä»–é•·å…§å®¹æ¨¡å‹æˆ–åˆ†å¡Šç­–ç•¥ã€‚</p>
<h3 id="Comparison-with-Traditional-Embedding-Methods" class="common-anchor-header">èˆ‡å‚³çµ±åµŒå…¥æ–¹æ³•çš„æ¯”è¼ƒ</h3><p>ç‚ºäº†é€²ä¸€æ­¥å±•ç¤º Late Chunking çš„å„ªå‹¢ï¼Œæˆ‘å€‘ä¹Ÿä½¿ç”¨ä¸€çµ„æ¨£æœ¬æ–‡ä»¶å’ŒæŸ¥è©¢ï¼Œå°‡å®ƒèˆ‡å‚³çµ±çš„åµŒå…¥æ–¹æ³•é€²è¡Œæ¯”è¼ƒã€‚</p>
<p>å†è®“æˆ‘å€‘é‡æº« Milvus 2.4.13 ç™¼è¡Œç´€éŒ„çš„ç¯„ä¾‹ï¼š</p>
<pre><code translate="no"><span class="hljs-title class_">Milvus</span> <span class="hljs-number">2.4</span><span class="hljs-number">.13</span> introduces dynamic replica load, allowing users to adjust the number <span class="hljs-keyword">of</span> collection replicas without needing to release and reload the collection. <span class="hljs-title class_">This</span> version also addresses several critical bugs related to bulk importing, expression parsing, load balancing, and failure recovery. <span class="hljs-title class_">Additionally</span>, significant improvements have been made to <span class="hljs-variable constant_">MMAP</span> resource usage and <span class="hljs-keyword">import</span> performance, enhancing overall system efficiency. <span class="hljs-title class_">We</span> highly recommend upgrading to <span class="hljs-variable language_">this</span> release <span class="hljs-keyword">for</span> better performance and stability.
<button class="copy-code-btn"></button></code></pre>
<p>æˆ‘å€‘æ¸¬é‡æŸ¥è©¢åµŒå…¥ï¼ˆ"milvus 2.4.13"ï¼‰å’Œæ¯å€‹åˆ†å¡Šä¹‹é–“çš„<a href="https://zilliz.com/blog/similarity-metrics-for-vector-search#Cosine-Similarity">ä½™å¼¦ç›¸ä¼¼åº¦</a>ï¼š</p>
<pre><code translate="no">cos_sim = <span class="hljs-keyword">lambda</span> x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))

milvus_embedding = model.encode(<span class="hljs-string">&#x27;milvus 2.4.13&#x27;</span>)

<span class="hljs-keyword">for</span> chunk, late_chunking_embedding, traditional_embedding <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(chunks, chunk_embeddings, embeddings_traditional_chunking):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;similarity_late_chunking(&quot;milvus 2.4.13&quot;, &quot;<span class="hljs-subst">{chunk}</span>&quot;)&#x27;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;late_chunking: &#x27;</span>, cos_sim(milvus_embedding, late_chunking_embedding))
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;similarity_traditional(&quot;milvus 2.4.13&quot;, &quot;<span class="hljs-subst">{chunk}</span>&quot;)&#x27;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;traditional_chunking: &#x27;</span>, cos_sim(milvus_embedding, traditional_embeddings))
<button class="copy-code-btn"></button></code></pre>
<p>Late Chunking çš„è¡¨ç¾æŒçºŒå„ªæ–¼å‚³çµ±çš„ chunkingï¼Œæ¯å€‹ chunk çš„ä½™å¼¦ç›¸ä¼¼åº¦éƒ½è¼ƒé«˜ã€‚é€™è­‰å¯¦äº†å…ˆåµŒå…¥å®Œæ•´æ–‡ä»¶èƒ½æ›´æœ‰æ•ˆåœ°ä¿ç•™å…¨å±€ä¸Šä¸‹æ–‡ã€‚</p>
<pre><code translate="no"><span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Milvus 2.4.13 introduces dynamic replica load, allowing users to adjust the number of collection replicas without needing to release and reload the collection.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.8785206</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Milvus 2.4.13 introduces dynamic replica load, allowing users to adjust the number of collection replicas without needing to release and reload the collection.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.8354263</span>

<span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;This version also addresses several critical bugs related to bulk importing, expression parsing, load balancing, and failure recovery.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.84828955</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;This version also addresses several critical bugs related to bulk importing, expression parsing, load balancing, and failure recovery.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.7222632</span>

<span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Additionally, significant improvements have been made to MMAP resource usage and import performance, enhancing overall system efficiency.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.84942204</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;Additionally, significant improvements have been made to MMAP resource usage and import performance, enhancing overall system efficiency.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.6907381</span>

<span class="hljs-title function_">similarity_late_chunking</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;We highly recommend upgrading to this release for better performance and stability.&quot;</span>)
<span class="hljs-attr">late_chunking</span>: <span class="hljs-number">0.85431844</span>
<span class="hljs-title function_">similarity_traditional</span>(<span class="hljs-string">&quot;milvus 2.4.13&quot;</span>, <span class="hljs-string">&quot;We highly recommend upgrading to this release for better performance and stability.&quot;</span>)
<span class="hljs-attr">traditional_chunking</span>: <span class="hljs-number">0.71859795</span>
<button class="copy-code-btn"></button></code></pre>
<p>æˆ‘å€‘å¯ä»¥çœ‹åˆ°ï¼Œå…ˆåµŒå…¥å®Œæ•´çš„æ®µè½å¯ä»¥ç¢ºä¿æ¯å€‹åˆ†å¡Šéƒ½å¸¶æœ‰ "<code translate="no">Milvus 2.4.13</code>" ä¸Šä¸‹æ–‡ï¼Œé€²è€Œæå‡ç›¸ä¼¼åº¦åˆ†æ•¸å’Œæª¢ç´¢å“è³ªã€‚</p>
<h3 id="Testing-Late-Chunking-in-Milvus" class="common-anchor-header"><strong>åœ¨ Milvus æ¸¬è©¦å¾ŒæœŸåˆ†å¡Š</strong></h3><p>ä¸€æ—¦ç”Ÿæˆäº†åˆ†å¡ŠåµŒå…¥ï¼Œæˆ‘å€‘å°±å¯ä»¥å°‡å…¶å­˜å…¥ Milvus ä¸¦é€²è¡ŒæŸ¥è©¢ã€‚ä¸‹é¢çš„ç¨‹å¼ç¢¼æœƒå°‡åˆ†å¡Šå‘é‡æ’å…¥åˆ°é›†åˆä¸­ã€‚</p>
<h4 id="Importing-Embeddings-into-Milvus" class="common-anchor-header"><strong>å°‡åµŒå…¥å‘é‡åŒ¯å…¥ Milvus</strong></h4><pre><code translate="no">batch_data=[]
<span class="hljs-keyword">for</span> i in <span class="hljs-keyword">range</span>(<span class="hljs-built_in">len</span>(chunks)):
    data = {
            <span class="hljs-string">&quot;content&quot;</span>: chunks[i],
            <span class="hljs-string">&quot;embedding&quot;</span>: chunk_embeddings[i].tolist(),
        }

    batch_data.<span class="hljs-built_in">append</span>(data)

res = client.insert(
    collection_name=collection,
    data=batch_data,
)
<button class="copy-code-btn"></button></code></pre>
<h4 id="Querying-and-Validation" class="common-anchor-header">æŸ¥è©¢èˆ‡é©—è­‰</h4><p>ç‚ºäº†é©—è­‰ Milvus æŸ¥è©¢çš„æº–ç¢ºæ€§ï¼Œæˆ‘å€‘å°‡å…¶æª¢ç´¢çµæœèˆ‡æ‰‹å‹•è¨ˆç®—çš„ç²—ç•¥ä½™å¼¦ç›¸ä¼¼åº¦å¾—åˆ†é€²è¡Œæ¯”è¼ƒã€‚å¦‚æœå…©ç¨®æ–¹æ³•éƒ½å‚³å›ä¸€è‡´çš„ top-k çµæœï¼Œæˆ‘å€‘å°±å¯ä»¥ç›¸ä¿¡ Milvus çš„æœå°‹æº–ç¢ºåº¦æ˜¯å¯é çš„ã€‚</p>
<p>æˆ‘å€‘æ¯”è¼ƒ Milvus çš„æœ¬æ©Ÿæœå°‹èˆ‡ç²—æš´çš„ä½™å¼¦ç›¸ä¼¼æ€§æƒæï¼š</p>
<pre><code translate="no"><span class="hljs-keyword">def</span> <span class="hljs-title function_">late_chunking_query_by_milvus</span>(<span class="hljs-params">query, top_k = <span class="hljs-number">3</span></span>):
    query_vector = model(**tokenizer(query, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)).last_hidden_state.mean(<span class="hljs-number">1</span>).detach().cpu().numpy().flatten()

    res = client.search(
                collection_name=collection,
                data=[query_vector.tolist()],
                limit=top_k,
                output_fields=[<span class="hljs-string">&quot;id&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>],
            )

    <span class="hljs-keyword">return</span> [item.get(<span class="hljs-string">&quot;entity&quot;</span>).get(<span class="hljs-string">&quot;content&quot;</span>) <span class="hljs-keyword">for</span> items <span class="hljs-keyword">in</span> res <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> items]

<span class="hljs-keyword">def</span> <span class="hljs-title function_">late_chunking_query_by_cosine_sim</span>(<span class="hljs-params">query, k = <span class="hljs-number">3</span></span>):
    cos_sim = <span class="hljs-keyword">lambda</span> x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))
    query_vector = model(**tokenizer(query, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)).last_hidden_state.mean(<span class="hljs-number">1</span>).detach().cpu().numpy().flatten()

    results = np.empty(<span class="hljs-built_in">len</span>(chunk_embeddings))
    <span class="hljs-keyword">for</span> i, (chunk, embedding) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(chunks, chunk_embeddings)):
        results[i] = cos_sim(query_vector, embedding)

    results_order = results.argsort()[::-<span class="hljs-number">1</span>]
    <span class="hljs-keyword">return</span> np.array(chunks)[results_order].tolist()[:k]
<button class="copy-code-btn"></button></code></pre>
<p>é€™è­‰å¯¦äº† Milvus èˆ‡æ‰‹å‹•ä½™å¼¦ç›¸ä¼¼åº¦æƒææœƒè¿”å›ç›¸åŒçš„ top-k ç‰‡æ®µã€‚</p>
<pre><code translate="no">&gt; late_chunking_query_by_milvus(<span class="hljs-string">&quot;What are new features in milvus 2.4.13&quot;</span>, 3)

[<span class="hljs-string">&#x27;\n\n### Features\n\n- Dynamic replica adjustment for loaded collections ([#36417](https://github.com/milvus-io/milvus/pull/36417))\n- Sparse vector MMAP in growing segment types ([#36565](https://github.com/milvus-io/milvus/pull/36565))...
</span><button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">&gt; late_chunking_query_by_cosine_sim(<span class="hljs-string">&quot;What are new features in milvus 2.4.13&quot;</span>, 3)

[<span class="hljs-string">&#x27;\n\n### Features\n\n- Dynamic replica adjustment for loaded collections ([#36417](https://github.com/milvus-io/milvus/pull/36417))\n- Sparse vector MMAP in growing segment types (#36565)...
</span><button class="copy-code-btn"></button></code></pre>
<p>å› æ­¤ï¼Œå…©ç¨®æ–¹æ³•éƒ½æœƒç”¢ç”Ÿç›¸åŒçš„å‰ä¸‰å¤§å¡Šï¼Œè­‰å¯¦äº† Milvus çš„æº–ç¢ºæ€§ã€‚</p>
<h2 id="Conclusion" class="common-anchor-header">ç¸½çµ<button data-href="#Conclusion" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>åœ¨é€™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å€‘æ·±å…¥æ¢è¨äº† Late Chunking çš„æ©Ÿåˆ¶å’Œå„ªé»ã€‚æˆ‘å€‘é¦–å…ˆè­˜åˆ¥äº†å‚³çµ±åˆ†å¡Šæ–¹æ³•çš„ç¼ºé»ï¼Œå°¤å…¶æ˜¯åœ¨è™•ç†é•·æ–‡ä»¶æ™‚ï¼Œä¿ç•™ä¸Šä¸‹æ–‡æ˜¯éå¸¸é‡è¦çš„ã€‚æˆ‘å€‘ä»‹ç´¹äº†å¾ŒæœŸåˆ†å¡Š (Late Chunking) çš„æ¦‚å¿µ - åœ¨å°‡æ–‡æª”åˆ†å‰²æˆæœ‰æ„ç¾©çš„åˆ†å¡Šä¹‹å‰å…ˆåµŒå…¥æ•´å€‹æ–‡æª”ï¼Œä¸¦å±•ç¤ºäº†é€™å¦‚ä½•ä¿ç•™å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¾è€Œæé«˜èªç¾©ç›¸ä¼¼æ€§å’Œæª¢ç´¢æº–ç¢ºæ€§ã€‚</p>
<p>æ¥è‘—ï¼Œæˆ‘å€‘ä½¿ç”¨ Jina AI çš„ jina-embeddings-v2-base-en æ¨¡å‹é€²è¡Œå¯¦ä½œï¼Œä¸¦èˆ‡å‚³çµ±æ–¹æ³•æ¯”è¼ƒè©•ä¼°å…¶æ•ˆèƒ½ã€‚æœ€å¾Œï¼Œæˆ‘å€‘å±•ç¤ºäº†å¦‚ä½•å°‡ Chunk embeddings æ•´åˆåˆ° Milvus ä¸­ï¼Œä»¥é€²è¡Œå¯æ“´å……ä¸”ç²¾ç¢ºçš„å‘é‡æœå°‹ã€‚</p>
<p>Late Chunking æä¾›äº†ä¸€ç¨®<strong>ä¸Šä¸‹æ–‡ç¬¬ä¸€</strong>çš„åµŒå…¥æ–¹æ³•ï¼Œéå¸¸é©åˆä¸Šä¸‹æ–‡æœ€é‡è¦çš„è¤‡é›œé•·ç¯‡æ–‡ä»¶ã€‚å…ˆåµŒå…¥æ•´å€‹æ–‡å­—ï¼Œä¹‹å¾Œå†é€²è¡Œåˆ†å¡Šï¼Œæ‚¨å¯ä»¥ç²å¾—ä»¥ä¸‹å¥½è™•</p>
<ul>
<li><p><strong>æ›´ç²¾ç¢ºçš„æª¢ç´¢æº–ç¢ºåº¦</strong></p></li>
<li><p><strong>ç²¾ç°¡ã€é›†ä¸­çš„ LLM æç¤º</strong></p></li>
<li><p>ğŸ› ï¸ å¯èˆ‡ä»»ä½•é•·å…§å®¹æ¨¡å‹<strong>ç°¡å–®æ•´åˆ</strong></p></li>
</ul>
