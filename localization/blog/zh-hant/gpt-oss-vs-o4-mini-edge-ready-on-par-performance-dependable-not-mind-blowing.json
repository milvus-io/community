{"codeList":["! pip install --upgrade \"pymilvus[model]\" openai requests tqdm\n","# Download and prepare Milvus docs\n! wget https://github.com/milvus-io/milvus-docs/releases/download/v2.4.6-preview/milvus_docs_2.4.x_en.zip\n! unzip -q milvus_docs_2.4.x_en.zip -d milvus_docs\n\nfrom glob import glob\ntext_lines = []\nfor file_path in glob(\"milvus_docs/en/faq/*.md\", recursive=True):\n    with open(file_path, \"r\") as file:\n        file_text = file.read()\n    text_lines += file_text.split(\"# \")\n","from openai import OpenAI\n\n# Using OpenRouter for cloud access\nopenai_client = OpenAI(\n    api_key=\"<OPENROUTER_API_KEY>\",\n    base_url=\"https://openrouter.ai/api/v1\",\n)\n\n# Set up embedding model\nfrom pymilvus import model as milvus_model\nembedding_model = milvus_model.DefaultEmbeddingFunction()\n\n# Test embedding dimensions\ntest_embedding = embedding_model.encode_queries([\"This is a test\"])[0]\nembedding_dim = len(test_embedding)\nprint(embedding_dim)\nprint(test_embedding[:10])\n","768\n[-0.04836066  0.07163023 -0.01130064 -0.03789345 -0.03320649 -0.01318448\n -0.03041712 -0.02269499 -0.02317863 -0.00426028]\n","from pymilvus import MilvusClient\n\n# Initialize Milvus client\nmilvus_client = MilvusClient(uri=\"http://localhost:19530\", token=\"root:Milvus\")\ncollection_name = \"gpt_oss_rag_collection\"\n\n# Clean up existing collection\nif milvus_client.has_collection(collection_name):\n    milvus_client.drop_collection(collection_name)\n\n# Create new collection\nmilvus_client.create_collection(\n    collection_name=collection_name,\n    dimension=embedding_dim,\n    metric_type=\"IP\",  # Inner product distance\n    consistency_level=\"Strong\",\n)\n","from tqdm import tqdm\n\ndata = []\ndoc_embeddings = embedding_model.encode_documents(text_lines)\n\nfor i, line in enumerate(tqdm(text_lines, desc=\"Creating embeddings\")):\n    data.append({\"id\": i, \"vector\": doc_embeddings[i], \"text\": line})\n\nmilvus_client.insert(collection_name=collection_name, data=data)\n","Creating embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 1222631.13it/s]\n{'insert_count': 72, 'ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71], 'cost': 0}\n","question = \"How is data stored in milvus?\"\n","search_res = milvus_client.search(\n    collection_name=collection_name,\n    data=embedding_model.encode_queries(\n        [question]\n    ),  # Convert the question to an embedding vector\n    limit=3,  # Return top 3 results\n    search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n    output_fields=[\"text\"],  # Return the text field\n)\n","import json\n\nretrieved_lines_with_distances = [\n    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n]\nprint(json.dumps(retrieved_lines_with_distances, indent=4))\n","[\n    [\n        \" Where does Milvus store data?\\n\\nMilvus deals with two types of data, inserted data and metadata. \\n\\nInserted data, including vector data, scalar data, and collection-specific schema, are stored in persistent storage as incremental log. Milvus supports multiple object storage backends, including [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/?nc1=h_ls), [Google Cloud Storage](https://cloud.google.com/storage?hl=en#object-storage-for-companies-of-all-sizes) (GCS), [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs), [Alibaba Cloud OSS](https://www.alibabacloud.com/product/object-storage-service), and [Tencent Cloud Object Storage](https://www.tencentcloud.com/products/cos) (COS).\\n\\nMetadata are generated within Milvus. Each Milvus module has its own metadata that are stored in etcd.\\n\\n###\",\n        0.6572664976119995\n    ],\n    [\n        \"How does Milvus flush data?\\n\\nMilvus returns success when inserted data are loaded to the message queue. However, the data are not yet flushed to the disk. Then Milvus' data node writes the data in the message queue to persistent storage as incremental logs. If `flush()` is called, the data node is forced to write all data in the message queue to persistent storage immediately.\\n\\n###\",\n        0.6312144994735718\n    ],\n    [\n        \"How does Milvus handle vector data types and precision?\\n\\nMilvus supports Binary, Float32, Float16, and BFloat16 vector types.\\n\\n- Binary vectors: Store binary data as sequences of 0s and 1s, used in image processing and information retrieval.\\n- Float32 vectors: Default storage with a precision of about 7 decimal digits. Even Float64 values are stored with Float32 precision, leading to potential precision loss upon retrieval.\\n- Float16 and BFloat16 vectors: Offer reduced precision and memory usage. Float16 is suitable for applications with limited bandwidth and storage, while BFloat16 balances range and efficiency, commonly used in deep learning to reduce computational requirements without significantly impacting accuracy.\\n\\n###\",\n        0.6115782856941223\n    ]\n]\n","context = \"\\n\".join(\n    [line_with_distance[0] for line_with_distance in retrieved_lines_with_distances]\n)\n","SYSTEM_PROMPT = \"\"\"\nHuman: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\n\"\"\"\nUSER_PROMPT = f\"\"\"\nUse the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n<context>\n{context}\n</context>\n<question>\n{question}\n</question>\n\"\"\"\n","response = openai_client.chat.completions.create(\n    model=\"openai/gpt-oss-120b\",\n    messages=[\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n        {\"role\": \"user\", \"content\": USER_PROMPT},\n    ],\n)\nprint(response.choices[0].message.content)\n","Milvus stores its data in two distinct layers:\n\n| Type of data | Where it is stored | How it is stored |\n|-------------|-------------------|-----------------|\n| **Inserted data** (vector data, scalar fields, collection‑specific schema) | In the **persistent object storage** configured for the cluster. The data are written as **incremental logs** (append‑only logs) that are persisted by the DataNode. | The DataNode reads from the message‑queue and writes the incoming data into the storage backend (MinIO, AWS S3, GCS, Azure Blob, Alibaba OSS, Tencent COS, etc.). When a `flush()` call is issued, the DataNode forces all queued data to be written to the persistent storage immediately. |\n| **Metadata** (information about collections, partitions, indexes, etc.) | In **etcd**. Each Milvus module (catalog, index, etc.) keeps its own metadata. | The metadata is generated and managed by Milvus and persisted in the distributed key‑value store **etcd**. |\n\n**Summary:**  \n- **Inserted data** = incremental logs stored in the chosen object‑storage backend.  \n- **Metadata** = stored in the distributed configuration store **etcd**.  \n\n\nTogether, these two storage mechanisms (object storage for the actual data and etcd for metadata) make up Milvus’s data‑storage architecture.\n"],"headingContent":"","anchorList":[{"label":"是什麼讓 GPT-oss 與眾不同？","href":"What-Makes-GPT-oss-Special-and-Why-You-Should-Care","type":2,"isActive":false},{"label":"GPT-oss 與其他推理模型的比較","href":"GPT-oss-vs-Other-Reasoning-Models","type":2,"isActive":false},{"label":"實際操作：使用 GPT-oss + Milvus 進行建置","href":"Hands-on-Building-with-GPT-oss-+-Milvus","type":2,"isActive":false},{"label":"對 GPT-oss 的最後感想","href":"Final-Thoughts-on-GPT-oss","type":2,"isActive":false}]}