{"codeList":["FieldSchema(\n    name=\"text\",\n    dtype=DataType.VARCHAR,\n    max_length=512,\n    analyzer_params={\n       \"tokenizer\": \"standard\"   # Configure Tokenizer here\n    }\n)\n","FieldSchema(\n    name=\"text\",\n    dtype=DataType.VARCHAR,\n    max_length=512,\n    analyzer_params={\n        \"tokenizer\": \"standard\",\n        \"filter\": [\n            \"lowercase\",\n            {\n               \"type\": \"stop\", # Specifies the filter type as stop\n               \"stop_words\": [\"of\", \"to\", \"_english_\"], # Defines custom stop words and includes the English stop word list\n            },\n            {\n                \"type\": \"stemmer\",  # Specifies the filter type as stemmer\n                \"language\": \"english\"\n            }],\n    }\n)\n","FieldSchema(\n        name=\"text\",\n        dtype=DataType.VARCHAR,\n        max_length=512,\n        analyzer_params={\n           \"tokenizer\": \"jieba\",  \n            \"filter\": [\"cncharonly\", \"stop\"]  # Custom combination for mixed Chinese-English text\n        }\n    )\n","from pymilvus import MilvusClient, DataType, Function, FunctionType\n\nclient = MilvusClient(\n    uri=\"http://localhost:19530\",\n)\n\nschema = client.create_schema()\n\nschema.add_field(\n    field_name=\"id\",                  # Field name\n    datatype=DataType.INT64,          # Integer data type\n    is_primary=True,                  # Designate as primary key\n    auto_id=True                      # Auto-generate IDs (recommended)\n)\n\nschema.add_field(\n    field_name='text',\n    datatype=DataType.VARCHAR,\n    max_length=1000,\n    enable_analyzer=True,\n    analyzer_params={\n            \"tokenizer\": \"standard\",\n            \"filter\": [\n            \"lowercase\",\n            {\n            \"type\": \"stop\", # Specifies the filter type as stop\n            \"stop_words\": [\"of\", \"to\", \"_english_\"], # Defines custom stop words and includes the English stop word list\n            },\n            {\n                \"type\": \"stemmer\",  # Specifies the filter type as stemmer\n                \"language\": \"english\"\n            }],\n        },\n    enable_match=True,\n)\n\nschema.add_field(\n    field_name=\"sparse\",                   # Field name\n    datatype=DataType.SPARSE_FLOAT_VECTOR  # Sparse vector data type\n)\n\nbm25_function = Function(\n    name=\"text_to_vector\",            # Descriptive function name\n    function_type=FunctionType.BM25,  # Use BM25 algorithm\n    input_field_names=[\"text\"],       # Process text from this field\n    output_field_names=[\"sparse\"]     # Store vectors in this field\n)\n\nschema.add_function(bm25_function)\n\nindex_params = client.prepare_index_params()\n\nindex_params.add_index(\n    field_name=\"sparse\",        # Field to index (our vector field)\n    index_type=\"AUTOINDEX\",     # Let Milvus choose optimal index type\n    metric_type=\"BM25\"          # Must be BM25 for this feature\n)\n\nCOLLECTION_NAME = \"english_demo\"\n\nif client.has_collection(COLLECTION_NAME):\n    client.drop_collection(COLLECTION_NAME)  \n    print(f\"Dropped existing collection: {COLLECTION_NAME}\")\n\nclient.create_collection(\n    collection_name=COLLECTION_NAME,       # Collection name\n    schema=schema,                         # Our schema\n    index_params=index_params              # Our search index configuration\n)\n\nprint(f\"Successfully created collection: {COLLECTION_NAME}\")\n\n# Prepare sample data\nsample_texts = [\n    \"The quick brown fox jumps over the lazy dog\",\n    \"Machine learning algorithms are revolutionizing artificial intelligence\",  \n    \"Python programming language is widely used for data science projects\",\n    \"Natural language processing helps computers understand human languages\",\n    \"Deep learning models require large amounts of training data\",\n    \"Search engines use complex algorithms to rank web pages\",\n    \"Text analysis and information retrieval are important NLP tasks\",\n    \"Vector databases enable efficient similarity searches\",\n    \"Stemming reduces words to their root forms for better searching\",\n    \"Stop words like 'the', 'and', 'of' are often filtered out\"\n]\n\n# Insert data\nprint(\"\\nInserting data...\")\ndata = [{\"text\": text} for text in sample_texts]\n\nclient.insert(\n    collection_name=COLLECTION_NAME,\n    data=data\n)\n\nprint(f\"Successfully inserted {len(sample_texts)} records\")\n\n# Demonstrate tokenizer effect\nprint(\"\\n\" + \"=\"*60)\nprint(\"Tokenizer Analysis Demo\")\nprint(\"=\"*60)\n\ntest_text = \"The running dogs are jumping over the lazy cats\"\nprint(f\"\\nOriginal text: '{test_text}'\")\n\n# Use run_analyzer to show tokenization results\nanalyzer_result = client.run_analyzer(\n    texts=test_text,\n    collection_name=COLLECTION_NAME,\n    field_name=\"text\"\n)\n\nprint(f\"Tokenization result: {analyzer_result}\")\nprint(\"\\nBreakdown:\")\nprint(\"- lowercase: Converts all letters to lowercase\")\nprint(\"- stop words: Filtered out ['of', 'to'] and common English stop words\")  \nprint(\"- stemmer: Reduced words to stem form (running -> run, jumping -> jump)\")\n\n# Full-text search demo\nprint(\"\\n\" + \"=\"*60)\nprint(\"Full-Text Search Demo\")\nprint(\"=\"*60)\n\n# Wait for indexing to complete\nimport time\ntime.sleep(2)\n\n# Search query examples\nsearch_queries = [\n    \"jump\",           # Test stem matching (should match \"jumps\")\n    \"algorithm\",      # Test exact matching\n    \"python program\", # Test multi-word query\n    \"learn\"          # Test stem matching (should match \"learning\")\n]\n\nfor i, query in enumerate(search_queries, 1):\n    print(f\"\\nQuery {i}: '{query}'\")\n    print(\"-\" * 40)\n    \n    # Execute full-text search\n    search_results = client.search(\n        collection_name=COLLECTION_NAME,\n        data=[query],                    # Query text\n        search_params={\"metric_type\": \"BM25\"},\n        output_fields=[\"text\"],         # Return original text\n        limit=3                         # Return top 3 results\n    )\n    \n    if search_results and len(search_results[0]) > 0:\n        for j, result in enumerate(search_results[0], 1):\n            score = result[\"distance\"]\n            text = result[\"entity\"][\"text\"]\n            print(f\"  Result {j} (relevance: {score:.4f}): {text}\")\n    else:\n        print(\"  No relevant results found\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Search complete！\")\nprint(\"=\"*60)\n","Dropped existing collection: english_demo\nSuccessfully created collection: english_demo\n\nInserting data...\nSuccessfully inserted 10 records\n\n============================================================\nTokenizer Analysis Demo\n============================================================\n\nOriginal text: 'The running dogs are jumping over the lazy cats'\nTokenization result: ['run', 'dog', 'jump', 'over', 'lazi', 'cat']\n\nBreakdown:\n- lowercase: Converts all letters to lowercase\n- stop words: Filtered out ['of', 'to'] and common English stop words\n- stemmer: Reduced words to stem form (running -> run, jumping -> jump)\n\n============================================================\nFull-Text Search Demo\n============================================================\n\nQuery 1: 'jump'\n----------------------------------------\n  Result 1 (relevance: 2.0040): The quick brown fox jumps over the lazy dog\n\nQuery 2: 'algorithm'\n----------------------------------------\n  Result 1 (relevance: 1.5819): Machine learning algorithms are revolutionizing artificial intelligence\n  Result 2 (relevance: 1.4086): Search engines use complex algorithms to rank web pages\n\nQuery 3: 'python program'\n----------------------------------------\n  Result 1 (relevance: 3.7884): Python programming language is widely used for data science projects\n\nQuery 4: 'learn'\n----------------------------------------\n  Result 1 (relevance: 1.5819): Machine learning algorithms are revolutionizing artificial intelligence\n  Result 2 (relevance: 1.4086): Deep learning models require large amounts of training data\n\n============================================================\nSearch complete！\n============================================================\n","from pymilvus import MilvusClient, DataType, Function, FunctionType\nimport time\n\n# Configure connection\nclient = MilvusClient(\n    uri=\"http://localhost:19530\",\n)\n\nCOLLECTION_NAME = \"multilingual_demo\"\n\n# Drop existing collection if present\nif client.has_collection(COLLECTION_NAME):\n    client.drop_collection(COLLECTION_NAME)\n\n# Create schema\nschema = client.create_schema()\n\n# Add primary key field\nschema.add_field(\n    field_name=\"id\",\n    datatype=DataType.INT64,\n    is_primary=True,\n    auto_id=True\n)\n\n# Add language identifier field\nschema.add_field(\n    field_name=\"language\",\n    datatype=DataType.VARCHAR,\n    max_length=50\n)\n\n# Add text field with multi-language analyzer configuration\nmulti_analyzer_params = {\n    \"by_field\": \"language\",  # Select analyzer based on language field\n    \"analyzers\": {\n        \"en\": {\n            \"type\": \"english\"  # English analyzer\n        },\n        \"zh\": {\n            \"type\": \"chinese\"  # Chinese analyzer\n        },\n        \"jp\": {\n            \"tokenizer\": \"icu\",  # Use ICU tokenizer for Japanese\n            \"filter\": [\n                \"lowercase\",\n                {\n                    \"type\": \"stop\",\n                    \"stop_words\": [\"は\", \"が\", \"の\", \"に\", \"を\", \"で\", \"と\"]\n                }\n            ]\n        },\n        \"default\": {\n            \"tokenizer\": \"icu\"  # Default to ICU general tokenizer\n        }\n    },\n    \"alias\": {\n        \"english\": \"en\",\n        \"chinese\": \"zh\", \n        \"japanese\": \"jp\",\n        \"中文\": \"zh\",\n        \"英文\": \"en\",\n        \"日文\": \"jp\"\n    }\n}\n\nschema.add_field(\n    field_name=\"text\",\n    datatype=DataType.VARCHAR,\n    max_length=2000,\n    enable_analyzer=True,\n    multi_analyzer_params=multi_analyzer_params\n)\n\n# Add sparse vector field for BM25\nschema.add_field(\n    field_name=\"sparse_vector\",\n    datatype=DataType.SPARSE_FLOAT_VECTOR\n)\n\n# Define BM25 function\nbm25_function = Function(\n    name=\"text_bm25\",\n    function_type=FunctionType.BM25,\n    input_field_names=[\"text\"],\n    output_field_names=[\"sparse_vector\"]\n)\n\nschema.add_function(bm25_function)\n\n# Prepare index parameters\nindex_params = client.prepare_index_params()\nindex_params.add_index(\n    field_name=\"sparse_vector\",\n    index_type=\"AUTOINDEX\",\n    metric_type=\"BM25\"\n)\n\n# Create collection\nclient.create_collection(\n    collection_name=COLLECTION_NAME,\n    schema=schema,\n    index_params=index_params\n)\n\n# Prepare multilingual test data\nmultilingual_data = [\n    # English data\n    {\"language\": \"en\", \"text\": \"Artificial intelligence is revolutionizing technology industries worldwide\"},\n    {\"language\": \"en\", \"text\": \"Machine learning algorithms process large datasets efficiently\"},\n    {\"language\": \"en\", \"text\": \"Vector databases provide fast similarity search capabilities\"},\n    \n    # Chinese data  \n    {\"language\": \"zh\", \"text\": \"人工智能正在改变世界各行各业\"},\n    {\"language\": \"zh\", \"text\": \"机器学习算法能够高效处理大规模数据集\"},\n    {\"language\": \"zh\", \"text\": \"向量数据库提供快速的相似性搜索功能\"},\n    \n    # Japanese data\n    {\"language\": \"jp\", \"text\": \"人工知能は世界中の技術産業に革命をもたらしています\"},\n    {\"language\": \"jp\", \"text\": \"機械学習アルゴリズムは大量のデータセットを効率的に処理します\"},\n    {\"language\": \"jp\", \"text\": \"ベクトルデータベースは高速な類似性検索機能を提供します\"},\n]\n\nclient.insert(\n    collection_name=COLLECTION_NAME,\n    data=multilingual_data\n)\n\n# Wait for BM25 function to generate vectors\nprint(\"Waiting for BM25 vector generation...\")\nclient.flush(COLLECTION_NAME)\ntime.sleep(5)\nclient.load_collection(COLLECTION_NAME)\n\n# Demonstrate tokenizer effect\nprint(\"\\nTokenizer Analysis:\")\n\ntest_texts = {\n    \"en\": \"The running algorithms are processing data efficiently\",\n    \"zh\": \"这些运行中的算法正在高效地处理数据\", \n    \"jp\": \"これらの実行中のアルゴリズムは効率的にデータを処理しています\"\n}\n\nfor lang, text in test_texts.items():\n    print(f\"{lang}: {text}\")\n    try:\n        analyzer_result = client.run_analyzer(\n            texts=text,\n            collection_name=COLLECTION_NAME,\n            field_name=\"text\",\n            analyzer_names=[lang]\n        )\n        print(f\"  → {analyzer_result}\")\n    except Exception as e:\n        print(f\"  → Analysis failed: {e}\")\n\n# Multi-language search demo\nprint(\"\\nSearch Test:\")\n\nsearch_cases = [\n    (\"zh\", \"人工智能\"),\n    (\"jp\", \"機械学習\"),\n    (\"en\", \"algorithm\"),\n]\n\nfor lang, query in search_cases:\n    print(f\"\\n{lang} '{query}':\")\n    try:\n        search_results = client.search(\n            collection_name=COLLECTION_NAME,\n            data=[query],\n            search_params={\"metric_type\": \"BM25\"},\n            output_fields=[\"language\", \"text\"],\n            limit=3,\n            filter=f'language == \"{lang}\"'\n        )\n        \n        if search_results and len(search_results[0]) > 0:\n            for result in search_results[0]:\n                score = result[\"distance\"]\n                text = result[\"entity\"][\"text\"]\n                print(f\"  {score:.3f}: {text}\")\n        else:\n            print(\"  No results\")\n    except Exception as e:\n        print(f\"  Error: {e}\")\n\nprint(\"\\nComplete\")\n","Waiting for BM25 vector generation...\n\nTokenizer Analysis:\nen: The running algorithms are processing data efficiently\n  → ['run', 'algorithm', 'process', 'data', 'effici']\nzh: 这些运行中的算法正在高效地处理数据\n  → ['这些', '运行', '中', '的', '算法', '正在', '高效', '地', '处理', '数据']\njp: これらの実行中のアルゴリズムは効率的にデータを処理しています\n  → ['これらの', '実行', '中の', 'アルゴリズム', '効率', '的', 'データ', '処理', 'し', 'てい', 'ます']\n\nSearch Test:\n\nzh '人工智能':\n  3.300: 人工智能正在改变世界各行各业\n\njp '機械学習':\n  3.649: 機械学習アルゴリズムは大量のデータセットを効率的に処理します\n\nen 'algorithm':\n  2.096: Machine learning algorithms process large datasets efficiently\n\nComplete\n"],"headingContent":"","anchorList":[{"label":"什麼是 Milvus Analyzer？","href":"What-is-Milvus-Analyzer","type":2,"isActive":false},{"label":"分析器類型","href":"Analyzer-Types","type":2,"isActive":false},{"label":"使用 Milvus 分析器進行實際編碼","href":"Hands-on-Coding-with-Milvus-Analyzer","type":2,"isActive":false},{"label":"結論","href":"Conclusion","type":2,"isActive":false}]}