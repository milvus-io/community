---
id: 2021-09-26-onnx.md
title: 使用 ONNX 處理模型
date: 2021-09-26T00:00:00.000Z
desc: 如何基於 ONNX 和 Milvus 使用多種模型進行圖像搜索
cover: assets.zilliz.com/medium_1_cfb009269a.png
tag: Engineering
canonicalUrl: >-
  https://zilliz.com/blog/combine-ai-models-for-image-search-using-onnx-and-milvus
---
<custom-h1>使用 ONNX 和 Milvus 結合圖片搜尋的 AI 模型</custom-h1><p>Open Neural Network Exchange (ONNX) 是一種開放格式，用來表示機器學習模型。自 2017 年開放原始碼以來，ONNX 已經發展成為 AI 的標準，提供機器學習和深度學習模型的建構塊。ONNX 定義了通用的檔案格式，讓 AI 開發人員能夠在各種框架、工具、運行時和編譯器中使用模型，並有助於提高人工智能社群的創新速度。</p>
<p>Milvus 是一個開放原始碼向量資料庫，具有高度彈性、可靠性和極快的速度。它支援向量的新增、刪除、更新與近乎即時的搜尋。Milvus 擁有一套完整的直覺式 API，並支援多種廣泛採用的索引函式庫 (例如 Faiss、NMSLIB 和 Annoy)，可簡化特定情境下的索引選擇。Milvus 簡單易用，已在全球數百個組織和機構中使用，包括圖片、音訊和視訊搜尋、推薦、聊天機器人、新藥搜尋等。</p>
<p>本文將介紹如何以 ONNX 與 Milvus 為基礎，使用多種模型進行圖像搜尋。它以 VGG16 和 ResNet50 模型為例，利用 ONNX 運行不同的 AI 模型來產生特徵向量，最後在 Milvus 中執行特徵向量檢索來返回相似的圖像。</p>
<h2 id="Process-Models-with-ONNX" class="common-anchor-header">使用 ONNX 處理模型<button data-href="#Process-Models-with-ONNX" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>ONNX 格式可以輕鬆地在 AI 模型之間交換。例如，TensorFlow 模型可以轉換為 ONNX 格式，並在 Caffe 環境中執行。在本範例中，我們將在 Keras 框架下預先訓練好的 ResNet50 模型轉換成 ONNX 格式，然後以 ONNX 格式來呼叫 VGG16 模型，以分析不同的模型。</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> keras.applications.resnet50 <span class="hljs-keyword">import</span> ResNet50
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># load keras-resnet50 model and save as a floder</span>
model_resnet50 = ResNet50(include_top=<span class="hljs-literal">False</span>, pooling=<span class="hljs-string">&#x27;max&#x27;</span>, weights=<span class="hljs-string">&#x27;imagenet&#x27;</span>)
tf.saved_model.save(model_resnet50, <span class="hljs-string">&quot;keras_resnet50_model&quot;</span>)

<span class="hljs-comment"># convert resnet50 model to onnx</span>
! python -m tf2onnx.convert --saved-model <span class="hljs-string">&quot;keras_resnet50_model&quot;</span> --output <span class="hljs-string">&quot;onnx_resnet50.onnx&quot;</span>
<button class="copy-code-btn"></button></code></pre>
<p>注意：當我們使用<code translate="no">keras2onnx.convert_keras(model, model.name)</code> 介面來轉換模型時，它會返回錯誤<code translate="no">AttributeError:'KerasTensor' object has no attribute'graph'</code> 。那麼我們可以使用 Python 的 Bash 指令，依照 Stack Overflow 上的解決方案進行轉換。</p>
<h2 id="Extract-Feature-Vectors-using-Models" class="common-anchor-header">使用模型擷取特徵向量<button data-href="#Extract-Feature-Vectors-using-Models" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>將 ResNet50 模型轉換成 ONNX 格式後，就可以直接透過推論來擷取圖片的特徵向量。注意：提取後需要對特徵向量進行規範化。</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># get the image vectors with onnx model</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_onnx_vectors</span>(<span class="hljs-params">onnx_model, img_path</span>):
    img = image.load_img(img_path, target_size=(<span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=<span class="hljs-number">0</span>)
    x = preprocess_input(x)
    
    sess = onnxruntime.InferenceSession(onnx_model)
    x = x <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(x, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">else</span> [x]
    feed = <span class="hljs-built_in">dict</span>([(<span class="hljs-built_in">input</span>.name, x[n]) <span class="hljs-keyword">for</span> n, <span class="hljs-built_in">input</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sess.get_inputs())])
    feat = sess.run(<span class="hljs-literal">None</span>, feed)[<span class="hljs-number">0</span>]
    
    norm_feat = feat[<span class="hljs-number">0</span>] / LA.norm(feat[<span class="hljs-number">0</span>])
    norm_feat = [i.item() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> norm_feat]
    <span class="hljs-keyword">return</span> norm_feat
<button class="copy-code-btn"></button></code></pre>
<p>使用 ONNX 格式的 VGG16 模型處理圖片資料：</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># generate vectors with ResNet50 and VGG16 ONNX model</span>
2vec_resnet = get_onnx_vectors(<span class="hljs-string">&quot;onnx_resnet50.onnx&quot;</span>, <span class="hljs-string">&quot;./pic/example.jpg&quot;</span>)
3vec_vgg = get_onnx_vectors(<span class="hljs-string">&quot;onnx_vgg16.onnx&quot;</span>, <span class="hljs-string">&quot;./pic/example.jpg&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Store-Vector-Data" class="common-anchor-header">儲存向量資料<button data-href="#Store-Vector-Data" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>圖片等非結構化資料無法直接由電腦處理，但可以透過 AI 模型轉換成向量，再由電腦進行分析。Milvus 向量資料庫是專為大量非結構化資料分析而設計。它可以儲存向量資料，並進行近乎即時的分析。首先，在 Milvus 中建立相應模型的集合，然後插入圖像向量。</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> milvus <span class="hljs-keyword">import</span> *

<span class="hljs-comment"># create collections in Milvus</span>
milvus.create_collection(resnet_collection_param)
milvus.create_collection(vgg_collection_param)

<span class="hljs-comment"># insert data to Milvus and return ids</span>
status, resnet_ids = milvus.insert(resnet_collection_name, resnet_vectors)
status, vgg_ids = milvus.insert(vgg_collection_name, vgg_vectors)
<button class="copy-code-btn"></button></code></pre>
<p>插入資料成功後，Milvus 會返回向量所對應的 ID，我們就可以依據 ID 來尋找圖片。由於此案例中使用的 Milvus 1.1 不支援標量篩選 (Milvus 2.0 現在已支援)，因此使用 Redis 來儲存向量 ID 和圖片路徑的 key-value。</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> redis
<span class="hljs-keyword">def</span> <span class="hljs-title function_">img_ids_to_redis</span>(<span class="hljs-params">img_directory, res_ids</span>):
  <span class="hljs-keyword">for</span> img, ids <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(images, res_ids):
    redis.<span class="hljs-built_in">set</span>(ids, img)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Search-for-Similar-Images" class="common-anchor-header">搜尋相似圖片<button data-href="#Search-for-Similar-Images" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>儲存資料之後，我們就可以擷取向量。Milvus 支援多種距離計算方法，包括歐氏距離、內積距離和漢明距離。本文的圖像相似性搜尋採用 Milvus 中向量間的 Euclidean 距離計算，回傳相似向量 ID，再在 Redis 中找出 ID 對應的圖像。</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># search in Milvus and return the similarly results with ids</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">search_in_milvus</span>(<span class="hljs-params">collection_name, search_vector</span>):
    status, results = milvus.search(collection_name, TOP_K, [search_vector])
    <span class="hljs-built_in">print</span>(status)
    re_ids = [x.<span class="hljs-built_in">id</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
    re_distance = [x.distance <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
    <span class="hljs-keyword">return</span> re_ids, re_distance
    
<span class="hljs-comment"># get the images according the result ids</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_sim_imgs</span>(<span class="hljs-params">collection_name, search_vector</span>):
    ids, distance = search_in_milvus(collection_name, search_vector)
    img = [red.get(i).decode(<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ids]
    <span class="hljs-keyword">return</span> ids, distance, img
<button class="copy-code-btn"></button></code></pre>
<p>本文以 VGG16 與 ResNet50 模型為例，說明透過 ONNX 處理多種模型，並結合多種模型與 Milvus 進行相似向量檢索，得到相似的圖像。以上兩個模型都是以 Keras 架構為基礎，可以快速抽取特徵向量。從 Notebook 可以看到，雖然 Milvus 根據這兩個模型在 COCO 資料集上搜尋圖片的結果很相似，但它們的歐氏距離卻不一樣。您也可以嘗試使用其他資料集比較兩個模型的搜尋結果。</p>
<p>Milvus 是一個高效能、高可用性的向量資料庫，可用於處理由大量非結構化資料所產生的特徵向量。如需更多解決方案，您可以參考<a href="https://github.com/milvus-io/bootcamp">Milvus bootcamp</a>。</p>
<h2 id="References" class="common-anchor-header">參考資料<button data-href="#References" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ol>
<li>https://github.com/onnx/onnx</li>
<li>https://onnx.ai/</li>
<li>https://milvus.io/cn/</li>
<li>https://github.com/milvus-io/bootcamp</li>
</ol>
<h3 id="About-author" class="common-anchor-header">關於作者</h3><p>陳詩雨，Zilliz 數據工程師，畢業於西安電科大學計算機專業。自加入 Zilliz 以來，她一直在探索 Milvus 在各個領域的解決方案，例如音視頻分析、分子式檢索等，大大豐富了社區的應用情境。目前，她正在探索更多有趣的解決方案。業餘時間，她喜歡運動和閱讀。</p>
